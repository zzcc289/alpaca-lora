[
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nLeonardo Chiariglione\n1996-01-23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11* ** *N1128*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG 95/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1995"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Leonardo Chiariglione - Convenor*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Thirty-fourth WG11 meeting notice"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 34th WG11 meeting will be held in Florence, Italy at the kind\ninvitation of UNINFO, the Italian National Body, on 96/03/25-29 at"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCentro Affari Firenze"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPiazza Adua, 1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFlorence (Italy)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTel. + 39 55 277 31"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFax + 39 55 2773 433"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnexes 1 to 3 contain the proposed agenda, the registration form and\nthe logistic information, respectively."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPlease note that because of other international events during that\nperiod of time, a very early hotel reservation (say, by *31 January\n1996*) is advisable."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo reserve your room you may like to contact"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhttp://www.venere.it/img_italy/italy_reg.conf?180,190"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(the meeting place is in the part of Florence marked with a II in the\nmap)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAlternatively you may like to use the services of the travel agent of\nannex 3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThose intending to submit contributions to the meeting are advised to\nbase their actions on Annex 4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 1_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Agenda*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"9%,91%\",]\n|===\n|1. |Opening\n| |\n|2. |Roll call of participants\n| |\n|3. |Approval of agenda\n| |\n|4. |Allocation of contributions\n| |\n|5. |Communications from Convenor\n| |\n|6. |Report of previous meeting\n| |\n|7. |Processing of NB Position Papers\n| |\n|8. |MPEG Phase 2\n|8.1 |Video\n|8.2 |Audio\n|8.3 |Verification of MPEG-2\n|8.3.1 |Video Quality\n|8.3.2 |Audio Quality\n|8.4 |Amendments\n|8.5 |Corrigenda\n|8.6 |Part 4 (Conformance)\n| |\n|8.7 |Part 5 (Software)\n|8.8 |Part 6 (DSM-CC)\n|8.9 |Part 7 (NBC Audio)\n|8.10 |Part 9 (RTI)\n|8.11 |Part 10 (DSM-CC Conformance)\n|8.12 |Multi-view profile\n|8.13 |Workplan\n| |\n|9. |MPEG Phase 4\n|9.1 |Applications and Requirements\n|9.2 |Syntax\n|9.3 |Tools\n|9.3.1 |Audio\n|9.3.2 |Video\n|9.3.3 |Synthetic/Natural Hybrid\n|9.4 |Call for proposals\n|9.5 |Tests\n|9.6 |Verification Models\n|9.7 |Workplan\n| |\n|10. |Overall WG11 workplan\n| |\n|11. |Liaison matters\n| |\n|12. |Administrative matters\n|12.1 |Schedule of future MPEG meetings\n|12.2 |MPEG document management\n| |\n|13. |Organisation of this meeting\n|13.1 |Tasks for subgroups\n|13.2 |Finalisation of meeting allocation\n| |\n|14. |Planning of future activities\n| |\n|15. |Resolutions of this meeting\n| |\n|16. |A.O.B\n| |\n|17. |Closing\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 2_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Thirty-fourth ISO/IEC JTC1/SC29/WG11 meeting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Florence, Italy, 96/03/25-29)_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Registration form*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPlease send this form to"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"43%,12%,45%\",]\n|===\n|Dr. Leonardo Chiariglione |Tel: |+39 11 228 6120/6116/5111"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Convenor WG11 |Fax: |+39 11 228 6299/6190/5520"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Multimedia and Video Services |Email:\n|leonardo.chiariglione@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|CSELT | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Via G. Reiss Romoli, 274 | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|I-10148 Torino | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|ITALY | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nYour name:_______________________________________________________"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAffiliation:_______________________________________________________(do\nnot"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAddress:________________________________________________________write if"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_______________________________________________________________unchanged)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTelephone:______________________________________________________(do not"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFacsimile________________________________________________________write\nif"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nE_mail:_________________________________________________________unchanged)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(do not write if your data are unchanged but be sure that you are known\nto the Convenor)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nI intend to participate in the WG11 meeting mentioned above: [ y ] [ n ]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(please circle the one which applies)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nI intend to participate in the following subgroup meetings (please\ncircle those of your interest)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"19%,14%,14%,11%,16%,12%,14%\",]\n|===\n|INTEGR |VIDEO |AUDIO |TEST |IMPLEM |SYST |DSM\n|Requirem. |4:2:2 |NBC |Audio | | |DSM-CC\n|MSDL |MVP |MPEG-4 |Video | | |DSM-RSF\n|SNHC-V |MPEG-4 | | | | |\n|SNHC-A | | | | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 3_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Logistic information*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUNINFO, the Italian Association of Standardization in Information\nTechnology, is very pleased to host the 34th Meeting of ISO/IEC JTC 1/SC\n29/WG 11 MPEG in Florence from 25 to 29 March 1996."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MEETING LOCATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCentro Affari Firenze"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPiazza Adua, 1 Florence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTel. + 39 55 2773437"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFax + 39 55 2773433"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Centro Affari is in the heart of the city, it is only ten minutes\nwalking distance from Piazza Duomo and it is right across the street\nfrom S. Maria Novella Train Station."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA meeting fee will be requested to cover meeting expenses, including the\ncost of lunches and coffee breaks. A preregistration form is attached."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDue to other international events during that period of time, a well\nadvanced hotel reservation (by *31 January 1996*) is advisable. We also\ninclude the form of the travel agency in charge of this."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*REGISTRATION CONDITIONS*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPre-registration form must be sent to UNINFO with the indication of the\nappropriate payment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo form will be handled without the appropriate payment indication."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe hotel accommodation form must be sent to Newtours travel agency."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*PRE-REGISTRATION FORM*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG Meeting, Florence, 25-29 March 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFirst name Last (Family) name"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAddress"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCity\n............................................................................................."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCountry Postal Code"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTelephone Fax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nE-mail"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"27%,13%,20%,20%,20%\",]\n|===\n|FEES | |with lunch |without lunch |\n| | | | |\n|Full session (5 days) | | | |\n| |Prepaid |Lit. 700.000 |Lit. 500.000 |\n| |On-site |Lit. 750.000 |Lit. 550.000 |\n| | | | |\n|Single days : | | | |\n|( Mon ( Tues ( Wed |Prepaid |Lit. 150.000 |Lit. 120.000 |\n|( Thurs ( Frid |On-site |Lit. 160.000 |Lit. 110.000 |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Payment Method*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* *Prepaid (before 28 February 1996)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Cheque or money order, made payable to UNINFO in Italian Lire and\ndrawn on at the following italian bank:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIstituto Bancario San Paolo di Torino - Agenzia N. 1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCorso Re Umberto, 53 - 10128 Torino - Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAccount N: 11459 registered to UNINFO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSort Code: 1025 1001"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* *On-Site*\n* Payment at the meeting site."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncash or by credit card: DINERS, VISA, MASTER CARD, EUROCARD (American\nExpress card and cheque are not accepted)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPlease, send by fax the completed form as soon as possible, in any case\n*not later than 15 March 1996.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mail completed form with pre-payment by 28 February, 1996, to:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUNINFO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCorso Galileo Ferraris, 93"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n10128 TORINO - ITALY"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nor FAX to UNINFO at + 39 11 501837"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nE-mail: uninfo@polito.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*HOTEL ACCOMMODATION FORM*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*UNINFO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG Meeting, Florence, 25-29 March 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Deadline: 31 January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPlease type or print in capital letters and return by airmail to:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNEWTOURS S.r.l."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nc/o Mr. Andrea Redditi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVia San Donato, 20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nI -50127 Firenze Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPhone + 39.55.33611"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFax + 39.55.3361350"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFamily\nName.....................................................Name.................................................."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of\nInstitution......................................................................................................"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPostal Code and\nCity.........................................Country.............................................."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPhone................................................................Fax......................................................"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAccomodation (in Italian Lire):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll requests must be accompanied by a deposit, as specified in the table\nbelow + 20.000 Lire for agent fees and mailed directly to NewTours:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"25%,25%,25%,25%\",]\n|===\n|Hotel |Single |Double |Double single use\n| |Min/Max |Min/Max |Min/Max\n| | | |\n|**** |210.000/250.000 |290.000/330.000 |240.000/302.000\n|*** |130.000/170.000 |185.000/250.000 |160.000/240.000\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe indicated rates, in Italian Lire, are valid for the year 1996 and\ninclude one overnight stay, continental breakfast, taxes, V.A.T."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe first night deposit (Min. rate) must be mailed to Newtours within 31\nJanuary 1996."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPlease book:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNr..... Single room/s or double for single use Nr....... Double room/s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHotel**** Hotel ***"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nArrival date..........................................Departure\ndate.............................................."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1st night deposit Lit.............................x Nr.......room/s\nLit..............................."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*PAYMENT*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAgent Fees Lit. 20.000 x Nr...........Room/s\nLit....................................."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTotal Hotel Reservation Deposit Lit....................................."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMethod of Payment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPayments in Italian Liras should be made in favour of Newtours s.r.l. as\nfollowing:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Cheque made out to Newtours s.r.l.\n* Bank Transfer to Newtours s.r.l."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCassa di Risparmio di Firenze - Agency 8"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAccount number 6608/00 - CAB 02808 - ABI 6160"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVia Il Prato, 2 -50144 Florence Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Charge to Credit Card (please indicate number and expiration date)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAmerican Express Visa"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiners Club Eurocard (Master card)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName (as shown on the card)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n............................................................................................................................."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCard Number...................................................Expiration\ndate.............................."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*PRACTICAL INFORMATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nYou could arrive by plane at the Florence or Pisa airport."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBoth airports can be reach by bus and by train"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Bus from town to Florence Airport*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Autostazione SITA - Via Santa Caterina da Siena corner Piazza Stazione\n- Journey Time 15\u2019\n* Bus line ATAF n\u00b0 62"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Train services to and from Pisa Airport*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Florence-Pisa - Platform n\u00b0 5_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTrain departure from Santa Maria Novella Railway Station:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n7.54 a.m., 10.05 a.m., 11.05 a.m., 12.20 p.m., 1.05 p.m., 2.05 p.m.,\n3.05 p.m., 4.05 p.m., 5.05 p.m. - Journey time : 60\u2019"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Pisa-Florence_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTrain departure from Galileo Galilei Airport"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n10.44 a.m., 11.44 a.m., 12.44 a.m., 1.44 p.m., 2.44 p.m., 3.41 p.m.,\n4.44 p.m., 5.44 p.m., 11.50 p.m."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Car Rental*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFollowing some agency where you can rent a car in Florence:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(approximately Lit, 170.000/day, Lit. 800.000/week)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Avis*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBorgognissanti 128 r"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTel. 213629"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Europcar*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBorgognissanti 53 r"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTel. 2360072/3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHertz"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVia Finiguerra, 33 r"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTel. 282260-2398205"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Italy by car*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBorgognissanti 134 r"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTel. 293021 -287161"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Maggiore*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVia Finiguerra 31r"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTel . 210238-294578"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Bus in Florence/Tickets*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n60 minuti ticket Lit. 1400"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMultiple ticket Lit. 5400"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n120 minuti ticket Lit. 1900"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n24 Hours ticket Lit. 5000"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOne or more runs, starting from the moment the ticket is punched, can be\nmade, as long as they are within the same time limit. The ticket is\nvalid for part or all of the journey of one or more lines. Must be\npunched only at the beginning of first run."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Banks*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe banks offering foreign currencies exchange are all situated in the\nCentre of Florence."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOffice hours: 8.30 a.m to 1.30 p.m - 3 p.m to 4.p.m"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*List of restaurants near the main hotel/meeting place*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformations will be given directly in Florence."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Sightseeing, cultural opportunities*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe program will be prepared later."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Shopping*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformations will be given directly in Florence."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Climate*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the end of March, temperatures in Florence usually vary between 10 \u00b0C\nand 20\u00b0C."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Further informations on Florence are available at the following web\nsite:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhttp://www.venere.it/img_italy/italy_reg.conf?180,190"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n**********************************************"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 4_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG document handling*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSee WG11N1139"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANIZATION FOR STANDARDIZATION\nPeter Schirling\n1996-01-31"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11N1129*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,85%\",]\n|===\n|Source: |Leonardo Chiariglione - Convenor\n|Title: |List of documents (1128-1184)\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"10%,9%,17%,64%\",]\n|===\n|No. |Date |Source |Title"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1128 |95/12 |NB of Italy |Invitation to the 34th Meeting in Firenze\nItaly"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1129 |96/01 |Convenor |List of Documents from Munich"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1130 |96/01 |Convenor |Resolutions of the Munich meeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1131 |96/01 |Convenor |Report of the 33rd meeting in Munich, Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1132 |96/01 |Audio |MPEG-2 NBC Audio RM3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1133 |96/01 |Convenor |Ad-hoc group on MPEG-2 Multi-view Profile"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1134 |96/01 |Video & Test |MPEG-2 4:2:2 Profile at Main Level\nsubjective Assessment Report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1135 |96/01 |Audio |NBC Reference Model 2 Core Experiments Subjecive\nTests: Overall Results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1136 |96/01 |Audio |MPEG-4 - 64Kbps Audio CODEC Subjective Tests:\nOverall Results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1137 |96/01 |Audio |Bibliography of Audio subgroup Documents"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1138 |96/01 |Audio |A Decscription of the EXCEL5 Spreadsheet used for\nthe Audio NBC Test results analysis"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1139 |96/01 |Convenor |Guidelines for WG11 document registration\nfacility"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1140 |96/01 |Test |Results of MPEG-2 MP@HL (H-14) Video Verification\nTest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1141 |96/01 |DSM |Liaison Letter to ITU-T SG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1142 |96/01 |Convenor |Ad-hoc Group on Test Methodology for Formal NBC\nTest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1143 |96/01 |Audio |Preliminary Draft of MPEG-4 Audio VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1144 |96/01 |Audio |MPEG-4 Audio Test Result (MOS)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1145 |96/01 |Convenor |Ad-hoc Group MPEG-2 NBC RM3 Audio Test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1146 |96/01 |Convenor |Ad-hoc Group on MPEG-4 VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1147 |96/01 |Convenor |Ad-hoc Group on RM3 Specification and WD"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1148 |96/01 |Convenor |Ad-hoc Group on Revisions of IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1149 |96/01 |Convenor |Ad-hoc Group on SNHC Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1150 |96/01 |Audio |MPEG-2 NBC RM Audio Test Plan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1151 |96/01 |Audio |Preliminary MPEG-2 Audio NBC WD"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1152 |96/01 |Audio |Draft Revisions to IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1153 |96/01 |Convenor |Ad-hoc Group on Core Experiments on Coding\nEfficiency for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1154 |96/01 |Convenor |Ad-hoc Group on Core Experiments on Object\nScalability for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1155 |96/01 |Convenor |Ad-hoc Group on Core Experiments on Error\nResilience Aspects for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1156 |96/01 |Convenor |Ad-hoc Group on Core Experiments on\nMulti-functional Coding for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1157 |96/01 |Convenor |Ad-hoc Group on Software Development of the\nVideo VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1158 |96/01 |Convenor |DoC on AMD/2 13818-2 (4:2:2 Profile)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1159 |96/01 |Video |AMD/2 ITU-T H.262 \\| ISO/IEC 13818-2 Final Text"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1160 |96/01 |Convenor |Ad-hoc Group on Synthetic/Natural Hybrid Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1161 |96/01 |Convenor |Ad-hoc Group on MPEG-4 Video Verification Model\nDocument Editing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1162 |96/01 |Video |Report on the Evaluation of Tools and Algorithms of\nVideo Submissions for MPEG-4 in January 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1163 |96/01 |HoD |Response to National Body Contributions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1164 |96/01 |MSDL |MSDL WD Version 1.0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1165 |96/01 |Convenor |Ad-Hoc Group on Syntactic Description Language"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1166 |96/01 |Convenor |Ad-hoc Group on Requirements for MPEG-4 Virtual\nMachine"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1167 |96/01 |Convenor |Ad-hoc Group on MSDL Architecure and Objects\nHierarchy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1168 |96/01 |MSDL/Audio |NBC Audio Syntax Description with MSDL"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1169 |96/01 |ISG |Methodology used for assessment of implementation\ncost and performance for proposals incorporated into the Verification\nModels of MPEG-4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1170 |96/01 |Convenor |Ad-hoc Group on Defining the Framework of\nImplementation Complexity Analysis when Performing Core Experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1171 |96/01 |Convenor |Ad-hoc Group on Defining and Implementing\nInstrumentation Tools for Embedding within VMs.96/1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1172 |96/01 |Video |MPEG-4 Video Verification Model - Version 1.0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1173 |96/10 |Liaison |Liaison Statement to ITU-T SG15-WP2/15"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1174 |96/10 |Liaison |Liaison Statement to ITU-R SG11, TG11/3 and SG10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1175 |96/01 |SNHC |Advance Notice of Call for Proposals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1176 |96/01 |Convenor |Integrated MPEG Workplan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1177 |96/01 |Convenor |MPEG-4 Project Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1178 |96/01 |Video |Informative Annex for 4:2:2 Profile"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1179 |96/01 |Audio |Requirements for Submission of Technical Proposals\nto MPEG Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1180 |96/01 |Convenor |Ad-hoc Group on Review and Clarfiy the DSM CC\nDIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1181 |96/01 |DSM |Investigate Low Bandwidth"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1182 |96/01 |Convenor |Ad-hoc Group on DSM Verification (DSM RSF)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1183 |96/01 |DSM |Clarification on DSM CC DIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1184 |96/01 |DSM |DSM RSF WD\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\n**********\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11N1130*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,80%\",]\n|===\n|Source: |Leonardo Chiariglione - Convenor\n|Title: |Resolutions of 33rd WG11 meeting\n|Status: |Approved at 33rd meeting\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *WG11 approves the reports from the Integration, Video, Audio, Test, Implementation, DSM and HoD.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Subgroup recommendations"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *The Integration group recommends*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== The Advance Notice of the Call for Proposals for MPEG4 Synthetic-Natural Hybrid Coding (WG11 N1175)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== The MSDL Working Draft, ver. 1.0 (WG11 N1164)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== The Description of NBC Audio syntax with MSDL (WG11 N1168)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== The MPEG4 Project Description (WG11 N1177)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== The holding of an additional meeting in Sept 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== The establishment of the following ad hoc groups:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Joint Audio/Video/Integration ad hoc group on Syntax Decription Language (WG11 N1165)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Ad hoc group on requirements for an MSDL Virtual Machine (WG11 N1166)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Ad hoc group on MSDL Architecture and Object Hierarchy (WG11 N1167)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Ad hoc group on Synthetic/Natural Hybrid Coding WG11 N1160)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== The Video group recommends"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== the approval of the \u201eReport on MPEG-2 4:2:2-Profile @ Main Level subjective assessments\u201c (WG11 N1134)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== the approval of the \u201eDisposition of Comments of national bodies on the Draft Ammendment on the 4:2:2-Profile\u201c (WG11 N1158)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== the promotion of document (WG11 N1159) on the 4:2:2- Profile to Ammendment 2 of ISO/IEC IS 13818-2."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== to establish an ad-hoc group on \u201eMPEG-2 Multi-view Profile (WG11 N1133)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== the approval of WG11 N1162 on \u201eReport on the evaluation of tools and algorithms of video submissions for MPEG-4 in January 1996\u201c."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== to establish an ad-hoc group on \u201eCore experiments on coding efficiency in MPEG-4 video\u201c (Prediction, Frame texture coding, quantiser and bit-rate control)\u201c (WG11 N1153)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== to establish an ad-hoc group on \u201eCore experiments on content-based coding and access in MPEG-4 video\u201c (Shape and Alpha channel coding, Object/Region texture coding) (WG11 N1154)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *to establish an ad-hoc group on \u201eCore experiments on error resilience aspects in MPEG-4 video\u201c (WG11 N1155).*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *to establish an ad-hoc group on \u201eCore experiments on multifunctional coding aspects in MPEG-4 video\u201c (spatio-temporal scalability, multi-view and model manipulation, pre-, mid- and post-processing) (WG11 N1156).*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *the approval (WG11 N1172) as the first \u201eMPEG-4 video verification model\u201c*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== to establish an ad-hoc group for \u201eMPEG-4 Video Verification Model Document Editing\u201c as described in (WG11 N1161)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== the approval of the response to national body contributions on MPEG-4 video (WG11 N1163)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *the organisation of an MPEG meeting in September 1996.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Ad-hoc Group on Software Development of the Video VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== The Audio group recommends"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the test results for MPEG-2 NBC given in WG11/N1135 be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the test results for MPEG-4 at 64 kb/s given in WG11/N1136 be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the definition and technical description of MPEG-2 NBC RM3 given in WG11/N1132 be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the proposals and time line for the NBC RM3 tests to be completed before March 1996 given in WG11/N1150 be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the preliminary Working Draft for MPEG-2 NBC given in WG11/N1151 be referred to the ad-hoc group for review by March 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the test results for MPEG-4 MOS tests given in WG11/N1144 be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the preliminary VM for MPEG-4 Audio given in WG11/N1143 be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the Advance Notice of Call for Proposals for MPEG-4 SNHC (WG11 N1175) be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the description of NBC Audio syntax with MSDL given in WG11/N1168 be approved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the draft revisions to IS 13818-3 given in WG11/N1152 be referred to the ad-hoc group for review by March 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that MPEG Audio should make available to ITU-R all relevant audio test results to help the ITU-R in their considerations of bit rate reduction applied to broadcast audio systems."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the content of all future technical descriptions for codecs/tools etc. are required to conform to the outlines given in WG11 N1179"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the proponent of MPEG-4 Audio proposals for the VM provide technical descriptions of their proposals in line with WG11 N1179 by February 23 to the Chair of the ad-hoc group on Audio VM (WG11 N1146)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the bibliography of MPEG Audio documentation given in WG11/N1137 be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the description of the data analysis package for audio results processing and spreadsheet proforma given in WG11/N1138 be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the work of the ad-hoc groups on conformance and technical report as mandated at the Dallas meeting in documents WG11/N1044 & 1049 be extended to the March 1996 meeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the following ad-hoc groups be established"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Ad Hoc Group on MPEG-2 NBC RM3 Audio test, N1145 - Schreiner"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Ad-Hoc Group on MPEG-4 VM, N1146 - Edler"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Ad Hoc Group on RM3 specification and WD, N/1147 - Bosi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Ad Hoc Group on revisions of 13818-3, N/1148 - Stoll"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Ad Hoc Group on SNHC Audio, N/1149 - Kaneko"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== The Test group recommends"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the document \u2018MPEG-2 4:2:2 Profile at Main Level Subjective Assessment Report\u201d (WG11 N1134) be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the document \u2018Results of MPEG-2 MP@HL (H-14) video verification test\u201d (WG11 N1140) be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the document \u2018MPEG4 audio test results (MOS)\u201d (WG11 N1144) be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the document \u2018NBC RM2 core experiment subjective test: overall results\u201d (WG11 N1135) be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the document \u2018MPEG4 64 kbit/s audio codec subjective test: overall results\u201d (WG11 N1136) be approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== that the ad-hoc group on test methodology for formal NBC test, (WG11 N 1142) be established."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== The Implementation Studies group recommends"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== The proposed metrics gathering solution that ISG intends to make available for use in performing VM core experiments relies on the availability of an ANSI C definition. As such the ISG reaffirms even more strongly its request that verification models be made available in ANSI C format."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Levels and profiles of MPEG-4 be defined such that they take into account :-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* *Power consumption*\n* Thermal environment\n* Data Storage capacity\n* Communications channel bandwidth."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Encoders consider adding a computational complexity when deciding the\ncompression factor to be applied to the data. Suggest that consideration\nbe given to :-*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* *Defining decoder profiles within which a number of decoders could\noperate within. E.g. decoders capable of 1GOP, decoders with nMBytes of\nDRAM etc. ...*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Adoption of the Methodology used for assessment of implementation cost\nand performance for proposals incorporated into the Verfification Models\nof MPEG-4 (WG11 N1169) as a basis for the ad-hoc group proposed in WG11\nN1170).*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== The establishement of the following ad-hoc groups"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== ad-hoc group defining framework of implementation complexity analysis when performing core experiments (WG11 N1170)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== ad-hoc group on defining and implementing instrumentation tools for embedding within VM\u2019s (WG11 N1171)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== The DSM group recommends"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Approve the document \u2018Clarifications on the DSM-CC DIS\u2019 (WG11 N1183)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Approve the document \u2018DSM-RSF Working Draft\u2019 (WG11 N1184)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Approve the Liaison letter to ITU-T SG11 (WG11 N1185)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Recommend that the responsibiliy for DSM-RSF will be taken up by the DSM-CC group."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Establish the following ad-hoc groups:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Ad Hoc Group to Review and Clarify the DSM-CC DIS (WG11 N1180)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Ad Hoc Group to Investigate Low Bandwidth Data Representations for DSM-CC (WG11 N1181)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Establish an Ad Hoc Group for DSM Verification (DSM-RSF, WG11 N1182)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== The HoD group recommends"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== The appointment of Messrs. Tim Addington and Don Hooper as editors of 13818-6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *WG11 approves the Disposition of Comments to ISO/IEC DIS 13818-2 DAM 2 (WG11 N1158) and the final text of ISO/IEC IS 13818-2 AMD 2 (WG11 N1159) and requests the Convenor to forward the documents to the SC29 Secretariat for further processing.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== WG11 approves the MPEG-2 Audio NBC RM 3 (WG11 N1132)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== WG11 approves the MPEG-2 workplan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"14%,52%,8%,9%,9%,8%\",]\n|===\n|Part |Title |WD |CD PDAM PDTR |DIS DAM DTR DCOR |IS AMD TR COR\n|2/Amd 2 |4:2:2 profile | | | |96/01\n|2/Amd 3 |Multiview profile | |95/11 |96/03 |96/11\n|2/Cor 1 |Technical Corrigendum 1 | | | |95/11\n|2/Cor 2 |Technical Corrigendum 2 | | |95/11 |96/03\n|4 |Conformance testing | | | |96/03\n|5 |Software simulation | | | |96/03\n|6 |Systems extensions - DSM-CC | | |95/11 |96/07\n|7 |Audio extensions - NBC mode |96/03 |96/07 |96/11 |97/03\n|8 |VOID (withdrawn) | | | |\n|9 |Systems extensions - RTI | | |95/11 |96/03\n|10 |Conformance extensions - DSM-CC |96/03 |96/07 |96/11 |97/03\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *WG11, considering its category C liaison with DAVIC and their Call for Proposals No. 4 in the area of high quality audio and scalable information representation, requests that the Convenor transmit the NBC Audio RM3 (WG11 N1132) and the MPEG-4 Video VM 1 (WG11 N1172) to DAVIC for their information.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== WG11 approves"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"14%,67%,19%\",]\n|===\n| |MPEG-4 Video VM |(WG11 N1172)\n| |MPEG-4 Audio VM |(WG11 N1143)\n| |SNHC Advance Notice of Call for Proposals |(WG11 N1175)\n| |MSDL V. 1.0 |(WG11 N1164)\n| |MPEG-4 project description |(WG11 N1177)\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *WG11 approves the detailed MPEG-4 workplan*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"9%,9%,82%\",]\n|===\n|Mtg |Date |Result"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|33rd |01/96 |Evaluation of new proposals for tools and algorithms by\npanel of experts Test results and preliminary evaluation (audio).\nAdvance notice of SNHC call for proposals. Definition of first set of\ncore experiments. MSDL WD 1.0. VMs established, considering all\nproposals, following defined procedure. Begin SNHC test data set\nconstruction."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|34th |03/96 |Results of first set of core experiments. VMs updated.\nDefine second set of core experiments. MSDL WD 1.1. MSDL for NBC (audio)\nfinalized. SNHC call for proposals SNHC experiment design. Complete SNHC\ntest data set."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |06/96 |SNHC proposals received."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|35th |07/96 |Results of second set of core experiments. VMs updated.\nDefine third set of core experiments. MSDL WD 1.2. SNHC proposal\nevaluations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|36th |11/96 |Call for proposals for 7/97 for new tools and new complete\nalgorithms. First draft of Test Procedures Document MPEG-4 WD-1\ncontaining Audio WD Video WD MSDL WD 2.0. SNHC WD 1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|37th |03/97 |Final version of Test Procedures Document. MPEG-4 WD-2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|38th |07/97 |MPEG-4 WD-3 Validation of new proposals and existing VMs\nby complete formal tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|39th |11/97 |MPEG-4 CD approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|40th |03/98 |Clarification of MPEG-4 CD"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|41st |07/98 |MPEG-4 DIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|42nd |11/98 |MPEG-4 IS\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *WG11 approves its integrated workplan (WG11 N01176)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== WG11 approves the response to the National Bodies of France and Japan (WG11 N1163)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== WG11 approves its five-year meeting schedule"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLegend:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"12%,27%,8%,15%,8%,13%,7%,10%\",]\n|===\n|O: |Integration |V: |Video |A: |Audio |T: |Test\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"13%,7%,8%,11%,14%,12%,5%,5%,5%,5%,5%,5%,5%\",]\n|===\n|No. |YY |MM |DD |City |Country |O |V |A |T |I |S |D\n|32 |95 |11 |06-10 |Dallas |US |X |X |X |X |X |X |X\n|33 |96 |01 |22-24 |Munich |DE |X |X |X |X |X | |X\n|34 |96 |03 |25-29 |Florence |IT |X |X |X |X |X |X |X\n|35 |96 |07 |08-12 |Tampere |FI |X |X |X |X |X |X |X\n|36 |96 |09 | | | | | | | | | |\n|37 |96 |11 | | | | | | | | | |\n|38 |97 |03 | | | | | | | | | |\n|39 |97 |07 |(07-11) |Stockholm |SE |X |X |X |X |X |X |X\n|40 |97 |10 |27-31 |Fribourg |CH |X |X |X |X |X |X |X\n|41 |98 |03 | | | | | | | | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *The Convenor would like to express his thanks to Peter Schirling for his support in the preparation of all documents for the Wednesday Plenary.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== WG11 thanks Siemens AG for hosting the 33rd MPEG meeting and the following individuals for their support of this meeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"16%,84%\",]\n|===\n| |Dr. Bernard Hammer\n| |Mr. Fritz Seytter\n| |Dr. Peter Glei(l\n| |Mr. Norbert \u00d6rtel\n| |Ms. Reisert\n| |Mr. Baumgartl\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWG11 adjourned on 96/01/24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Ad-hoc groups established at Berlin*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1133"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"19%,81%\",]\n|===\n|Title: |Establishment of ad hoc group on MPEG-2 Multi-view Profile\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate*:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* to start exchanging bitstreams,\n* to continue organizing the framework/plan for verification testing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair*: Ajay Luthra (aluthra@gi.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1142"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title* : ** Ad-hoc group on test methodology for formal NBC test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To review the test methods reported in WG11/N0685 and to\ndefine procedures for future formal NBC audio test."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChairman: H. Suzuki JVC suzukihr@krhm.jvc-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1145"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Ad-Hoc Group to Conduct the of MPEG-2 Audio NBC Reference Model\n3 Core Experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To conduct the of NBC RM3 (WG11/N1132) core experiment\nmonophonic and stereophonic listening tests according to (N1150), to\nperform the analysis of the test results, and to prepare the report of\nthe results for the March 1996 MPEG meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* P.G. Schreiner III"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1146"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* *Ad Hoc Group on MPEG-4 Verification Models*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMandate: To continue the evaluation of the results of the MPEG-4 audio\nproposal tests, the evaluation of the proposal technical descriptions,\nand the development of the detailed VMs. This task includes the\ncollection of more detailed technical descriptions for nine of the\nproposals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* B. Edler"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1147"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,85%\",]\n|===\n|Title: |Ad-hoc group on MPEG-2 Audio NBC (13818-7) Reference Model 3\n(RM3) Specification and Working Draft Development"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"22%,78%\",]\n|===\n|Mandate: |To progress the work on the preparation of the first Working\nDraft for MPEG-2 NBC (13818-7) Audio Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chair |Marina Bosi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Vice-Chair |Martin Dietz\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1148"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* *Ad Hoc Group on finalising* *revisions to IS 13818-3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMandate:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* To review editorial changes to IS 13818-3 contained in WG11/N1152\n* To ensure that details relating to the use of prediction with\ndynamic\u00a0crosstalk, and LFE syntax are correctly assimilated\n* To prepare and approve an informative Annex which provides information\nhow to use MPEG-2 BC multichannel coding or the MPEG-2 NBC mode together\nwith 2-channel Layer II, e.g. simulcast.\n* To present to the March 1996 meeting of MPEG a final version of the\nrevised IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* G. Stoll (E-Mail: stoll@irt.de)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1149"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title: Adhoc Group on the SNHC/Audio*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMandate: To disseminate SNHC Notice of a Call for Proposal (CFP), to\ngenerate the interest for contributions to the first CFP and to\nco-ordinate discussion about the first experiments among the experts.\nJoint with SNHC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman: I. Kaneko*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1153"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on core experiments on efficient\ncoding in MPEG-4 video* (Prediction, Frame texture coding, quantiser and\nbit-rate control)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* 1) To collect core experiments description __(deadline : 2nd\nweek after the 33rd MPEG meeting)__2) Editing a document with all core\nexperiments __(deadline : 3rd week after the 33rd MPEG meeting)__3)\nDistribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n__ 4) Development of evaluation criteria for results of core\nexperiments5) Coordination of common conditions for appropriate core\nexperiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair:* John Muller (jmuller@iterated.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1154"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on core experiments on\ncontent-based coding and access* *in MPEG-4 video* (Shape and Alpha\nchannel coding, Object/Region texture coding)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* 1) To collect core experiments description __(deadline : 2nd\nweek after the 33rd MPEG meeting)__2) Editing a document with all core\nexperiments __(deadline : 3rd week after the 33rd MPEG meeting)__3)\nDistribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n__ 4) Development of evaluation criteria for results of core\nexperiments5) Coordination of common conditions for appropriate core\nexperiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair:* Touradj Ebrahimi (ebrahimi@epfl.ch)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIbrahim Sezan (co-chair ; sezani@sharpsla.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1155"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on core experiments on error\nresilience aspects in MPEG-4 video*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMandate: 1) To collect core experiments description __(deadline : 2nd\nweek after the 33rd MPEG meeting)__2) Editing a document with all core\nexperiments __(deadline : 3rd week after the 33rd MPEG meeting)__3)\nDistribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n__ 4) Development of evaluation criteria for results of core\nexperiments5) Coordination of common conditions for appropriate core\nexperiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair:* James Brailean (brailean@areaplg2.corp.mot.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1156"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on core experiments on\nmultifunctional coding aspects in MPEG-4 video* (spatio-temporal\nscalability, multi-view and model manipulation, pre-, mid- and post-\nprocessing)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* 1) To collect core experiments description __(deadline : 2nd\nweek after the 33rd MPEG meeting)__2) Editing a document with all core\nexperiments __(deadline : 3rd week after the 33rd MPEG meeting)__3)\nDistribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n__ 4) Development of evaluation criteria for results of core\nexperiments5) Coordination of common conditions for appropriate core\nexperiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair:* Atul Puri (ap@big.att.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1157"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle Ad-hoc group for the software development of the Video VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMandate Prepare the development of software for video verification"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChair Henri Sanson"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1160"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title: Ad Hoc Group on Synthetic/Natural Hybrid Coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. Solicit community expertise and participation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. Complete final Call for Proposals with PPD."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. Develop Virtual Playground and Test Data Set."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4. Develop Media Model proposal evaluation criteria."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman: Peter K. Doenges, Evans & Sutherland*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1161"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on MPEG-4 Video Verification\nModel Document Editing*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To maintain a consistent version of the verification model\n(VM) document through"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- coordination of the definition of the VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- continuing Editing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair:* Touradj Ebrahimi (ebrahimi@epfl.ch)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1165"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Ad Hoc Group on Syntactic Description Language"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate: Complete MSDL Part 5 and related Annex*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* {empty}1. Collect and complete requirements from Audio/Video/SNHC\nexperts\n* 2 Complete and check the formal rules\n* 3 Describe Audio/Video/SNHC syntax with these rules"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* MSDL : Alexandros Eleftheriadis (Columbia University)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCo-chairs: AUDIO : James Johnston (AT&T)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVIDEO : Georges Campbell (Compression Lab. Inc)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1166"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Ad Hoc Group on requirements for a possible MPEG-4 virtual\nmachine"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n**Mandate: Document virtual machine aspects in MPEG-**4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* {empty}1. Analyse work in this area\n* 2 Analyse real time aspects (including synchronisation)\n* 3 Analyse possible architecture\n* 4 Issue requirements and recommandations on the topic"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* Jean-Claude Dufourd (ENST)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1167"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* MSDL Architecture and Objects Hierarchy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate: Complete Part1 and Part2 of the WD and related annex.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* {empty}1. Collect and complete requirements from Audio/Video/SNHC\nexperts\n* 2 Refine the architecture and class hierarchy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* Olivier AVARO (FRANCE TELECOM CNET)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCo-chair: Julien Sign\u00e8s (FRANCE TELECOM CCETT)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1170"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"14%,86%\",]\n|===\n|Title: |Ad-hoc group on defining framework of implementation complexity\nanalysis when performing core experiments."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To formalize the approach that should be taken when\nperforming implementation complexity analysis. To provide general\ncriteria for simplification of implementation. To define the format of\nassessment reports."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Nicolas Demmassieux\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1171"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"22%,78%\",]\n|===\n|Title: |Ad-hoc group on defining and implementing instrumentation tools\nfor embedding within VM\u2019s."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To investigate the feasibility of embedding intstrumentation\nwithin VM\u2019s capture gross performance metric\u2019s. If feasible produce an\ninitial set of tools to demonstrate the technique. Use elements of NBC\naudio as a test bed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Vice Chairman: |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Paul Fellows\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1180"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Ad Hoc Group to Review and Clarify the DSM-CC DIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To review DIS and document clarifications as needed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* Chris Adams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1181"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Ad Hoc Group to Investigate Low Bandwidth Data Representations\nfor DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Convenor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To investigate data representations which could reduce\nbandwidth"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrequirements for DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1182"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Ad hoc group of DSM-RSF."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To plan, coordinate, synchronize, execute and evaluate tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* Martin Fisher (mrf@sybase.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nPeter Schirling\n1996-04-05"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11N1131*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,80%\",]\n|===\n|Source: |Leonardo Chiariglione - Convenor\n|Title: |Report of 33rd WG11 meeting\n|Status: |Draft\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Opening*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 33^rd^ MPEG meeting was held in Munich, Germany at the invitation of\nDIN, the German National Body and hosted by Siemens. Dr. Claus Weyrich,\nDirector of Siemens Corporate Research, welcomed the delegates."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Roll call of participants*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex 1 gives the attendance list."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Approval of agenda*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex 2 gives the approved meeting agenda."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Allocation of contributions*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex 3 gives the list of papers submitted to the meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Communications from Convenor*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere were no communications."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Report of previous meeting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Dallas meeting report could not be approved because its drafting had\nnot been completed due to the missing contribution of one Chairman."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Processing of NB Position Papers*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese were considered and an approved response produced."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *MPEG Phase 2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Video*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo specific activity took place on this matter"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Audio*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo specific activity took place on this matter was reported or took\nplace at the meeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Verification of MPEG-2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *Video Quality*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MPEG-2 Video Verification tests were completed with the approval of\nthe report on 4:2:2 Profile @ Main Level subjective assessment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *Audio Quality*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo specific activity on this subject was reported or took place at the\nmeeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Amendments*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 4:2:2 profile amendment was finally approved. Further bitstream\nverification work on the MVP profile was carried out."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Corrigenda*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo specific activity on this subject was reported or took place at the\nmeeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Part 4 (Conformance)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo specific activity on this subject was reported or took place at the\nmeeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Part 5 (Software)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo specific activity on this subject was reported or took place at the\nmeeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Part 6 (DSM-CC)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClarifications on DIS 13818-6 were produced."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Part 7 (NBC Audio)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe NBC Audio Reference Model 3 was produced and approved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Part 9 (RTI)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo specific activity on this subject was reported or took place at the\nmeeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Part 10 (DSM-CC Conformance)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA Working Draft was produced and approved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Workplan*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis was produced and approved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *MPEG Phase 4*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA new MPEG-4 project description was produced and approved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Applications and Requirements*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo further work was done on the document produced in Dallas."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Syntax*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA new version of the MSDL WD was produced"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Tools*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *Audio*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nConsiderable efforts were spent to review the submissions received in\nresponse to the second MPEG-4 Call."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *Video*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nConsiderable efforts were spent to review the submissions received in\nresponse to the second MPEG-4 Call."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *Synthetic/Natural Hybrid*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFurther work to refine the nature and scope of technologies to be\nrequested in a Call was carried out.."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Call for proposals*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn advance notice of a call for SNHC was issued."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Tests*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nConsiderable efforts were spent in informal testing of audio and video\nproposals."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Verification Models*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Video group successfully produced the first MPEG-4 Video\nVerification Model."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Workplan*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe detailed workplan produced at Dallas was retained."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Overall WG11 workplan*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis was produced and approved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Liaison matters*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBecause of the short duration of the meeting only few liaison documents\nwere produced by the subgroups."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Administrative matters*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Schedule of future MPEG meetings*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis was updated."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *MPEG document management*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe meeting confirmed the satisfactory arrangement achieved with the new\ndocument handling systems."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Organisation of this meeting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Tasks for subgroups*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"19%,81%\",]\n|===\n|Integration |MSDL WD\n| |MSDL for NBC\n| |SNHC advance call\n|Video |4:2:2 profile\n| |MPEG-4 submissions\n| |MPEG-4 VM\n|Audio |NBC WD\n| |MPEG-4 submissions\n|Test |4:2:2 verification test\n| |NBC tests\n|Implementation |NBC complexity assessment\n| |MPEG-4 complexity assessment\n|DSM |Clarify DSM-CC DIS\n| |DSM-CC Conformance Testing WD\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Finalisation of meeting allocation*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSubgroups met at all available times and had several joint meetings."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Planning of future activities*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following ad-hoc groups were established:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"8%,92%\",]\n|===\n|No. |Title"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1133 |Ad-hoc group on MPEG-2 Multi-view Profile"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1141 |Ad-hoc Group on Test Methodology for Audio and Video MPEG-4\nVerification Test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1142 |Ad-hoc Group on Test Methodology for Formal NBC Test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1145 |Ad-hoc Group MPEG-2 NBC RM3 Audio Test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1146 |Ad-hoc Group on MPEG-4 VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1147 |Ad-hoc Group on RM3 Specification and WD"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1148 |Ad-hoc Group on Revisions of IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1149 |Ad-hoc Group on SNHC Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1153 |Ad-hoc Group on Core Experiments on Coding Efficiency for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1154 |Ad-hoc Group on Core Experiments on Object Scalability for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1155 |Ad-hoc Group on Core Experiments on Error Resilience Aspects for\nMPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1156 |Ad-hoc Group on Core Experiments on Multi-functional Coding for\nMPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1157 |Ad-hoc Group on Software Development of the Video VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1160 |Ad-hoc Group on Synthetic/Natural Hybrid Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1161 |Ad-hoc Group on MPEG-4 Video Verification Model Document Editing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1165 |Ad-Hoc Group on Syntactic Description Language"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1166 |Ad-hoc Group on Requirements for MPEG-4 Virtual Machine"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1167 |Ad-hoc Group on MSDL Architecure and Objects Hierarchy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1170 |Ad-hoc Group on Defining the Framework of Implementation\nComplexity Analysis when Performing Core Experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1171 |Ad-hoc Group on Defining and Implementing Instrumentation Tools\nfor Embedding within VMs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1180 |Ad-hoc Group on Review and Clarify the DSM CC DIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1182 |Ad-hoc Group on DSM Verification (DSM RSF)\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex 10 gives details of each ad-hoc groups established."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Resolutions of this meeting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese were approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *A.O.B*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere were no other business."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Closing*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe meeting closed on 96/01/24 at 22:00"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 1_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*List of participants*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"9%,19%,14%,41%,17%\",]\n|===\n|Title |Name |Surname |Affiliation |Nat.Body"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Frater |Michael |University of New South Wales |Australia"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Van Droogenbroeck |Marc |Belgacom / New Developments |Belgium"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Badiqu\u00e9 |Eric |European Commission |Belgium"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Ir |Delmot |Thierry |U.C.L.-Telecommunication Lab |Belgium"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Christophe |Yves |Vrije Universiteit Brussel |Belgium"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Balabanian |Vahe |Bell-Northern Research |Canada"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Casey |Liam |BNR |Canada"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Kari |Jarkko | |Finland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Grassel |Guido |Nokia |Finland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Rzeszutko |Marcin |Nokia |Finland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Turker |Mustafa Ali |Nokia |Finland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Vaananen |Mauri |Nokia |Finland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Yin |Lin |Nokia |Finland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Heinonen |Taisto |Nokia Research Center |Finland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Nieweglowski |Jacek |Nokia Research Center |Finland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Yin |Lin |Nokia Research Center |Finland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Lecomte |Daniel |Alcatel |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Madec |Gerard |CCETT |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Mainard |Laurent |CCETT |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Peigne |Bernard |CCETT |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Rault |Jean-Bernard |CCETT |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Sanson |Henri |CCeTT |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Signes |Julien |CCeTT |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mrs |Theot |Christine |CCETT |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Marie |Xavier |Ceil Ingenierie |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Dufourd |Jean-Claude |ENST |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Privat |Gilles |France Telecom |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Avaro |Olivier |France Telecom CNET |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Prof |Demassieux |Nicolas |France Telecom/ENST |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Loret |Bruno |France-Telecom-CNET |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Bouchard |Lionel |LEP |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miss |Corset |Isabelle |LEP |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mrs |Jeannin |Sylvie |LEP |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Molter |David |LEP |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Navarro |William |Matra Communication |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Bonnard |Pierre |MATRA Comp. |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Vial |Jean-Francois |Thomson MultiMedia |France"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Kaup |Andre | |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Koechling |Christian |Bosch |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Mueller |Joerg-Martin |Bosch Telecom |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Bancroft |David |BTS Broadcast Television Systems GmbH |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Blitzer |Hans Werner |DeTe Berkom |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Knoll |Angelika |Deutsche Telekom |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Schwalbe |Ralf |Deutsche Telekom |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |List |Peter |Deutsche Telekom AG |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Spille |Jens |Deutsche Thomson-Brandt |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Herpel |Carsten |Deutsche Thomson-Brandt GmbH |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mrs |Aign |Susanna |DLR |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Dietz |Martin |FHG-IIS |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Zimmer |Gerhard |FHG-IIS |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Brandenburg |Karlheinz |FHG-IIS-A |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Qian |Deyu |Fraunhofer-Institut f\u00fcr Festkoerpertechnologie |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Junge |Guenther |Fujitsu Mikroelektronik GmbH |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Hofrichter |Klaus |GMD Fokus |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Kraft |Andreas |GMD Fokus |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |De Lameillieure |Jan |Heinrich-Hertz-Institut |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Selinger |Thorsten |HHI |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Sikora |Thomas |HHI |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Stabernack |Benno |HHI |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Griwodz |Carsten |IBM |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Schertz |Alexander |Institut fuer Rundfunktechnik |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Stoll |Gerhard |IRT |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Steinbrink |Bernd |Journalist |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Knabe |Gerald |Q-Team Dr. Knabe GmbH |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Fischer |Ralf |Robert Bosch GmbH |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Koechling |Christian |Robert Bosch GmbH |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Lappe |Dirk |Robert Bosch GmbH |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Nitsche |Gunnar |Robert Bosch GmbH |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Illgner |Klaus |RWTH Aachen |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Mueller |Frank |RWTH Aachen |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Laier |Joachim |Siemens |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Pandel |Juergen |Siemens |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Sebestyen |Istvan |Siemens |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Gleissl |Peter |Siemens AG |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Hammer |Bernard |Siemens AG |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Hofmeir |Stefan |Siemens AG |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Mielkau |Uwe |Siemens AG |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Panis |Stathis |Siemens AG |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Seytter |Fritz |Siemens AG |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Fechter |Frank |Technische Universitaet Braunschweig |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |M\u00f6ller-Streitb\u00f6rger |Wolfgang |Textransfer |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Pirkmayer |Teodor |TU Berlin |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Ricken |Christof |TU Braunschweig |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Hutter |Andreas |TU Muenchen |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Kuhn |Peter |TU Muenchen |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Stechele |Walter |TU Muenchen |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Steckenbiller |Helmut |TU Muenchen |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Edler |Bernd |Uni Hannover |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Schroeder |Karsten |Universitaet Dortmund |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Grill |Bernhard |University of Erlangen |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Faerber |Niko |University of Erlangen-Nuremberg |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Wiegand |Thomas |University of Erlangen-Nuremberg |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Fuchs |Hendrik |University of Hannover |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Gerken |Peter |University of Hannover |Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Ward |Lam |TELTEC Ireland |Ireland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Brady |Noel |TELTEC-DCY |Ireland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Parladori |Giorgio |Alcatel |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Giorgio |Parladori |Alcatel Telettra |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Battista |Stefano |CSELT |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Chiariglione |Leonardo |CSELT |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Ms |Contin |Laura |CSELT |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Gandini |Marco |CSELT |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Sereno |Daniele |CSELT |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Chimienti |Antonio |CSTV-CNR |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Lavagetto |Fabio |DIST-University of Genova |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Baroncini |Vittorio |F.U.B |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Russo |Giuseppe |Fondazione Ugo Bordoni |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Antoniazzi |Stefano |ITALTEL |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Dimino |Giorgio |RAI |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Zuccaro |Amedeo |SGS Thomson |Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Morimatsu |Eishi |Fujitsu Laboratories ltd |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Hanamura |Tsuyoshi |GCL |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Kameyama |Wataru |GCL |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Katayama |Yasuo |GCL |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Kaneko |Itaru |GCL, Waseda University |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Nakaya |Yuichiro |Hitachi, Ltd |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Date |Akira |Hitachi,Ltd., Central Research Laboratory |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Suzuki |Hiroaki |JVC |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Yamada |Kunio |JVC |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Machida |Yutaka |Matsushita |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Yoshida |Koji |Matsushita Communication Ind. Co., Ltd |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Boon |C. S |Matsushita Electric Industrail Co |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Etoh |Minoru |Matsushita Electric Industrial Co., Ltd |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Arakawa |Hiroshi |Matsushita Electric Industrial Co.,Ltd |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Kogure |Takuyo |Matsushita Electric Industrial Co.,Ltd |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Miyasaka |Shuji |Matsushita Electric Industrial Co.,ltd |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Fukuhara |Takahiro |Mitsubishi Electric Corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Masahiro |Iwadare |NEC |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Koyama |Hitoshi |NEC Corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Miyamoto |Yoshihiro |NEC Corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Hamada |Hiroyuki |NHK |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Sakaida |Shinichi |NHK |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Watanabe |Kaoru |NHK |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Nakasu |Eisuke |NHK (Japan Broadcasting Corporation) |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Oosa |Kinya |Nippon Steel Corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Urano |Joji |Nippon Televison Network Corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Jozawa |Hirohisa |NTT |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Miki |Satoshi |NTT |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Moriya |Takehiro |NTT |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miss |Hotani |Sanae |NTT DoCoMo |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Miki |Toshio |NTT DoCoMo |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Wu |Zhixiong |Oki Electric Industry Co., Ltd |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Nakamura |Takeshi |Pioneer |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Suzuki |Masami |Pioneer |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Fujimura |Kouta |Sanyo Electric Co., Ltd |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Hibi |Keiichi |Sharp corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Katata |Hiroyuki |Sharp Corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Nishiguchi |Masayuki |Sony |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Kitamura |Takuya |Sony Corp |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Ogata |Masami |Sony Corp |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Suzuki |Teruhiko |Sony Corp |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Tong |Tak-Yen |Sony Corp |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Akagiri |Kenzo |Sony Corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Koike |Takashi |Sony Corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Matsumoto |Jun |Sony Corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Oikawa |Yoshiaki |Sony Corporation |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Itoh |Yuji |Texas Instruments Tsukuba R&D Center |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Homma |Teru |Toppan Printing Co., Ltd |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Watanabe |Toshiaki |Toshiba |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Ueno |Hideyuki |Toshiba corp |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Miyamori |Hisashi |Waseda University |Japan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Byeungwoo |Jeon | |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Hwang |Duckdong |Daewoo Electronics co |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Jin Hun |Kim |Daewoo Electronics Co. Ltd |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Kim |Jin Hun |Daewoo Electronics Co. Ltd |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Kim |Yong Han Kim |Elec. and Telecom. Research Institute (ETRI)\n|Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Hong |Jin Woo |ETRI |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Moon |Joo-Hee |Hyundai Electronics Industries Co., Ltd |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Park |Gwang-Hoon |Hyundai Electronics Industries Co., Ltd |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Prof |Kim |Jae-kyoon |KAIST |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Kim |Dae Young |LG Electronics |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Kim |Young-Goan |LG semicon. |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Kim |Sang-Wook |Samsung AIT |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Seo |Yang-Seock |Samsung AIT |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Shin |Jae-Seob |Samsung AIT |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Jeon |Byeungwoo |Samsung Electronics |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Lee |Yung-Lyul |Samsung Electronics Co.,ltd |Korea"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Koenen |Rob |KPN Research |Netherlands"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Bosveld |Frank |Philips |Netherlands"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Rosengren |Joergen |Philips |Netherlands"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |van Twist |Rob |Philips |Netherlands"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |de Bont |Frans |Philips Consumer Electronics |Netherlands"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Beuker |Rob |Philips Research Laboratories |Netherlands"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Ir |Oomen |Werner |Philips Research Laboratories |Netherlands"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Bjontegaard |Gisle |Telenor |Norway"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Danielsen |Robert |Telenor R&D |Norway"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miss |Klungsoyr |Gunn Kristin |Telenor R&D |Norway"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Jedrzejek |Czeslaw |EFP, Franco-Polish School |Poland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miss |Martins |M. Isabel |INESC |Portugal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Ferreira |Anibal |INESC-Porto |Portugal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Lobato Correia |Paulo |Instituto Superior Tecnico |Portugal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Prof |Pereira |Fernando |Instituto Superior Tecnico |Portugal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Tan |Ah Peng |Asia Matsushita Electric (S) Pte Ltd |Singapore"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Tan |Thiow-Keng |Asia Matsushita Electric (S) Pte Ltd |Singapore"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Roser |Miguel |Telefonica Investigacion y Desarrollo |Spain"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Mas Ribe\u2019s |Joan Maria |UCL-Telecommunications Lab. |Spain"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Ekudden |Erik |Ericsson |Sweden"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Brusewitz |Harald |Ericsson Radio Systems |Sweden"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Lindqvist |Morgan |Ericsson Radio Systems |Sweden"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Einarsson |Torbj\u00f6rn |Ericsson Telecom |Sweden"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Li |Haiko |Linkoeping Univ. |Sweden"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Nazari |Ala |Telia Research |Sweden"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mrs |Ekvall |Christel |Telia Research AB |Sweden"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Franceschi |Olle |Teracom Svensk Rundradio AB |Sweden"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miss |Olsson |Sofie |Teracom Svensk Rundradio AB |Sweden"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Poffet |Hanspeter |Alcatel STR |Switerlan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Buhan |Corinne |EPFL |Switzerland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Bhattacharjee |Sushil |EPFL |Switzerland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Castagno |Roberto |EPFL |Switzerland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Ebrahimi |Touradj |EPFL |Switzerland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miss |Le Buhan |Corinne |EPFL |Switzerland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Mattavelli |Marco |EPFL |Switzerland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Piron |Laurent |EPFL |Switzerland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |von Ow |Andreas C. |Studer Professional Audio AG |Switzerland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Meares |David |British Broadcasting Corporation |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Mulroy |Patrick |BT Laboratories |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Casey |Thomas |CIHE |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Mason |Arthur Gordon |DMV |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Marks |Brian |FBM |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Hobson |Paola |Motorola Ltd. |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Winder |Simon |PACT, Partnership in Advanced Computing Technologies\n|UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Hotchkiss |Andy |PACT/SRF Bristol |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Fellows |Paul |SGS-Thomson Microelectronics Limited |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Charig |Francis |Tao Group Limited |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Henson |Andrew |Tao Group Limited |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Hinsley |Christopher |Tao Group Limited |UK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Gardos |Tom | |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Tekalp |Murat | |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Stampleman |Joseph |Apple Computer |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Petajan |Eric |AR&T Bell Labs |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Dalton |Robert |AT&T |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Johnston |James |AT&T |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Li |Chia |AT&T |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |McPheters |Mike |AT&T |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Quackenbush |Schuyler |AT&T |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Jacquin |Arnaud |AT&T Bell Laboratories |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Ostermann |J\u0161rn |AT&T Bell Laboratories |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Puri |Atul |AT&T Bell Labs |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Siegell |Bruce |Bellcore |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Prof. |Eleftheriadis |Alexandros |Columbia University |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Suzuki |Norihiro |Columbia University |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Cismas |Sorin |CompCore Multimedia, Inc |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Sodagar |Iraj |David Sarnoff Research Center |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Chiang |Tihao |David Sarnoff Research Center |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Zhang |Ya-Qin |David Sarnoff Research Center |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Schaphorst |Richard |Delta Information Systems |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Hooper |Donald |Digital Equipment Corp |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Dufaux |Frederic |Digital Equipment Corporation |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Goldman |Matthew |Digital Equipment Corporation |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Adams |Chris |DiviCom |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Bosi |Marina |Dolby Laboratories |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Doenges |Peter |Evans & Sutherland |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Coleman |Mike |Five Bats Research |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Yao |Jason |Fujitsu Laboratories of America |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Sathe |Vinay |General Instrument |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Luthra |Ajay |General Instrument |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Narasimhan |Sam |General Instrument |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Rajan |Ganesh |General Instrument Corporation |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Azadegan |Faramarz |GTE Laboratories |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miss |Choi |Diana |Hughes Electronics |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Fetvedt |John |IBM |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Schirling |Peter |IBM |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Rossignac |Jarek |IBM Research |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Huang |Chien-Min |IC Image, Inc. |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Romriell |Joseph |Intel Corporation |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Jacoby |Ronald |Interactive Digital Solutions |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Zeug |Michael |Iterated Systems |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Chuang |Roger |Iterated Systems, Inc. |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Muller |John |Iterated Systems, Inc. |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Li |Weiping |Lehigh University |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Campbell |George |LLI |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |DelRegno |Christopher |MCI |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Horne |Caspar |Mediamatics |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Lee |Ming-Chieh |Microsoft |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Chen |Wei-ge |Microsoft Corp |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Powell |Bill |Microsoft Corp |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Bell |Bob |Mitsubishi Electronics America |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Thom |David |Mitsubishi Electronics America Inc |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Banham |Mark |Motorola |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Brailean |James |Motorola |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |O'Connell |Kevin |Motorola |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Pan |Davis |Motorola, Inc |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |David |Malloy |Next Level / General Instrument |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Malloy |David |NEXT LEVEL/General Instrument |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Challipali |Kiran |Philips research center |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Grinnell |Richard |PictureTel Corp |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Sullivan |Gary |PictureTel Corp |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Shen |Janice |Rockwell |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Reader |Cliff |Samsung Semiconductor |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Addington |Tim |Scientific Atlanta |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Schreiner |Peter |Scientific Atlanta |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Lei |Shawmin |Sharp |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Sezan |Ibrahim |Sharp Labs of America |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Dygert |Timothy |Stellar One Corp |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Van Loo |James |Sun Microsystems |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Fisher |Martin |Sybase, Inc |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Cherry |Guy |Tektronix |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Pennet |Bruce |Tektronix |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Tabatabai |Ali |Tektronix |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Lueck |Chuck |Texas Instruments |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Moccagatta |Iole |Texas Instruments |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Talluri |Raj |Texas Instruments |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Oehler |Karen |Texas Instruments, Inc |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Crinon |Regis |Thomson Consumer Electronics Inc |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mr |Neff |Ralph |UC Berkeley |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Chou |Philip |Xerox |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr |Strait |Jeff |Zenith |USA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Bostanci |Hakki Tunc | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Chu |Chung-Tao | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Liang |Gang | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 2_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Agenda*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"8%,92%\",]\n|===\n|1. |Opening\n| |\n|2. |Roll call of participants\n| |\n|3. |Approval of agenda\n| |\n|4. |Allocation of contributions\n| |\n|5. |Communications from Convenor\n| |\n|6. |Report of previous meeting\n| |\n|7. |Processing of NB Position Papers\n| |\n|8. |MPEG Phase 2\n|8.1 |Video\n|8.2 |Audio\n|8.3 |Verification of MPEG-2\n|8.3.1 |Video Quality\n|8.3.2 |Audio Quality\n|8.4 |Amendments\n|8.5 |Corrigenda\n|8.6 |Part 4 (Conformance)\n|8.7 |Part 5 (Software)\n|8.8 |Part 6 (DSM-CC)\n|8.9 |Part 7 (NBC Audio)\n|8.10 |Part 9 (RTI)\n|8.11 |Part 10 (DSM-CC Conformance)\n|8.12 |Multi-view profile\n|8.13 |Workplan\n| |\n|9. |MPEG Phase 4\n|9.1 |Applications and Requirements\n|9.2 |Syntax\n|9.3 |Tools\n|9.3.1 |Audio\n|9.3.2 |Video\n|9.3.3 |Synthetic/Natural Hybrid\n|9.4 |Call for proposals\n|9.5 |Tests\n|9.6 |Verification Models\n|9.7 |Workplan\n| |\n|10. |Overall WG11 workplan\n| |\n|11. |Liaison matters\n| |\n|12. |Administrative matters\n|12.1 |Schedule of future MPEG meetings\n|12.2 |MPEG document management\n| |\n|13. |Organisation of this meeting\n|13.1 |Tasks for subgroups\n|13.2 |Finalisation of meeting allocation\n| |\n|14. |Planning of future activities\n| |\n|15. |Resolutions of this meeting\n| |\n|16. |A.O.B\n| |\n|17. |Closing\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 4_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Documents submitted*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nKEY: Available - WD-Withdrawn; NO-not in FTP directory"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"10%,4%,7%,6%,9%,22%,42%\",]\n|===\n|Number |Date |Available |Group |Section |Source |Title"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0551 |95/12 |19960111 |MPEG-2 |Audio |David Meares, Sang-Wook Kim |NBC\nReference Model 2 subjective tests: overall results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0552 |95/12 |19960111 |MPEG-4 |Video |Ulrich Benzler, Oliver Werner\n|Motion and aliasing compensating prediction with quarter-pel accuracy\nand adaptive overlapping blocks as proposal for MPEG-4 tool evaluation -\nTechnical description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0553 |96/01 |19960119 |MPEG-4 |Video |Michael Zeug, John Muller\n|Iterated Systems, Inc. MPEG-4 Video Submission Technical Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0554 |96/01 |19960118 |MPEG-4 |Video |C. S. Park, J. R. Kim, J. I. Kim,\nJ. T. Lim, D. D. Hwang, J. H. Kim, H. S. Kim, K. H. Chang |Daewoo\nalgorithm for object scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0555 |96/01 |19960120 |MPEG-4 |Video |C. S. Park, J. R. Kim, J. I. Kim,\nJ. T. Lim, D. D. Hwang, J. H. Kim, H. S. Kim, and K. H. Chang. |Daewoo\nproposal for region texture coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0556 |96/01 |WD |MPEG-4 |Video |M. S. Lee, H. S. Kim, and K. H. Chang.\n|Daewoo algorithm for image data compression."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0557 |96/01 |19960103 |MPEG-4 |Video |R.A. Beuker, R. Heusdens, A.\nKalker, H. Theunis |Adaptive filterbanks with segmentation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0558 |96/01 |19960119 |MPEG-2 |Audio |S. R. Quackenbush, J. D.\nJohnston, J. Herre |An Improved NBC RM2 Noiseless Coding Kernel"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0559 |96/01 |19960116 |MPEG-2 |Audio |S. R. Quackenbush |An Automated\nMethod for Making Tapes for High-Quality Subjective Listening"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0560 |96/01 |19960116 |MPEG-2 |Audio |J. Herre, S. R. Quackenbush, J.\nD. Johnston, D. Sinha |An Enhanced Noise Masking Technique for the\nMPEG-2 NBC RM2 Audio Coder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0561 |96/01 |19960114 |MPEG-4 |Audio |Scott Diamond |MPEG4 Audio 64kbps\nsubjective tests:overall results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0562 |96/01 |19960123 |MPEG-4 |Audio |Masayuki Nishiguchi, Jun\nMatsumoto, Shiro Omori, Kazuyuki Iijima |Report on tape preparation and\nMOS tests in Sony for 6.0 and 2.0 kbps coders for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0563 |96/01 |19960109 |MPEG-2 |Audio |Jean-Bernard RAULT |Proposal for\nchanges in the 13818-3 syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0564 |96/01 |19960117 |MPEG-4 |Video |Jae-Seob Shin, Shi-Hwa Lee,\nSung-Gul Ryoo, Seong-Jin Kim, Yang-Seock Seo |Video Compression\nAlgorithm using Motion Segmentation and Color Perception"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0565 |96/01 |19960116 |MPEG-4 |Video |Yu-Shin Cho, Shi-Hwa Lee,\nJae-Seob Shin, Yang-Seock Seo |Shape Coding Tool: Using polygonal\napproximation and reliable residue error sampling method"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0566 |96/01 |19960118 |MPEG-4 |Video |Sung-Gul Ryoo, Seong-Jin Kim,\nYang-Seock Seo |RRate Control Tool: Based on Human Visual Sensitivity\nfor Low Bitrate Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0567 |96/01 |19960112 |MPEG-2 |Test |Eisuke Nakasu |Results of MP@HL\n(H-14) subjective assessment tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0568 |96/01 |19960112 |MPEG-2 |Test |Eisuke Nakasu |Results of 4:2:2@ML\nsubjective assessment tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0569 |96/01 |19960111 |MPEG-4 |Systems |Peter Sheldon, John Cosmas |A\nText Level Syntax Language"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0570 |96/01 |19960110 |MPEG-4 |Systems |Peter Sheldon, John Cosmas\n|Level 1 Model for MSDL"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0571 |96/01 |19960112 |MPEG-4 |Video |G.Russo, S.Colonnese, A.Neri,\nP.Talone |Moving objects versus still background classification: a\nspatial temporal segmentation tool for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0572 |96/01 |19960112 |MPEG-4 |Test |ACTS MOMUSYS, (Stathis Panis -\nSiemens AG, Gunnar Nitsche - Bosch GmbH) |Realistic Tests for Error\nResilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0573 |96/01 |19960115 |MPEG-4 |Video |Touradj Ebrahimi, Sushil\nbhattacharjee, Franck Bossen, Roberto Castagno, Carmen De Sola, Corinne\nLe Buhan, Laurent Piron, Emmanuel Reusens, Vincent Vaerman |Improved\nImplementation Dynamic Coding of Visual Informatio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0574 |96/01 |19960112 |MPEG-4 |Audio |Anibal Ferreira |Re-submission of\nthe INESC audio coding proposal (technical update)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0575 |96/01 |19960112 |MPEG-4 |Audio |Anibal Ferreira |An improved\nfunctionality: static selection of the coding delay mode"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0576 |96/01 |19960110 |MPEG-2 |DSM |Vahe Balabanian, Liam Casey\n|End-to-End Walkthrough of DSM-CC DIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0577 |96/01 |19960110 |MPEG-2 |DSM |Vahe Balabanian,, Liam Casey\n|Binding Resources for Download and the Download Interface"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0578 |96/01 |WD |MPEG-2 |DSM | |Liaison re: ITU-T DSS2 GIT Fields\nAssigned to DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0579 |96/01 |19960110 |Liaison |DSM |Vahe Balabanian,, System\nIntegration TC |Liaison re: ITU_T DSS2 GIT Fields Assigned to DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0580 |96/01 |19960116 |MPEG-4 |Audio |Kenzo Akagiri, Takashi Koike\n|Technical description of Sony's coding algorithm for MPEG-4 Audio\n24kbps compression coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0581 |96/01 |19960116 |MPEG-4 |Audio |Kenzo Akagiri, Takashi Koike\n|Technical description of Sony's coding algorithm for MPEG-4 Audio\nbitrate scalability coding (64kbps-24kbps-6kbps)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0582 |96/01 |19960116 |MPEG-4 |Video |Hiroyuki KATATA, Norio ITO,\nHiroshi KUSAO |Video coding algorithm for compression efficiency"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0583 |96/01 |19960113 |MPEG-4 |Video |Tomoko AONO, Norio ITO, Hiroyuki\nKATATA, Hiroshi KUSAO |Wavelet based video coding algorithm for object\nscalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0584 |96/01 |19960116 |MPEG-4 |Audio |Naoki Iwakami,, Kazunaga Ikeda,,\nTakehiro Moriya,, Satoshi Miki,, Akio Jin |NTT's improved audio coder\nfor 24 kbit/s and above"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0585 |96/01 |19960116 |MPEG-4 |Audio |Takehiro Moriya,, Satoshi Miki,,\nAkio Jin,, Naoki Iwakami,, Kazunaga Ikeda |NTT's audio/speech coders in\nharmoney with the ITU-T standardization"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0586 |96/01 |19960113 |MPEG-4 |Video |Keiichi HIBI, Nobuyuki EMA, Seiji\nSATO |Video coding algorithm using adaptive 2D-triangle mesh based\nprediction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0587 |96/01 |19960113 |MPEG-4 |Video |Keiichi HIBI, Nobuyuki EMA, Seiji\nSATO |Wavelet based layered algorithm for error resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0588 |96/01 |19960112 |MPEG-4 |Audio |Daniele SERENO, Michele FESTA\n|Detailed description of the improved MAVT MPEG-4 audio candidate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0589 |96/01 |19960116 |MPEG-4 |Video |T.K. Tan, S.M. Shen |Loop Filter\nin Motion Compensation Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0590 |96/01 |19960116 |MPEG-4 |Video |S.M. Shen, T.K. Tan |Intra Frame\nWavelet Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0591 |96/01 |19960123 |MPEG-4 |Audio |Masayuki Nishiguchi, Jun\nMatsumoto, Shiro Omori, Kazuyuki Iijima |Technical description of Sony\nIPC speech coder for MPEG-4 additional call for proposals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0592 |96/01 |19960115 |MPEG-4 |Video |Weiping Li,\nH.Q.Cao,S.Li,W.Li,F.Ling,S.A.Segan,H.Sun,J.P.Wus,Y.Q.Zhang |A Video\nCoding Algorithm Using Vector-Based Techniques"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0593 |96/01 |19960115 |MPEG-4 |Audio |Ah-Peng Tan |Technical\nDescription of Proposal for MPEG-4 Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0594 |96/01 |19960112 |MPEG-4 |Video |Michael R. Frater, John F. Arnold\n|Error Patterns for Error Resilience Core Experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0595 |96/01 |19960112 |MPEG-4 |Video |Shinichi Sakaida,Yoshiaki\nShishikui |Spatial Segmentation using K-means algorithm"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0596 |96/01 |19960112 |MPEG-4 |Video |Yoshiaki Shishikui,Shinichi\nSakaida |Region Support DCT(RS-DCT)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0597 |96/01 |19960115 |HoD |Video |The National Body of Japan |On\nEstablishment of Video Verification Models"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0598 |96/01 |19960116 |MPEG-4 |Video |M.Etoh, H.Arakawa, T.Maeda |H.263\nImplementation in MSDL and Extension to Real Time Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0599 |96/01 |19960113 |MPEG-4 |Video |Yoshihiro Miyamoto, Yotaka\nYokoyama |Video Coding Algorithm using Adaptive Warping Prediction -\nTechnical Descriptionini"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0600 |96/01 |19960112 |MPEG-4 |Video |harald.brusewitz,,\ngoran.bang@era-t.ericsson.se |A tool for generating bit error resilient\nfixed length code tables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0601 |96/01 |19960112 |MPEG-4 |Video\n|harald.brusewitz@era-t.ericsson.se |Low complexity encoder and error\nresilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0602 |96/01 |19960115 |MPEG-4 |Video |Karsten Schroeder, Holger Hornig\n|Grid Based Motion Compensation and Shape Coding Using Curved Triangles"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0603 |96/01 |19960116 |MPEG-4 |Video |Shinya Kadono, C.S.Boon\n|Macroblock based coding og shape and opacity data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0604 |96/01 |19960115 |MPEG-4 |Video |Christian Koechling, Gunnar\nNitsche |Interactive video manipulation based on H.263 and Java"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0605 |96/01 |19960112 |MPEG-4 |SNHC |Peter K. Doenges |Report of the Ad\nHoc Group on Synthetic/Natural Hybrid Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0606 |96/01 |19960112 |MPEG-4 |Audio |Bob Dyas |AMP - Audio Matching\nPursuits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0607 |96/01 |19960112 |MPEG-4 |Audio |James Thi |Technical Description\nof The Rockwell Audio Coding Proposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0608 |96/01 |19960112 |MPEG-4 |Audio |Dr. Huan-yu Su |Technical\ndescription of Rockwell's speech coding proposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0609 |96/01 |19960116 |MPEG-4 |Video |Y. Nakaya, A. Date, S. Misaka, Y.\nSuzuki |Technical description of Hitachi's proposed video coding\nalgorithm ver.2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0610 |96/01 |19960115 |MPEG-4 |SNHC |Itaru Kaneko |Chairman's report\nonthe work of the Audi Ad-Hoc Group on SNHC/Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0611 |96/01 |19960116 |MPEG-2 |Audio |Itaru Kaneko |Description of\nGCL's experiment for core experiment 2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0612 |96/01 |19960117 |MPEG-2 |Video |Bob Eifrig |Report of the ad-hoc\ngroup on 4:2:2 profile conformance testing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0613 |96/01 |19960116 |MPEG-4 |Video |C. S. Boon, S. Kadono |DCT Coding\nof Macroblocks Padded Using Alpha Channel"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0614 |96/01 |19960116 |MPEG-4 |Video |C. S. Boon, S. Kadono, J.\nTakahashi, M. Okuno |A Study on Down-conversion methods for binary and\ngreyscale alpha planes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0615 |96/01 |19960118 |MPEG-4 |Video |Hirohisa Jozawa, Kazuto Kamikura,\nAtsushi Sagata |Technical description of video proposal for MPEG-4\nalgorithm evaluation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0616 |96/01 |19960115 |MPEG-4 |Video |Gisle Bjontegaard |An error\nresilience method based on back channel signalling and FEC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0617 |96/01 |19960115 |MPEG-4 |Video |Gisle Bjontegaard |A simple edge\nloopfilter to reduce blocking and mosquito noise"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0618 |96/01 |19960115 |MPEG-4 |SNHC |Yong Han Kim |On requirements of\nMPEG-4/SNHC for its application to digital desktop studio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0619 |96/01 |19960115 |HoD |Systems |Pete Schirling |Ad-hoc report on\nupdating the procedures for electronic distribution of MPEG and WG 11\ndocuments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0620 |96/01 |19960115 |MPEG-4 |Video |T. Ebrahimi, O. Egger, M. Kunt\n|Arbitrarily-Shaped Region Interior Coding Using Embedded Zerotrees"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0621 |96/01 |19960116 |MPEG-4 |Systems |Angelika Knoll |Proposal for a\nhigh level MSDL-Blanguage"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0622 |96/01 |19960118 |MPEG-4 |Systems |Angelika Knoll |A compression\nmechanism converting source code in high level language to MSDL-B."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0623 |96/01 |19960115 |MPEG-4 |Video |Faramarz Azadegan |Use of\nInter-Block Compression to Improve Coding Efficiency of Intra-Coded\nFrames"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0624 |96/01 |19960115 |MPEG-4 |Video |Faramarz Azadegan |Alternative to\nBorder Extension in Image/Object Filtering"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0625 |96/01 |19960115 |MPEG-4 |Video |Jean-Francois VIAL, Edouard\nFRANCOIS |Technical description of the video coder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0626 |96/01 |19960123 |MPEG-2 |Audio |Karlheinz Brandenburg |Report of\nthe Ad Hoc Group on NBC syntax development"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0627 |96/01 |19960118 |MPEG-4 |Video |S. Battista (CSELT), L. Margarit\n(Poly. Univ. of Bucarest) |A proposal for a class library for 2d video."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0628 |96/01 |19960123 |MPEG-2 |Audio |Marina Bosi |Report of the Ad-Hoc\ngroup on MPEG-2 audio NBC working draft development"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0629 |96/01 |19960117 |MPEG-4 |Video |A. Murat Tekalp, Yucel Altunbasak\n|An H.263 compatible system based on a triangular-mesh"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0630 |96/01 |19960124 |MPEG-4 |Audio |Bernd Edler |MPEG-4 audio test\nresults"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0631 |96/01 |19960117 |MPEG-4 |Video |Henri Sanson, Patrice Soyer\n|Application constraints for VM definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0632 |96/01 |19960117 |MPEG-4 |Audio |Bernd Edler |Technical\ndescription of proposal from University of Hannover / Deutsche Telekom\nAG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0633 |96/01 |19960117 |MPEG-4 |Systems |Julien SIGNES |Object-oriented\nrepresentation of audio-visual data for MSDL"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0634 |96/01 |19960124 |MPEG-4 |Audio |Bernd Edler |Report of the ad hoc\ngroup on MPEG-4 audio test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0635 |96/01 |19960117 |MPEG-4 |Audio |Gerald Schuller, Bernd Edler\n|Description of a filter bank with a low system delay as a tool for\naudio coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0636 |96/01 |19960122 |MPEG-2 |Test |Thierry ALPERT |EBU participation\nto the MP@HL (H14) verification"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0637 |96/01 |19960116 |MPEG-4 |Video |Iraj Sodagar, Ya-Qin Zhang |Very\nLow Bit Rate Video Codec"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0638 |96/01 |19960116 |MPEG-4 |Audio |Bernhard Grill, Thomas Sporer\n|Technical description of the Error Resilience Supplement to the\nContribution of the University of Erlangen and FhG-IIS to MPEG-4 Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0639 |96/01 |19960118 |MPEG-4 |Video |Ming-Chieh Lee, Wei-ge Chen,\nChuang Gu, Bruce Lin, Steve Zabinsky, Rick Szeliski |Microsoft Proposal\nfor MPEG4 Video 2nd Evaluation Phase"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0640 |96/01 |19960122 |MPEG-2 |Audio |Peter G. Schreiner III |Report of\nthe Ad-Hoc Group to Conduct the Second Set of MPEG-2 Audio NBC Reference\nModel 2 Core Experiments and the MPEG-4 Audio Listening Test Evaluations\nfor 64kb/s Submissions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0641 |96/01 |WD |MPEG-2 |Audio |Peter G. Schreiner III |Report of the\nAd-Hoc Group to Conduct the Second Set of MPEG-2 Audio NBC Reference\nModel 2 Core Experiments and the MPEG-4 Audio Listening Test Evaluations\nfor 64kb/s Submissions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0642 |96/01 |19960119 |MPEG-4 |Video |Touradj Ebrahimi |Ad Hoc group\nreport for VMs based on content representation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0643 |96/01 |19960115 |MPEG-4 |Video |Chung-Tao Chu, Dimitris\nAnastassiou, Shih-Fu Chang |Hybrid Block-Based/Segment-Based Video\nCoding at Very Low Bitrate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0644 |96/01 |19960115 |MPEG-4 |Audio |Mike McLaughlin |Speech Coding\nfor MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0645 |96/01 |19960119 |MPEG-4 |Requirements |Michael Zeug |Report of Ad\nHoc Group on MPEG4 Project Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0646 |96/01 |19960118 |MPEG-4 |Video |Gary J. Sullivan, Rick S.\nGrinnell, Henrique S.Malvar, Wilson C. Chung |An MPEG-4 Video Coding\nProposal using a Modulated Lapped Transform Enhancement of H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0647 |96/01 |19960124 |MPEG-4 |Audio |Bernd Edler, Takehiro Moriya\n|Results of additional MPEG-4 audio error resilience tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0648 |96/01 |19960116 |MPEG-2 |Audio |J. D. Johnston, S. R. Quackenbush\n|Stereo Pair Joint Coding in the NBC Reference Model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0649 |96/01 |19960116 |MPEG-4 |Video |Raj Talluri,, Tom Bannon |A\nProposal for MPEG-4 Structure and Syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0650 |96/01 |19960116 |MPEG-4 |Video |R. Nagarajan, R. R. Burns, P. Au\n|MPEG4 Tool Submission: Low Bit Rate Object Based Video Coding Using\nWarping Techniques"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0651 |96/01 |19960116 |MPEG-2 |Video |Ajay Luthra |Report on the\nActivity of Multi-View Profile Adhoc Group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0652 |96/01 |19960116 |MPEG-2 |Audio |Kenzo Akagiri |Complexity\nestimation on NBC preprocessing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0653 |96/01 |19960117 |MPEG-4 |Video |Frederic Dufaux |Background\nmosaicking"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0654 |96/01 |19960117 |MPEG-4 |Video |Kohtaro Asai, Takahiro Fukuhara\n|Core Experiments of Video Coding with Block-Partitioning and Adaptive\nSelection of Two Frame Memories (STFM/LTFM)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0655 |96/01 |19960118 |MPEG-2 |Video |Ali Tabatabai |4:2:2 Profile\nSubjective Quality Test AdHoc Group Report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0656 |96/01 |19960116 |MPEG-2 |Test |Joji Urano |Report of the ad-hoc\ngroup on MPEG-2 verification test for MP@HL(H14)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0657 |96/01 |19960117 |MPEG-4 |Video |DELMOT Thierry |Region enhanced\nH.263 coder : a trial"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0658 |96/01 |19960117 |MPEG-4 |Audio |Masahiro Iwadare |Technical\ndescription of MPEG-2/NBC lossless coding by NEC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0659 |96/01 |19960118 |MPEG-2 |DSM |Vahe Balabanian, Liam Casey |Draft\nInput for DSM-CC DIS Annex G"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0660 |96/01 |19960124 |MPEG-4 |Requirements |Richard Schaphorst |Status\nof the ITU/LBC Experts Group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0661 |96/01 |WD |MPEG-4 |Requirements |Richard Schaphorst |Status of\nthe ITU/LBC Experts Group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0662 |96/01 |19960119 |MPEG-2 |Audio |S. R. Quackenbush , |Report of\nthe Ad-hoc Group on Complexity of NBC RM2 Functions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0663 |96/01 |WD |MPEG-4 |Test |Alpert T., Nasse D. |EBU participation\nto the 4:2:2 profile verification"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0664 |96/01 |19960122 |MPEG-2 |Test |Alpert T., Nasse D. |EBU\nparticipation to the 4:2:2 profile verification"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0665 |96/01 |19960119 |MPEG-4 |Systems |Afnor |French National Body\nResolution"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0666 |96/01 |19960119 |MPEG-2 |DSM |Regis J. Crinon, Frank Bosveld\n|DSMCC: Modifications to U-U Object Carousels in Annex F."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0667 |96/01 |19960119 |MPEG-2 |DSM |Regis J. Crinon , Frank Bosveld\n|DSMCC: DSMCC: Transport of Download messages in DSMCC sections"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0668 |96/01 |19960119 |MPEG-4 |Audio |William Navarro |Improved MAVT\nMPEG-4 Audio Candidate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0669 |96/01 |19960119 |MPEG-4 |Video |Atul Puri |Report of Ad hoc Group\non Coordination of Future Experiments in MPEG-4 Video"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0670 |96/01 |19960120 |MPEG-4 |Systems |O. AVARO |MSDL AHG Report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0671 |96/01 |19960119 |MPEG-4 |Video |I. Corset, S.Jeannin |Proposal\nfor a video Verification Model structure allowing both block-based and\nregion-based methods to be tested"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0672 |96/01 |19960119 |MPEG-2 |DSM |Regis J. Crinon , Don Hooper\n|DSMCC: Need for additional IDL Syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0673 |96/01 |19960120 |MPEG-2 |DSM |Frank Bosveld |DSMCC: Proposal to\nmake Annex F (U-U Object Carousels) normative"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0674 |96/01 |19960120 |MPEG-2 |DSM |Frank Bosveld |DSMCC: Modifications\nto Download and U-U Object Carousels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0675 |96/01 |19960130 |MPEG-4 |Requirements |Richard Schaphorst |LBC\nLiaison to ISO/IEC JTC1/SC29/WG11 (MPEG)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0676 |96/01 |19960121 |MPEG-2 |Audio |J. Rowlands |Report of the ad-hoc\ngroup on MPEG-2 audio technical report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0677 |96/01 |19960122 |MPEG-2 |Audio |Gerhard Stoll |Report of the\nAd-hoc Group on revisions to IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0678 |96/01 |19960122 |MPEG-2 |DSM |Chris Adams |DSM CC Adhoc Report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0679 |96/01 |19960122 |MPEG-4 |Video |Joern Ostermann |Algorithms"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0680 |96/01 |19960122 |MPEG-4 |Audio |Davic Pan |Audio Proposals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0681 |96/01 |19960122 |MPEG-4 |Audio |Gerhard Stoll |Comment on the\nITU-R special rapporteur document 11-3/88-E (20. October 1995) with the\ntitle: \" tutorial information on multichannel audio coding methods\nrecommended for digital television systems\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0682 |96/01 |19960122 |MPEG-2 |DSM |Mike McPheters, Scott Gavin, Hung\nNguyen |Proposal for DSM-CC Recovery Procedures"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0683 |96/01 |19960122 |MPEG-2 |DSM |Mike McPheters, Scott Gavin, Hung\nNguyen |Proposal for DSM-CC Error Handling"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0684 |96/01 |19960122 |MPEG-2 |DSM |Peter Gleissl |DSM-CC Extensions\nfor SDB in ATM Access Networks"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0685 |96/01 |19960122 |MPEG-2 |DSM |Peter Gleissl |New Chapter Switched\nDigital Broadcast - Overview / Message Definitions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0686 |96/01 |19960122 |MPEG-2 |DSM |Peter Gleissl |New Chapter Switched\nDigital Broadcast - Command Sequences"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0687 |96/01 |19960122 |MPEG-2 |DSM |Peter Gleissl |New Chapter Switched\nDigital Broadcast - State-Event-Tables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0688 |96/01 |19960123 |MPEG-4 |Systems |David Malloy |Broadcast Service\nSupport in Fiber to The Curb Networks"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0689 |96/01 |19960123 |MPEG-2 |DSM |David Malloy |Proposed Text for\nAnnex H"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0690 |96/01 |19960123 |MPEG-4 |Systems |Gilles Privat |A system view of\nMSDL Architeture"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0691 |96/01 |19960125 |----------- |----------------- |Pete Schirling\n|MUNICH DOCUMENT CONTRIBUTION REGISTER\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 4_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG Integration Meeting Report*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Cliff Reader, Chairman*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe meeting faced the dual challenges of urgent need for three specific\nitems and a short schedule of only three days. The first item was an\ninstantiation of the MSDL syntax for NBC audio. This was needed to allow\nthe audio work to continue, and to bring the MSDL work \u201cdown to ground\u201d\nwith a concrete deliverable. The second item was a Call for Proposals,\nCfP, for the Hybrid Coding work. Lastly, a revised Project Description\nwas long overdue. To accomplish this work, the Integration group\neffectively split into several groups working in parallel. To maintain\ncoordination, a series of brief \u201cplenary\u201d sessions were held. The\nIntegration group appreciated the Convenor\u2019s efforts to substantially\nreduce the WG11 plenaries, the effect of which was to give almost a\nwhole day(!) to the subgroups."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDuring the meeting, MSDL activities followed two tracks:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe first, most urgent track concerned the use of MSDL to describe the\nsyntax of an existing algorithm, namely the NBC audio RM3 decoder. The\nmeetings were attended by audio experts who helped produce specific\nrequirements on the needed syntactic features jointly with experts from\nthe MSDL group. The MSDL group took these requirements into account to\nproduced some formal rules to describe the NBC Audio syntax. Document\nN1168 includes the result of this collaboration."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe requirements are not exhaustive and will be completed later on, for\nexample during construction of the audio VM. The set of formal rules\nhave been taken from document N1111 and improved by taking the previous\nrequirements into consideration. At this stage, all the syntactic\nfeatures to satisfy the request have not been developed but they are\nsufficient to describe the complete NBC syntax."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompared to the traditional pseudo-C code used in MPEG-2, there is added\nvalue given by describing the syntax in a formal way. The consistency of\nthis description can be tested contrary to the pseudo-C code approach.\nThis will allow an automated procedure for bitstream conformance and\nconsistency checking. Moreover, the formal description used is simpler\nand will improve readability. Note that the description does not\ndescribe a coding or decoding process. It is truly the description of\nthe interchange format."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe work on syntax description will be continued in an ad hoc group that\nis joint with video and audio (N1165)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe second track was concerned with clarification of the architecture.\nThis is a long-term effort, that needs thoughtful exchanges and feed\nback from many activities. It is intended to provide to all the MPEG\ngroups a vision of the global system definition for MPEG-4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe use of OMT representation and diagrams have enhanced the definition\nand the representation of the various MSDL objects. This notation has\nproven to be simple, clear, precise and useful. The intention is to keep\nit for the final class hierarchy definition."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe accomplishment of this meeting was a more consistent and solid\narchitecture for MSDL. This is documented in the MSDL Working Draft\nVersion 1.0, N1164. The goals and methods have converged significantly\nand the various MSDL concepts (including the ideas of scene composition,\nvirtual machines, ...) are finding their place in the work of all the\nMPEG subgroups. An ad hoc group will continue the work on architecture\nand the object hierarchy (N1167)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt this meeting, coordination took more concrete shape with the Audio\ngroup. Other joint meetings showed that interactions should now grow\nwith Video and SNHC group. A joint meeting was held with MHEG. Although\ninitialized, the collaboration with MHEG needs a focus that is still to\nbe found."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs part of the integration group, MSDL is helping the other subgroups\nachieve a final consistent, flexible and useful standard. This means :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* providing methodical tools and a global vision for developing and\nintegrating the different parts of the MPEG-4 standard.\n* collecting and integrating the requirements coming from the various\nsubgroups in this structure.\n* providing feed-back to the documents produced in MPEG, regarding this\nvision and methodology."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLastly, although the topics of coding methods and virtual machines were\nnot a focus of this meeting, an ad hoc group was established to gather\nrequirements for virtual machines in preparation for development of this\nsubject at the next meeting (N1166)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe objective of the SNHC AHG at the Munich meeting was to generate the\nCall for Proposals on Media Models. The CfP was to include an overview\nof the \"Virtual Playground\" purpose and content, the technical\nrequirements for the envisioned SNHC objects and bitstream coding, and a\nfinal PPD."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe effort required integration of the SNHC Audio group and their\nrequirements for the CfP. Video and Test people also alerted SNHC to the\nVOP paradigm emerging in Video VM work to represent video objects in\nsupport of the shape coding, scalability, and content-based\ninteractivity requirements of MPEG-4. VOP concepts generally appear to\nmesh well with SNHC objectives, although ultimate integration of object\ntypes in an MSDL class hierarchy supporting SNHC is not proven. Content\nand composition objects in MSDL work appear to reinforce SNHC\nrequirements. MSDL's object library development is expected to provide\nadequate flexibility to absorb novel modeling and coding techniques\ncontributed by SNHC CfP respondents."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe SNHC working sessions were organized in two phases: first a review\nof technology focus areas and document submissions pertaining to SNHC\nrequirements and second, a team-based writing and editing effort. Given\nthe state of preparation for this meeting, and the tight schedule at\nMunich, we did not complete the PPD portion of the CfP. Details in the\nVirtual Playground and Media Model Requirements were also less than\nmature, due to meeting time available, lively unresolved debate, and the\nneed to develop \"Virtual Playground\" theming, the proposal process, and\nplateaus in the scope of SNHC standardization more carefully."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe original scope of the Munich CfP was adjusted to an Advanced Notice\nof Call for Proposals. The AN of CfP was completed as document N1175.\nThis document covers: the requirements addressed by SNHC, the functional\narchitecture, the program of work, solicited technology, general\nproposal requirements and evaluation, milestones and schedule, Test Data\nSet and \"Virtual Playground\" (Annex A), the PPD (Annex B: to be supplied\nin March), and Media Model Preliminary Requirements (Annex C). Informal\nand formal submissions pertaining to MPEG-4 SNHC were discussed and\ndistributed (See the document listing at the end of this report).\nRequirements groupings were drawn from these and other subjects\ninitiated by attendees. After extensive discussion, the following areas\nwere selected for technology emphasis in the compression and real-time\nrequirements for the SNHC AN of CfP:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompression and simplification of synthetic data representations:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Synthetic and natural audio data, including 2D/3D sound sources"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Geometry (polyhedra, voxels, meshes, etc.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Photometry (normals, colors, surface properties, texture attachments)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Animation and deformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Images and video imbedded in 2D/3D"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nParameterized animated models:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Encoding of parameterized models"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Encoding of parameter streams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNew primitive operations for compositing of natural and synthetic\nobjects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScalability for:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Extracting time-critical data subsets consistently across hybrid\nmodels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Time-critical rendering & trade-offs in temporal/spatial scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nReal-time interactivity with hybrid environments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRigorous modeling of timing and synchronization in hybrid models"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSynthetic audio:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- 3D localization"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- audio attached to 3D geometry"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- MIDI or higher-level symbolic musical data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- extensibility"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSNHC members were very dedicated in the long SNHC working sessions in\nMunich to complete the AN of CfP. We had solid participation in Munich\nessential for us to progress as we did. We enjoyed new members with\nhybrid A/V and graphics background. We should thank all who invested\nthemselves in this work, argued and cemented important issues, and added\nsubstance with their contributions. We should amplify this focus of\ninterest which members are now demonstrating."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe schedule for the program of work of SNHC had been questioned as very\naggressive. The existing planned WG11 meeting schedule would require\nvery rapid industry preparation of proposals and utilization of the test\ndata set, potentially discouraging important participation and\nsubmissions. A recommendation was to add a WG11 meeting in September\n1996, consistent with like desires of the Video group. The AN of CfP\nmilestones were then phased ahead of the September meeting to\naccommodate more reasonable proposal work. Scheduling for test data set\ndevelopment and proposal submissions was adjusted accordingly. The work\nof SNHC will continue in the re-established ad hoc group (N1160)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSome objections were raised about use of the terminology \"Virtual\nPlayground\" conveying a less-than-serious professional overture to\npotential proposal submitters from fields such as scientific\nvisualization. The term was originally coined to appeal to the artistic\ncommunity of content developers in the games and education community.\nThe MPEG Integration group was asked to recommend more widely identified\nlanguage that will convey broader application domains and attract\ndifferent professional engineering cultures to contribute to both the\nopen and controlled versions of the \"Virtual Playground\". It must be\nremembered however, that the scientific uses represent niche\napplications compared to the mass consumer markets MPEG4 is expected to\nserve."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-----------------------------------------------------------------------------"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/0618. (Munich) Yong Han Kim, ETRI, On Requirements for SNHC for\nIts Application to Desktop Digital Studio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG95/0464 (Dallas) Eric Petajan, Hans Peter Graf, AT&T Bell Labs.,\nFace Feature Analysis & Communication for Face Animation in MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUnreg'ed Moezzi/Katkere/Jain Visual Computing Laboratory, UCSD (given by\nA. Luthra) Interactive 3D Digital Video in MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUnreg'ed. Colin Campbell Microsoft Corp (given by W. Powell) Untitled\n--- MPEG-4 Requirements, Rich. Media Types, Interactive Media, Media\nIntegration, Independence of Run-Time Environment, Architectural\nProvision for Distribution, Broadcast & Push/Pull Modes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUnreg'ed. Richard Lerner, Amerinex Artificial Intelligence (given by P.\nDoenges), Synergy Between MPEG-4 & the Image Understanding Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUnreg'ed. Cliff Reader, Samsung Semiconductor, MPEG-4 Virtual\nPlayground, (SNHC reflector)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUnreg'ed. Peter Doenges, Evans & Sutherland, Detailed Agenda for SNHC at\n33rd WG11 Munich, (SNHC reflector)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUnreg'ed. Peter Doenges, Evans & Sutherland, Initial Vision,\nApplications, Object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRequirements for MPEG-4 SNHC, (SNHC reflector)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUnreg'ed. Itaru Kaneko, GC Laboratories, MPEG4-SNHC Draft SNHC/Audio AHG\nReport, (SNHC reflector)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nKey related documents:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/N1172 MPEG-4 Video Group MPEG-4 Video Verification Model, Version\n1.0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/0669 Atul Puri, AT&T Bell Labs., Report of Ad Hoc Group on\nCoordination of Future Experiments in MPEG-4 Video"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/0642 Touradj Ebrahimi, EPFL, Report of Ad Hoc Group on Definition\nof VMs for Content-based Video Representation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThanks to the dedication and excellent writing skills of one\nparticipant, a new MPEG4 Project Description was produced (N1177). The\nIntegration group thanks the Convenor for this welcome assistance!"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 5_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG Video Meeting Report*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: T.Sikora, Chairman*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG-2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDuring the Munich MPEG meeting the MPEG-2 4:2:2 Profile extension was\npromoted from DAM to AM status, based on the test results for subjective\nverification of the 4:2:2 Profile, detailed in document N1134, and the\nsuccessful completion of the remaining 4:2:2 Profile conformance testing\nissues. Document N1159 provides the details of the promotion of the\n4:2:2 Profile to Amendment 2 of ISO/IEC IS 13818-2."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor the MPEG-2 Multiview Profile the work also concentrated on issues\nrelated to bitstream verification and subjective verification tests. The\nvideo group held joint sessions with the Test Subgroup to discuss\ndetails of the subjective verification tests for the extension. A\npromotion of the Multiview extension to DAM is expected for March 1996."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor the MPEG-4 standardization phase the main activities focused on the\nevaluation of the tools and algorithms submitted to the MPEG-4 second\nround of tests, on the definition of the first MPEG-4 Video Verification\nModel and on the establishment of associated MPEG-4 Core Experiments."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn an AdHoc group meeting, which was hosted by Deutsche Telekom in\nMunich on the 20th and 21st of January 1996, the remaining tools and\nalgorithms submitted to the second round of MPEG-4 tests were evaluated.\nAs a result a number of tools and algorithms were recommended to the\nMPEG Video Group for further review. Document N1162 details the report\non the evaluation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Munich MPEG meeting witnessed the completion and approval of the\nfirst draft of the MPEG-4 Video Verification Model 1.0, described in\ndocument WG11 N1172. Many of the functionalities outlined in the MPEG-4\nPPD require means for interaction and manipulation of visual information\non the bitstream level, and the provision to cater for source input data\ncomposed of synthetic and natural scenes. The architecture of the\nVerification Model supports a content based layered representation\n(Video Object Planes) of the input source to assist these\nfunctionalities. A first set of Core Experiments was defined based on\nthe outcome of the first and second round of MPEG-4 tests, to\ncollaboratively improve the Verification Model in future MPEG meetings."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nConsidering the tight MPEG-4 time schedule, with the definition of the\nfirst MPEG-4 Video Working Draft targeted for the November 1996 MPEG\nmeeting, the Video Group recommends to organise an additional MPEG\nmeeting in September 1996."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 6_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG Audio Meeting Report*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: P. Schreiner, Chairman Audio Subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nD. Meares, Secretary Audio Subgroup"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Status: Draft*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n96-04-05 09:35 AM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. Opening of the meeting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MPEG/Audio Subgroup meeting was held during the 33rd meeting of WG11\nin Munich, Germany on January 22 to 24, 1996. The list of participants\nis given in Annex A-I. The Chairman welcomed the delegates to the\nmeeting and outlined the work for the three days. He explained the\npurpose and scheduling of the joint activities with other groups."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2. Approval of agenda*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe agenda as presented in Annex A-II was discussed and approved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3. Dallas meeting report*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe audio part of the Dallas meeting report had been previously\ndistributed and was approved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4. Allocation of contributions*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll contributions were listed (see section 13) and allocated to the\nagenda. All contributions were presented either in Audio plenary or in\nthe task group discussions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5 Ad-hoc group reports*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.1 Ad-hoc group on MPEG-2 audio NBC (13818-7) Working Draft\ndevelopment, M0628 - Bosi*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis was reported in plenary as having very few contributions via\ne-mail. Ms Bosi encouraged contributions during the week."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n5.2 Ad-hoc group on NBC syntax development, M0626 - Brandenburg"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition to the e-mail exchanges, an informal group met before the\nMunich meeting in order to look for some consensus in the views. As a\nresult, an annex to the report was able to propose an NBC syntax for\nfurther discussion at the Munich meeting. Mr. Brandenburg described the\ndetails of the proposal to the meeting. The recommendation that the\nproposal be treated as a working draft for the week was accepted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n5.3 Ad-hoc group on *a revision to IS 13818-3, M0677 - Stoll*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis group had reviewed the UK editorial suggestions and had approved\ntheir adoption. Additional changes to resolve the conflict between\nprediction and dynamic crosstalk had been resolved at the Dallas\nmeeting. Further changes were reviewed to cover factors relating to LFE\nsyntax."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n5.4 Ad-hoc group on SNHC/Audio (synthetic audio coding), M0610 - Kaneko"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Kaneko presented an overview of the way that SNHC would apply to\naudio. In principle, it could be used to introduce spatialisation into\nsound such that as you move a virtual picture source around a stage the\nsound signature will be processed accordingly. The report of the group\nlists all the functionality of the SNHC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n5.5 Ad-hoc group on complexity of NBC RM2 features, M0662 - Quackenbush"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe only progress in this ad-hoc group was an input from Sony,\nMPEG96/M0652 on their estimation of coding complexity for their\nproposal. This looked at the compromise between storage needs and\nprocessing power. Mr. Zuccaro of Implementation Group attended this\npresentation, and further contact was organised."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.6 Ad-hoc group on audio conformance testing, M0xxx - Kerkhof*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAlthough Mr. Kerkhof could not attend this meeting and despite the\nad-hoc group\u2019s mandate having been formally extended to the March 1996\nmeeting, an interim, informal copy of the groups report was presented to\nthe Audio Subgroup by Mr. Stoll. Mr. Stoll reported that the bitstream\ntests are now showing successful decoding for all bitstreams for which\ndecoding had been attempted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere were eight bitstreams (10, 11, 12, 13, 21, 22, 23 & 32) that had\nnot so far been encoded, and several others not decoded. The group will\nfill in the gaps as follows."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"30%,37%,33%\",]\n|===\n|Bitstream No |Encode by |Decode by\n|10 |Philips |IRT\n|11 |Philips |IRT\n|12 |Philips |IRT\n|13 |IRT |CCETT\n|21 |Philips |Samsung\n|22 |Philips |CCETT\n|23 |FhG |BBC\n|24 - 26 |Philips |IRT\n|27 - 29 |Philips |IRT\n|30 - 31 |Philips |RAI\n|32 |IRT |CCETT\n|33 |Philips |IRT\n|34 |Philips |IRT\n|35 |Philips |IRT\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.7 Ad-hoc Group on MPEG-2 Audio Technical Report, M0676 - Rowlands*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis report was presented by Mr. Thom. The full Layer 2 decoder software\nand near full encoder (omits prediction and non-zero delay) are on the\nftp site. Also full Layers I and III LSF encoder and decoder are on the\nftp site. All but one of the test bitstreams had been decoded correctly."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n5.8 Ad-hoc Group to conduct second set of MPEG-2 Audio NBC RM2 core\nexperiments and the MPEG-4 audio listening test evaluation for 64 kb/s\nsubmissions, M0640 - Schreiner"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Schreiner presented the report of the MPEG-2 NBC RM2 and MPEG-4 64\nkb/s test ad-hoc group. The tests had taken place since the Dallas\nmeeting, November 1995, and discussion had continued in the ad-hoc group\nmeeting immediately prior to this meeting. The ad-hoc group had reviewed\nthe tests results and had decided that for both groups of tests some of\nthe test site information and procedures were inconsistent. As a result,\nthe ad-hoc group had decided to eliminate the inconsistent results from\nthe overall analyses. This had produced tighter confidence bounds for\nthe remaining results despite the reduced number of test results. The\nproblems of inconsistency will have to be studied and addressed in the\ncontext of further tests to avoid them next time."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe group also reviewed the lossless coding proposals and have\ndetermined that certain features should be input into NBC RM3\nconsiderations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRM3 will be based on RM2 (FHG-D1) with the following additional features"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Improved features from FHG-QC, including target syntax\n* 1 bit for the DOL-TF switching\n* Lossless coding according to modified AT&T proposal\n* Additional lossless coding according to techniques similar to the NEC\nproposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe next stage of core experiment tests will evaluate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* RM2 (FHG-D1), as reference to previous test results\n* RM3\n* Advanced block switching from modified DOF-TF\n* Pre-processing from SON_PP\n* Time domain noise shaping from AT&T"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe group had also discussed the test techniques to be used for the\nfuture evaluations and had noted that loudspeaker assessments now needed\nto be included. The report of the ad-hoc group meeting in Munich is\ncontained in the ad-hoc group report, M0640."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.9 Ad-hoc group on MPEG-4 Audio evaluations, M0680 - Pan*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis group had considered the 16 proposals that were received as a\nresult of the November 1995 call. 7 were felt to be minor modifications\nof earlier proposals and 9 proposals lacked sufficient technical\ndetails. The group had recommended that some proposals be considered\nfurther in the development of the verification models (VMs)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.10 Ad-hoc Group on MPEG-4 Audio test, M0634 - Edler*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Edler presented an overview of the mammoth task undertaken by his\ngroup. The report runs to about 100 pages and thus gives problems in\ncopying for the group. There was understandably a strong desire by\nmembers to have access to the results during this meeting, so this was\nfacilitated. Work would continue during the MPEG meeting to determine\nthe significance of the data in the many possible comparisons between\ncodecs in the different functionalities tested. It was noted that\ndocument formatting problems resulting from the nonstandardisation of\nthe international versions of Microsoft Excel 5.0 were delaying\nprogress."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6. Temporary Task Group Formation*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo accomplish the large number of tasks to be performed by the Audio\nSubgroup, 5 task groups were formed as indicated in Annex A-IV. The\nresults of each of the task groups were presented to and discussed by\nthe entire Audio Subgroup, including iterations as necessary. The\nconclusions of the task groups are included in the output documents."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*7. Subjective test results obtained since the last meeting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n7.1 NBC tests results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Meares presented the report written by himself and Sang-Wook Kim,\ndocument M0551. The methodology of the tests was briefly discussed,\nalong with mention of those who had contributed at various stages to the\ntest effort. In analysing the results, the authors had found that there\nwere some serious problems with results from two test sites, and this\nhad led the Ad-hoc Group to recommend that the data from these sites be\nremoved from the analysis: this having been done, the confidence\nintervals in the results had been reduced. The Audio Subgroup endorsed\nthis decision. Mr. Meares then presented the revised plots of results."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn discussion, it was noted that the results for the different modules\nwere not statistically different and thus ranking of the proposals could\nnot be based solely on these results. However, some pointers from the\nresults could be considered by the Task Group in developing the RM3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn additional feature of the accepted results was noted during\ndiscussion. In the information from the test sites, several admitted\nthat they had \u2018used expert listeners\u2019 and therefore did not carry out\nthe required training phase of the tests. Significantly, these sites had\nreturned results with wider confidence bounds than had those sites who\nhad carried out the training. It was resolved that in all future tests\nthe training phase will be mandatory."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe revised results and full details of the tests are contained in\noutput document WG11/N1135."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*7.2 MPEG-4 64 kb/s test results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOn behalf of the author Scott Diamond, Mr. Meares presented the results\nof these tests, document M0561. Again during the Ad-hoc Groups appraisal\nof the report, it was noted that one of the sites, which was not\ncompliant with the requirements of the tests, had returned results\nconsiderably different from the other sites: their results were\neliminated from the final analysis. The conclusions from these tests are\nthat some of the test modules were statistically different from others,\nand that the better modules were using features already contained in\nMPEG-2 NBC RM2. It was also noted that the requirement for\nfunctionalities in addition to compression for the codecs required in\nMPEG-4 tests was leading to lower diff-grades due to the increased\ncomplexity. The results of the MPEG-4 64kb/s tests were considered\nduring the NBC RM3 development."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe revised results and full details of the tests are contained in\noutput document WG11/N1136."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*7.4 MPEG-4 Subjective test results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt various stages during the meeting, the MPEG-4 tests results, document\nM0630, were discussed, both by the entire Audio Subgroup and by the Task\nGroup. The report is very thorough and the tables and diagrams are\nextensive. The Audio Subgroup congratulated Mr. Edler and Ms Contin for\ntheir excellent and extensive data analysis."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOn behalf of the Task Group, Mr. Grill sought and received one page\ntechnical summaries of the proposals. As in the past, these descriptions\nwere found to be very variable in the amount and type of information\nprovided and thus an editing group drafted out a set of requirements for\nall future technical proposals. This is given in document WG11/N1179.\nAdditional descriptions were requested from the MPEG-4 proponents in the\nfollowing resolution:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cthat the proponents of MPEG-4 Audio proposals for the VM submitted for\nevaluation and test provide technical descriptions of their proposals in\nline with WG11/N1179 to the chair of the ad-hoc group on Audio VM, Mr.\nEdler. The submissions relating to evaluation proposals are required by\n18 March 1996: the proposals relating to tested modules are required by\n23 February 1996.\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis resolution was approved by the Audio Subgroup, but unfortunately,\ndue to timing problems, was not communicated to the Convenor in time to\nbecome a WG11 resolution. It is, however, expected that the Audio\nmembers will comply with their agreement to the resolution of the Audio\nSubgroup."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe approved MOS test results report is contained in document\nWG11/N1144."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*8 Task group reports*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n8.1 *MPEG-2 Technical report finalisation - Thom* The Technical report\nis completed apart from a few details. However, if IS13818-3 is revised\nthen that will have impact the Technical report and the Conformance\ndocuments. Volunteers were obtained to complete several outstanding\ntasks as indicated in the table below."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"65%,35%\",]\n|===\n|Decoder verification with conformance bitstreams |Telekom , TI, CCETT\n|Internal encoder to internal decoder verification |IRT, Telekom\n|Internal encoder to external decoder verification |IRT, TI\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*8.2 RM3 development including syntax leading to WD - Bosi* Ms. Bosi\npresented the draft revisions to NBC RM2 progressing the documents\ntowards the embodiment of NBC RM3 and the WD input. All of the revisions\nwere discussed and several conditions of the next set of core\nexperiments were debated. In addition to this, it was noted that, while\nthe test of \u2018prediction-off\u2019 as requested by the USNB at the Dallas\nmeeting could not be accommodated during these tests, it needed to be\ntested as soon as possible. Also, a core experiment with window\nswitching removed would be needed to justify the retention of this\ntechnique in the Reference Model."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe verified changes to NBC RM2 have been incorporated in RM3. Document\nWG11/N1132 contains the revised details."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe preliminary WD for NBC, based on an e-mail distribution by Ms Bosi,\nwas discussed. Volunteers were collected for the drafting work. This\neffort will continued with ad-hoc group work. Templates for documents\nwill be identified, as will a suitable drawing package. The format of\nthe WD is contained in WG11/N1151"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*8.3 RM3 core experiment design and schedule (to include loudspeaker\ndetails) - Quackenbush/Fuchs* Mr. Quackenbush presented the work of this\ntask group. The group had considered all aspects of both the mono and\nstereo tests, the latter using both headphones and loudspeakers. The use\nof loudspeakers was seen to require substantial control of the test\nenvironment and a minimum specification was drafted. In discussion in\nAudio plenary, it was noted that the lack of training at some test sites\nin the past had given rise to higher degrees of uncertainty in the\nresults. It was decided that all test centres *must* in the future run\nspecific training for each set of tests, and all listeners, irrespective\nof their apparent degree of expertise, *must* perform the training\ntasks. Commitments were obtained for the supply of source test material\nfor both the stereo and the mono experiments. The time lines and test\ndetails for the NBC RM3 tests are given in document WG11/N1150."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*8.4 VMs for MPEG-4 - Edler* All ** MPEG-4 proposals were considered at\nlength by this Task Group and discussed with the aim of developing a\ncommon VM. Means of identifying common groups amongst the proposals were\nidentified as follows:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Codecs based on time/frequency mapping\n* LPC-based Analysis/Synthesis codecs\n* Codecs based on a parametric description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProposal analysis based on this grouping allowed a provisional VM to be\nproposed. The record of this work is given in WG11/N1143. The work on\nVMs will continue into the ad-hoc group to be chaired by Mr. Edler."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*8.5 MPEG-2 IS13818-3 revision - Stoll* The work of this group went\nwell, but even so there was seen to be a need to carry the checking\nactivity into an ad-hoc group. The mandate for this group requires that\nthe full revised text be prepared prior to and presented at the March\nmeeting. The edited text and the basis of the editing is recorded in\ndocument WG11/N1152."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn discussion, it was observed that the UK document WG11/N0972 (July\n95), had requested that the relevant sections of IS11172-3 be copied\ninto IS13818-3, rather than just be referenced. This, however, would\nsignificantly increase the size of IS13818-3 and lead later to problems\nin ensuring that the two texts were kept in step, one with the other. It\nwas decided therefore not to import extensive sections of IS11172-3, and\nMr. Meares, as UK HOD, undertook to report this back to the UK."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*9. Additional papers*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*9.1 Tape production*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Quackenbush presented his paper, document M0559, on the way in which\nAT&T had prepared the automatic editing program for test tape\npreparation. This treats all announcements, and stimuli as computer\nfiles and generates DAT recordings in a controlled random fashion. The\ngroup went on to discuss the additional problems of a multichannel\nequivalent. This will be addressed in a joint ad-hoc group with Test."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*9.2 NBC noise masking*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Quackenbush presented to the group document M0558 on noise masking\nas applied by AT&T to NBC. This he described as effectively noise\nshaping in the time domain which leads to better masking of signals with\ntransient content without going into short block length. The results\nshow for male speech and RM2 a coding benefit of about 1.3 diff-grade\npoints."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*9.3 Bibliography*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDuring the meeting, Mr. Meares prepared a bibliography of the Audio\nSubgroup\u2019s input and output documents since he started working as\nSubgroup Secretary in July 1994. This was well received by members and\nthus converted into output document WG11/N1137."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*9.4 NBC data processing spreadsheet*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Meares also prepared the descriptive text and an edited spreadsheet\nto describe the spreadsheet features which enabled the NBC data and\nMPEG-4 64 kb/s data to be analysed. This was immediately requested by a\nnumber of people in the Audio and Test Subgroups and was converted into\noutput document WG11/N1138. (The electronic version contains both text\nand spreadsheet files.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*10. Consideration of National Body Comments*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo National Body comments were communicated to the Audio Subgroup."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*11. Liaison with other bodies*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n11.1 ITU-R 11-3 and 10C"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn his document M0681, Mr. Stoll references an ITU-R document, document\n11-3/88. Both the ITU-R document and the input paper were described to\nthe group. The essence of the discussion was that a special Rapporteur\nto ITU-R TG11-3 had presented a summary of previous results relating to\nboth MPEG-1 and MPEG-2 tests which omitted much of the essential details\nof the test results and some vital details from the conclusions of the\nreports quoted. This would lead to incorrect conclusions with respect to\nMPEG compliant codecs. Much of the information was already available\nwithin the ITU-R but in the groups WP10C and TG10-3. It was decided\ntherefore to raise the matter through a liaison statement and to forward\nthe information, with the liaison, to ITU-R SG 11, TG 11-3 and WP 10C.\nReport WG11/N0685 which contains the quoted results was approved for\nforwarding to ITU-R. The Liaison statement, WG11/N1174 includes\nreferences to other MPEG test results with the offer to forward them\nalso to ITU-R if requested."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*11.2 ITU-T/SG 15 - WP2/15*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTwo questions, namely 6/15 and 7/15, being addressed by WP2/15 are known\nto reference work related to the coding of speech at low bit rates. The\nAudio Subgroup therefore decided to advise ITU-T of our latest MPEG-4\nMOS tests and to send to them a copy of the results report, WG11/N1144.\nThe Liaison statement is WG11/N1173."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*12. Joint* *Subgroup Activities*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n12.1 Test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA meeting was held with Test to consider all aspects of the way in which\naudio tests had been conducted and the options for improvements for\nfuture tests. Concerns were expressed by both Test and Audio members\nover inadequate training, numbers of listeners at each site, control and\nspecification of room acoustics for loudspeaker assessments, etc. for\nthe brief format tests being used for the NBC reference model core\nexperiment work.. Test will consider the multichannel coding test\ndetails contained in N0685 in the work of an ad-hoc group, whose mandate\nis given in WG11/N1142."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn subsequent discussion in Audio plenary, Mr. Johnston noted that the\n\u2018reverberation distance\u2019 is an important factor and that different\nresults may be generated by carrying out tests in circumstances where\nthe listener is either inside or outside the reverberation distance. In\nview of ITU-R\u2019s work in this area, it was agreed that Mr. Meares would\ninformally communicate this opinion to the chair of ITU-R TG 10-3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*12.2 Implementation*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe NBC RM3 coder complexity issues were discussed by Audio members with\nImplementation. Implementation were encouraged to think in terms of\nsignal processing rather than C code. NBC RM2 decode source code was\nprovided to be used as a test case for the Implementation complexity\nanalysis work."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*12.3 Integration*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n12.3.1 SNHC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Kaneko presented the Audio SNHC considerations to both the Audio\nSubgroup and SNHC. The needs of the Audio Subgroup were successfully\nmarried into the joint paper WG11/N1175. The SNHC call for proposals was\nmodified to an advanced notice of the formal call stating the purpose of\nthe call and the schedule of activities relating to the formal call. It\nwas recognised that detailed requirements for the call must be developed\nprior to the issuance of the call."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*12.3.2 MSDL*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Johnston joined MSDL at various times and went over the NBC RM2\nsyntax with them. The MSDL members were given a concrete example to work\nwith. It was observed that MSDL are considering bitstream as a language\nrather than a process. The meetings were found to be mutually\nbeneficial."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere were a series of exchanges with MSDL in the form of members from\nAudio or MSDL joining each other\u2019s meeting for discussions. The aim was\nto incorporate MSDL into the NBC syntax. This is achieved in document\nWG11/N1168."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt should be recorded that not all members of the Audio Subgroup see the\nimmediate benefit of MSDL as no supporting tools are available to\nconvert this into microprocessor instructions, but it was accepted that\nit may develop into a useful higher level descriptive language."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt was agreed that the NBC reference model work would continue to use\npseudo C code descriptions in addition to the use of MSDL. The pseudo C\ncode is the common construct used in MPEG-2, and the MSDL is the native\nconstruct of MPEG-4. The MPEG-2 NBC work is being used for the\ntransition from pseudo C representation to the use of MSDL. The time\ncritical NBC schedule will be used to further the development of MSDL."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*13. Contributed documents*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following documents were contributed to the Audio Subgroup:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"16%,25%,59%\",]\n|===\n|Number |Source |Title"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0551 |David Meares, Sang-Wook Kim |NBC Reference Model 2 subjective\ntests: overall results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0558 |S. R. Quackenbush, J. D. Johnston, J. Herre |An Improved NBC RM2\nNoiseless Coding Kernel"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0559 |S. R. Quackenbush |An Automated Method for Making Tapes for\nHigh-Quality Subjective Listening"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0560 |J. Herre, S. R. Quackenbush, J. D. Johnston, D. Sinha |An\nEnhanced Noise Masking Technique for the MPEG-2 NBC RM2 Audio Coder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0561 |Scott Diamond |MPEG-4 Audio 64 kbps subjective tests: overall\nresults"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0562 |Masayuki Nishiguchi, Jun Matsumoto, Shiro Omori, Kazuyuki Iijima\n|Report on tape preparation and MOS tests in Sony for 6.0 and 2.0 kbps\ncoders for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0563 |Jean-Bernard RAULT |Proposal for changes in the 13818-3 syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0574 |Anibal Ferreira |Re-submission of the INESC audio coding proposal\n(technical update)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0575 |Anibal Ferreira |An improved functionality: static selection of\nthe coding delay mode"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0580 |Kenzo Akagiri, Takashi Koike |Technical description of Sony's\ncoding algorithm for MPEG-4 Audio 24kbps compression coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0581 |Kenzo Akagiri, Takashi Koike |Technical description of Sony's\ncoding algorithm for MPEG-4 Audio bitrate scalability coding (64 kbps-24\nkbps - 6 kbps)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0584 |Naoki Iwakami, Kazunaga Ikeda, Takehiro Moriya, Satoshi Miki,\nAkio Jin |NTT's improved audio coder for 24 kbit/s and above"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0585 |Takehiro Moriya, Satoshi Miki, Akio Jin, Naoki Iwakami, Kazunaga\nIkeda |NTT's audio/speech coders in harmony with the ITU-T\nstandardisation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0588 |Daniele SERENO, Michele FESTA |Detailed description of the\nimproved MAVT MPEG-4 audio candidate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0591 |Masayuki Nishiguchi, Jun Matsumoto, Shiro Omori, Kazuyuki Iijima\n|Technical description of Sony IPC speech coder for MPEG-4 additional\ncall for proposals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0593 |Ah-Peng Tan |Technical Description of Proposal for MPEG-4 Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0606 |Bob Dyas |AMP - Audio Matching Pursuits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0607 |James Thi |Technical Description of The Rockwell Audio Coding\nProposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0608 |Dr. Huan-yu Su |Technical description of Rockwell's speech coding\nproposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0610 |I. Kaneko |Chairman\u2019s report on the work of the Audio ad-hoc\ngroup on SNHC/Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0611 |I. Kaneko |Description of GCL\u2019s experiment for NBC core\nexperiment 2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0626 |Karlheinz Brandenburg |Report of the Ad-hoc Group on NBC syntax\ndevelopment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0628 |Marina Bosi |Report of the Ad-hoc Group on MPEG-2 Audio NBC\n(13818-7) Working Draft Development"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0630 |Bernd Edler |MPEG-4 Audio Test Results (MOS Tests)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0632 |Bernd Edler, Heiko Purnhagen |Technical Description of the MPEG-4\nAudio Coding Proposal from University of Hannover and Deutsche Telekom\nAG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0634 |Bernd Edler |Ad Hoc Group on MPEG-4 Audio test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0635 |Gerald Schuller, Bernd Edler |Description of a Filter Bank with a\nLow System Delay as a Tool for Audio Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0638 |Bernhard Grill, Thomas Sporer |Technical description of the Error\nResilience Supplement to the Contribution of the University of Erlangen\nand FhG-IIS to MPEG-4 Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0640 |P. G. Schreiner III |Report of the Ad-Hoc Group to Conduct the\nSecond Set of MPEG-2 Audio NBC Reference Model 2 Core Experiments and\nthe MPEG-4 Audio Listening Test Evaluations for 64 kb/s Submissions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0644 |Mike McLaughlin |Speech Coding for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0648 |J. D. Johnston, S. R. Quackenbush |Stereo Pair Joint Coding in\nthe NBC Reference Model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0652 |Kenzo Akagiri |Complexity estimation on NBC preprocessing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0658 |Masahiro Iwadare |Technical description of MPEG-2 NBC lossless\ncoding by NEC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0662 |S. R. Quackenbush |Report of the Ad-hoc Group on Complexity of\nNBC RM2 Functions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0668 |William Navarro |Improved MAVT MPEG-4 Audio Candidate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0676 |Jon Rowlands |Ad-hoc Group on MPEG-2 Audio Technical Report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0677 |Gerhard Stoll |Report of the Ad-Hoc Group on revisions to IS\n13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0680 |Davis Pan |Ad-hoc group on MPEG-4 Audio evaluations"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0681 |Gerhard Stoll |Comment on the ITU-R special Rapporteur document\n11-3/88-E (20. October 1995) with the title: \" tutorial information on\nmultichannel audio coding methods recommended for digital television\nsystems\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0xxx |Leon van de Kerkhof |Report of the Ad-hoc group on editing the\naudio-related part of DIS ISO/IEC 13818-4\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *14. Output Documents*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following output documents were produced by the Audio Subgroup:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"16%,25%,59%\",]\n|===\n|N1132 |Marina Bosi |MPEG-2 Audio NBC (13818-7) Reference Model 3 (RM3)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1135 |David Meares, Sang-Wook Kim |NBC Reference Model 2 subjective\ntests: overall results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1136 |Scott Diamond |MPEG-4 Audio 64 kbps subjective tests: overall\nresults"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1137 |David Meares |Bibliography of Audio Subgroup documents"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1138 |David Meares |A description of the EXCEL 5 spreadsheet used for\nAudio NBC test results analysis"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1143 |Bernd Edler |Preliminary Draft of MPEG-4 Audio Verification\nModel"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1144 |Bernd Edler, Laura Contin |MPEG-4 Audio Test Results (MOS Tests)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1145 |Peter Schreiner III |Ad-Hoc Group to Conduct the of MPEG-2 Audio\nNBC Reference Model 3 Core Experiments: Mandate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1146 |Convenor |Ad Hoc Group on MPEG-4 Verification Models: Mandate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1147 |Convenor |Ad-hoc group on MPEG-2 Audio NBC (13818-7) Reference\nModel 3 (RM3) Specification and Working Draft Development: Mandate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1148 |Convenor |Ad Hoc Group on finalising revisions to IS 13818-3:\nMandate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1149 |Convenor |Ad-hoc Group on the SNHC/Audio: Mandate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1150 |Schuyler Quackenbush |MPEG-2 NBC RM Audio Test Plan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1151 |Marina Bosi |Preliminary MPEG-2 Audio NBC (13818-7) Working\nDraft"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1152 |Gerhard Stoll |Draft Revisions to IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1168 |MSDL and Audio Subgroups |Description of NBC Audio Syntax with\nMSDL"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1173 |Convenor |Liaison to ITU-T/SG 15 - WP2/15 - Questions 6/15 and\n7/15."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1174 |Convenor |Liaison statement to ITU-R Study Group 11, Task Group\n11/3 and Study Group 10."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1175 |SNHC and Audio Subgroups |MPEG-4 Synthetic Natural Hybrid\nCoding: Advanced Notice of Call for Proposals."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1179 |S. Quackenbush, K. Brandenburg, M. Bosi |Requirements for\nSubmission of Technical Proposals to MPEG Audio\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*15. Ad-hoc groups*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following ad-hoc groups were established:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[loweralpha]\n. Ad Hoc Group on MPEG-2 NBC RM3 Audio test, N1145 - Schreiner\n. Ad-Hoc Group on MPEG-4 VM, N1146 - Edler\n. Ad Hoc Group on RM3 specification and WD, N/1147 - Bosi\n. Ad Hoc Group on revisions of 13818-3, N/1148 - Stoll\n. Ad Hoc Group on SNHC Audio, N/1149 - Kaneko"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTheir mandates and memberships are given in the Annex A-V."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*16. Recommendations*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA list of recommendations was prepared for approval at the final MPEG\nplenary meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*17. Agenda for next meeting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe agenda for the next MPEG Audio meeting in March \u201896 in Florence was\napproved (see Annex A-III)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*18. Close of meeting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Schreiner thanked the participants for all their hard work in\npreparation for and during this meeting. He also thanked the hosts for\nthe facilities provided. With that, he declared the Audio Subgroup\nmeeting closed and wished members a safe return journey."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex A-I*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n33rd MPEG/Audio Munich Meeting Participant List (January 1996)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,12%,28%,40%\",]\n|===\n|Name |Country |Affiliation |e-mail address\n|Akagiri, K. |J |Sony |ken@av.crl.sony.co.jp\n|Bont F.d. |NL |Philips CE |debontf@ce.philips.nl\n|Bosi, M. |USA |Dolby Laboratories |mab@dolby.com\n|Brandenburg, K. |DE |FhG - IIS |bdg@iis.fhg.de\n|Contin, Laura |I |CSELT |laura.contin@cselt.stet.it\n|Dietz, M. |DE |FhG-IIS |diz@iis.fhg.de\n|Dimino, G. |I |RAI |dimino@crrai.it\n|Edler, B. |DE |University Hannover |edler@tnt.uni-hannover.de\n|Ekudden, E. |S |Ericsson |erik.ekudden@era-t.ericsson.se\n|Ferreira, A. |I |INESC |ajf@inescn.pt\n|Fuchs, H |DE |University of Hannover |fuchs@tnt.uni-hannover.de\n|Grill, B. |DE |Univ. of Erlangen |grl@lte.e-technik.uni-erlangen.de\n|Hong, J.W. |KR |ETRI |jwhong@audio.etri.re.kr\n|Hotani, S. |J |NTTDoCoMo |hotani@mlab.nttdocomo.co.jp\n|Iwadare, M. |J |NEC |sc29a@dsp.cl.nec.co.jp\n|Johnston, J. |USA |AT&T |jj@research.att.com\n|Kaneko, I. |J |GCL |itaru-k@gctech.co.jp\n|Kim, S-W. |KR |Samsung |swkim@dspsun.sait.samsung.co.kr\n|Koike, T. |J |Sony |koike@av.crl.sony.co.jp\n|Lindqvist, M. |S |Ericsson |morgan.lindqvist@era-t.ericsson.se\n|Lueck, C. |USA |TI |lueck@hc.ti.com\n|Mainard, L |Fr |CCETT |lmainard@ccett.fr\n|Matsumoto, J. |J |Sony |jun@pcrd.sony.co.jp\n|Meares, D. J. |UK |BBC |david.meares@rd.bbc.co.uk\n|Miki, S. |J |NTT |miki@splab.hil.ntt.jp\n|Miyasaka, S. |J |Matsushita |miyasaka@ arl.drl.mei.co.jp\n|Moriya, T. |J |NTT |moriya@splab.hil.ntt.jp\n|Muller, J-M. |DE |Bosch Telekom |jmm@bk.bosch.de\n|Navarro W. |Fr |Matra Communication |wnavarro@matra-com.fr\n|Nishiguchi, M. |J |Sony |nishi@pcrd.sony.co.jp\n|Oikawa, J |J |Sony |oikawa@av.crl.sony.co.jp\n|Oomen, W. |NL |Philips |oomena@prl.philips.nl\n|Pan, D. |USA |Motorola |pan@ukraine.corp.mot.com\n|Parladori, G. |I |Alcatel Telettra |gparladori@tlt.alcatel.it\n|Quackenbush, S. |USA |AT&T |srq@research.att.com\n|Schreiner, P. G. |USA |Scientific Atlanta |pgs@sciatl.com\n|Schwalbe, R. |DE |Deutsche Telekom AG |schwalbe@audio.fz.telekom.de\n|Sereno, D. |I |CSELT |daniele.sereno@cselt.stet.it\n|Stoll, G. |DE |IRT |stoll@irt.de\n|Suzuki, M. |J |Pioneer |masa@crdl.pioneer.co.jp\n|Tan, Ah-Peng |RS |Asia Matsushita Electric |aptan@avirc.ams.com.sg\n|Thom, D. |USA |Mitsubishi |dthom@msm.mea.com\n|V\u00e4\u00e4n\u00e4nen, M. |FIN |Nokia Res. Center |mauri.vaananen@research.nokia.com\n|Watanabe, K. |J |NHK |watanabk@strl.nhk.or.jp\n|Yin, Lin |FIN |Nokia |lin.yin@research.nokia.fi\n|Yoshida, K. |J |Matsushita |Kyoshida@telecom.mci.mei.co.jp\n| | | |\n| | | |\n| | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex A-II*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAgenda for 33rd MPEG/Audio Subgroup Meeting in Munich"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"64%,36%\",]\n|===\n|Item |Contributions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1. Opening of the meeting |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Approval of agenda |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Allocation of contributions |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Communications from the Chairman |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Dallas meeting report |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Report of ad hoc group activities |M0610, M0626, M0628, M0634,\nM0640, M0662, M0676, M0679, M0680, M0xxx"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Resolution of National Body comments |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. MPEG-2 |M0563"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8.1 MPEG-2 part 4 Compliance |M0xxx"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8.2 MPEG-2 part 5 - Technical Report Verification Testing |M0676"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8.3 MPEG-2 audio quality update |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8.4 Copyright identifier |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8.5 MPEG-2 IS13818-3 revision |M0563"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. MPEG-4 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9.1 MPEG-4 audio tests and evaluation |M0632, M0635, M0638, M0647"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9.2 Test and Evaluation Procedure - co-ordinated with Test |M0562"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9.3 VM activities - co-ordinated with MSDL Task groups a) First draft\nof MPEG-4 VM description |M0574, M0575, M0580, M0581, M0584, M0585,\nM0588, M0591, M0593, M0606, M0607, M0608, M0644"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9.4 Finalise the reports of the tests and evaluation |M0630, M0680"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. MPEG-2 NBC RM |M0611"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.1 Results of subjective tests |M0551, M0561"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.2 NBC RM3 experiment planning |M0559"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.3 Discussion of new proposals |M0574, M0575"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.4 Development of RM3 |M0558, M0560, M0652, M0648, M0658"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.5 NBC syntax and MSDL |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.6 NBC WD development |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|11. Joint activities |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|11.1 Test |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|11.2 Implementation |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|12. Liaison matters |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|13. Discussion of unallocated Contributions |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|14. Recommendations for final plenary |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|15. Agenda for next meeting |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|16. A.O.B. |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|17. Closing of the meeting |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex A-III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAgenda for the 34th MPEG/*Audio Subgroup Meeting in Florence, March\n1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"76%,24%\",]\n|===\n|1. Opening of the meeting |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Approval of agenda |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Allocation of contributions |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Communications from the Chairman |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Munich meeting report |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Report of ad hoc group activities |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Resolution of National Body comments |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. MPEG-2 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8.1 MPEG-2 part 4 Compliance |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8.2 MPEG-2 part 5 - Technical Report Verification Testing 8.2.1\nConversion to IS |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8.3 MPEG-2 audio quality update |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8.4 Revision to IS 13818-3 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. MPEG-4 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9.1 VM activities |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9.2 MSDL |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9.3 SNHC |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. NBC RM |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.1 Results of subjective tests |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.2 NBC RM experiment planning |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.3 Discuss results of pre-selection experiments |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.4 Development of RM3 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.5 NBC syntax and MSDL |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10.6 NBC WD development |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|11. Liaison matters |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|12. Discussion of unallocated Contributions |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|13. Recommendations for final plenary |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|14. Agenda for next meeting |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|15. A.O.B. |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|16. Closing of the meeting |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex A-IV"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n** *Audio Task Groups*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*RM3 development including syntax leading to WD - Bosi*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Akagiri |Bosi |Brandenburg\n|Dietz |Iwadare |Johnston\n|Oomen |Quackenbush |Oikawa\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*RM3 core experiment design and schedule (to include loudspeaker\ndetails) - Schuyler/Fuchs*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Akagiri |Johnston |Lueck\n|Oomen |Quackenbush |Vaananen\n|Watanabe |Fuchs |Oikawa\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG-2 IS revision - Stoll*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Dietz |Dimino |Grill\n|Kaneko |Stoll |Schwalbe\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VMs for MPEG-4 - Edler*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"17%,17%,15%,17%,17%,17%\",]\n|===\n|Akagiri |K. |Bont |F.d. |Bosi |M.\n|Brandenburg |K. |Edler |B. |Ekudden |E.\n|Ferreira |A. |Grill |B. |Hong |J.W.\n|Hotani |S. |Iwadare |M. |Kim |S-W.\n|Koike |T. |Lindqvist |M. |Matsumoto |J.\n|Miki |S. |Miyasaka |S. |Moriya |T.\n|Muller |J-M. |Navarro |W. |Nishiguchi |M.\n|Pan |D. |Schwalbe |R. |Sereno |D.\n|Suzuki |M. |Tan |A-P. |Thom |D.\n|Yin |L |Yoshida |K. | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG-2 Technical report finalisation - Thom*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Thom |Schwalbe |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Audio test methodology review - Schreiner*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,16%,16%,16%,16%,16%\",]\n|===\n|Meares |D. |Schreiner |P. |Contin |L.\n|Baroncini |V. |Susuki |H. | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 7_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG Test Meeting Report*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Laura Contin, Chairman*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MPEG Test Subgroup met in Munich during the 33rd meeting of WG11.\nThe following issues were addressed: NBC audio test, MPEG-2 MP@HL test,\nMPEG-2 4:2:2 profile test, MPEG-2 multiview profile test."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG-2 Audio NBC test*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDavid Mears presented the results of the tests carried out after the\nDallas meeting on the MPEG-2 NBC RM2. In general it was observed a good\nagreement across the test sites, except for a few of them. This problem\nwas probably due to differences in the instructions and lack of training\nphase. For this reason, in the future tests, the instructions and their\ntranslations will be defined with particular care and the training phase\nwill be mandatory. Concerning this last point, the possibility to have\nboth group and individual training will be considered."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPeter Schreiner explained that for future tests, in particular for the\nformal tests that must be concluded before November \u201896, the test\nmethods must be very selective, stable and repeatable and the stereo\nsignals should be reproduced not only by headphones but, at least in\nsome test site, also by loudspeakers. This will add additional problems\nrelated to the listening conditions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPeter Schreiner suggested to base the definition of the test method for\nthe formal test on doc. N0063 of March \u201894"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn ad hoc group was established with the mandate of reviewing that\ndocument and suggesting possible methodological changes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG-2 MP@HL test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEBU and NHK submitted documents with the results obtained with\nnon-expert viewers. Other results were already presented and discussed\nduring the Dallas meeting (see WG11/1028)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe results of all the experiments carried out on MP@HL are summarized\nin WG11/1140."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis concludes the activity on MP@HL verification test."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG-2 4:2:2 profile test*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe results obtained from tests carried out in several laboratories in\nUSA, Japan and Europe were discussed and the presentation layout were\ndefined."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThree documents were produced:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* a detailed report of the tests, including both test procedures and\nexperimental results (WG11/1134)\n* the amendment to the IS 13818-2 (WG11/1158)\n* an informative annex to AMD/2 13818-2, including a summary of the test\nresults (WG11/1178)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis concludes the activity on MPEG-2 4:2:2 profile"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG-2 Multiview profile test*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMr. Luthra illustrated the status of the work of the ad hoc group on\nMultiview profile. The bitstream exchange should start just after the\nmeeting and should be completed before the Florence meeting. The\nverification tests are scheduled after this activity is concluded."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe ad hoc group on Multiview Profile asked the Test Subgroup for\nassistance in defining the test procedures. The main difficulty is\nrelated to the differences among the display systems available in the\npotential test sites."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Test Subgroup has not direct expertise on subjective quality\nassessment of stereoscopic video sequences, but it will try to collect\nthe information useful to maximize the significance of the test."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA first description of the test procedures is given in doc. MPEG/N651."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 8_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG Implementation Studies Meeting Report*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Paul Fellows, Chair*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Implementation Studies sub-group (ISG) was re-established during the\nDallas meeting in November 1995 and consequently the Munich 96 meeting\nmarked the first full meeting of ISG activities."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tasks set for the meeting were as follows :-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. To investigate the role that ISG will play in the Verification Model\nconstruction.\n. To discuss performance complexity analysis with the Audio Group\npertaining to NBC audio."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Implementation Studies sub-group met two days during the week under\nchairmanship of Mr. Paul Fellows. The following meeting sessions were\nheld:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMon 14:00 - 17:00 sole session : investigation of VM role."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMon 17:00 - 18:30 Meeting with Audio : Understanding of NBC audio."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTue 09:30 - 17:00 sole session : Develop VM role and work on N1169."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2. Documents*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.1 Input documents"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"14%,21%,65%\",]\n|===\n|95/433 |P. Fellows |Discussion document : Real time implementation\nissues for MSDL.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.2 Output documents"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"21%,18%,61%\",]\n|===\n|WG11 N1028 |Resolutions of 32nd WG11 meeting |Contribution to\nrecommendations\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3. Activities*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.1 Status"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe main output of the meeting is documented in WG11 N1169. As such this\nreport does not attempt to duplicate N11169 and discusses other\nactivities that the group was involved in during the meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.2 Audio meeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe audio group kindly gave a presentation on NBC audio and their\nknowledge of its implementation complexity."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe description was based on RM2 (as defined in N1095) and discussed the\nvarious stages of the algorithm and the precision of data required to be\nmaintained."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe presentation was well received and provided a very welcome \u201cleg-up\u201d\nthe learning curve for the audience."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.3 Plans"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe activity of the group will be to :-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Define a work plan for 1996.\n. Participate in the two established AdHoc Groups (N1170 & N1171).\n. Post meeting : work has begun on these two areas and the basic outline\nstrategy formulated.\n. Two Email reflectors have been set up for this purpose :-\n. N1171\n. isg_ah_vm@fzi.de\n. Send an Email to isg_ah_vm-request@fzi.de to join.\n. N1170\n. isg_ah_1169@fzi.de\n. Send an Email to isg_ah_1169-request@fzi.de to join."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 9_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG DSM eeting Report*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Chris Adams, Chair*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe main DSM-CC meeting was three days. Having just completed the DIS in\nthe November 1995, the focus was on review and reflection. The first day\nwas spent reviewing various contributions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"11%,30%,59%\",]\n|===\n|Number |Source |Title"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0576 |Vahe Balabanian, Liam Casey |End-to-End Walkthrough of DSM-CC DIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0577 |Vahe Balabanian,, Liam Casey |Binding Resources for Download and\nthe Download Interface"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0578 | |Liaison re: ITU-T DSS2 GIT Fields Assigned to DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0579 |Vahe Balabanian,, System Integration TC |Liaison re: ITU_T DSS2\nGIT Fields Assigned to DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0659 |Vahe Balabanian, Liam Casey |Draft Input for DSM-CC DIS Annex G"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0666 |Regis J. Crinon, Frank Bosveld |DSMCC: Modifications to U-U\nObject Carousels in Annex F."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0667 |Regis J. Crinon , Frank Bosveld |DSMCC: DSMCC: Transport of\nDownload messages in DSMCC sections"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0672 |Regis J. Crinon , Don Hooper |DSMCC: Need for additional IDL\nSyntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0673 |Frank Bosveld |DSMCC: Proposal to make Annex F (U-U Object\nCarousels) normative"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0674 |Frank Bosveld |DSMCC: Modifications to Download and U-U Object\nCarousels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0682 |McPheters |Proposal for DSM-CC Recovery Procedures"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0683 |McPheters |Proposal for DSM-CC Error Handling"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|? |David Malloy |Broadcast Service Support in FTTC Networks"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|? |David Malloy |Proposed Text for Annex H"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0684 |Peter Gleissl |DSM-CC Extensions for Switched Digital Broadcast\nin ATM Access Networks"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0685 |Peter Gleissl |New Chapter Switched Digital Broadcast - Overview\n/ Message Definitions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0686 |Peter Gleissl |New Chapter Switched Digital Broadcast - Command\nSequences"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0687 |Peter Gleissl |New Chapter Switched Digital Broadcast - State\nEvent Tables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|? |X3L3 |US NB Comments\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe second day was spent fully on a walkthrough and review of a DSM-CC\nU-U Session. Many major misunderstandings were uncovered. This\ninformation is useful input to the committee so that we highlight issues\nthat need decisions and clarifications in the text."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs a result of National Body comments in the Dallas meeting the group\nhad agreed to improve signaling support for digital broadcast. Many\ncontributions and much discussion resulted in a proposal for support of\na Digital Broadcast Service. The Ad Hoc group was assigned to further\nrefine this signaling."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe group spent some time considering testing and simulation of the\nstandard. Volunteers were solicited for testing of various components of\nthe standard."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-SRM (SA, ATT, Matsushita, NT, DEC, Nokia, NLC/GI)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Server UN (DEC, GI/NLC, SGI/IDS, Sun)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Server Download (DEC, SGI)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Server UU (DEC, SGI)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Client UN (SA, DiviCom, GI, Nokia, Matsushita)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Client Download (DiviCom, Thomson, SA)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Client UU (DEC/DiviCom, Tek, Sun, SGI)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe output of the group was summarized in N1183 Clarifications on the\nDSM-CC DIS. This document covers the Server Session Setup issue,\nDownload refinements, Annex F U-U Data Carousels, Annex G Association\nTag, U-U Erata, and Digital Broadcast Service."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThree Ad Hoc groups were recommended. The first to Review and Clarify\nthe DSM-CC DIS. The second to Investigate Low Bandwidth Data\nRepresentation for DSM-CC. The third to Plan, Coordinate, Synchronize,\nExecute and Evaluate Tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Annex 10_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Ad-hoc groups established at Munich*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"21%,79%\",]\n|===\n|1133 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad hoc group on MPEG-2 Multi-view Profile"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |to start exchanging bitstreams,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |to continue organizing the framework/plan for verification testing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chair: |Ajay Luthra (aluthra@gi.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1142 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title : |Ad-hoc group on test methodology for formal NBC test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To review the test methods reported in WG11/N0685 and to\ndefine procedures for future formal NBC audio test."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |H. Suzuki JVC suzukihr@krhm.jvc-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1145 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-Hoc Group to Conduct the of MPEG-2 Audio NBC Reference Model\n3 Core Experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To conduct the of NBC RM3 (WG11/N1132) core experiment\nmonophonic and stereophonic listening tests according to (N1150), to\nperform the analysis of the test results, and to prepare the report of\nthe results for the March 1996 MPEG meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |P.G. Schreiner III"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1146 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad Hoc Group on MPEG-4 Verification Models"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To continue the evaluation of the results of the MPEG-4 audio\nproposal tests, the evaluation of the proposal technical descriptions,\nand the development of the detailed VMs. This task includes the\ncollection of more detailed technical descriptions for nine of the\nproposals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |B. Edler"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1147 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on MPEG-2 Audio NBC (13818-7) Reference Model 3\n(RM3) Specification and Working Draft Development"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To progress the work on the preparation of the first Working\nDraft for MPEG-2 NBC (13818-7) Audio Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chair |Marina Bosi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Vice-Chair |Martin Dietz"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1148 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad Hoc Group on finalising revisions to IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To review editorial changes to IS 13818-3 contained in\nWG11/N1152"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |To ensure that details relating to the use of prediction with\ndynamic\u00a0crosstalk, and LFE syntax are correctly assimilated"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |To prepare and approve an informative Annex which provides\ninformation how to use MPEG-2 BC multichannel coding or the MPEG-2 NBC\nmode together with 2-channel Layer II, e.g. simulcast."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |To present to the March 1996 meeting of MPEG a final version of the\nrevised IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |G. Stoll (E-Mail: stoll@irt.de)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1149 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Adhoc Group on the SNHC/Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To disseminate SNHC Notice of a Call for Proposal (CFP), to\ngenerate the interest for contributions to the first CFP and to\nco-ordinate discussion about the first experiments among the experts.\nJoint with SNHC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |I. Kaneko"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1153 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on core experiments on efficient coding in MPEG-4\nvideo (Prediction, Frame texture coding, quantiser and bit-rate control)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |1) To collect core experiments description(deadline : 2nd\nweek after the 33rd MPEG meeting)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |2) Editing a document with all core experiments(deadline : 3rd week\nafter the 33rd MPEG meeting)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |3) Distribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |4) Development of evaluation criteria for results of core experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |5) Coordination of common conditions for appropriate core experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chair: |John Muller (jmuller@iterated.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1154 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on core experiments on content-based coding and\naccess in MPEG-4 video (Shape and Alpha channel coding, Object/Region\ntexture coding)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |1) To collect core experiments description(deadline : 2nd\nweek after the 33rd MPEG meeting)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |2) Editing a document with all core experiments(deadline : 3rd week\nafter the 33rd MPEG meeting)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |3) Distribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |4) Development of evaluation criteria for results of core experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |5) Coordination of common conditions for appropriate core experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chair: |Touradj Ebrahimi (ebrahimi@epfl.ch)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Ibrahim Sezan (co-chair ; sezani@sharpsla.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1155 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on core experiments on error resilience aspects in\nMPEG-4 video"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |1) To collect core experiments description(deadline : 2nd\nweek after the 33rd MPEG meeting)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |2) Editing a document with all core experiments(deadline : 3rd week\nafter the 33rd MPEG meeting)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |3) Distribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |4) Development of evaluation criteria for results of core experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |5) Coordination of common conditions for appropriate core experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chair: |James Brailean (brailean@areaplg2.corp.mot.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1156 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on core experiments on multifunctional coding\naspects in MPEG-4 video (spatio-temporal scalability, multi-view and\nmodel manipulation, pre-, mid- and post- processing)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |1) To collect core experiments description(deadline : 2nd\nweek after the 33rd MPEG meeting)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |2) Editing a document with all core experiments(deadline : 3rd week\nafter the 33rd MPEG meeting)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |3) Distribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |4) Development of evaluation criteria for results of core experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |5) Coordination of common conditions for appropriate core experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chair: |Atul Puri (ap@big.att.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1157 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title |Ad-hoc group for the software development of the Video VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate |Prepare the development of software for video verification"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chair |Henri Sanson"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1160 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad Hoc Group on Synthetic/Natural Hybrid Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |1. Solicit community expertise and participation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |2. Complete final Call for Proposals with PPD."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |3. Develop Virtual Playground and Test Data Set."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |4. Develop Media Model proposal evaluation criteria."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Peter K. Doenges, Evans & Sutherland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1161 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on MPEG-4 Video Verification Model Document\nEditing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To maintain a consistent version of the verification model\n(VM) document through"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |- coordination of the definition of the VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |- continuing Editing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chair: |Touradj Ebrahimi (ebrahimi@epfl.ch)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1165 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad Hoc Group on Syntactic Description Language"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |Complete MSDL Part 5 and related Annex"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |1. Collect and complete requirements from Audio/Video/SNHC experts"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |2 Complete and check the formal rules"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |3 Describe Audio/Video/SNHC syntax with these rules"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |MSDL : Alexandros Eleftheriadis (Columbia University)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Co-chairs: |AUDIO : James Johnston (AT&T)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |VIDEO : Georges Campbell (Compression Lab. Inc)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1166 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad Hoc Group on requirements for a possible MPEG-4 virtual\nmachine"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |Document virtual machine aspects in MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |1. Analyse work in this area"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |2 Analyse real time aspects (including synchronisation)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |3 Analyse possible architecture"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |4 Issue requirements and recommandations on the topic"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Jean-Claude Dufourd (ENST)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1167 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |MSDL Architecture and Objects Hierarchy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |Complete Part1 and Part2 of the WD and related annex."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |1. Collect and complete requirements from Audio/Video/SNHC experts"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |2 Refine the architecture and class hierarchy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Olivier AVARO (FRANCE TELECOM CNET)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Co-chair: |Julien Sign\u00e8s (FRANCE TELECOM CCETT)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1170 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on defining framework of implementation complexity\nanalysis when performing core experiments."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To formalize the approach that should be taken when\nperforming implementation complexity analysis. To provide general\ncriteria for simplification of implementation. To define the format of\nassessment reports."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Nicolas Demassieux"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1171 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on defining and implementing instrumentation tools\nfor embedding within VM\u2019s."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To investigate the feasibility of embedding intstrumentation\nwithin VM\u2019s capture gross performance metric\u2019s. If feasible produce an\ninitial set of tools to demonstrate the technique. Use elements of NBC\naudio as a test bed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Vice Chairman: |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Paul Fellows"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1180 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad Hoc Group to Review and Clarify the DSM-CC DIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To review DIS and document clarifications as needed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Chris Adams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1181 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad Hoc Group to Investigate Low Bandwidth Data Representations\nfor DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To investigate data representations which could reduce\nbandwidth requirements for DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1182 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad hoc group of DSM-RSF."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mandate: |To plan, coordinate, synchronize, execute and evaluate tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Martin Fisher (mrf@sybase.com)\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= Quantization and Coding\nS. R. Quackenbush\n1996-01-23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IECJTC1/SC29/WG11/*N1132*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source : Audio subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: *MPEG-2 Audio NBC (13818-7) Reference Model 3 (RM3)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStatus: Approved *21.01.96 04:35*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthors : Marina Bosi, K. Brandenburg, J. Johnston"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}0. Introduction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis document describes the non-backwards compatible (NBC) extension to\nIS 13818-3, 13818-7, reference model 3 (RM3) audio coder. The reference\nmodel is composed of 6 basic modules, as shown in Fig. 1. For each\nmodule the following will be presented:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* a description of the module algorithm,\n* the module function prototype definition,\n* an example function call, including any initialization that must be\ndone,\n* a description of core experiments for this module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe interface definition for each module may pertain only to RM3. The\ninterfaces will be modified as the core experiments progress so as to\naccommodate alternative algorithms for the modules. Furthermore, the\nmodules shown in Fig. 1 can be decomposed into simpler tools in order to\nserve all aspects of the core experiments. Each incremental modification\nshould address only one functionality of the reference model. During the\ncore experiments, the performance of the new coders is compared to that\nof the current reference model. The test methodology employed is\ndescribed in document ISO/IEC JTC1/SC29/WG11/N1034, \u201cAudio Subjective\nTest Methods for High Quality Codec Evaluations.\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe starting point of this process is a coding system which consists of\na Time to Frequency (T/F) module with the frequency resolution selected\naccording to the results of the first NBC core experiment (1024/128\nfrequency lines with Dolby windows) and the other modules which are\ncontained in FHG_D1 (a system proposed by Fraunhofer Gesellschaft with\nthe Hannover prediction module, see also ISO/IEC JTC1/SC29/WG11/N0973).\nFhG_D1 is called the baseline system for the NBC reference model 2, RM2.\nThe results of the second round of core experiments are described in\nISO/IEC JTC1/SC29/WG11/N1135. The main target of these experiments was\nthe Quantization and Coding module, QC, although optimization of the T/F\nmodule and the practicability of the Pre-processing module were also\ntested. The differences between RM2 and the current reference model,\nRM3, include enhancements in the lossless coding tools of the QC module,\na newly defined syntax, and an adaptive window shaping tool in the T/F\nmodule."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis document is organized as follows:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. Description of the preprocessing module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. Description of the time to frequency mapping module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. Description of the psychoacoustic model."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4. Description of the joint coding module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5. Description of the quantization and coding module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}6. Description of the bit stream formatter."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Fig. 1* - Block diagram of RM."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe RM platform is repeated here for convenience:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPC, 486 or Pentium"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n8 MB or more memory"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLinux operating system (install \u201cslackware\u201d options)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProgramme module"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGCC ANSI c-compiler"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nobject code modules (This is a starting point- source code is\npreferable.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nASCII header prototype file"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOptional additional platforms"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSGI R4000"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSUN SPARC 2."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. Description of the preprocessing module*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.1 Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe preprocessing module has two sub modules, preprocessing1 and\npreprocessing2. There are corresponding postprocessing modules in the\ndecoder."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe preprocessing1 is used for premixing, pre-distortion and creating\nthe noise coding channels. The following techniques are used."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(a) premixing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(b) pre-distortion"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(c) creating the simulcast channels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(d) creating the noise channels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe simulcast channels are used for transmitting the premixing channels.\nIf the simulcast channels is used, the decoder can get the stereo\nsignals without downmixing."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe noise channels are the error signals of the dematrixed channels\nwhich are not independently encoded. To cancel the dematrixed channels\nnoise, the noise channel signals are added to the dematrixed channels at\nthe decoder."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe preprocessing2 module is used for the preprocessing of the time to\nfrequency mapping module. This module includes the PQF(Polyphase\nQuadrature Filter) and/or the gain control. The output of this module\nincludes the control signals of the window switching and/or the gain\ncontrol. The event_map and gain_info are input and output of this\nmodule."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe input signal is divided by a PQF into four equal-width frequency\nbands if PQF is selected. By using the PQF, reproduction of narrow\nbandwidth sound can be achieved using a low cost decoder which does not\nneed to utilize a full transform from full band encoded bit stream. This\nis the frequency scalability."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe gain control is necessary only when an attack signal is detected,\nand hence, only a small number of bits are required to set the number of\ngain information data zero in ordinary frames. This is useful to reduce\nthe pre-echo. The gain control are introduced for every output subband\nif PQF is used. The length of the output gain controlled signal array\nmust be twice."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.2. The preprocessing1 and postprocessing1 modules*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_General definitions:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum CHANNEL_NO \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEFT_CHAN = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRIGHT_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCENTER_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLFE_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEFT_SURR_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRIGHT_SURR_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMORE_LEFT_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMORE_RIGHT_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNOISE_L_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNOISE_R_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMAX_CHANNELS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* MORE_LEFT_CHAN and MORE_RIGHT_CHAN are used for simulcast channels or\n8 ch configuration. NOISE_L_CHAN and NOISE_R_CHAN are used for the noise\ncancellation of premixed channels. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Required definitions for preprocessing1 and postprocessing1 modules:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* definitions of the time signal buffer sizes */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define TIME_SIGNAL_LEN BLOCK_LEN_LONG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Interface for the preprocessing1 module_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npreproc1( /* Input */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint input_number_channels,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *input_channel_config,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *p_input_signals,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Output */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *output_number_channels,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *output_channel_config,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *p_output_signals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Interface for the postprocessing1 module_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npostproc1( /* Input */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint input_number_channels,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *input_channel_config,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *p_input_signals,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Output */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *output_number_channels,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *output_channel_config,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *p_output_signals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* The input_channel_config and output_channel_config indicate the\nchannel order of p_input_signals and p_output_signals by CHANNEL_NO. The\np_input_signals and p_output_signals data order are [0][0], [0][1], ...,\n[0][1023], [1][0], ..., [1][1023], ..., [channels][samples]. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.2.1. Example function call for preprocessing1 and postprocessing1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following sample program is for the noise channel coding."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nexample_program_pre1_post1()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint input_number_channels, output_number_channels;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *input_channel_config, *output_channel_config;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *p_input_signals, *p_output_signals;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninput_number_channels = 5;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninput_channel_config = (int *)calloc(input_number_channels,\nsizeof(int));"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninput_channel_config[0] = LEFT_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninput_channel_config[1] = RIGHT_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninput_channel_config[2] = CENTER_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninput_channel_config[3] = LEFT_SURR_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninput_channel_config[4] = RIGHT_SURR_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\np_input_signals_proc1 = (double *)calloc(input_number_channels *"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTIME_SIGNAL_LEN, sizeof(double));"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput_number_channels = 7;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput_channel_config = (int *)calloc(output_number_channels *\nsizeof(int));"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput_channel_config[0] = MORE_LEFT_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput_channel_config[1] = MORE_RIGHT_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput_channel_config[2] = CENTER_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput_channel_config[3] = LEFT_SURR_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput_channel_config[4] = RIGHT_SURR_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput_channel_config[5] = NOISE_L_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput_channel_config[6] = MORE_RIGHT_CHAN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\np_output_signals_proc1 = (double *)calloc(output_number_channels *\nTIME_SIGNAL_LEN * sizeof(double));"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhile(read_input_signal(p_input_signals) ) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Preprocessing1 module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npreproc1(input_number_channels, input_channel_config,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n&output_number_channels, output_channel_config,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\np_input_signals, p_output_signals);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Postprocessing1 module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npostproc1(output_number_channels, output_channel_config,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n&input_number_channels, input_channel_config,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\np_output_signals, p_input_signals);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.3. The preprocessing2 and postprocessing2 modules*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf PQF is used, adding to 44 samples delay before the psycho module is\nrequired."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_General definitions:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum CHANNEL_NO \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEFT_CHAN = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRIGHT_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCENTER_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLFE_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEFT_SURR_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRIGHT_SURR_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMORE_LEFT_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMORE_RIGHT_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNOISE_L_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNOISE_R_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMAX_CHANNELS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* MORE_LEFT_CHAN and MORE_RIGHT_CHAN are used for simulcast channels or\n8 ch configuration. NOISE_L_CHAN and NOISE_R_CHAN are used for the noise\ncancellation of premixed channels. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum INPUT_ID \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_PCM = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_PQF,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_GAIN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_GAIN_PQF"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Required definitions for preprocessing2 and postprocessing2 modules:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* definitions of the time signal buffer sizes */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define TIME_SIGNAL_LEN BLOCK_LEN_LONG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define GAIN_CONTROLED_TIME_SIGNAL_LEN 2*BLOCK_LEN_LONG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* The length of the output time signal array of prepro2() and the input\ntime signal array of postpro2() must be twice if input_type is\nINPUT_GAIN or INPUT_GAIN_PQF. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum WINDOW_TYPE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLONG_BLOCK = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSTART_BLOCK,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSHORT_BLOCK,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSTOP_BLOCK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong win_type; /* window type */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong win_len; /* window length */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble alpha; /* parameter used to control the window shape */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *window; /* pointer to the window */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} EVENT;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong n_events; /* number of windows in a block */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong n_samp_in; /* number of input samples */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong n_coef_out; /* number of output coefficients */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEVENT *event; /* pointer to identified windows in a block */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} EVENT_MAP;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* difinition of gain info used by Sony. The gain info must be\ntransmitted. The maximum number of bits used for gain_info is 66*4+2\nbits per block per audio channel */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint lev;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint loc;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} GDATA;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint num_gain_data;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGDATA gData[7];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} GINFO;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint max_band;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGINFO gInfo[4];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} GAIN_INFO;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* definition of preprocessing 2 and postprocessing 2 control & info\nstructure */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *p_in_time_signal;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *p_out_time_dignal;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *input_type;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEVENT_MAP *p_event_map;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGAIN_INFO *gain_info;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} PRE_PRO_2_INFO;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Interface for the preprocessing2 module_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nprepro2( /* Input */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong channel_enable_mask, /* bit #0 turns on processing of"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchannel #0 etc. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPRE_PRO_2_INFO pre2_info[MAX_CHANNELS]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* input: *p_in_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput: *p_out_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nother input/output: *input_id, *event_map,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*gain_info */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Interface for the postprocessing2 module_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npostpro2( /* Input */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong channel_enable_mask, /* bit #0 turns on processing of"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchannel #0 etc. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPRE_POST_2_INFO post2_info[MAX_CHANNELS]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* input: *p_in_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput: *p_out_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nother input: *input_id, *gain_info */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.3.1. Example function call for preprocessing2 and postprocessing2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following sample program is for the hybrid configuration with the\ngain control."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define INPUT_DATA_LENGTH (TIME_SIGNAL_LEN*MAX_CHANNELS)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nexample_program_pre2_post2()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint ch;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong channel_enable_mask;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble p_input_signals[INPUT_DATA_LENGTH];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble p_input_buffer[2*INPUT_DATA_LENGTH];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble p_channel_signals[TIME_SIGNAL_LEN];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble p_buffer[GAIN_CONTROLED_TIME_SIGNAL_LEN];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPRE_POST_2_INFO pre2_info[MAX_CHANNELS];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nT2M_CHANNEL_INFO ch_info[MAX_CHANNELS];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGAIN_DETECTION_INFO gain_detect_info[MAX_CHANNELS];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* The each struct must be initialized precisely */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninit_pre2_info(pre2_info);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninit_ch_info(ch_info);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninit_gain_detect_info(gain_detect_info);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhile(read_input_signal(p_input_signals) ) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* copy to buffer for delay */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncopy_data(p_input_signals, /* source */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\np_input_buffer + INPUT_DATA_LENGTH, /* destination */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_DATA_LENGTH); /* length */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfor(ch=0; ch<MAX_CHANNELS; ch++) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif(ch == 0) channel_enable_mask = 0;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* copy to a channel data from the multi channel data */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncopy_data(p_input_signals + (ch* TIME_SIGNAL_LEN),"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\np_channel_signals,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTIME_SIGNAL_LEN);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Event detection module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwindow_ctl(channel_enable_mask,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnum_groups, channel_group,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* p_channel_signals, */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npre2_info[ch].p_event_map.event..win_type);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Gain detection module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncopy_data(p_channel_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngain_detect_info[ch].p_in_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTIME_SIGNAL_LEN);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngain_detect_info[ch].input_type = INPUT_GAIN_PQF;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngain_detect(channel_enable_mask, gain_detect_info);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Preprocessing2 module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncopy_data(gain_detect_info[ch].gain_info,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npre2_info[ch].gain_info,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsizeof(GAIN_INFO));"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncopy_data(p_input_buffer + (ch* TIME_SIGNAL_LEN),"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npre2_info[ch].p_in_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTIME_SIGNAL_LEN);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npre2_info[ch].input_type = INPUT_GAIN_PQF;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nprepro2(channel_enable_mask, pre2_info);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Time to frequency module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncopy_data(pre2_info[ch].p_output_signals,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nch_info[ch].p_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGAIN_CONTROLED_TIME_SIGNAL_LEN);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nch_info[ch].p_event_map.n_sample_in ="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGAIN_CONTROLED_TIME_SIGNAL_LEN;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nch_info[ch].p_event_map.n_coef_out = BLOCK_LEN_LONG;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nch_info[ch].input_id = pre2_info[ch].input_type;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntime2freq(channel_enable_mask, ch_info);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Frequency to time module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfreq2time(channel_enable_mask, ch_info);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Postprocessing2 module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncopy_data(ch_info[ch].p_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npre2_info[ch].p_in_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGAIN_CONTROLED_TIME_SIGNAL_LEN);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npostpro2(channel_enable_mask, pre2_info);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchannel_enable_mask++;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncopy_data(p_input_buffer + INPUT_DATA_LENGTH,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\np_input_buffer,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_DATA_LENGTH);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.4. Description for the gain control detection module*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe gain control detection module produces the gain control information\nif input_type is INPUT_GAIN or INPUT_GAIN_PQF. The output gain control\ninformation is for the previous input time signal. This means that this\nmodule has the one BLOCK_LEN_LONG delay."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_General definitions:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum CHANNEL_NO \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEFT_CHAN = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRIGHT_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCENTER_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLFE_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEFT_SURR_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRIGHT_SURR_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMORE_LEFT_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMORE_RIGHT_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNOISE_L_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNOISE_R_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMAX_CHANNELS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* MORE_LEFT_CHAN and MORE_RIGHT_CHAN are used for simulcast channels or\n8ch configuration. NOISE_L_CHAN and NOISE_R_CHAN are used for the noise\ncancellation of premixed channels. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum INPUT_ID \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_PCM = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_PQF,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_GAIN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_GAIN_PQF"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Required definitions for the gain control detection module:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* definitions of the spectral resolutions of the windows */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define BLOCK_LEN_LONG 1024 /* #spectral values in long blocks */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* definitions of the time signal buffer sizes */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define TIME_SIGNAL_LEN BLOCK_LEN_LONG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* difinition of gain info used by Sony. The gain info must be\ntransmitted. The maximum number of bits used for gain_info is 66*4+2\nbits per block per audio channel */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint lev;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint loc;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} GDATA;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint num_gain_data;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGDATA gData[7];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} GINFO;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint max_band;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGINFO gInfo[4];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} GAIN_INFO;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* definition of the gain control detection control & info structure */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndoulble *p_in_time_signal;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *input_type;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGAIN_INFO *gain_info;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} GAIN_DETECTION_INFO;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Interface for the gain control detection module_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngain_detect( /* Input */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong channel_enable_mask, /* bit #0 turns on processing of"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchannel #0 etc. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGAIN_DETECTION_INFO gain_detect_info[MAX_CHANNELS]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* input: *p_in_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nother input: *input_type,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput: *gain_info */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.5. Core experiment proposed by Sony*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe core experiment proposed by Sony is a combination of the PQF with\ngain control and 4*MDCT with block switching."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2. Description of the time to frequency mapping module*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.1. Algorithm description*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe analysis or synthesis filter bank is a"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLet x\u2019(n) represent the input sequence for a given channel modulated\nwith the window W(n). The output frequency sequence, X(k), is defined\nby:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[pic]-1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe symmetrical window coefficients are given by the following\nequations:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic] for [pic] and all [pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe selection of the appropriate window shape for each applicable block\ntakes place in the encoder and is sent to the decoder. In this approach,\nduring long blocks, N = 2048, alpha = 4.0 is used when the coding\nprocess will apparently benefit from good stop band performance,\notherwise alpha = 1.5. Similarly, during short blocks, N = 256, the\nwindow can be selected as either a window with alpha = 6 or a window\nwith alpha = 2."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.2. Interface specification*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_General definitions:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum CHANNEL_NO \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEFT_CHAN = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRIGHT_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCENTER_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLFE_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEFT_SURR_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRIGHT_SURR_CHAN,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMAX_CHANNELS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum WINDOW_TYPE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLONG_BLOCK = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSTART_BLOCK,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSHORT_BLOCK,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSTOP_BLOCK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum INPUT_ID \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_PCM = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_PQF"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_GAIN"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINPUT_GAIN_PQF"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum OUTPUT_ID \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOUTPUT_REAL = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOUTPUT_CMPX"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Required definitions for time to frequency mapping module:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* definitions of the spectral resolutions of the windows */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define SHORT_BLOCKS_IN_LONG_BLOCK xxx /* no of short blocks replacing\none long block */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define BLOCK_LEN_LONG xxx /* #spectral values in long blocks */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define BLOCK_LEN_SHORT xxx /* #spectral values in short blocks */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define BLOCK_LEN_START xxx /* #spectral values in start blocks */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define BLOCK_LEN_STOP xxx /* #spectral values in stop blocks */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* definitions of the frequency output buffer sizes */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define OUTPUT_LEN_LONG BLOCK_LEN_LONG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define OUTPUT_LEN_SHORT BLOCK_LEN_LONG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define OUTPUT_LEN_START BLOCK_LEN_LONG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define OUTPUT_LEN_STOP BLOCK_LEN_LONG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define MAX_OUTPUT_LEN max( OUTPUT_LEN_LONG, OUTPUT_LEN_SHORT,\nOUTPUT_LEN_START, OUTPUT_LEN_STOP )"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* the event map controls block switching */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong win_type; /* window type */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong win_len; /* window length */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble alpha; /* parameter used to control the window shape */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *window; /* pointer to the window */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} EVENT;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong n_events; /* number of windows in a block */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong n_samp_in; /* number of input samples */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong n_coef_out; /* number of output coefficients */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEVENT *event; /* pointer to identified windows in a block */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} EVENT_MAP;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* definition of filterbank control & info structure */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *p_time_signal;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *p_spectrum;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEVENT_MAP *p_event_map;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong input_id;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong output_id;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} T2M_CHANNEL_INFO;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Interface for the time to frequency mapping module_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntime2freq( /* Input */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong channel_enable_mask, /* bit #0 turns on processing of"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchannel #0 etc. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nT2M_CHANNEL_INFO ch_info[MAX_CHANNELS]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* input via *p_time_signal,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nother input: event_map"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput spectrum is delivered to the location specified by *p_spectrum */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Ordering of spectral output (*p_spectrum):_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn case of long blocks the ordering is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nspectral_line[BLOCK_LEN_LONG]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA long block may be replaced by a short block sequence:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nspectral_line[SHORT_BLOCKS_IN_LONG_BLOCK][BLOCK_LEN_SHORT]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn case of complex output the order of the spectral values is Re / Im /\nRe / Im ..."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor the processing of the lfe channel (channel #3) a different\ntime-frequency mapping method may be required"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Interface for the frequency to time mapping module_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfreq2time( /* Input */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong channel_enable_mask, /* bit #0 turns on processing of"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchannel #0 etc. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nT2M_CHANNEL_INFO decoder_ch_info[MAX_CHANNELS]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* input via *p_spectrum,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nother input: event_map,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noutput time signal is delivered to the location specified by *p_time_sig\n*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOrdering of spectral input (*p_spectrum) is as described above for the\noutput of the encoder module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.3. Initialization and function call example*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Definition example for RM2_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define SHORT_BLOCKS_IN_LONG_BLOCK 8 /* no of short blocks replacing one\nlong block */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define BLOCK_LEN_LONG 1024 /* #spectral values in long blocks */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define BLOCK_LEN_SHORT 128 /* #spectral values in short blocks */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define BLOCK_LEN_START 1024 /* #spectral values in start blocks */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define BLOCK_LEN_STOP 1024 /* #spectral values in stop blocks */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* In conformance with the selection of the RM2 time to frequency\nmodule, the Dolby window coefficients are supplied. To facilitate the\nuse of the RM2 time to frequency module an initialization routine is\nalso supplied */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEVENT_MAP event_type[4];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEVENT events[SHORT_BLOCKS_IN_LONG_BLOCK]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* This initialization routine sets up the event map for the RM2 MDCT (\nfor further usage see sample main.c ) */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint init_events(EVENT_MAP event_type);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.4. Core experiments*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDolby and FhG are proposing an advanced block switching scheme. which\nemployes the following window types:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum WINDOW_TYPE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nONLY_LONG_WINDOW = 0,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLONG_START_WINDOW"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLONG_STOP_WINDOW"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSHORT_START_WINDOW"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSHORT_STOP_WINDOW"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEIGHT_SHORT_WINDOW"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSHORT_EXT_STOP"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNINE_SHORT_WINDOW"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3. Description of the psychoacoustics model*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3.1 /* psycho-acoustic model */*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npsych_init(); /* initialization of the psychoacoustic module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid psych_init( void );"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnbc_psych(): psychoacoustic calculation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* main psychoacoustic function */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid nbc_psych("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBC_PSY_OUT *nbc_psy_out, /* (OUT) psychoacoustic ouput structure */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfloat *in_buffer_ptr[] /* (IN) input time signal, 1024 vlues for each\nfunction call */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong block_type; /* blocktype */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort short_region[3]; /* number of short blocks in one short group */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfloat ratio[NO_BARC]; /* ratio of allowed noise/energy per\npsychoacoustic band */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong morebits; /* bits desired in addition */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong ibzn_delta; /* difference in the bit allocation from average rate\n*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} NBC_CHANNEL_SI;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBC_CHANNEL_SI nbc_si[CHANNELS]; /* see above */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble time[CHANNELS][IBLEN]; /* x timesignals, Offset: IBLEN */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} NBC_PSY_OUT;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3.2 Description of the event detection.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe event detection module measures changes in the time-frequency\nstatistics of the input channels and specifies when the time/frequency\nmapping module should switch to a short window length. Although all\ninput channels can switch window length independently, subsequent joint\nchannel coding (matrixing) modules may require that groups of channels\nswitch together, so a mechanism to group channels is provided. The\nmodule output is window type (long, short, start, stop)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe RM2 reference software (FHG_D1) as it appears on the server has the\nevent detection inside the psychoacoustic model."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[put CHANNEL_NO enum here]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[put WINDOW_TYPE enum here]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[put BLOCK_LEN enum here]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfunction prototype:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwindow_ctl("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* inputs */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong channel_enable_mask, /* As in t/f module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong num_groups, /* Specifies number of channel groups */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong channel_group[MAX_CHANNELS], /* Specifies to which group each\nchannel belongs."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach channel must be assigned to a group. Array index is channel number,\narray value"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nis group number (starting from zero). Each channels can be assigned to\nits own group */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* output */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong win_type[MAX_CHANNELS] /* Value is that for long, start, short,\nstop."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf channels are grouped then the win_type for all channels in the group\nis identical */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4. Description of the joint coding module*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThree different methodologies are considered"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. Matrix"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. Dynamic crosstalk"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. Prediction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe expect that method one and two will be useful as stand alone modules\nas well as when used one after the other."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4.1. Matrix*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExtension of MS-like techniques to more than two channels (the number of\noutput channels is equal to the number of input channels). The matrix\nhas an inverse. This technique is generally most effective in the lower\nfrequency range."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf just pairs of channels are considered: Left / right and left-surround\n/ right-surround in the case of 5-channel configuration (3/2), then the\nfollowing matrix configuration modes are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nL R C Ls Rs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*L+R* *L-R* C Ls Rs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nL R C *Ls+Rs* *Ls-Rs*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*L+R* *L-R* C *Ls+Rs* *Ls-Rs*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe bold-marked channels are processed jointly and the remaining\nchannels are passed without processing."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe joint channel coding in the current version of the reference model,\nRM3, operates only on channel pairs."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThey are coded as pairs by coding left and right as either left + right\n(L/R) or mid/side (M/S). The L/R vs. M/S decision is made on a coder\nband by coder band basis (see Tables 1 and 2) for all frequency samples\nin the current block.. For each coder band this process is used:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1) For each coder band, not only L and R raw thresholds, but also\nM=(L+R)/2 and S=(L-R)/2 raw thresholds are calculated. For the raw M and\nS thresholds, rather than using the tonality for the M or S threshold,\none uses the more tonal value from the L or R calculation in each\nthreshold calculation band."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2) The raw thresholds for M, S, L and R, and the spread energy\nfor M, S, L and R, are all brought into an \u201cimaging control process\u201d."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3) The final, protected thresholds for all of M,S,L and R are\ndirectly applied to the appropriate spectrum."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4) The number of bits actually required to code M/S, and the\nnumber of bits required to code L/R are calculated."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5) The less expensive coding method is used in the given coder\nband, and the stereo mask is set accordingly."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe inputs of the stereo coding decision block are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe right and left spectra,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe M and S spectra"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe M, S, L and R protected thresholds"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe outputs are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe spectra, with L/M and R/S intermingled as decided on a coder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nband by coder band basis"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe proper thresholds, as selected for each coder band"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe stereo mask, containing the pattern of MS vs. LR coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe stereo image protection block has as inputs:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe R, L, M, and S raw thresholds"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe R, L, M and S spread energies"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIts outputs are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nR, L, M, S protected thresholds"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe protection process is as follows, for each coder band:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMthr,Sthr,Rthr, Lthr are the raw thresholds."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMengy,Sengy,Rengy,Sengy are spread energy."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMfthr, Sfthr, Rfthr, Lfthr are the final (output) thresholds."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbmax(i) is the BMLD protection ratio, as defined in Johnston,Ferreirra,\nASSP/91"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nt=Mthr/Sthr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (t>1) t=1/t"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRfthr= max(Rthr*t, min (Rthr, bmax*Rengy)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLfthr= max(Lthr*t, min (Lthr, bmax) *Lengy)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nt=min(Lthr, Rthr)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMfthr=min(t, max(Mthr, min(Sengy*bmax,Sthr) )"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSfthr=min(t, max(Sthr, min(Mengy*bmax,Mthr))"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4.2. Dynamic crosstalk*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProcessing corresponds to dynamic crosstalk described for MPEG-2-BC.\nThis joint channel coding technique is a general form of intensity\nstereo coding, and is generally most effective in the higher frequency\nrange."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor each channel configuration of the coding system, the possible\ncombinations of channels to be processed jointly have to be defined. In\nthe following only the 2-channel and the 5-channel (3/2) configurations\nare considered. Joint channel processing for the remaining channel\nconfigurations has to be defined."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJoint processing for the 2-channel case:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nL R"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*L/R* x"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJoint processing for the 5-channel case:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nL R C Ls Rs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*L/R* x C Ls Rs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*L/C/R* x x Ls Rs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*L/Ls* R C x Rs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nL *R/Rs* C Ls x"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nL R C *Ls/Rs* x"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*L/R* x C *Ls/Rs* x"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*L/Ls R/Rs* C x x"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*L/C/R* x x *Ls/Rs* x"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*L/C/R/Ls/Rs* x x x x"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe bold-marked channels are processed jointly and the remaining\nchannels are passed without processing. Channels marked by x need not to\nbe quantised."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following interface is needed:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInput: output of the time/frequency mapping or alternatively the M-S\nblock: all M spectral components of all channels, masked threshold\ninformation and tonality flags for all spectral components of all\nchannels."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOutput: Lower frequency limit L for which dynamic crosstalk is applied\n-> quantizer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDynamic crosstalk configuration information: K configuration indices per\nshort or long block for the K scalefactor bands -> quantiser"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDynamic crosstalk information for the K scalefactor bands -> quantiser"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nN processed spectral components of all channels -> quantiser"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nM-N unmodified spectral components of all channels -> quantiser"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFurthermore the definition of scale factor bands has to be known to the"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndynamic crosstalk module. The configuration information consists of\nflags indicating if dynamic crosstalk is applied to a specific subband\ngroup."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble **pp_spectrum, /* pointer to array of spec coef for each channel\nin group */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble **pp_thr, /* pointer to array of thr values for each channel in\ngroup. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble **pp_tonal, /* pointer to array of tonality flags for each\nchannel in group */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble **pp_scf, /* pointer to array of scalefactors for each channel in\ngroup. (scale- factors are peak values) */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong *matrix_config /* array giving matrix configuration by scalefactor\nband. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} DYN_CT_MATRIX;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfunction prototype:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndyn_ct_matrix ("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* input */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlong num_groups, /* Specifies number of channel groups */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* input and output */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDYN_CT_MATRIX matrix_info[MAX_CHANNELS]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4.3. Prediction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPrediction of spectral components based on preceding components and/or\ncomponents in other channels. In case of prediction, the outputs of the\nmodule to the quantiser are prediction error signals. The simplest\napproach is to replace the Matrix by a zero order predictor, e.g. giving\nthe following signals to the quantiser:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nleft, right - quantised left, left surround, right surround - quantised\nleft surround"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn this case the quantised signals of some channels are needed as input\nto the joint channel block, i.e. the quantiser first has to be called\nfor a subset of channels and after prediction for the rest of the\nchannels."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the general case adaptive predictors of higher order can be used\nwhich calculate a prediction value from quantised preceding signals from\nthe same and other channels and from quantised simultaneous signals of\nother channels. Therefore the predictor configuration has to be adjusted\nwith the quantiser module and it seems useful to integrate this type of\nprediction in that module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4.4 Core experiments*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJoint coding experiments are currently planned for the RM3 operating in\nstereo mode vs. RM3 operating in dual mono mode (no joint coding or bit\nallocation). This set of core experiment will determine whether RM3 can\nbe improved by joint bit allocation and joint coding of channel pairs\nusing M/S (sum/difference) matrixing. For these experiments, the\nevaluation will be done using both headphones and loudspeakers (see also\nISO/IEC JTC1/SC29/WG11/N01150)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the future, core experiments may be planned to determine if RM3 can\nbe improved by joint coding of channel pairs using intensity stereo\nmatrixing."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. {blank}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFive-channel joint coding experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor these experiments RM will process 5 channels, the stimulus set will\nbe 5-channel audio (L,R,C,Ls,Rs) and the evaluation will be done using\nloudspeakers. The presentation format will be similar to that used in\nthe RM3 listening tests, but with the test material recorded onto Tascam\n8-track tapes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. {blank}\n. Measure the improvement in RM when the best stereo matrixing module is\nused for both L,R and Ls,Rs.\n. {blank}\n. If the best stereo matrixing module can be extended to 5-channel\nmatrixing then measure the improvement in RM when the 5-channel module\nis used.\n. {blank}\n. Measure the improvement in RM when simultaneous 5-channel matrixing is\nused. It might be that more than one matrix set for simultaneous\ncombinations will be tested (one example of a matrix set is given in\nsection 4.2).\n. {blank}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5. Description of the quantization and coding module*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.1 Coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Noiseless Coding Method for Individual Channels*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe noiseless coding method for individual channels relies on two\ndivisions of the quantized spectrum. The first, fixed division, is into\n\u201cscale factor bands\u201d, where there is one scalefactor per band, these\nbands contain a multiple of 4 quantized spectral coefficients, and no\nmore than 32 quantized spectral coefficients."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe second division, which is data dependent, is the division of scale\nfactor bands into sections. The importance of a section is that there is\none huffman codebook used per section."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFirst a description of the Huffman codebooks. There are currently 7\nhuffman codebooks defined for the spectral data, as listed in Table N1\nbelow. In addition, there is one huffman codebook for DPCM scalefactor\ntransmission, where the DPCM coding is done on the quantized (i.e.\nprecalculated) scale-factor values. This DPCM coding will be described\nbelow. There are at least two other \u201ccodebooks\u201d that are assigned to\nsections above and beyond the actual Huffman codebooks, specifically the\n\u201czero\u2019 codebook, indicating that neither scalefactors nor quantized data\nwill be transmitted, and the \u201cintensity codebook\u201d indicating that this\nindividual channel is part of a channel pair, and that the data that\nwould normally be scalefactors is rather steering data for intensity\nstereo. In this case, there are no quantized spectral data transmitted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE N1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Codebook Number |Dimension of Codebook |LAV for codebook\n|1 |4 |1\n|2 |4 |1\n|3 |4 |2\n|4 |2 |3\n|5 |2 |5\n|6 |2 |9\n|7 |2 |(16) ESC\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the target syntax, 4 bits will be used to select the table. The\nfollowing codebooks will be used:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Codebook Number |Dimension of Codebook |LAV for codebook\n|0 |n |0\n|1 |4 |1\n|2 |4 |1\n|3 |4 |2\n|4 |4 |2\n|5 |2 |3\n|6 |2 |3\n|7 |2 |5\n|8 |2 |5\n|9 |2 |9\n|10 |2 |9\n|11 |2 |16\n|12 |2 |16\n|13 |2 |(16) ESC\n|14 |2 |(16) ESC ?\n|15 |0 |intensity\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe dimension of the codebook shows how many individual spectral lines\nare included in one Huffman codeword. The \u201cLAV\u201dcolumn show the largest\nabsolute value that is encoded in a given codebook. A word of\nexplaination for the ESC codebook:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe ESC codebook has codes from -16 to16 inclusive. The values from -15\nto 15 encode actual data values, the values -16 and 16 trigger an\n\u201cescape\u201d sequence that will be described below. This ESC sequence is how\nquantized spectral elements of LAV>15 are transmitted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe escape value consists of n 1\u2019s, followed by a zero, followed by n+4\nbits of escape data, that may be decoded by calculating the absolute\nvalue as 2^(n+4)+escape data. In other words, an escape word of 00000\nwould decode as 16, an escape word of 01111 as 31, an escape word of\n1000000 as 32, one of 1011111 as 63, and so on."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nQuantized spectral coefficients. Transmitted for non-zero sections from\nlow to high frequency, using the codebook indicated by the secton. For\n\u201cintensity\u201d codebook sections, this data is omitted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition a technology proposed by NEC for RM2 will also be included\nin RM3. This technology is related with noiseless coding to be applied\nto huffman coding parts for quantized frequency components. This\ntechnology is related with noiseless coding to be applied to coding\nparts for quantized frequency components."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSeveral non-zero-amplitude samples are replaced by samples with smaller\namplitudes in order to enable the use of code tables with higher coding\nefficiency. This replacement is compensated by sending differences in\namplitude and frequency positions of the samples. The freqeuncy\ninformation is represented by the combination of the scalefactor band\nnumber to indicate the starting points, and offsets. Currently, the\nmaximum number of samples to be replaced is set to 3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.2. Codebook partitioning*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe codebook partitioning in RM3 is based on the AT&T dynamic\npartitioning method. In the encoder, the following process determines\nthe actual partitioning (sectioning) as follows:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1) Calculate the cost of sending each possible section, i.e., the cost\nof sending a new section wherever called for.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2) Calculate the cost of removing each of the seperators between\nsections.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3) Remove the most costly seperator, as long as it has a positive cost\n(negative effect on data compresion.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4) Repeat 3 until there are no separators that do not provide\ncompression gain.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.3. Quantization*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe current reference model uses non-uniform quantization (X0.75) as\ndescribed in 11172-3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe granularity of the quantizer step size is 1.5 dB."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.4. Scalefactor bands*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe current reference uses 36 to 49 scalefactor bands for the long\nwindow case and 12 to 14 scalefactor bands for short windows. A\nsuperframe structure is used to code scalefactors for short windows. In\naddition, there is one huffman codebook for DPCM scalefactor\ntransmission, where the DPCM coding is done on the quantized (i.e.\nprecalculated) scale-factor values. The order of data transmission is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPCM Scalefactor. This scalefactor is the first scale factor, starting\nfrom lowest frequency, that has a non-zero codebook. This first\nscalefactor is transmitted as a PCM word in order to provide the\nabsolute gain reference."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSection information: The section information is transmitted as pairs of\ndata, where each data pair contains a codebook and a count of how many\nscalefactor bands are included in that section."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDPCM scalefactors: The rest (if any) of the scalefactors in\nnon-zero-section bands are transmitted in a DPCM fashion, with the\ndifference between the active scalefactor and the previous active\nscalefactor transmitted via a Huffman code."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScalefactor coding as done in RM 2 is still under consideration as an\noptional technique to be tested."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nQuantized spectral coefficients. Transmitted for non-zero sections from\nlow to high frequency, using the codebook indicated by the secton. For\n\u201cintensity\u201d codebook sections, this data is omitted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.5. Buffer techniques*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA short term buffer as in IS 11172-3 will be used. The total length of\nthe buffer in RM 3is 1024 bytes. No core experiment is currently\nproposed on the buffer technique."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.6. Prediction (intra-channel)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe prediction module as supplied by Hannover University is part of RM\n3. A backward-adaptive lattice structure predictor is used. The\npredictor is 2 taps long working on prior blocks for each frequency\nline. Provisions for stability control are incorporated."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.7. Framing*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe current RM 3uses a frame length of n 1024 time-domain samples, 1 <=\nn <= 4. For short blocks, scalefactors are valid for more than one\nwindow in time direction."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.8. Function prototypes and basic structures*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n5.8.1. Function prototypes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe RM2 (see also ISO/IEC JTC1/SC29 WG11 N1095) software on the Hannover\nftp-site is described below and it consists of the following parts:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. psychoacoustic (object code)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. t2f-module (object code)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. quantization loops (object code) with the following submodule:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhole inner loop (object), further splitted into three objects:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}a) quantizer (object)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}b) scalefactor bitcounter (object)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}c) Huffman bitcounter (object)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4. bitstream encoder (source)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5. decoder (source)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDifferent modules for the quantization can be implemented by replacing\nthe quantization loops subfunctions or the whole module. The bitstream\nencoder is source and can therefore be adapted easily."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Spectrum Encoding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nloops_init(); /* initializes the loops interface */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* function for the loops module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid *nbc_encoder("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort gran_cnt, /* IN, granule (0 or 1) */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndouble *spec_in, /* IN */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* pointer to the not quantized spectral values from the t2f module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBC_PSY_OUT *nbc_psy_out, /* IN */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* output structure from psychoacoustic module */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint header_bits, /* IN */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* number of header bits (for us up now 32), because loops need to know"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nthe bits left for the dynamic part */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint sideinfo_bits, /* IN */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* number of side info bits ( now 80 ) */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *bits_per_frame, /* OUT */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* total frame length in bit */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nframe_params *fr_ps, /* OUT */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* bitstream encoder structure, containg header infos (see bit_stream.h)\n*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort quant[GRANULES][MAX_CHANNELS][IBLEN], /* OUT */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* quantized output values from the loops, not really needed, because"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhuffman encoding itself is done in the loops part */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIII_side_info_t *l3_sideinfo, /* OUT */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* side information according to the standard */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIII_scalefac_t *scalefacs, /* OUT */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* scale factors */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint ancillary[GRANULES][NSB_LONG], /* OUT */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* ancillary data for prediction on/off (1=on) for each scalefactor band"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(this means 36 time 0 or 1 */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *anc_rate, /* OUT */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* number of ancillary bits, here 36 */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint huff_len[GRANULES][MAX_CHANNELS][2*IBLEN], /* OUT */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* number of bits used for the Huffman data in huff_data */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBS_TYPE huff_data[GRANULES][MAX_CHANNELS][2*IBLEN] /* OUT */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Huffman data themselves */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Inner Loop*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* return value: number of unused bits for the quantization."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis function calls all routines to perform an inner loop as described\nin the standard. In"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhere no noise shaping is done, only a quantization of the whole spectrum\nis performed so long, until"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nthe maximum of the quantized values is in the permitted range */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint inner_loop("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSPEC_DATATYPE *spec_ptr, /* (IN) spectrum */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort *quant_ptr, /* (OUT) contains the quantized data */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSCALING_SIDE_INFO *ssi_ptr, /* (IN/OUT) contains side infos */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSCFBD_INFO *sci_ptr, /* (IN) scalefactor band related informations */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHUFFMAN_SIDE_INFO *hc_side_info_ptr, /* (OUT) infos concerning the\nHuffman coder */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint start_qstep_size, /* (IN) starting step size of the quantizer */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint huffman_bits, /* (IN) allowed bits in the dynamic part */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort *pass1, /* (IN) first iteration ? */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint nr_of_active_sfb, /* (IN) nr of scale factor bands that are not"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncompletely zero at the start of the loops */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *loc_sfb_max_offs, /* (OUT) the line offset of the maximum quantized"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvalue for each scalefactor band */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint spect_lines, /* (IN) nr of lines in the spectrum not completely zero"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nat the start of the loop*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint fch, /* (IN) no of the first channel */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint lch[GRANULES], /* (IN) no of the last channel for each granule */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint fgr, /* (IN) no of the first channel */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint lgr /* (IN) no of the last granule */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Quantizer*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* non uniform quantizer. The return value is the maximum of the\nquantized values. It has to be smaller then MAXQUANT. */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort quantize_sfbs("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort *pass1, /* (SRC)first Iteration? */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSPEC_DATATYPE *spec_ptr, /* (SRC)xr on intialization, NULL otherwise */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort *quant_ptr, /* (DEST)data field to be quantized */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *loc_sfb_max_offs_ptr, /* (SRC) the line offset of the maximum\nquantized"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvalue for each scalefactor band */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *max_offset, /* (SRC/DEST) the line offset of the biggest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nquantized value in the whole spectrum."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe function doesn't perform quantization but"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nreturns only maxquant if max_offset is not NULL */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort *sfb_width_ptr, /* (SRC)scalefactorband-widths */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfloat *quantizer_sfb, /* (SRC)quantizers */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint nr_of_sfb ); /* (SRC)nr of scale factor bands to be quantized */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* Returns the global gain. Is called to get a starting point of the\nglobal gain before the loops"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nprocess starts */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort calc_start_quantizer( SPEC_DATATYPE max_abs_value );"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Scalefactor Coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* function to check if the amplification limits have been reached */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid get_sf_amp_limits("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSCALING_SIDE_INFO *ssi_ptr,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSCFBD_INFO *sci_ptr,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint nr_of_active_sfb );"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* returns the number of bits needed for the scalefactors */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint sf_bits_grch("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSCFBD_INFO *sci_ptr, /* (IN) contains infos about scalefactor bands as\nwidth... */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSCALING_SIDE_INFO *ssi_ptr, /* (OUT) for example the number of scalefac\nbits is written in here */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIS_OUT_INFO *is_info_ptr, /* (IN) only relevant for joint stereo, for no\nuse here */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort *quant_ptr, /* (IN) quantized values */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLOOP_GRCH_INFO *lgcp, /* (IN) information needed internally for the\nloops */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint mode_flag /* (IN) several possibilities: should be set to zero or 2\n*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Spectrum Coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* return value: number of bits for Huffman Encoding */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint spec_bitcount("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort *quant_data_ptr, /* (IN) quantized data */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort block_type, /* (IN) block_type */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort mixed_block_flag, /* (IN) not needed for NBC */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort *sfb_width_ptr, /* (IN) width of the scalefactor bands (sfb) */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *loc_sfb_max_offs_ptr, /* (IN) the line offset of the maximum\nquantized"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvalue for each scalefactor band */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint known_rzeros, /* (IN) number of lines jnown to be zero at the upper"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nend of the spectrum */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint sub_div_procedure, /* (IN) several possiblities for the Huffman\nprocess"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHC_REG_THIRDS or HC_REG_FULLSEARCH */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHUFFMAN_SIDE_INFO *hc_side_info_ptr); /* (OUT) Huffman ifnformations */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* real encoder, used in the bitstream encoder */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunsigned short spec_encoder("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort *quant_data, /* (IN) quantized data */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort sfb_width[], /* (IN) sfb widthes */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHUFFMAN_SIDE_INFO *hci_ptr, /* (IN) Huffman ifnformations */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunsigned long *hc_ptr, /* (OUT) ptr to array where to write the huffman\ncode words */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint *hcl_ptr); /* (OUT) ptr to array where to write the huffman code\nlengthes */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Bitstream Encoder*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* open the device to write the bit stream into it */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid open_bit_stream_w(bs, bs_filenam, size)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBit_stream_struc *bs; /* bit stream structure */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchar *bs_filenam; /* name of the bit stream file */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint size; /* size of the buffer */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid III_format_bitstream( int bitsPerFrame,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nframe_params *in_fr_ps,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshort l3_enc[2][2][BLOCK_LEN_LONG],"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* changed from int to short for NBC */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIII_side_info_t *l3_side,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIII_scalefac_t *scalefac,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBit_stream_struc *in_bs,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint ancillary[36],"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint ancillary_bits,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint huff_len[2][2][2*BLOCK_LEN_LONG],"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBS_TYPE huff_data[2][2][2*BLOCK_LEN_LONG] )"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA detailed description of the structures used can be found on the ftp\nsite."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.9 Core experiments*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following core experiment has been proposed by AT&T."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Temporal noise shaping (TNS) in perceptual coders via LPC prediction in\nthe Frequency Domain*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInappropriate temporal spread of quantization noise in time is known to\nbe the reason for the so-called \"pre-echo\" artifacts. These artifacts\nshow up when a transient signal is being coded because the quantization\nnoise is spread out over the whole window length. Due to the low\nbackward masking ability of the human auditory system, the quantization\nnoise is perceived by the listener as an artifact. This can present a\nmajor problem especially in the case of \"pitched\" signal consisting of a\npseudo-stationary series of impulse-like signals (e.g. speech) that are\ndifficult to handle with known methods like window switching. In fact, a\ncoder using only window switching techniques would have to code such a\nsignal most of the time in \"short block\" mode in order to avoid the\npre-echo problems arising from the impulse-like structure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe proposed method overcomes such problems by offering an alternative\nmethod for temporal noise shaping (TNS). A coder using TNS will apply\nthe following processing steps:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00a5 the input signal is decomposed into spectral coefficients by a\nhigh-resolution filterbank / transform (like most of today\u00d4s perceptual\ncoders)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00a5 the coding of the spectrum is done using an LPC-type predictor that\noperates on the filterbank outputs (in FREQUENCY)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00a5 employing a closed-loop (DPCM-like) prediction system will give a\ncoding gain for transient signals, however,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00a5 the preferred solution is the use of an open-loop predictor quantizer\nwhich will result in a time-shaped quantization error at the output of\nthe decoder. Since the prediction filter has been applied to SPECTRAL\ncoefficients, the quantization noise in the signal after the inverse\nfilterbank will be shaped in TIME, putting the quantization noise under\nthe actual signal. In this way, temporal problems with unmasking, either\nin transient or pitchy signals, are avoided without the need for\nsubstantial overcoding and its commensurate expediture of bits."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSince predictive coding is applied to spectral domain data, the\nrelations known for classic predictions are valid with time and\nfrequency domain swapped:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00a5 Prediction gain is achived depending on the \"envelope flatness\nmeasure\" of the signal (as opposed to the \"spectral flatness measure\"),\ni.e. the potential gain of the method increases the more transient the\nsignal is."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00a5 If an open-loop quantization scheme is used in the encoder the\nprediction error is shaped in time (as opposed to frequency)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn effect, the TNS technique is equivalent to applying an adaptive time\ndomain window by prediction in the frequency domain, effectively using\nconvolution by a few elements in the frequency domain to instantiate\ntime-domain noise shaping. Contrary to the \"gain change\" approach,\nhowever, there is no need to employ a sophisticated hybrid filterbank\nand the application range of the process is not restriced to the fixed\nfrequency bands defined by the first stage of the hybrid filterbank."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs the TNS process can be done either for the entire spectrum, or for\nonly part of the spectrum, the time-domain noise control can be applied\nin any necesssary frequency-dependent fashion."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPlease note that both closed-loop and open-loop quantization / coding\ncan be used in the encoder without any need to change the normative\nparts of a standard, i.e. the bitstream format and the decoding process."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following pre-screening experiments have been proposed:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Coding using arithmetic coding- GCL\n* *GCL is going to carry out prescreening test with its*\n* *lossless coding technique. Technique used will be*\n* *same as tested in 2nd core experiment with two*\n* *possible changes.*\n* *(1) Arithmetic coding will be replaced with*\n* *equivalent substitute for reduced complexity.*\n* *(2) To verify performance with new techniques*\n* *such as new predictor parameter from Univ.*\n* *Hannover or AT&T lossless technique,*\n* *modified reference model can be used,*\n* if they are supplied timely**.**Tests procedure is same\n* as previous lossless coding test. No listening\n* test will be carried out.\n* {blank}\n* Trellis coding- TI\n* TI will be conducting experiments involving the\n* integration of a trellis coded quantizer with\n* RM2. A series of prescreening tests will be\n* performed and the results will be presented at\n* the March meeting\n* Pyramid Vector coding- Alcatel-Telettra (?)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Bidimensional quantization- CCETT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6. Description of the bit stream formatter*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAudio_Data_Transport_Stream versus Raw_Data_Stream"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Raw_Data_Stream contains all data which belong to the audio and are\nchanging from block to block or frame to frame. Syntax elements which\nare constant within an audio stream or audio file, are used to enhance\nthe parsability or error resilience or are not audio data are described\nwithin a Audio_Data_Transport_Stream. The simplest\nAudio_Data_Transport_Stream contains just one repetition of these\nconstant syntax elements (e.g. layer, sampling_frequency,\nchannel_configuration etc.), followed by a Raw_Data_Stream which can be\ndecoded with the help of the information in the\nAudio_Data_Transport_Stream. Additionally, the\nAudio_Data_Transport_Stream contains data elements which help with\nsynchronization and error resilience."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBelow a Audio_Data_Transport_Stream similar to MPEG-1 / MPEG-2 syntax is\ngiven. This will be recognized by MPEG-1 decoders as a \u201eLayer 4\u201c\nbit-stream."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|audio sequence() | |\n|\\{ | |\n|while (nextbits()==syncword) \\{ | |\n|adts0_frame() | |\n|} | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *Audio_Data_Transport_Stream frame, ADTS0*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|adts0_frame() | |\n|\\{ | |\n|adts0_fixed_header() | |\n|adts0_variable_header() | |\n|error_check() | |\n|NBC_Raw_Data() | |\n|byte_alignment() | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *Fixed Header of ADTS0*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis header contains the syncword plus all parts of the header which are\nnecessary for decoding and which do not change from frame to frame. A\nmimumum Audio_Data_Transport stream could transmit these data just once\nat the start time of the transmission resp. start of a file for storage."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|adts0_fixed_header() | |\n|\\{ | |\n|syncword |12 |bslbf\n|ID |1 |bslbf\n|layer |2 |bslbf\n|protection_bit |1 |bslbf\n|sampling_frequency |2 |bslbf\n|private_bit |1 |bslbf\n|channel_configuration |3 |bslbf\n|original/copy |1 |bslbf\n|home |1 |bslbf\n|emphasis |2 |bslbf\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *Variable Header of ADTS0*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe variable header of ADTS0 contains header data which change from\nframe to frame. A minimum Audio_Data_Transport stream can have some of\nthese omitted, others defined to be static for the audio data to be\ncoded and put into the fixed header."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|adts0_variable_header() | |\n|\\{ | |\n|bitrate_index |4 |bslbf\n|copyright_id |1 |bslbf\n|copyright_id_start |1 |bslbf\n| | |\n|if ( bitrate_index != 0 ) \\{ | |\n|main_data_begin |10 |bslbf\n|} | |\n|else \\{ | |\n|next_header |12 |bslbf\n|buffer_fullness |8 |bslbf\n|} | |\n|number_of_raw_data_blocks_in_frame |2 |uimsfb\n|for(nraw=0; nraw<number_of_raw_data_blocks_in_frame; nraw++) \\{ | |\n|num_syntactic_elements(nraw) |5 |uimsfb\n|} | |\n|padding_bit |1 |bslbf\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *Error detection*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis is the error detection as defined for MPEG-1 and MPEG-2 audio."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|error_check() | |\n|\\{ | |\n|if (protection_bit==0) | |\n|crc_check |16 |rpchof\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *Raw Data*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis is the raw_data_stream. It is really a data stream which is put\ninto the Audio_Data_Transport stream either using constant rate headers\nand a back-pointer construction as is MPEG-1 Layer 3 or a variable rate\nheader and a buffer fullness measure with all the data of one frame\ncontained between two occurences of the header."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Raw_Data_Stream*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|NBC_raw_data_stream() | |\n|\\{ | |\n|while ( NBC_raw_data_block()) | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|NBC_raw_data_block() | |\n|\\{ | |\n|while(MIN_CP_VALUE<=next_bits(8)<=MAX_LFE_VALUE) | |\n|syntactic_element() | |\n|while (MIN_DATA_VALUE <= next_bits(8) <= MAX_DATA_VALUE) \\{ | |\n|data_element() | |\n|} | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|syntactic_element() | |\n|\\{ | |\n|if (MIN_CP_VALUE <= next_bits(8) <= MAX_CP_VALUE) \\{ | |\n|channel_pair_element() | |\n|} | |\n|if (MIN_CC_VALUE <= next_bits(8) <= MAX_CC_VALUE) \\{ | |\n|coupling_channel_element() | |\n|} | |\n|if (MIN_LFE_VALUE <= next_bits(8) <= MAX_LFE_VALUE) \\{ | |\n|lfe_channel_element() | |\n|} | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|channel_pair_element() | |\n|\\{ | |\n|channel_pair_id |8 |bslbf\n|two_chan |1 |uimsbf\n|window_sequence |3 |uimsbf\n|window_shape |1 |uimsbf\n|if( two_chan ) \\{ | |\n|ms_mask_present |1 |uimsbf\n|if( ms_mask_present ) | |\n|for( sfb=0; sfb < num_sfb; sfb++ ) \\{ | |\n|ms_used[sfb] |1 |uimsbf\n|} | |\n|} | |\n|} | |\n|individual_channel_stream(0) | |\n|if( two_chan ) \\{ | |\n|individual_channel_stream(1) | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|individual_channel_stream() | |\n|\\{ | |\n|predictor_data_present |1 |uimsbf\n|if(window_sequence>=SHORT_START_WINDOW) \\{ | |\n|scale_factor_grouping |3-8 |uimsbf\n|} | |\n|first_scale_factor |8 |uimsbf\n|section_data() | |\n|if (predictor_data_present) \\{ | |\n|predictor_reset |5 |uimsbf\n|for( sfb=0; sfb<num_sfb; sfb++ ) \\{ | |\n|prediction_used[sfb] |1 |uimsbf\n|} | |\n|} | |\n|scalefactor_data() | |\n|spectral_data() | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|section_data() | |\n|\\{ | |\n|top=number_of_coderbands[window_sequence] | |\n|k=0 | |\n|i=0 | |\n|while ( k<top) \\{ | |\n|sect_cb[i] |4 |uimsbf\n|len=0 | |\n|while (tmp == 15 ) len += 15 |4 |uimsbf\n|len += tmp | |\n|sect_start[i]=k | |\n|sect_end[i]=k+len | |\n|k += len | |\n|i++ | |\n|} | |\n|num_sec=i | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|scalefactor_data() | |\n|\\{ | |\n|for (i=1; i<num_sfb; i++) \\{ | |\n|if (sect_cb[i] > 0) | |\n|hcod_sf[dpcm_sf[i]] |1..12 |uimsbf\n|} | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|spectral_data() | |\n|\\{ | |\n|for (i=0; i<num_sec; i++) \\{ | |\n|if (sect_cb[i] != 0 && sect_cb[i] != INTENSITY_CB) \\{ | |\n|for (k=bin[sect_start[i]; k< bin[sect_end[i]]; ) \\{ | |\n|if (sect_cb[i]<4) \\{ | |\n|hcod[sect_cb][w][x][y][z] k += 4 |1...31 |uimsbf\n|else \\{ | |\n|hcod[sect_cb][y][z] k += 2 |1..31 |uimsbf\n|if (sect_cb[i]==7) \\{ | |\n|if (\\|y\\|==16) | |\n|hcod_esc_y |1..31 |uimsbf\n|if (\\|z\\|==16) | |\n|hcod_esc_z |1..31 |uimsbf\n|} | |\n|} | |\n|} | |\n|} | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"70%,15%,15%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|coupling_channel_element() | |\n|\\{ | |\n|coupling_channel_id |8 |bslbf\n|number_of_coupled_channel_pairs |8 |uimsbf\n|for ( ncp=0;ncp<number_of_coupled_channel_pairs;ncp++) \\{ | |\n|get_ccp(ncp); } |8 |uimsbf\n|window_sequence |3 |uimsbf\n|window_shape |1 |bslbf\n|individual_channel_stream() | |\n|while (gain_element_present()) | |\n|get_gain_element() |1 ... 31 |uimsbf\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDefinitions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPADDING_VALUE 0x00MIN_CP_VALUE 0x01"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMAX_CP_VALUE 0x1F"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMIN_CC_VALUE 0x20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMAX_CC_VALUE 0x2F"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMIN_LFE_VALUE 0x30"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMAX_LFE_VALUE 0x3F"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMAX_NSEL_VALUE 0xEF"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMIN_DATA_VALUE 0xF0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMAX_DATA_VALUE 0xFE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPADDING_DATA_VALUE 0xFF"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nONLY_LONG_WINDOW 0x0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLONG_START_WINDOW 0x1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLONG_STOP_WINDOW 0x2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSHORT_START_WINDOW 0x3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSHORT_STOP_WINDOW 0x4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEIGHT_SHORT_WINDOW 0x5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSHORT_EXT_STOP 0x6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNINE_SHORT_WINDOW 0x7"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnext_bits(n) reads next n bits of the bit stream. The pointer to the bit\nstream is not changed (e.g. the next call of next_bits() with the same\nvalue n will read the same bits as the previous call)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntransport_align_function() function which performs byte alignement if\nrequired by the transport layer. For raw data stream this is just a\ndummy function doing nothing."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnot_byte_aligned() function that returns one as long as the current bit\nstream pointer is not byte aligned with the first bit of the bit stream.\nOtherwise it returns 0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBit stream elements"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBC_raw_data_stream() stream of raw data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBC_raw_data_block() block of raw data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*num_syntactic_elements* the number of syntactic elements in the bit\nstream. Must be less than 0xF0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsyntactic_element() element of the bit stream that contains audio data.\nMay be a channel pair, channel coupling or low frequency enhancement\nchannel element"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndata_element() element of the bit stream that contains audio related\ndata"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*padding_bit* bit to be discarded by the decoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*padding_byte* byte to be discarded by the decoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchannel_pair_element() part of the bit stream that contains audio data\nfor one or a pair of channels."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncoupling_channel_element() part of the bit stream that contains audio\ndata for a coupling channel"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlfe_channel_element() part of the bit stream that contains audio data\nfor a low sampling frequency enhancement channel"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following syntax elements are related to NEC noiseless coding (see\nSection 5.5.) and will be incorporated in the RM3 target syntax."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnumber_of_replacement 2 uimsbf"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif(number_of_replacement >0) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstart_sfb 6 uimsbf"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfor(k=0;k<number_of_replacement;k++) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noffset[k] 5 uimsbf"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndiff_amplitude[k] 4 uimsbf"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor completeness, the MSDL specifications for the RM3 syntax is\ndescribed below. This description is not yet finalized."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SYNCWORD=?; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ PADDING_VALUE=0x00;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_CP_VALUE=0x01;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_CP_VALUE=0x1F;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_CC_VALUE=0x20;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_CC_VALUE=0x2F;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_LFE_VALUE=0x30;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_LFE_VALUE=0x3F;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_NSEL_VALUE=0xEF;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_DATA_VALUE=0xF0;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_DATA_VALUE=0xFE;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ PADDING_DATA_VALUE=0xFF;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ ONLY_LONG_WINDOW=0x0;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ LONG_START_WINDOW=0x1;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ LONG_STOP_WINDOW=0x2;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SHORT_START_WINDOW=0x3;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SHORT_STOP_WINDOW= 0x4;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ EIGHT_SHORT_WINDOW =0x5;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SHORT_EXT_STOP=0x6;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ NINE_SHORT_WINDOW= 0x7;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ sampling_frequency_table (_int_(2), double rates) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ channel_configuration_table (_uint_(3), ?) ("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ emphasis_table (_uint_(2), ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ bitrate_index_table(_uint_(4), ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ window_sequence_table(_bit_(3), ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ _int_ number_of_coderbands[8]= \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// 8 values go here"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ hcod_sf_vlc ** (_vlc_, ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// scale factor Huffman codebook goes here"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ hcod_vlc ** (_vlc_, ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// Huffman codebook goes here"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ scalefactor_data \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// nonzero(a, b) returns the number of non-zero elements of array a of\nlength b"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (_nonzero_(sfb_cb, number_of_coderbands[window_sequence]) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(hcod_sf__vlc_) *hcod_sf*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ spectral_data \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (max_sd[window_sequence]) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (sd_nelems[window_sequence][cb]) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(hcod_vlc) *hcod*[cb_nelem[cb]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass individual_channel_stream \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *predictor_data_present*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (window_sequence >= SHORT_DATA_WINDOW) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1)\n*scalefactor_grouping*[scalefactor_group_size[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *first_scalefactor*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_rle_(4, 4) *sfb_cb*[number_of_coderbands[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (predictor_data_present) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(5) *predictor_reset*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *prediction_used*[num_sfb[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nscalefactor_data *ScaleFactorData*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nspectral_data *SpectralData*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ syntactic_element \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// empty on purpose"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ data_element: _bit_(8) MIN_DATA_VALUE .. MAX_DATA_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *n_bytes*; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *data*[n_bytes]; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ lfe_channel_element _is_ syntactic_element:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) MIN_LFE_VALUE .. MAX_LFE_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(4) *n_samples*; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(12) *samples*[n_samples]; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ coupling_channel_element _is_ syntactic_element:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) MIN_CC_VALUE .. MAX_CC_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *number_of_coupled_channel_pairs*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (number_of_coupled_channel_pairs) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(5) *cc_index*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *ccp*[3];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(window_sequence_table) *window_sequence*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *window_shape*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nindividual_channel_stream *IndividualChannelStream*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (_nonzero_(ccp, 3 * number_of_coupled_channel_pairs) - 1) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (_nonzero_(sfb_cb,number_of_scoderbands[window_sequence])) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(scalefactor_vlc) *gain_element*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ channel_pair_element _is_ syntactic_element :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) MIN_CP_VALUE .. MAX_CP_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *two_chan*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(window_sequence_table) *window_sequence*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *window_shape*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (two_chan) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *ms_mask_present*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (ms_mask_present) _bit_(1) *ms_used*[num_sfb[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nindividual_channel_stream *IndividualChannelStream0*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (two_chan) individual_channel_stream *IndividualChannelStream1*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ NBC_raw_data_block \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_list_ \\{ syntactic_element *SyntacticElement*; }"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_list_ \\{ data_element *DataElement*;}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ NBC_raw_data_stream \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_list_ \\{ NBC_raw_data_block *NBCRawDataBlock*;}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ adts0_variable_header \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(bitrate_index_table) *bitrate_index*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *copyright_id*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *copyright_id_start*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (bitrate_index!=0) _uint_(10) *main_data_begin*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_else_ \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(12) *next_header*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) *buffer_fullness*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(2) *number_of_raw_data_blocks_in_frame*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(5) *num_syntactic_elements*[number_of_raw_data_blocks_in_frame];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *padding_bit*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ adts0_fixed_header : aligned _bit_(12)=SYNCWORD \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *ID*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(2) *layer*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *protection_bit*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(sampling_frequency_table) *sampling_frequency*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *private_bit*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(channel_configuration_table) *channel_configuration*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *original_copy*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(1) *home*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(emphasis_table) *emphasis*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ adts0_frame \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nadts0_fixed_header *Adts0FixedHeader*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nadts0_variable_header *Adts0VariableHeader*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (protection_bit==0) _uint_(16) *crc_check*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBC_Raw_Data *NBCRawData*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ audio_sequence \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhile (SYNCWORD) adts0_frame *Adts0Frame*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ANNEX A*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThird Set of Mono Core Experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe mono RM3 functionalities are the result of the merging of the RM2\nfunctionalities and the ATT_NC, DOL_TF, FHG_QC, NEC_NC, and syntax (as\ndefined in Section 6) new functionalities (see also ISO/IEC\nJTC1/SC29/WG11/N1135)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDuring the third set of mono core exeriments, subjective listening tests\nwill be carried out to examine the following codecs. Prediction on/off\nwill not be tested at this stage, but it will be addressed during the\nnext phase of tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1) *RM3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2) *SON_P1*: Sony\u2019s proposal to include the pre-processing\noptional module (PQF, gain control, window switching, see also Section\n1.5.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3) *DOF_T1*: Dolby\u2019s and FhG\u2019s joint proposal which exploits\nadaptive block switching in the TF module ( see also Section 2.4.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4) *ATT_NS* AT&T\u2019s noise shaping proposal (see also Section 5.9)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor comparison the RM2 will also be included in the tests. The following\nprogram items will be used in the mono listening tests ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"40%,60%\",]\n|===\n|Program item code |Program item\n|1 |Harpsichord\n|2 |Castanets\n|3 |Male German speech\n|4 |Bagpipes\n|5 |Glockenspiel\n|6 |Pitch Pipe\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA total of 5* 6 = 30 trials will be carried out. The total duration of\nthe test, allocating two minutes per trial, is 60 minutes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe work plan for the mono listening tests is as follows."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"28%,72%\",]\n|===\n|3 March |Bitstreams and decoders to Hannover"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4 March |Decoded bitstreams (and hiding of identity of the decoded\nbitstreams) by Hannover"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|11 March |Tape production (Hannover or Telekom) finished and sent to\nsites"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|12-13 March |Test data by 7 test sites (AT&T, Dolby, FhG, GCL, NHK,\nPhilips, Sony) and identity information from Hannover to TI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|18 March 1996 |Results Analysis and Report by TI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|22 March 1996 |Ad Hoc Group meeting\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor further details on the work plan see ISO/IEC JTC1/SC29/WG11/N1150."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ANNEX B*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFirst Set of Stereo Core Experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe stereo RM3 functionalities are the result of the merging of the mono\nRM3 functionalities and the joint coding as described in Sections 4.1.\nand 4.4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDuring the first set of stereo core exeriments, subjective listening\ntests will be carried out to examine the following codecs."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1) RM3 operating in dual mono mode."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2) RM3_STE Stereo RM3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following program items will be used in the stereo tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"40%,60%\",]\n|===\n|Program item code |Program item\n|1 |Harpsichord\n|2 |Castanets\n|3 |Dorita\n|4 |We shall be happy\n|5 |Glockenspiel\n|6 |Pitch Pipe\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe work plan for the stereo listening tests is as follows."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"28%,72%\",]\n|===\n|3 March |Bitstreams and decoders to Hannover"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4 March |Decoded bitstreams (and hiding of identity of the decoded\nbitstreams) by Hannover"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|11 March |Tape production (Hannover or Telekom) finished and sent to\nsites"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|12-13 March |Test data by 7 test sites w. headphones (AT&T, Dolby, FhG,\nGCL, NHK, Philips, Sony) and identity information from Hannover to TI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|12-13 March |Test data by 5 test sites w. loudspeakers (AT&T, Dolby,\nFhG, GCL, Sony) and identity information from Hannover to TI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|18 March 1996 |Results Analysis and Report by TI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|22 March 1996 |Ad Hoc Group meeting\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor further details on the work plan see ISO/IEC JTC1/SC29/WG11/N1150."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= Establishment of Ad hoc group on MPEG-2 Multi-viedw Profile\nGeneric Employee\n1996-01-23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND ASSOCIATED AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11 *N1133*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG 96/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1996 January"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"19%,81%\",]\n|===\n|Source: |Video and Test Subgroups\n|Title: |Establishment of ad hoc group on MPEG-2 Multi-view Profile\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate*:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* to start exchanging bitstreams,\n* to continue organizing the framework/plan for verification testing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair*: Ajay Luthra (aluthra@gi.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Duration*: Until the Florence Meeting (3/96)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Communications*: E-mail"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Membership:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nanastas@ctr.columbia.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnsuzuki@ctr.columbia.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchoquet@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngerard.fernando@eng.sun.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhomma@itl.toppan.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nazuma@crl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntchiang@earth.sarnoff.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njan@hhi.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndanny@iris.elis.rug.ac.be"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbgh@research.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nimaizumi@strl.nhk.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nkopernik@fz.telekom.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnakasu@strl.nhk.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nap@big.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntahara@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbelle@ctr.columbia.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nR.terHorst@research.kpn.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nManfred.Ziegler@zfe.siemens.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npg@barco.be"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbj@rnd.sec.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlucas@ime.gov.sg"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmisezan@kodak.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsikora@hhi.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsaito@rd.ikegami.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nkklee@saitgw.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntktan@avirc.ams.com.sg"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstrintzi@eng.auth.gr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nserafim@dion.eng.auth.gr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nkogure@drl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nkonrad@inrs-telecom.uquebec.ca"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlaura.contin@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nleonardo.chiariglione@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nxchen@gi.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvsathe@gi.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsuzukihr@krhm.jvc-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nurano@ntv.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvittorio@fub.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\naluthra@gi.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= The MPEG-2 standard provides a broad range of compression tools that\nallow its use in a variety of different applications. Forcing... On the\nother hand, letting each user arbitrarily pick his own tools can cause\ninteroperability problems. Therefore MPEG\nZFE T SN 2\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11 *N1134*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary, 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: MPEG-2 4:2:2 Profile at Main Level Subjective Assessment Report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSource: Video and Test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MPEG-2 standard provides a broad range of compression tools that\nallow its use in a variety of different applications. Forcing the use of\nall tools could be too costly in applications which do not need them. On\nthe other hand, letting each user arbitrarily pick his own tools could\ncause interoperability problems. Therefore MPEG-2 defines various\nprofiles and levels (ISO/IEC 13818-2 chapter 8). Profiles specify the\nmaximum set of allowable tools. An encoder can use a subset of the\nallowable tools, but a compliant decoder must be able to handle all of\nthe tools within the profile. Levels specify the resolution of the\npicture. A combination of profile and level specifications defines a\npoint of compliance. Prior to the 4:2:2 Profile, MPEG-2 had 11 defined\ncompliance points. The 4:2:2 Profile at Main Level adds an additional\ncompliance point."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 4:2:2 Profile may be useful in applications which require:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( higher quality than Main Profile at Main Level"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( better chroma resolution than Main Profile at Main Level"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( post processing after compression and decompression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( multiple generations of compression and decompression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( short Group of Pictures (GOP) for editability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( capability to pass all active video"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( capability to pass vertical blanking interval information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 4:2:2 Profile at Main Level extends the highest allowed data rate to\n50 Mbit/s compared to 15 Mbit/s in the Main Profile at Main Level. This\nallows use of multiple generations and/or shorter GOP while still\nmaintaining picture quality."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 4:2:2 Profile also provides full 4:2:2 chroma resolution,\neliminating the degradation caused in down-conversion to 4:2:0\nresolution. This is important in applications requiring multiple\ngenerations and in applications having post processing between\ncompression and decompression."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAlthough both 4:2:2 chroma resolution and higher data rates are included\nin the MPEG-2 High Profile, the High profile also requires scalability.\nSince the"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n4:2:2 Profile does not include scalability, more cost effective\nimplementations are possible for those applications which do not require\nscalability."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 4:2:2 Profile extends the maximum lines per frame from 480 lines to\n512 lines in 525/60, and from 762 lines to 608 lines in 625/50. This\nallows passing the entire active picture and also allows passing\nvertical blanking interval information. Users need to be aware of the\neffects of compression in their particular vertical interval\napplication."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSince compliant 4:2:2 decoders must be capable of handling all the tools\nin the Profile, different encoding parameters may be chosen within the\nconstraints of the Profile while still maintaining interoperability.\nFurther, since both 4:2:2 and 4:2:0 are allowed in the 4:2:2 Profile,\n4:2:2@ML decoders will be capable of decoding MP@ML streams."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest Sequences"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe test sequences were generated using computer simulation of the\nMPEG-2 compression and decompression. For 525/60, the test material\nincluded:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Gwen"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Trailblazers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Mobile and Calendar"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Dissolve"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor 625/50, the test material included:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Balls of Wool"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Cactus and Comb"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Basketball"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Wall"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Renata and Butterfly"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Mobile and Calendar"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cGwen\u201d is a chroma key test sequence with a woman in the foreground\nkeyed over a forest scene in the background. \u201cGwen\u201d is a difficult\nsequence to chroma key but an easy sequence to compress. Both \u201cCactus\nand Comb\u201d and \u201cBalls of Wool\u201d are chroma key sequences which were used\nwith a colored background. \u201cTrailblazers\u201d is a rapid motion basketball\nsequence shot with an un-shuttered CCD camera. \u201cBasketball\u201d is also a\nrapid motion sports sequence. Both are typical program material and\nmoderately difficult to compress. \u201cWall\u201d consists of a woman standing in\nfront of wall made of many small stones. \u201cRenata\u201d consists of a woman in\nfront of a complex background with a dissolve to a complex image of\nbutterflies. \u201cMobile and Calendar\u201d is a particularly difficult\ncompression test sequence with saturated colors and complex motion.\n\u201cDissolve\u201d consists of two segments of \u201cMobile and Calendar\u201d with a one\nsecond fade between the two segments and is also difficult to compress."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest sequences were supplied by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( ITU-R"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Portland Trailblazers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( SMPTE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Tektronix"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Test Procedures*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG has conducted experiments to verify the performance of the 4:2:2\nProfile. The results of those experiments are presented here. There are\nseparate tests for 525/60 and 625/50. The 525/60 tests explore a broad\nrange of data rates and GOP structures, while the 625/50 tests include\nmore variety of test material but less combinations of data rate, GOP\nstructure, and number of generations. The parameters chosen for the\nexperiments are for example only, and do not cover the entire range of\nallowed parameter values. The examples are not intended as specific\nrecommendations. Each application should use the combination of\nparameters that is most appropriate, depending on its requirements for\nquality, editability, and cost."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tests include both a single generation and eight generations of\ncascaded compression and decompression. For the eight generation tests,\nseparate tests were done with no shifts, with two spatial shifts, and\nwith two temporal shifts. Spatial shifting means that the picture was\nshifted horizontally and vertically by two pixels and two spatial lines\nbetween the first and second generations and then back between the fifth\nand sixth generations. Spatial shifting represents the effects of\npicture repositioning which might occur in a DVE. Temporal shifting\nmeans that the GOP structure was shifted one frame between the first and\nsecond generations and again between the fifth and sixth generations.\nTemporal shifting represents the effect of multiple generations which\nhave different GOP alignment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChroma key experiments were done by processing the foreground with blue\nscreen through compression and decompression. After decompression the\ncomponent digital signal was chroma keyed to add the background. The\nbackground image was not compressed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMixed environment tests for 525/60 used MPEG-2 4:2:2 compression and\ndecompression cascaded with a compressed digital VTR using 2:1\nintra-field compression. The tests used a total of eight generations of\ncompression. The four odd number generations were MPEG and the four even\nnumber generations were compressed digital VTR. There were no shifts\nbetween generations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMixed environment tests for 625/50 used only MPEG compression. The tests\nused a total of three generations of compression. The first and third\ngenerations were MPEG-2 4:2:2 compression with IBBP GOP structure at 20\nMbit/s, while the second generation was MPEG-2 4:2:2 compression with\nI-only GOP structure at 50 Mbits/s. A temporal shift of one frame was\nincluded between the second and third generations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompression and decompression processing were contributed by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( CCETT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( FTZ"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( IRT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( JVC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Sony"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Technical University of Braunschweig/BTS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Tektronix"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEditing and duplication of test tapes were contributed by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( RAI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Tektronix"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Subjective Assessment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe subjective assessment used the DSCQS method described in ITU-R Rec.\nBT.500-6. Both expert and non-expert viewing sessions were conducted at\na number of sites around the world. All of the expert viewing results\nwere combined, and all of the non-expert viewing results were combined.\nBoth expert and non-expert results are presented here. Only subjective\ntest results are presented, as signal to noise is not regarded as a\nreliable measure of picture quality in these cases."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExpert subjective assessment viewing sessions were conducted by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( NHK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( SMPTE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNon-expert subjective assessment viewing sessions were conducted by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( CCETT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( JVC/MPT/NHK/NTV"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( RAI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Technical University of Braunschweig/BTS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Test Results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt should be kept in mind that \u201cMobile and Calendar\u201d and \u201cDissolve\u201d are\nparticularly difficult sequences so will have more subjective\ndegradation than some other sequences. \u201cTrailblazers\u201d and \u201cBasketball\u201d\nare more typical program material. \u201cGwen\u201d is so difficult to chroma key\nthat the impact of compression is less than on some other sequences.\n\u201cGwen\u201d will therefore have less subjective degradation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt should be noted that application of this Profile is an area of\nongoing progress. Results presented here reflect varying degrees of\nalgorithm refinement, so further improvement can be expected."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest results are presented in the following order:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 525/60 Expert Viewers, Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 525/60 Non-Expert Viewers, Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 525/60 Expert Viewers, Non-Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 525/60 Non-Expert Viewers, Non-Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 625/50 Expert Viewers, Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 625/50 Non-Expert Viewers, Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 625/50 Expert Viewers, Non-Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 625/50 Non-Expert Viewers, Non-Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tables of test results are organized with higher data rates\npresented first and lower data rates presented last. Within a given bit\nrate, results are organized by GOP structure, number of generations, and\ntype of shifting. The mean and confidence interval are given for each\ntest sequence."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that while subjective viewing tests often use a five point\nimpairment scale, these tests used the continuous quality scale\nspecified in ITU-R Rec. BT.500-6. The subjective assessments were done\non a continuous 0 to 100 scale which was divided into five segments\nrepresenting \u201cExcellent\u201d, \u201cGood\u201d, \u201cFair\u201d, \u201cPoor\u201d, and \u201cBad\u201d. Results are\nthe difference between original and compressed sequence ratings, on a 0\nto 100 scale, with 0 representing no degradation through compression and\n100 being the worst possible rating."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 1: 525/60 Subjective Assessment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExpert View**ers**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Homogenous Environment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,9%,16%,17%,19%,10%,11%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Original |nafootnote:[na stands for Not Applicable] |na |na |Dissolve\n|-0.50 |2.14"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|50 |IB |1 |na |Mobile |2.81 |2.35"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |2.97 |2.23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Trailblazers |2.17 |1.83"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |9.31 |4.80"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |15.31 |4.24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Mobile |9.86 |2.89"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |I |1 |na |Gwen |2.47 |2.10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |11.17 |3.82"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |13.17 |3.75"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Gwen |-0.14 |2.18"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Trailblazers |1.31 |2.00"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |12.22 |4.90"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |21.33 |3.72"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|30 |IB |1 |na |Gwen |-0.44 |1.84"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |13.56 |4.39"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |15.83 |4.33"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Gwen |-2.00 |2.59"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Trailblazers |7.42 |2.90"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |19.11 |4.13"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |21.75 |6.13"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Mobile |23.17 |3.95"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |I |1 |na |Gwen |0.44 |3.20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |19.81 |3.42"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |21.11 |4.77"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Gwen |6.00 |2.54"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Trailblazers |3.14 |1.77"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |42.83 |5.64"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |34.94 |4.78\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,11%,15%,17%,18%,9%,10%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|20 |IBBP |1 |na |Mobile |11.11 |3.52"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |19.53 |3.98"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Trailblazers |5.00 |2.53"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |30.86 |5.23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |27.61 |5.80"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Mobile |33.28 |4.93"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |IB |1 |na |Gwen |2.36 |2.49"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |28.25 |5.20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |24.42 |5.36"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Gwen |-0.92 |1.51"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Trailblazers |11.81 |4.64"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |43.61 |5.29"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |38.67 |5.20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Mobile |39.03 |5.70"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6 MP@ML |IBBP |1 |na |Gwen |2.28 |2.09"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Trailblazers |18.83 |4.29\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 2: 525/60 Subjective Assessment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNon-Expert Viewers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHomogenous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,14%,14%,14%,17%,12%,11%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Original |na |na |na |Dissolve |-0.76 |2.47"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|50 |IB |1 |na |Mobile |0.23 |2.61"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |3.57 |2.28"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Trailblazers |2.48 |2.72"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |4.11 |3.14"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |3.92 |3.92"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Mobile |4.01 |2.82"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |I |1 |na |Gwen |0.80 |2.75"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |4.97 |3.60"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |2.69 |3.46"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Gwen |0.60 |2.45"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Trailblazers |2.34 |2.43"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |5.80 |3.15"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |15.03 |4.83"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|30 |IB |1 |na |Gwen |0.37 |2.37"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |9.44 |3.46"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |8.02 |3.60"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Gwen |-1.03 |2.82"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Trailblazers |4.85 |3.07"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |7.48 |3.89"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |17.48 |4.90"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Mobile |14.80 |4.41"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |I |1 |na |Gwen |0.93 |2.82"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |12.21 |3.87"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |4.79 |3.40"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Gwen |5.79 |3.00"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Trailblazers |3.12 |2.94"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |25.45 |5.98"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |23.35 |5.46\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,14%,14%,14%,17%,12%,11%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|20 |IBBP |1 |na |Mobile |5.22 |3.03"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |13.05 |3.51"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Trailblazers |6.64 |3.44"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |20.75 |4.63"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |19.39 |5.57"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Mobile |24.06 |5.24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |IB |1 |na |Gwen |1.13 |1.77"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |19.39 |5.07"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |None |Mobile |11.32 |5.26"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Spatial |Gwen |1.74 |2.37"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Trailblazers |8.30 |4.10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |27.56 |5.59"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |30.27 |5.11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Mobile |20.42 |5.70"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6 MP@ML |IBBP |1 |na |Gwen |0.95 |3.01"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Trailblazers |10.38 |4.35\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 3: 525/60 Subjective Assessment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExpert Viewers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMixed Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"19%,14%,14%,14%,16%,12%,11%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|30 |I |8 |None |Trailblazers |1.17 |2.73"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |32.22 |5.41"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |26.25 |5.09"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|20 |IB |8 |None |Trailblazers |5.94 |2.43"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |28.39 |4.78"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |27.22 |5.35\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 4: 525/60 Subjective Assessment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNon-Expert Viewers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMixed Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"19%,14%,14%,14%,16%,12%,11%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|30 |I |8 |None |Trailblazers |3.77 |2.82"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |13.11 |5.43"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |16.63 |4.66"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|20 |IB |8 |None |Trailblazers |3.54 |2.59"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |16.27 |4.66"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Dissolve |16.53 |4.01\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 5: 625/50 Subjective Assessment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExpert Viewers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHomogenous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"18%,10%,15%,14%,20%,12%,11%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Original |na |na |na |Balls of Wool |0.04 |1.16"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |0.00 |1.73"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Basketball |1.78 |1.74"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |0.66 |1.74"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |-0.84 |1.31"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |0.53 |2.68"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|50 |I |1 |na |Balls of Wool |0.08 |1.91"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |2.71 |2.66"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |2 Spatial |Balls of Wool |1.17 |1.84"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |10.71 |3.58"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Basketball |0.11 |2.02"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |0.63 |1.87"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |6.34 |2.63"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |10.09 |2.66"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|30 |IB |8 |2 Spatial |Basketball |6.03 |2.97"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |7.51 |3.24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |17.94 |3.58"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |18.77 |4.14"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Basketball |2.41 |2.04"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |5.78 |2.54"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |13.13 |3.44"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |17.53 |3.70"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |I |1 |na |Balls of Wool |0.75 |2.06"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |4.00 |1.92"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |2 Spatial |Balls of Wool |4.00 |2.73"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |16.04 |4.27"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Basketball |3.19 |2.57"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |7.13 |2.49"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |16.59 |3.16"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |27.16 |4.49\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"18%,10%,15%,14%,20%,12%,11%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|20 |IBBP |8 |2 Spatial |Basketball |12.97 |3.40"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |13.51 |3.83"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |21.69 |3.99"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |20.43 |3.98"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Basketball |12.72 |3.84"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |10.66 |3.11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |24.22 |3.27"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |22.44 |3.84"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |IB |1 |na |Balls of Wool |1.00 |3.70"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |5.58 |3.70"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |2 Spatial |Balls of Wool |6.46 |2.46"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |20.46 |5.41"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Basketball |6.25 |4.78"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |14.34 |3.45"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |19.75 |3.95"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |22.94 |4.09"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Basketball |6.49 |3.73"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |20.86 |4.20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |23.69 |4.07"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |26.14 |4.01"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6 MP@ML |IBBP |1 |na |Balls of Wool |16.83 |5.07"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |19.67 |5.09"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Basketball |32.31 |4.48"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |16.38 |3.17"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |18.22 |3.27"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |29.03 |4.40\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 6: 625/50 Subjective Assessment Results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNon-Expert Viewers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHomogenous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,10%,15%,15%,20%,12%,10%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Original |na |na |na |Balls of Wool |1.60 |2.31"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |1.50 |2.61"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Basketball |2.13 |2.89"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |1.85 |2.63"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |-0.53 |1.89"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |3.32 |2.17"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|50 |I |1 |na |Balls of Wool |-0.49 |2.69"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |0.19 |3.02"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |2 Spatial |Balls of Wool |2.31 |2.54"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |9.52 |3.10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Basketball |-2.13 |3.07"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |1.77 |2.08"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |3.13 |3.38"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |11.65 |3.13"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|30 |IB |8 |2 Spatial |Basketball |5.58 |3.07"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |6.28 |3.09"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |11.06 |3.96"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |12.49 |3.36"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Basketball |5.60 |2.71"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |8.96 |3.50"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |10.51 |3.40"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |13.23 |3.45"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |I |1 |na |Balls of Wool |-0.39 |2.79"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |7.75 |3.52"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |2 Spatial |Balls of Wool |8.38 |2.54"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |19.03 |4.42"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Basketball |2.57 |2.66"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |9.57 |4.11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |15.51 |4.07"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |23.97 |5.20\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,10%,15%,15%,20%,12%,10%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|20 |IBBP |8 |2 Spatial |Basketball |8.19 |4.01"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |9.67 |3.41"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |22.32 |4.31"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |18.47 |3.42"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Basketball |8.25 |3.38"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |16.18 |4.31"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |20.77 |4.45"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |16.99 |3.99"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |IB |1 |na |Balls of Wool |1.08 |2.40"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |4.47 |3.54"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |8 |2 Spatial |Balls of Wool |7.27 |3.18"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |18.12 |4.06"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Basketball |5.06 |2.82"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |17.18 |3.70"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |17.26 |4.17"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |21.62 |4.00"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |2 Temporal |Basketball |3.84 |3.98"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |16.47 |3.57"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |18.89 |4.63"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |22.91 |3.97"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6 MP@ML |IBBP |1 |na |Balls of Wool |21.34 |4.29"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Cactus/Comb |29.19 |4.41"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Basketball |24.10 |4.47"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |20.67 |4.67"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |23.04 |4.74"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |26.59 |3.88\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 7: 625/50 Subjective Assessment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExpert Viewers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMixed Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"17%,15%,14%,14%,19%,11%,10%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|20-50-20 |IBBP-I-IBBP |3 |1 Temporal |Basketball |4.88 |3.37"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |8.78 |3.30"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |12.72 |3.47"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |18.09 |3.80\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 8: 625/50 Subjective Assessment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNon-Expert Viewers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMixed Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,15%,15%,15%,19%,11%,10%\",]\n|===\n|Data Rate (Mbits/s) |GOP |Generation Number |Shifts |Sequence |Mean\n|Confid. Interval"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|20-50-20 |IBBP-I-IBBP |3 |1 Temporal |Basketball |5.45 |2.83"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Wall |9.72 |3.15"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Renata/Butterfly |15.18 |4.54"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\u00d2 |\u00d2 |\u00d2 |\u00d2 |Mobile |16.08 |3.65\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nDavid J. Meares\n1996-01-23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11**N1135**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/M0551"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSource: Audio subgroup"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStatus: Approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: NBC Reference Model 2 core experiment subjective tests: overall\nresults"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthors: D. J. Meares, BBC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nS-W. Kim, Samsung"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. Introduction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the Dallas meeting of the MPEG Audio Subgroup, November 1995, the\nad-hoc group on NBC RM2 reported (ISO/IEC JTC1/SC29/WG11/N1060) on the\ncore experiment pre-screening tests that had been carried out by\nFraunhofer (MPEG95/472), Dolby (MPEG95/474), GCL (MPEG95/478), Sony\n(MPEG95/483) and AT&T (MPEG95/533). Discussion during that meeting\nidentified five algorithms for full subjective evaluation, plus one\npossible addition, subject to intermediate pre-selection tests prior to\n20 November 1995. The latter addition was not submitted after all and so\nthis report restricts itself to the tests on the original five proposals\nin comparison with the reference codec from the RM1 tests, namely\nFhG_D1. The details relating to the planned tests are contained in\nISO/IEC JTC1/SC29/WG11/N1079, the more important of which are repeated\nhere. The test methodology is according to ISO/IEC JTC1/SC29/WG11/N1034."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese brief format subjective listening tests, using impairment scale\nranking of monophonic 64 kb/s compressed audio presented through\nheadphones from DAT test tapes, are used to determine whether a proposal\nprovides an improvement to the basic reference model codec FHG-D1. It is\na relative ranking with respect to the reference codec FHG-D1 that is\nbeing sought in these tests. It is not intended that the absolute\nimpairment ratings be used for comparison to any other codec ratings.\nThese tests were not designed to provide absolute impairment scores for\nany of the codecs."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2. Reference Model 2.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nReference Model 2, ISO/IEC JTC1/SC29/ WG11/ N1095 ** on which these\noptimisations and tests are based, is shown above."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3. Core experiment evaluations*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFive proposals were submitted for evaluation against the reference codec\nfrom the earlier optimisation tests (ISO/IEC JTC1/SC29/ WG11/N0982). The\nsix contenders were thus:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}i) *ATT_QC* AT&T\u2019s proposal to optimise the quantisation and\ncoding module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}ii) *DOF_TF* Dolby\u2019s and FhG proposal for an alternative block\nswitching in the time/frequency module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}iii) *DOL_TF*: Dolby\u2019s proposal which exploits adaptive window\nshaping in the time/frequency module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}iv) *FHG_D1* The reference codec."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}v) *FHG_QC* FhG\u2019s proposal to optimise the quantisation and\ncoding module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}vi) *SON_PP*: Sony\u2019s proposal to include the pre-processing\noptional module (PQF, gain control), cascaded with the FhG_D1 system\nwith long windows only (no block switching)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFuller descriptions of the proposals can be found in Annex 4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach of these proposals was assessed at 64 kb/s mono using the same\ncritical test material as had been used previously, namely:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"46%,54%\",]\n|===\n|Programme item code |Programme item\n|1 |Harpsichord\n|2 |Castanets\n|3 |German speech (female)\n|4 |Bagpipes\n|5 |Glockenspiel\n|6 |Pitch Pipe\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 1 -* MPEG-2 NBC RM Tests Critical Items."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4. Codec optimisation.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the Dallas meeting of the Audio Subgroup, November 1995, the Chairman\nhad stressed that specific optimisation of coding proposals to fine-tune\nthem uniquely to each programme item should be avoided. This resulted in\nthe following Resolution:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cThe audio subgroup recommends that in the absence of real time hardware\nfor NBC reference model work, the optimisation of codecs for individual\ntest items used in the experiments or tests is be limited to the codec\nvariations which could be accomplished with a practical real-time\nimplementation.The audio subgroup further recommends that for NBC\nreference model work a statement of all manual codec variations on\nindividual items shall be submitted with the items to be tested. These\nmanual tuning variations of the codec will be considered in the\ncomplexity evaluation of the technique to be performed by the\nImplementation Subgroup.\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following programme-item specific optimisations of the codecs are\ntherefore noted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*i) ATT_QC*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe ATT_QC coding system had only its coding bandwidth optimized on a\nper-item"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbasis, as follows:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"16%,40%,44%\",]\n|===\n| |item |bandwidth\n| |items 2, 4, 5 and 6 |15050 Hz\n| |item 1 and 3 (Harpsichord and German Speech) |13050 Hz\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ii) DOF_TF*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe DOF_TF encoder employs a modified time-to-frequency transform and\nblockswitching procedure relative to the FHG_D1 baseline system. For\nDOF_TF, differences can be generally separated into two groups:\nparameter differences and blockswitch detect differences. (For the\npurposes of this document, encoder parameters are categorized as either\n\"uniform\" or \"nonuniform\". For a particular experiment, uniform\nparameters are invariant across all six test sequences. A parameter is\nnonuniform if it assumes two or more different values during the six\nsequences.) Some of the nonuniform parameters in the DOF_TF experiments\nhave been directly carried over from the RM2 reference encoder FHG_D1.\nThese parameters are MAX_BIT_SPAR, MIN_REFILL_BITS, REFILL_RATIO, and\nCHAOS_MEASURE. In other cases, nonuniform parameters in the FHG_D1\nexperiments were changed to uniform for the DOF_TF experiment. These\nparameters are: RPMIN_S, RPELEV2_S, and MEHRBIT_RATIO. Encoding\nparameters which were nonuniform and different in both experiments are\nRPELEV_S and MAX_GET. RPELEV_S controls the degree with which the\nmasking curve for one short block depends upon the masking curve of the\npreceding block (prenoise control). MAX_GET places an upper bound on the\nnumber of bits added to a frame during START/SHORT/STOP frame bit\npiling. An informal listening test indicated that 2 different values for\neach of these parameters in the DOF_TF experiment gave the same quality\nas 3 different values in FHG_D1. The motivation for changing the\nparameters in DOF_TF was to reduce the number of different values for\nthe nonuniform parameters. Finally, there were cases where parameters\nwere uniform in FHG_D1 but nonuniform in DOF_TF."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoding parameters which were uniform in the FHG_D1 experiment, but\nnonuniform in the DOF_TF encoder are: PEW1_S, PEW2_S, MASK_HIGH, and\nMASK_LOW. PEW1_S and PEW2_S are weighting parameters used to calculate\nthe extra bits pulled from the reservoir for START/SHORT/STOP frames. Of\nthe six test sequences, all but the glockenspiel caused the maximum\nnumber of bits to be pulled from the reservoir for frames containing\nsharp attacks. The change in PEW1_S and PEW2_S reduces this disparity.\nTo implement this feature automatically, the equation for computing the\nnumber of reservoir bits should be modified to include a term reflecting\nthe sharpness of the signal attack. The two MASK parameters were changed\nin DOF_TF at the suggestion of FhG from 1.5, 3.5 to 1.0, 1.0. However,\nthe harpsichord parameter file inadvertently contained the old values of\n1.5, 3.5, making the parameters nonuniform."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe DOF_TF experiment used a different blockswitch detection scheme than\nFHG_D1. The FHG_D1 uses an automatic blockswitch detection scheme with\nsome nonuniform parameters influencing the decisions. The DOF_TF encoder\nreceived blockswitch decisions that were read from an external file.\nBagpipes and pitchpipe employed no blockswitching whatsoever in either\nexperiment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*iii) DOL_TF:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll parameters were identical between DOL_TF and the FHG_D1 baseline NBC\nsystem selected for RM2, i.e. the parameter tuning was preserved to\nminimize the number of differences between the DOL_TF and FHG_D1\nencoders."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*iv) FHG_D1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProgramme-item by programme-item optimisation used in FHG_D1:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Item 2 (castanets) got the parameters concerning the bit reservoir\ncontrol adapted. max_bit_spar was increased from 3000 to 8000. This is\nreally the normal value. For short tests the bit reservoir has some\npenalty with it since the simulation starts it set to empty. A realtime\nsystem would not have this problem, so no adaption would be necessary\nthere. Other bit reservoir parameters which are slightly changed in this\ncase are min_refill_bits, mehrbit_ratio and refill_ratio. The\npreechocontrol for shortblock was slightly changed, too. This tuning was\nnecessary due to a suboptimal way of short block coding and could be\neliminated with the optimized short block coding in FHG_QC.\n* For item 5 (glockenspiel) only the preechocontrol for short blocks was\nchanged (see explanation item 2)\n* Item 6 (pitch-pipe) got the parameters switchpe and switchpe2 set to\n10000. This basically switches the occurence of short blocks off. This\nwas done in order to circumvent a clear bug in the block switching\ncontrol. Since then, some work to fix this bug has been done, but this\nis not yet completed. In addition a modified chaos measurement was used.\nThis again can be eliminated by optimization of the psychoacoustic model\nwhich is also in progress."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"48%,13%,13%,13%,13%\",]\n|===\n|Parameter |default |tk2 |tk5 |tk6\n|Switch_decision | | | |\n|switch_pe |2000 | | |10000\n|switch_pe2 |1200 | | |10000\n|Preechocontrol | | | |\n|rpmin_s |0.01 |0.001 |0 |\n|rpelev_s |4 |2 |2 |\n|rpelev2_s |32 |16 |8 |\n|Bit Reservoir | | | |\n|max_get |700 |800 |850 |\n|max_bit_spar |3000 |8000 | |\n|min_refill_bits |25 |100 | |\n|mehrbit_ratio |0.6 |0.5 | |\n|refill_ratio |0 |0.1 | |\n|Chaos measure |0 | | |4\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*v) FHG_QC*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProgramme-item by programme-item optimisation used in FHG_QC:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Item 2 (castanets) was tuned in the same way as for FHG_D1, whereas\nthe parameters for preechocontrol are now default for all items.\n* Item 6 (pitch-pipe) used only long blocks and a modified chaos measure\n(same tuning as for FHG_D1).\n* Items 3 (german female speech) and 5 (glockenspiel) are only slightly\ntuned (each item has only one bit reservoir parameter slightly changed).\nThis can easily be eliminated and happend more by accident than by\nintention."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"45%,11%,11%,11%,11%,11%\",]\n|===\n|Parameter |default |tk2 |tk3 |tk5 |tk6\n|Switch_decision | | | | |\n|switch_pe |2000 | | | |10000\n|switch_pe2 |1200 | | | |10000\n|Bit Reservoir | | | | |\n|max_get |700 |800 | |850 |\n|max_bit_spar |3000 |8000 | | |\n|min_refill_bits |25 |100 |50 | |\n|mehrbit_ratio |0.6 |0.5 | | |\n|refill_ratio |0 |0.1 | | |\n|Chaos measure |0 | | | |4\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*vi) SON_PP:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe SON_PP encoder uses the same parameters that the FHG_D1 encoder uses\nfor the specific programme-items."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5. Preparation for decoding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe proponents of the above proposals submitted bitstreams and decoder\nsoftware to University of Hannover on or before the 15 November 1995.\nUniversity of Hannover carried out the decoding of the bitstreams and\nallocated pseudonyms for each proposal to ensure that the subsequent\nlistening tests complied with the \u2018double blind\u2019 requirement of ISO/IEC\nJTC1/SC29/WG11/ N1034, which defines the test methodology. It was\nparticularly important that this was done by University of Hannover, as\nAT&T, who edited the material into a test tape, was also proposing to be\none of the test centres. The true identity of the pseudonyms was\ncommunicated to BBC and Samsung to enable results analysis and report\npreparation to proceed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6. Preparation of the subjective test tapes*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe decoded stimuli were supplied to AT&T on Data-DAT and assembled, by\nthem, onto test tapes in randomised order."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* The first tape contained two test blocks (sessions) each of ten\ntrials, whilst the second tape contained one test block of ten trials\nand one test block of six trials. Within each tape, each block was\nseparated from the next one by approximately one minute break.\n* The duration of each session was about 25 minutes (for a group of 10\ntrials).\n* Each trial had the following presentation sequence:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cItem N\u201d, \u201cR\u201d, reference, \u201cA\u201d, ref./cod., \u201cB\u201d, cod./ref.,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cR\u201d, reference, \u201cA\u201d, ref./cod., \u201cB\u201d, cod./ref.10_second_gap"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cItem N\u201d, \u201cR\u201d, \u201cA\u201d and \u201cB\u201d were synthetic computer-generated\nspeech[multiblock footnote omitted] announcements, where N was the trial\nnumber. The spoken letter \u201cR\u201d represents the expression \u201creference\u201d."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* All trials (items) were numbered consecutively from 1 to 36 .\n* Additional announcements, \u201cStart of session N\u201d and \u201cEnd of session\u201d,\nwhere N was the session number, were included in the recordings to\nidentify the start and end of each session."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVisually this can be represented as:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe randomised order for the various sessions was communicated by AT&T\nto the BBC and Samsung in order that the results analysis could be\ncarried out."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBecause of the time constraints AT&T was not able to prepare a specific\ntraining tape. Nevertheless, all test centres were advised to run a\ntraining session, based on one of the main tapes chosen at random, to\ngive the listeners the necessary experience. The centres were advised\nthat the subjects could discuss the artifacts they heard, but that there\nwas to be no discussion on grades that they might subsequently give.\nThis is in line with the advice given in ITU-R Recommendation BS 1116."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn order to reduce experimental factors from affecting the test scores\n(i.e. to reduce the \u2018learning\u2019 effect) the tests sites were requested to\nstart their assessment with a \"randomised session number\" to avoid all\ntest sites starting with tape one, session one."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt should be recorded that the preparation of the test tapes was done\nunder severe time constraints. It was not therefore possible to check\nall of the replicated test cassettes with regard to tape errors. No\nerrors were, however, subsequently reported."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*7. Details relating to the subjective tests*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOnce the test tape had been prepared, copies were dispatched to the\nfollowing sites[multiblock footnote omitted] where the subjective tests\nwere carried out."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAT&T, Dolby, FhG, Motorola, NHK, Philips, RAI, Sony"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach test site was charged with providing the following information\nrelating to its part of the subjective tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHeadphone, type and model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNumber of subjects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFull results from each test tape and each subject, supplied as an EXCEL\nspreadsheet file to a pre-specified file format."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWhen the first round of NBC Reference model tests were conducted,\nsignificant differences were noted between the results obtained from\nheadphone listening and those obtained by loudspeaker reproduction. As\nthese new tests were again limited to monophonic stimuli, it was\ndecided, this time, to restrict the evaluations to headphones only."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe grading scale used for these tests was the ITU-R 5-point impairment\nscale, shown alongside. The tests were conducted according to the\ntriple-stimulus/hidden-reference/double-blind method. There was an\nadditional requirement that the subject must give a grade of \u20185.0\u2019 to\none of \u2018A\u2019 or \u2018B\u2019, whichever he/she determined was the hidden reference.\nThe grading scale was described as a continuous scale with grading to be\ngiven to one decimal place."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs already mentioned, to ensure that the tests complied with the Double\nBlind criterion, the identity of the systems in relation to the sequence\nof stimuli was withheld from the test centres by University of Hannover.\nOnly the BBC and Samsung, who were charged with carrying out the overall\nresults analysis, were advised during the execution of the tests of the\nsystem identities."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe test centres reported that their tests involved the following number\nof listeners and used the following transducers:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"36%,31%,33%\",]\n|===\n|Test centre |No of listeners |Type of headphone\n|AT&T |6 |Stax Lambda Nova\n|Dolby |5 |Stax Lambda Pro\n|FhG |3 9 |Stax Lambda Pro Stax Sigma Pro\n|Motorola |4 1 |Stax Lambda Pro Stax Nova Signature\n|NHK |12 |Stax Lambda Nova\n|Philips |5 |Stax Lambda Pro\n|RAI |5 |Stax Lambda Pro\n|Sony |5 |Stax Lambda Pro\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe age and gender profile of the test subjects was as follows:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"20%,10%,10%,10%,10%,10%,10%,10%,10%\",]\n|===\n| |21-25 |26-30 |31-35 |36-40 |41-45 |female |male |total\n|AT&T |0 |0 |1 |2 |3 |0 |6 |6\n|Dolby |0 |0 |2 |2 |1 |1 |4 |5\n|FhG |1 |8 |3 |0 |0 |1 |11 |12\n|Motorola |0 |2 |0 |3 |0 |0 |5 |5\n|NHK |1 |3 |5 |3 |0 |1 |11 |12\n|Philips |0 |2 |3 |0 |0 |0 |5 |5\n|RAI |0 |2 |1 |2 |0 |0 |5 |5\n|Sony |1 |2 |1 |1 |0 |0 |5 |5\n|Total |3 |19 |16 |13 |4 |3 |52 |55\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll test centres were asked to provide training for their test subjects\nprior to the formal evaluation phase. The following details were\nprovided."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAT&T did not do listener training prior to NBC listening tests as all\nlisteners were expert listeners, who have extensive experience with both\nthe test material and typical impairments."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDolby ran no specific training sessions but used previously trained\nsubjects."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt FhG, all subjects had participated in either tests or pre-screening\nusing the same test items. No on the spot training was performed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMotorola provided the following"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"21%,44%,35%\",]\n|===\n|Subject |training sequence tape |test sequence\n|1 |3 |3,4,1,2\n|2 |3 |3,4,1,2\n|3 |1 |2,1,3,4\n|4 |1 |2,1,3,4\n|5 |3 |4,3,1,2\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNHK divided into 4 groups, 3 listeners per group, for 12 listeners. Each\ngroup was carried out in randomized order for traing session and grading\nsessions. The order of sessions is as follows."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,16%,16%,16%,16%,16%\",]\n|===\n| |training |grading1 |grading2 |grading3 |grading4\n|group A |ses 1 |ses 3 |ses 4 |ses 1 |ses 2\n|group B |ses 2 |ses 1 |ses 2 |ses 3 |ses 4\n|group C |ses 3 |ses 1 |ses 3 |ses 2 |ses 4\n|group D |ses 3 |ses 2 |ses 4 |ses 1 |ses 3\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt Philips, session one from tape number 1 was used as the training\nsession."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt RAI, session 3 was used for training."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt Sony all the subjects listened to session 1 on tape 1 before starting\nthe listening test."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*8. Results analysis*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOnce the tests had been completed by each test centre, they communicated\ntheir results to the BBC and Samsung for analysis. As had been\nproscribed previously, the main presentation of results was to be\nlimited to one group of diagrams showing averages and 95 % confidence\nintervals, calculated over all test sites (one plot for all programme\nitems and one plot each for individual programme item), and one group of\ndiagrams showing the distribution of results as a histogram."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBy carrying out the data analysis twice and independently, the analysis\ncentres were able to ensure that no errors were introduced into the\nanalysis during the spreadsheet transcriptions and manipulations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe data analysis for the confidence intervals used the statistical\ntools built into the EXCEL 5 spreadsheet program. The computational\nalgorithms were:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhere"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nand where"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_x_ are the sample values and"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_n_ is the number of samples"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs before, the distribution of results is based on a weighted histogram.\nTo generate the histogram the results were first analysed into ranges,\n0.5 of a grade wide, centred on values of -4.5, -4.0, ..... to +1.0. The\ngroupingsfootnote:[ote this is a slightly different grouping to that\nused previously, ISO/IEC JTC1/SC29/WG11/N0973. In the former report the\ngroupings were offset relative to the results label. Thus the result\nlabelled \u201ccount= -4.5\u201d was in reality a count of all results between\n-4.5 and -4.0. In this case, the groupings are arranged to be\nsymmetrical. In practice, there is little significance in the earlier\n\u2018error\u2019 as it was the relative shape of the curves in the report that\nwas important, not the absolute values shown.] are thus"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor each codec the results were expressed as a percentage value and a\ndegree of smoothing was then applied. The smoothing was equivalent to a\ntriangular weighting, or window, applied over a group of five adjacent\nvalues, as follows."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*9. Validity checking of the test results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPhilips subjects #1, #2, #3 & #4 consistently failed to vote one of A or\nB as grade 5. Only subject #5 did it correctly. In order to be\nabsolutely rigorous, the ad-hoc group decided to omit these results from\nthe final analysis."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA number of test subjects gave diff-grades greater than +1, as follows"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"28%,16%,24%,16%,16%\",]\n|===\n|Subject |Centre |Programme |Diff-grade |Module\n|Iwadare |NHK |harpsichord |2 |ATT_QC\n|Koller, J\u00fcrgen |FhG |harpsichord |1.5 |SON_PP\n|Scott Bolton |Motorola |bagpipes |1.1 |FHG_D1\n|#5 |Philips |pitch pipes |1.5 |FHG_QC\n|#1 |RAI |German speech |1.5 |ATT_QC\n|#2 |RAI |glockenspiel |2.5 |FHG_D1\n|#2 |RAI |pitch pipes |1.5 |ATT_QC\n|#3 |RAI |harpsichord |2 |ATT_QC\n|#3 |RAI |bagpipes |2 |SON_PP\n|#3 |RAI |glockenspiel |2.2 |FHG_QC\n|#3 |RAI |pitch pipes |2 |FHG_D1\n|#3 |RAI |glockenspiel |1.5 |DOF_TF\n|#3 |RAI |bagpipes |2 |FHG_D1\n|#4 |RAI |castanets |2 |SON_PP\n|#5 |RAI |German speech |1.5 |FHG_D1\n|#5 |RAI |glockenspiel |1.6 |SON_PP\n|#5 |RAI |glockenspiel |1.7 |ATT_QC\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe individual positive diff-grades at NHK, FhG, Motorola and Philips\nare not significant. The RAI positive diff-grades, however, amount to\napprox. 7% of their results (i.e. 13 out of 180 cases). If diff-grades\nof ( +1.0 are included this figure increases to 17% (i.e. 31 out of 180\ncases). Again, to be absolutely rigorous, the ad-hoc group decided to\nomit the RAI results from the final analysis."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*10 Test results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe analyses of the \u2018valid\u2019 test results are given in Annex 1. These\nshow the means and 95% confidence intervals for the results of 6 test\ncentres and a total of 45 listeners. The results are given both\ncollectively and individually for all programme excerpts"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs has been the custom in previous tests, the variable analysed is the\ndiff-grade. This is the difference between the grade given for the coded\nstimulus minus the grade given for the hidden reference. Thus for a\nstimulus pair where the impairment of the coded signal was graded as\n\u2018imperceptible\u2019 relative to the hidden reference, both would have been\ngraded \u20185.0\u2019 and the diff-grade would be \u20180.0\u2019. Where the coded signal\nwas deemed to be \u2018slightly annoying\u2019, a grade of \u20183.0\u2019 would have been\ngiven, leading to a diff-grade of \u2018-2.0\u2019."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex 2 shows histogram analyses for all test results and all programme\nexcerpts, with the plots split into two groups of codecs for clarity.\nNote that the smoothing has an effect on the true meaning of both the\n\u201cdiff-grades\u201d and the \u201ccount\u201d (vertical) axes. This, however, is not\nimportant: it is the relative shapes of the curves, comparing one module\nto another, that is important."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex 3 shows a further analysis of the data, presenting in three graphs\nthe overall spread of confidence interval limits for different subgroups\nof the results."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote. In the graphical presentations any reference to All test centres\nrefers to results from those test centres which passed the validity\ncriteria."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*11. Observations on test results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf one looks at the overall spread of results for each test centre,\nacross all modules and programme items, the following spreads are noted\nas the difference between the highest \u2018upper\u2019 confidence interval and\nthe lowest \u2018lower\u2019 confidence interval boundary values."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"18%,44%,18%,20%\",]\n|===\n|Test centre |Spread of confidence boundaries (in impairment scale\nunits) |Number of subjects |Training"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|(All) |0.47 | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dolby |0.86 |5 |none"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|FhG |1.10 |12 |none"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|NHK |0.58 |12 |1 session"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Sony |0.55 |5 |1 session"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Motorola |0.97 |5 |1 session"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|AT&T |1.16 |6 |none\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis is shown graphically in Annex 3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnalysis to find out the relative sensitivities of the modules to the\ndifferent test excerpts was also carried out. Annex 3 shows a plot of\nthe overall spread of results for each test excerpt, across all modules\nand test centres, presenting for each excerpt the average of the \u2018mean\u2019,\nthe highest \u2018upper\u2019 confidence interval and the lowest \u2018lower\u2019\nconfidence interval boundary values. The spread of results is large,\nwith overlapping confidence intervals. However, there is slight evidence\nthat castanets and German speech were more demanding than the other\nitems."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex 3 also shows a plot of the overall spread of results for each test\nmodule, across all excerpts and test centres, presenting for each module\nthe average of the \u2018mean\u2019, the highest \u2018upper\u2019 confidence interval and\nthe lowest \u2018lower\u2019 confidence interval boundary values. Interestingly\nthere is a 2:1 range of spread of results for the different modules."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAttempts to examine the results according to type of headphone failed\nbecause of the wide variation in number of listeners on each headphone\ntype."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWhen one examines the distribution of diff-grades (histogram\ndistributions) for individual test centres, there is generally a clear\npeak in the subjective test grades given. However, there are some\ncombinations of test centre and test module whose results show a very\nbroad range of subjective qualities. Tabulated below are the obvious\nones, the breadth of plateaux being those without smoothing."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Test centre |Test module |Breadth of plateau\n|AT&T |ATT_QC |3.0\n|FhG |ATT_QC |2.5\n|Motorola |ATT_QC |2.0\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe significance of this observation is open to debate, but one\nimplication is that there may be some characteristic of the sound\nproduced by ATT_QC, for instance, which is not easily spotted, but when\nnoticed leads to a down grading of the results."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo try to establish a rank order of the modules, a search can be made of\nthose modules where a significant difference exists. If one looks for\nnon-overlapping confidence intervals (95%) across all test centres, the\nfollowing differences can be noted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Excerpt |Better module |Worse module\n|All |FHG_QC |SON_PP\n|All |FHG_QC |ATT_QC\n|All |DOF_TF |ATT_QC\n|Castanets |FHG_QC |DOF_TF\n|German speech |FHG_QC |DOL_TF\n|German speech |FHG_QC |SON_PP\n|Glockenspiel |DOF_TF |DOL_TF\n|Pitch pipe |DOF_TF |ATT_QC\n|Pitch pipe |DOL_TF |ATT_QC\n|Pitch pipe |FHG_QC |ATT_QC\n|Harpsichord |DOL_TF |FHG_D1\n|Harpsichord |DOL_TF |SON_PP\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe purpose of the tests was, however to identify improvements relative\nto FHG_D1. The only one noted (non-overlapping confidence intervals) is\nDOL_TF for the programme item harpsichord. None of the other results are\nsignificant in this context."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe overall conclusions from these observations are:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* that the results from some of the test centres were not sufficiently\nconsistent. Their inclusion was carefully discussed at the January 1996\nNBC Ad-Hoc Group meeting and it was decided to exclude them from the\nfinal analysis.\n* that overall castanets and German speech seemed in these tests to be\nthe more difficult items to code.\n* that there is no individual new proposal that consistently\nout-performs, in a statistically significant sense, the reference model,\nRM2 (FHG_D1).\n* that the lack of differences noted in these results may well be due to\nlimitations in the test procedure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOn the latter point it should be noted from document ISO/IEC\nJTC1/SC29/WG11/N1034 that this form of evaluation is only intended for\npreliminary evaluations of modular improvements to the Reference Model\nduring its development. To quote ISO/IEC JTC1/SC29/WG11 /N1034 these\ntests are for evaluations during the \u201c_Initial steps,_\u201d with the purpose\nof \u201c_Selection of best codec components, impression of audio quality at\na particular stage of codec development, basis for decision on future\nwork. The target is a rank order of codec performance._\u201d \u201c_Intermediate\nstep_\u201d tests are needed to bring into the evaluation the codecs\u2019\nsurround sound performance, but these too are limited to _Rank Order_\njudgements only. It is only in the \u201c_Final step_\u201d where sufficient\ncontrol is exercised over the test procedure, that true absolute\njudgements can be deemed to have been made. This point must be borne in\nmind whenever these results are quoted in other documents or\npresentations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*12. Conclusions*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA major collaborative set of tests has been conducted, pooling together\nthe resources of many members of the MPEG Audio Subgroup. These tests\nwere the first Core Experiments to quantify the benefits or otherwise of\nproposed changes to NBC RM2."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe results presented here will enable a decision to be made on the\nstructure and content of RM3, to be decided at the January 1996 meeting\nof MPEG Audio Subgroup."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThough these results are valuable in the context of optimisation of the\nreference model, the procedure is insufficient to draw any conclusions\nother than _Rank Order_ of the systems/modules under test. The results\nmust not be taken as indicative of the final absolute quality that would\nbe achieved by the systems/modules in the more appropriate _Final step_\ntests that must follow."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*13. Acknowledgements*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis report draws together the contributions made by a large number of\norganisations and individuals to an International co-operative set of\ntests. The authors are pleased to acknowledge the contributions from and\nthe support of the following organisations:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSource material preparation, BBC, AT&T, Philips"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCodec development AT&T, Dolby, FhG, Sony"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBit stream decoding University of Hannover"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest tape preparation AT&T"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSubjective tests AT&T, Dolby, FhG, GCL, Motorola, NHK, Philips, RAI,\nSony"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nResults analysis BBC, Samsung"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSupport and encouragement Scientific Atlanta (Ad-hoc Group Chairman)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest results: means and 95% confidence intervals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic][pic][pic][pic][pic][pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest results: distribution of grades"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic][pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest results: overall spread"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic][pic]* *[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 4*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTechnical descriptions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. Quantisation and coding module: ATT_QC*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe full technical description of AT&T\u2019s proposal to optimise the\nquantisation and coding module is given in document ISO/IEC\nJTC1/SC29/WG11/M0558, \u2018An Improved NBC RM2 Noiseless Coding Kernel\u2019."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2. Block Switching Module: DOF_TF*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis development was a collaboration between Dolby and Fraunhofer\nGesellschaft (see doc. MPEG95/293). The motivation for changing the RM2\napproach to block switching is to reduce the time interval during which\nthe audio signal is coded with reduced frequency resolution, and to\nprovide rapid switching from long to short blocks and back again, thus\nimproving the overall quality of coded transient signals."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.1. Algorithm Description*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe current RM2 coder uses four block types: LONG, START, SHORT, and\nSTOP."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe START and STOP blocks contain 1024 transform coefficients from a\nsingle asymmetric window of length 2048. The SHORT blocks also contain\n1024 transform coefficients, corresponding to the interleaved\ncoefficients from 8 overlapping windows of length 256."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the generalized Dolby blockswitching approach (see also MPEG95/293),\nwe redefine the START block to contain one bridge-in window of length\n1152, plus 4 windows of length 256. Similarly, we redefine the STOP\nblock to contain 3 windows of length 256 and one bridge-out window of\nlength 1152. The SHORT blocks will still contain 8 overlapping windows\nof length 256."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nImplementation of the new block switching scheme consists of a\nstraightforward modification of the windowing code and the forward and\ninverse transform filterbank routines in the T/F and F/T modules (see\nalso MPEG95/293). In addition, adjustments in the psychoacoustic model,\nscale factor coding, Huffman tables selection, and bit stream formatter\nwere made to reflect the different block sizes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3. Dynamic Window Shaping Module: DOL_TF*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis was a developement by Dolby. In order to best represent a generic\naudio signal in the frequency domain (given a certain frequency\nresolution of the selected filterbank), it is desirable to adapt the\nwindow design to the characteristics of the input signal (dynamic window\nshaping). For example, a window that exhibits steeper spectral\ntransition regions performs better for signal like the pitchpipe, while\nthe use of a window that has deeper stopbands is preferred for a signal\nlike the glockenspiel."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3.1. Algorithm Description*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe selection of the appropriate window shape for each applicable block\ntakes place in the encoder and is sent to the decoder. In this approach,\nduring LONG and STOP blocks a Dolby window with alpha = 4.0 (Figure\nA4-2) is used when the coding process will apparently benefit from good\nstop band performance, otherwise a Dolby window with alpha = 1.5 (Figure\nA4-1) is selected (see also MPEG95/047). Similarly, during SHORT and\nSTART blocks, the window can be selected as either a Dolby short window\nwith alpha = 6 (Figure A4-4) or a Dolby short window with alpha = 2\n(Figure A4-3) (see also MPEG95/047). The encoder estimates the need for\ngood stop band performance by experimentally windowing the signal with\nthe Dolby window, performing an MDCT transform, and counting the number\nof spectral lines below the stop band limit currently estimated to be\n-80 dB re: peak spectral level. If the number of such spectral lines\nexceeds a threshold value, currently 10% of the total number of spectral\nlines used, the first window is selected, else the second window is\nused. During LONG and STOP blocks the first 628 spectral lines out of\n1024 which emerge from the MDCT are included in the calculation,\ncorresponding to 16 kHz. Note that obtaining the spectrum using an MDCT\nin this case is partly a matter of convenience, and that a\nmagnitude-spectrum FFT might yield more accurate results. In this\nexperiment, only the Dolby alpha = 6 window is employed for SHORT and\nSTART blocks. Futher improvements for the SHORT and START blocks can be\nobtained by using the adaptive variation of short window types as\ndescribed above."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis selection technique is somewhat limited in its accuracy by its\ninability to anticipate the actions of the remainder of the coder, such\nas the effects of Huffman coding and prediction. Ultimately, there is no\ntechnical reason why the full quantization cycle couldn\u2019t be evaluated\nfor each window, but the choice of window shape selection algorithm is\nin any case an encoder issue, and feasibility of including window shape\nswitching in the decoder and bit stream is already established by the\ncurrent RM2 code. Implementation of the modified windowing arrangement\nis a simple and straightforward modification of the windowing code in\nthe Time to Frequency (T/F) and Frequency to Time (F/T) modules."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure A4-1. Dolby window, alpha = 1.5.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure A4-2. Dolby window, alpha = 4.0.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure A4-3. Dolby window, alpha = 2.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure A4-4. Dolby window, alpha = 6.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4. Reference codec: FHG_D1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe technical description of the RM2 reference codec, FHG_D1, can be\nfound in document ISO/IEC JTC1/SC29/WG11/N0973 Annex 3. Further\ninterface information can also be found in document ISO/IEC\nJTC1/SC29/WG11/N1095."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.* *Quantisation and coding module: FHG_QC*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere were two major changes in FHG_QC compared to FHG_D1:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* The bit stream format was changed in a way that the audio data side\ninformation is now located in the dynamic data.\n* The grouping of short blocks is done in a more flexible way. The\nFHG_D1 could use maximal 3 regions, whereas FHG_QC can use as many\nregions as desired. The bit stream information and the psychoacoustic\nmodel was changed accordingly. As described above a tuning of the\npreechocontrol for short blocks was eliminated by this optimization."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe syntax for a mono bit stream as well as the parameter changes in the\npsychoacoustic model are shown below."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nframe()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nheader() dynamic_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nheader()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsynchword 3 padding_bit 1 bitrate_index 4 sampling_frequency 2 mode 2\nmode_extension 2 main_data_begin 10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndynamic_data(main_data_begin)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nblock_type 2 part2_3_length 12 big_values 9 global_gain 8\nscalefac_compress 9 for(i=0;i<3;i++) table_select 5 region_count0 5\nregion_count1 4 scalefac_scale 1 count1_table_select 1 if( block_type !=\nSHORT_TYPE) preflag 1 pred_on 1 if( pred_on) pred_coeffs 36 scfsi 4 else\nshort_group_info 7 scalefacs() Huffman Data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"66%,17%,17%\",]\n|===\n|Parameter |FHG_D1 |FHG_QC\n|General | |\n|mask_low |1.5 |1\n|mask_high |3 |2\n|Preechocontrol | |\n|rpmin_s |0.01 |0\n|rpelev_s |4 |1\n|rpelev2_s |32 |10000\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6. Pre-processing module: SON_PP.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe block diagram of Sony\u2019s pre-processing module and corresponding time\nfrequency module of SON_PP are shown in Fig. A4-5."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6.1 pre-processing module:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe input signal is divided by a PQF (Polyphase Quadrature Filter) into\nfour equal-width frequency bands. Gain detectors detect the attack\nsignals and generate the gain control information. Gain modifiers modify\nthe gain of every output subband signals by using the gain control\ninformation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6.2 t/f module:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach of the gain modifier outputs is transformed into MDCT coefficients.\nThe window length of each MDCT is 512 samples and the total number of\noutput MDCT coefficients is 1024. The window switching scheme is not\nused."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6.3 others:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe bit stream formatter was changed to transfer the gain control\ninformation. The adjustments in the psychoacoustic model were made to\nreflect the gain controlled signals. The quantizer should be done\nadjustments but has not been done."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6.4 tuning issue:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTuning of encoder algorithm for each sequences is carried out by using\nthe same parameters for FHG_D1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= Quantization and Coding\nDavid J. Meares\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ORGANISATION INTERNATIONALE DE NORMALISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11/N1136"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG 96/M0561"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source : Audio subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Status: Approved*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title: MPEG4 - 64kbps audio codec subjective tests: overall results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthor: Scott Diamond"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*In response to the MPEG-4 call for proposals, ISO/IEC\nJTC1/SC29/WG11/N0999, a total of 22 codecs operating at 64 kb/s/ch were\nsubmitted. Of these proposals, 8 addressed compression only, 5\nscalability of type 1 (6/64 kb/s), 6 scalability of type 2 (6/24/64\nkb/s) and 3 error resilience. At this data rate, the audio subgroup\ndecided to test only submissions that address functionalities in\naddition to compression. The audio subgroup had previously found it\nnecessary to discard one of the error resilience proposals because its\nerror resilience capability was regarded as being non conformant with\nthe MPEG-4 requirements. The remaining 13 codecs were submitted for\nevaluation (ISO/IEC JTC1/SC29/WG11/N1079).*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe purpose of these tests is to provide a relative ranking of the\ncodecs submitted for test and obtain a general assessment of the codecs\nrelative to a more fullycharacterized reference. The test is not\ndesigned to provide absolute impairment scores for any of the codecs. It\nis not appropriate to use the impairment scores to compare to any other\ncodec rating tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe specifics of these codecs is shown in the table below."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,29%,28%,14%\",]\n|===\n|Codec Keyword |Organization |Codec Type |Doc No\n|MOT_08 |Motorola |Error Resilience |434\n|NTT_08 |NTT |Error Resilience |304\n|NEC_12 |NEC |Scalability 1 |431\n|SAM_12 |Samsung |Scalability 1 |397\n|SON_12 |Sony |Scalability 1 |363\n|UER_12 |U Erlangen/ FhG |Scalability 1 |426\n|APR_15 |Alcatel/Philips/RAI |Scalability 2 |351\n|MAV_15 |Bosch/CSELT MATRA/MAVT |Scalability 2 |412\n|MOT_15 |Motorola |Scalability 2 |434\n|NEC_15 |NEC |Scalability 2 |431\n|NTT_15 |NTT |Scalability 2 |304\n|UER_15 |U Erlangen/FhG |Scalability 2 |426\n|L3_MPG1 |MPEG1 Layer 3 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 1 -* MPEG-4 Audio Codec Submissions for subjective evaluation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MPEG1 Layer 3 codec was included as an anchor point for the\nsubjective tests. Each of these proposals was assessed at 64 kb/s mono\nusing the critical testing material listed in Table 2."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"46%,54%\",]\n|===\n|Program item code |Program item\n|1 |Harpsichord\n|2 |Castanets\n|3 |German speech (male)\n|4 |Trumpet Solo w/ Orchestra\n|5 |female vocal solo\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 2 -* MPEG-4 64kbps Tests Critical Items."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. Codec Tuning"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the Dallas meeting of the Audio Subgroup, November 1995, the Chairman\nhad stressed that specific optimization of coding proposals to fine-tune\nthem uniquely to each program item should be avoided. This resulted in\nthe following Resolution:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cThe audio subgroup recommends that in the absence of real time hardware\nfor NBC reference model work, the optimization of codecs for individual\ntest items used in the experiments or tests is be limited to the codec\nvariations which could be accomplished with a practical real-time\nimplementation.The audio subgroup further recommends that for NBC\nreference model work a statement of all manual codec variations on\nindividual items shall be submitted with the items to be tested. These\nmanual tuning variations of the codec will be considered in the\ncomplexity evaluation of the technique to be performed by the\nImplementation Subgroup.\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe intent of this resolution is also applicable to these MPEG-4 audio\ncodec evaluations. The following program-item specific optimizations of\nthe codecs are therefore noted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Alcaltel/Philips/RAI*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor the Alcatel/Philips/RAI coder, no manual `per-item' tuning has taken\nplace for the compression-only submissions at 64, 40 and 24 kb/s and the\nscalability functionalities 1 and 2. The only tuning performed is the\ntwo pass encoding to obtain the required bitrate(s). This is a procedure\nwhich can be easily automated in the future."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Bosch/CSELT/MATRA/MAVT*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWith reference to the request of information on the per-item tuning, we\nwish to clarify that the Bosch-Cselt-Matra candidate did not implement\nany tuning of parameters for specific items, meaning that all the\ninternal tables and parameters are always the same for any bit-rate,\neither for scalability and for multiple concurrent objects\nfunctionalities."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHowever, due to the object oriented architecture employed, the core\nalgorithm for music signals is different from the core algorithm for\nspeech signals. The decoder is the same. Concerning the 64kbit/s\ncompression candidate tested in the NBC, the core is always the same\neither for music and speech. (no manual tuning at all)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Motorola*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis note is to inform the group that no special manual tuning was\nperformed for any of Motorola's proposals. One item of note is that we\nhad trouble making the block switching mechanism work in our encoder so\nwe used all long blocks for everything except castanets. We used all\nshort blocks for castanets. We do not consider this manual tuning since\nit is clear that better, automatic, methods of block switching already\nexist, even within MPEG1.."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*NEC*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo manual tuning was done in encoding for all the MPEG-4 bitstreams by\nNEC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*NTT*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe had no tuning on 64 kbit/s scalability coders. However, we had manual\ntuning for 64 kbit/s error resilience coders."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(1)perceptual model parameters"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(2)window selection threshold"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwere slightly modified depending on the input sources"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Samsung*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSamsung did not do any per-item tuning for 64 kbps MPEG-4 submission"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Sony*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo manual tuning has been done for any of the MPEG4 proposals from Sony\nand Sony IPC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*University of Erlangen/FhG*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOn some items a more advanced iteration strategy was used, which wasn't\nstable enough at that time to be used for all items. This is marked in\nthe following list as cit2."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n64 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nno manual tuning, except cit2 for items 1,3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScaleable 64 - 6 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInner layer codec based on FS1016 CELP for Items 2,4,5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInner layer codec based on University of Hannover Coder for items 1,3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSlightly reduced audio bandwidth for item 5 (only 64 kbps Layer)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScaleable 64 - 24 - 6 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInner layer codec based on FS1016 CELP for items 2,4,5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInner layer codec based on University of Hannover's MPEG4 coder for\nitems 1,3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSlightly reduced audio bandwidth for Items 2,3 (only 24 kbps Layer)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3. Preparation for decoding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe proponents of the above proposals submitted bitstreams and decoder\nsoftware to University of Hannover on or before the 15 November 1995.\nUniversity of Hannover carried out the decoding of the bitstreams and\nallocated pseudonyms for each proposal to ensure that the subsequent\nlistening tests complied with the \u2018double blind\u2019 requirement of ISO/IEC\nJTC1/SC29/WG11/ N1034, which defines the test methodology. After the\ntests were completed, the true identity of the pseudonyms was\ncommunicated to Tektronix to enable results analysis and report\npreparation to proceed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4. Preparation of the subjective test tapes*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe decoded stimuli were supplied to AT&T on Data-DAT and assembled, by\nthem, onto test tapes in randomized order."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* The first tape contained three test blocks (sessions) each of eleven\ntrials, while the second tape contained two test block of eleven trials\nand one test block of ten trials. Within each tape, each block was\nseparated from the next one by approximately one minute break.\n* The duration of each session was about 25 minutes (for a group of 11\ntrials).\n* Each trial had the following presentation sequence:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cItem N\u201d, \u201cR\u201d, reference, \u201cA\u201d, ref./cod., \u201cB\u201d, cod./ref.,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cR\u201d, reference, \u201cA\u201d, ref./cod., \u201cB\u201d, cod./ref.10_second_gap"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cItem N\u201d, \u201cR\u201d, \u201cA\u201d and \u201cB\u201d were synthetic computer-generated\nspeech[multiblock footnote omitted] announcements, where N was the trial\nnumber. The spoken letter \u201cR\u201d represents the expression \u201creference\u201d."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* All trials (items) were numbered consecutively from 1 to 65 .\n* Additional announcements, \u201cStart of session N\u201d and \u201cEnd of session\u201d,\nwhere N was the session number, were included in the recordings to\nidentify the start and end of each session."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVisually this can be represented as:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe randomized order for the various sessions was communicated by AT&T\nto Tektronix in order that the results analysis could be carried out."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBecause of the time constraints AT&T was not able to prepare a specific\ntraining tape. Nevertheless, all test centers were advised to run a\ntraining session, based on one of the main tapes chosen at random, to\ngive the listeners the necessary experience. The centers were advised\nthat the subjects could discuss the artifacts they heard, but that there\nwas to be no discussion on grades that they might subsequently give.\nThis is in line with the advice given in ITU-R Recommendation BR 1116."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn order to reduce experimental factors from affecting the test scores\n(i.e. to reduce the \u2018learning\u2019 effect) the tests sites were requested to\nstart their assessment with a \"randomized session number\" to avoid all\ntest sites starting with tape one, session one."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt should be recorded that the preparation of the test tapes was done\nunder severe time constraints. It was not therefore possible to check\nall of the replicated test cassettes with regard to tape errors. No\nerrors were, however, subsequently reported."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5. Details relating to the subjective tests*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOnce the test tape had been prepared, copies were dispatched to the\nfollowing sites where the subjective tests were carried out."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCCETT, Mitsubishi, NTT and Sony"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach test site was charged with providing the following information\nrelating to its part of the subjective tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNumber of subjects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFull results from each test tape and each subject, supplied as an EXCEL\nspreadsheet file to a pre-specified file format."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe grading scale used for these tests was the ITU-R 5-point impairment\nscale:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tests were conducted according to the\ntriple-stimulus/hidden-reference/double-blind method. There was an\nadditional requirement that the subject must give a grade of \u20185.0\u2019 to\none of \u2018A\u2019 or \u2018B\u2019, whichever he/she determined was the hidden reference.\nThe grading scale was described as a continuous scale with grading to be\ngiven to one decimal place."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs already mentioned, to ensure that the tests complied with the Double\nBlind criterion, the identity of the systems in relation to the sequence\nof stimuli was withheld from the test centers by University of Hannover.\nThis information was only released to Tektronix after the subjective\ntests were completed ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe test centers reported that their tests involved the following number\nof listeners"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"48%,52%\",]\n|===\n|Site |Number of Listeners\n|CCETT |7\n|Mitsubishi |5\n|NTT |16\n|Sony |5\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 3 -* Number of Listeners at Each Site."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe sites were also asked to provide information on training, experience\nof listeners and other information specific to their test site. The\nfollowing replies were received."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*CCETT*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tapes were received rather late ( i.e. the 7th in the morning) so\nthat the planning was very difficult to do and no real training session\nwas conducted. On the other hand, the subjects were experienced\nlisteners, all working in the Audio lab and very familiar with tests\nprocedures. The panel was split in 4 groups (2+2+2+1). For each group,\nthe tapes presentation (R A B R A B) as well as the announcements\noccurring between each trial have been introduced. At the beginning of\neach session, a group had the possibility to adjust the reproduction\nlevel of the Stax lambda-pro headphones. No discussion between the\nmembers of a group was allowed (they were seated back to back).Though\nthe listeners have been informed that they were not going to assess pure\nbit rate reduction algorithms at 64kbps (i.e. other functionalities than\ncompression were targeted), they have been asked to stick to the 5-grade\nimpairment scale, which was printed on the scoring sheets, when\nevaluating the quality of A or B Vs the reference."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mitsubishi*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMitsubishi used untrained listeners for this test but before each\nsession we conducted a short ten minute introduction. As I do not have\nthe facilities I was not able to do any specific education on different\nkinds of artifacts to listen for. So basically they we very naive\nlisteners. By doing the training session I was able to verify that they\nwhere not hearing impaired!."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*NTT*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll listeners at NTT are related to the music, most of them are students\nin music academy or players of some musical instruments."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nListeners are divided into groups with 4 members. During the training\nphase, we showed several input sources to listeners and made them\ndiscuss about the degradation within a group. It took 30 minutes\nincluding the explanation of the test procedure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Sony*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll listeners listened to the session 4 on the tape 2 for the training.\nAll listeners were experienced people."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6. Results analysis*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOnce the tests had been completed by each test center, they communicated\ntheir results to Tektronix for analysis. As had been proscribed\npreviously, the main presentation of results was to be limited to one\ngroup of diagrams showing averages and 95 % confidence intervals,\ncalculated over all test sites (one plot for all program items and one\nplot each for individual program items), and one group of diagrams\nshowing the distribution of results as a histogram."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe data analysis for the confidence intervals used the statistical\ntools built into the EXCEL 5 spreadsheet program. The computational\nalgorithms were:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhere"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nand where"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_x_ are the sample values and"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_n_ is the number of samples"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs before, the distribution of results is based on a weighted histogram.\nTo generate the histogram the results were first analyzed into ranges,\n0.5 of a grade wide, centered on values of -4.5, -4.0, ..... to +1.0.\nThe groupings[multiblock footnote omitted] are thus"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor each codec the results were expressed as a percentage value and a\ndegree of smoothing was then applied. The smoothing was equivalent to a\ntriangular weighting, or window, applied over a group of five adjacent\nvalues, as follows."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*7. Test results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe test results are given in Annex 1. These show the means and 95%\nconfidence intervals for the results of 4 test centers and a total of 33\nlisteners. The results are given both collectively and individually for\nall program excerpts"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs has been the custom in previous tests, the variable analyzed is the\ndiff-grade. This is the difference between the grade given for the coded\nstimulus minus the grade given for the hidden reference. Thus for a\nstimulus pair where the impairment of the coded signal was graded as\n\u2018imperceptible\u2019 relative to the hidden reference, both would have been\ngraded \u20185.0\u2019 and the diff-grade would be \u20180.0\u2019. Where the coded signal\nwas deemed to be \u2018slightly annoying\u2019, a grade of \u20183.0\u2019 would have been\ngiven, leading to a diff-grade of \u2018-2.0\u2019."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex 2 shows histogram analyses for all test results and all program\nexcerpts. Note that the smoothing has an effect on the true meaning of\nboth the \u201cdiff-grades\u201d and the \u201ccount\u201d (vertical) axes. This, however,\nis not important: it is the relative shapes of the curves, comparing one\nmodule to another, that is important. Even with the smoothing, there are\nvery noticeable peaks at integral values. This peak is due to the large\nnumber listeners who used only integral values for codec scores."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*8. Observations on test results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Codec Ranking_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo try to establish a rank order of the modules, a search can be made of\nthose modules where a significant difference exists. If one looks for\nnon-overlapping confidence intervals (95%) across all test centers and\nall excepts, the following ranking can be noted:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nError Resilience: No clear ranking"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSalability 1: SON_12 and UER_12 ranked higher than NEC_12 and SAM_12"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSalability 2: APR_15 and UER_15 ranked higher than MAV_15, MOT_15,\nNTT_15 and NEC_15"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Site Dependency_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex 3 shows the difference grade scores of the codecs (for all\nexcerpts) on a site by site basis. The relative ranking between codecs\nremained very stable from test site to test site Only minor differences\nin relative ranking are seen among the various test sites. For example,\nat one of the test sites NTT_08 scored higher than MOT_08 (this is not\nsurprising since these codecs are statistically equivalent in the\noverall results)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe greatest difference in results from one test site to another was in\nthe overall level. The plots have a similar shape but are shifted up or\ndown. Depending on the test site the curve could be shifted by as much\nas +/- 0.5. Apparently test subjects uniformly upgraded or downgraded\nmaterial at the different sites. There is not a clear reason for the\noverall upward or downward shift of scores at the different sites (at\nleast not based on the information provided by the sites). The table\nbelow shows the average codec test score along with an estimation of the\nlistener skill level."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"30%,35%,35%\",]\n|===\n|Site |Average Codec Score |Listener Skill Level\n|All Sites |-1.96 |\n|CCETT |-2.50 |experienced\n|Mitsubishi |-2.32 |inexperienced\n|NTT |-1.58 |music students\n|Sony |-1.73 |unknown\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 4 -* Score Variation Across Sites."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe obvious conclusion from the site dependency data is that absolute\ncodec performance cannot be determined. Clearly one cannot fairly say\nthat codec X has a difference grade score of 4.2. The purpose of these\ntests is not to determine an absolute codec score but to rank the codec\nperformance. The codec ranking from site to site is very consistent and\nit is felt that the ranking results are statistically significant."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Incorrect Scores_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tests were conducted according to the\ntriple-stimulus/hidden-reference/double-blind method. As mentioned\npreviously, there was an additional requirement that the subject must\ngive a grade of \u20185.0\u2019 to one of \u2018A\u2019 or \u2018B\u2019, whichever he/she determined\nwas the hidden reference. For a high quality codec it is not surprising\nthat the listener will occasional incorrectly assign the hidden\nreference. Incorrect score become a concern only if a listener is making\nthis determination a large percentage of the time or if the listener is\nassigning a poor score to the item which is actually the hidden\nreference. The table below lists the number of diff grade score errors\nfor each site."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"24%,21%,29%,26%\",]\n|===\n|Site |Number Of Listeners |Number Of Diff Grade ( 1 |Number Of Diff\nGrade > 1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|CCETT |7 |1 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mitsubishi |5 |16 |5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|NTT |16 |30 |2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Sony |5 |1 |0\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 5 -* Count of positive Diff Grades."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA more detailed examination of the test scores shows that certain\nindividuals are more likely to make errors in assigning the codecs. This\ninformation should be communicated privately to the test site\ncoordinators."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Integer Results_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe ITU grading scale is described as a continuous scale with grading to\nbe given to one decimal place. Unfortunately many of the listeners\nchoose integer values (this is very apparent in the histograms). The\ntable below lists the number of listeners who used integer values at\neach site."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"28%,24%,48%\",]\n|===\n|Site |Number Of Listeners |Number of Listeners With Only Integer Scores\n|CCETT |7 |0\n|Mitsubishi |5 |5\n|NTT |16 |16\n|Sony |5 |1\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 6 -* Only Integer Scores."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs can be seen in the above table, two-thirds of the listeners\nrestricted their scores to integer values. Restricting scores to integer\nvalue clearly adds \u2018quantization noise\u2019 and should be avoided."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Cautionary Notes_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt should be noted from document ISO/IEC JTC1/SC29/WG11/N1034 that this\nform of evaluation is only intended for preliminary evaluations of\nMPEG-4 codecs. To quote ISO/IEC JTC1/SC29/WG11 /N1034 these tests are\nfor evaluations during \u201c_Initial steps,_\u201d with the purpose of\n\u201c_Selection of best codec components, impression of audio quality at a\nparticular stage of codec development, basis for decision on future\nwork. The target is a rank order of codec performance._\u201d \u201c_Intermediate\nstep_\u201d tests are needed to bring into the evaluation the codecs\u2019\nsurround sound performance, but these too are limited to _Rank Order_\njudgments only. It is only in the \u201c_Final step_\u201d where sufficient\ncontrol is exercised over the test procedure, that true absolute\njudgments can be deemed to have been made. This point must be born in\nmind whenever these results are quoted in other documents or\npresentations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Overall considerations_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn view of various departures from the required procedures used by the\nMitsubishi test site, the ad-hoc group decided to exclude the results of\nthis site from the final analyses presented in the Annex."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*9. Conclusions*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA major collaborative set of tests has been conducted, pooling together\nthe resources of many members of the MPEG Audio Subgroup. These tests\nwere the first experiments to quantify the benefits or otherwise of\nproposed MPEG-4 64\u00a0kbps codecs."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSome of the codecs indicated performance better than the reference\nversion of MPEG-1 Layer III at 64 kbps. The best of these are using\ntechiniques already in use in the NBC reference model work. There was\nsome evidence that as one goes from Scalability 1 to Scalability 2 there\nis a loss of performance of the best codecs, possibliy due to the\nincreased overheads associated with increased flexibility. The results\npresented here will be considered during the NBC Reference Model\noptimisation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote: the procedure used in these tests is insufficient to draw any\nconclusions other than _Rank Order_ of the codecs under test. The\nresults must not be taken as indicative of the final absolute quality\nthat would be achieved by the codecs in the more appropriate _Final\nstep_ tests that must follow."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*12. Acknowledgments*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis report draws together the contributions made by a large number of\norganizations and individuals to an International co-operative set of\ntests. The authors are pleased to acknowledge the contributions from and\nthe support of the following organizations:-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSource material preparation, BBC, AT&T, Philips"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCodec development Alcatel/Philips/RAI, Bosch/CSELT/MATRA/MAVT, Motorola,\nNEC, NTT, Samsung, Sony\\ and University of Erlangen/FhG."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBit stream decoding University of Hannover"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest tape preparation AT&T"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSubjective tests Sony, NTT, Mitsubishi, CCETT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nResults analysis Tektronix (with much assistance from BBC)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest results: means and 95% confidence intervals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic] [pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[pic] *Annex 2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest results: distribution of grades"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSite Dependent Data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= Number\nDavid J. Meares\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11N1137"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/xxx"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Audio subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStatus: Approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Bibliography of Audio Subgroup Documents"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthor: D. J. Meares"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"10%,11%,28%,51%\",]\n|===\n|Date |Number |Source |Title"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-03 |N0685 |Feige, Kirby |Report on the MPEG/Audio Multichannel\nFormal Subjective Listening Tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |193 |Moriya |Report of Ad-hoc group on subjective testing of\ncoders at low sampling frequencies"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |195 |Brandenburg |Report of Ad-hoc group for low bit-rate audio\ncoding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |218 |Dehery,et al |Verification of Multichannel Audio and\nextension to lower lower sampling frrequencies corresponding to DIS\n13818-3, Layer II"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |219 |Dehery, et al |Public C-code of Multichannel Audio DIS\n13818-3, Layer II"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |231 |Dehery, Mainard |Public MPEG-1, Layer II Syntax analyser\nand decoder software"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |239 |Meares |MPEG_2 Backwards Compatible Codecs: Proving a route\nto quality."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |304 |Audio Subgroup |Refined Requirements for MPEG-2 Audio NBC\nCoding Mode Extensions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |305 |Kenzo Akagiri |Channel Scalability for MPEG-2 Audio NBC\nCoding Mode"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |N0780 |Audio Subgroup |Audio Verification Tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |N0779 |Audio Subgroup |Test Procedures for Audio Verification\nTests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |N0739 |Audio Subgroup |MPEG-2 Backwards Compatible Codecs: Tests\nto prove the route to quality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |310 |Audio Subgroup |Recommendation on merging of MPEG-Audio\nwork items"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |N0781 |Audio Subgroup |Subjective testing of coders at low\nsampling frequencies"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |N0746 |Audio Subgroup |Requirements for Preliminary Proposal and\nDraft Requirements for Detailed Technical Proposal for the MPEG-2\nNon-backward Compatible (NBC) Extension"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-07 |N0796 |Audio Subgroup |Call for multichannel audio test\nsequences"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |351 |Meares |Brief subjective listening tests on MPEG-2 backward\ncompatible multichannel audio codecs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |369 |Searing |Proposed change in 11172 audio compliance"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |370 |Kaneko |GCL NBC extension proposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |371 |van de Kerkhof |Proposal for an MPEG-2 Audio NBC coding\nmode extension"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |372 |Akagiri |Preliminary technical description of Sony\u2019s coding\nalgorithm for MPEG-2 NBC multichannel audio coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |373 |Johnston et. al. |MPAC: Multichannel PAC coder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |374 |Forshay |Preliminary proposal for an NBC extension to\nMPEG-2 audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |375 |Forshay |Digital audio compression (AC-3) preliminary NBC\nproposal to MPEG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |376 |Brandenburg |Preliminary technical description for an NBC\nextension to MPEG-2 audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |377 |Stoll |Description of a proposal for a \u201cNon-backward\ncompatible surround system NBC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |378 |Fuchs |Preliminary technical description of NBC coding mode\nextension"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |379 |V\u00e4\u00e4n\u00e4nen |Preliminary proposal for the MPEG-2 NBC extension"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |380 |Dimino et al. |Call for contributions to MPEG-2 audio NBC\ncoding extensions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |394 |Pereira |Proposal for MPEG-4 direction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |411 |Kim |Requirements for low bitrate audio coding proposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |412 |Kim |Comments on Draft IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |432 |Spille |Proposal for an MPEG-2 audio NBC extension"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |437 | |Report on the subjective testing of coders at low\nsampling frequencies"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |443 | |Requirements for low bit rate /MPEG-4 Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |N0838 | |Blockwise analysis of NBC codec proposals."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |N0856 | |Brief subjective listening tests on MPEG-2 backwards\ncompatible multichannel audio codecs (MPEG #351)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |N0839 | |Requirements for preliminary proposal and revised\nrequirements for detailed technical proposal for the MPEG-2 NBC\nextension."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94-11 |N0803 | |( ISO/IEC 13818-3) International Standard (Audio\nSection)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0025 |Kaneko |GCL NBC Audio RM0, Final technical description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0026 |Akagiri |Detailed technical description based on MPEG2\naudio NBC reference model 1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0034 |Schreiner |Report on meeting of Audio Subgroup NBC Ad-hoc\ngroup, 1 - 3 February 1995"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0035 |Schreiner |Blockwise analysis of the NBC codecs according\nto RM 0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0036 |Schreiner |Definitions and interface description for the\ntime to frequency mapping of RM1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0037 |Rault |First technical description based on current NBC\nreference model."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0046 |v.d. Kerkhof |Proposal for an MPEG-2 audio non backwards\ncompatible coding mode extension."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0047 |Bosi |Detailed technical description of the Dolby proposal\nbased on NBC RM1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0073 |Kim |Proposed test procedures for functionalities 1, 3 7\nof MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0074 |Kim |Proposed contents for MPEG-4 audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0092 |Nielsen |Compliance testing of real audio decoders."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0093 |Brandenburg |Technical description for an NBC extension to\nMPEG-2 audio."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0126 |Vaananen |Detailed technical description of proposal for\nthe MPEG-2 non-backward compatible (NBC)extension."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0130 |USA NB |Resolutions of the US NB"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0131 |USA NB |resolutions of the US NB"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0153 |Dimino |Technical description of the proposed NBC coding\nsystem according to RM1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0154 |Quackenbush |MPAC technical description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |0172 |Meares |Report on brief assessments of the performance of\nISO/MPEG-2 Layer 3 at 7*128kb/s."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |N0891 | |Schedule of activities for MPEG-2 Audio Compliance"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |N0892 | |Audio considerations relating to the 4:2:2 profile"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |N0893 | |Discussions on and definition of the core experiments\non time/frequency mapping within NBC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |N0895 | |Report on brief assessments of the performance of\nISO/MPEG-2 Layer 3 at 7*128kb/s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |N0896 | |NBC reference model test methodology"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |N0933 | |Definitions and interface description for the time to\nfrequency mapping of RM1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-03 |N0934 | |Response to German andUS National Body contributions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0194 |Meares |Chairman\u2019s report on the work of the audio ad-hoc\ngroup on codec subjective test methodology"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0198 |Meares, Schreiner |Report of the ad-hoc group to conduct\nMPEG-2 Audio NBC reference model 1 core experiment on the time/frequency\nmapping element"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0199 |Kerkhof |Report of ad-hoc group on editing the audio\nrelated part of DIS ISO/IEC 13818-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0200 |Rowlands |Report of ad-hoc group on MPEG-2 audio technical\nreport"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0201 |Edler |Chairman\u2019s report on the work of the Audio ad-hoc\ngroup on objective measurement"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0206 |Meares |Audio test methodology"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0207 |Meares |NBC time/frequency module tests: information\nrelating to test preparation and execution"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0208 |Meares, Kim |NBC time/frequency module subjective tests:\noverall results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0209 |Meares |Background information on the problems of\naudio/video synchronisation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0210 |Meares |Proposed amendments of IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0232 |Kirby |Brief assessments of the performance of an\nISO/MPEG-2 Layer 2 audio codec operating at 896 kb/s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0244 |ITU-R TG10/4 |Liaison statement on objective perceptual\naudio quality assessment methods"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0247 |Vleuten et al |Predictive quantisation of subband and\ntransform signals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0248 |Brandenburg |Objective measurement test report from FhG,\nFraunhofer Institute for Integrated Circuits, Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0258 |Dimino |Comparisons between RAI-ALCATEL and Philips audio\ncodecs for the MPEG NBC RM1 experiment tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0260 |Parladori |Dynamic coding for audio visual compression\nsystem"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0281 |Brandenburg |NBC RM1 experiment test report from FhG,\nFraunhofer Institute for Integrated Circuits, Germany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0290 |V\u00e4\u00e4n\u00e4nen |Report of listening test for NBC Audio first\ncore experiment defined in ISO/IEC JTC1/SC29/WG11 N0893"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0293 |Bosi |Description of a high-frequency-resolution time to\nfrequency mapping module proposal for the non-backwards compatible\nMPEG-2 audio coding (13818-7)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |0300 |Kerkhof |Philips report on the NBC subjective listening\ntest results for RM1 experiment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |N0971 | |Audio subjective test methods for high quality codec\nevaluations"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |N0972 | |Proposed amendments of IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |N0973 | |NBC time/frequency module subjective tests: overall\nresults"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |N0974 | |Brief assessments of the performance of an ISO/MPEG-2\nLayer 2 audio codec operating at 896 kb/s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |N0981 | |Audio subjective test methods for low bit rate codec\nevaluations"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |N0982 | |Definitions and interface descriptions for RM2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |N0983 | |Technical Report: Schedule of activities for MPEG-2\naudio technical report until November 1995"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |N0984 | |Schedule of activities for MPEG-2 Audio Conformance\nuntil November 1995"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-07 |N1016 | |Schedule of activities for MPEG-2 NBC Reference Model 2\nuntil January 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0304 |Takehiro Moriya, Satoshi Miki, Kazunaga Ikeda, Naoki\nIwakami, Akio Jin, Kumiko Oguchi |Technical Description of the NTT\nProposal for MPEG-4/AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0321 |Masayuki Nishiguchi, Jun Matsumoto, Shiro Omori, Kazuyuki\nIijima |Technical Description of Sony IPC's proposals for MPEG-4 Audio\nand Speech Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0331 |David Meares |Presentation of grading scales to listening\ntest subjects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0345 |David Meares |Hardware and software requirements for the\nautomated editing of audio subjective test tapes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0346 |David Meares |MPEG-4 Audio registered codecs and\noutstanding test details"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0349 |Frank Feige, Ulf Wuestenhagen |A procedure to prepare\naudio test tapes for listening tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0350 |David Meares |MPEG-2 Audio bitstream compliance tests at\nthe BBC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0351 |Werner Oomen |Technical description of a proposal for\nMPEG-4 audio coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0362 |Kenzo Akagiri, Takashi Koike |Technical description of\nSony's coding algorithm for MPEG-4 Audio compression coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0363 |Kenzo Akagiri, Takashi Koike |Technical description of\nSony's coding algorithm for MPEG-4 Audio bitrate scalability coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0397 |Sang-Wook Kim, S.-H. Park, Y.-B. Thomas Kim |Technical\ndescription for a scaleable CODEC to MPEG-4 Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0398 |S.-W. Kim, D.-H. Kim, S.-H. Park, Y.-B. Thomas Kim\n|Technical description for a tool to MPEG-4 Audio: low complexity CODEC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0399 |Friedhelm Wuppermann, Frans de Bont |Proposal for an\nMPEG-4 audio codec with a bit rate of 16 kbit/s at a reference sampling\nfrequency of 16 kHz"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0401 |Laurent MAINARD, Jean Bernard RAULT |First Technical\nDescription of CCETT's MPEG-4 Proposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0402 |Toshio Miki, Sanae Hotani, Nobuhiko Naka, Tomoyuki Ohya\n|Technical Description of 6 kb/s PSI-CELP algorithm for MPEG-4 Error\nResilience Functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0404 |Toshio Miki, Tomoyuki Ohya, Sanae Hotani |Technical\nDescription of the PROTECTS as an Error Resilient Audio Coding Tool"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0409 |Giorgio Parladori, Marco Fratti |Audio Coding Tool\nProposal for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0412 |D. Sereno , C. Dorize, J.M. Mueller |Detailed description\nof the MAVT MPEG-4 audio candidate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0413 |D. Sereno , C. Dorize, J.M. Mueller |Functionalities\naddressed by the MAVT MPEG-4 audio candidate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0414 |Bernd Edler |Technical description of the MPEG-4 Audio\nCoding Proposal from University of Hannover and Deutsche Bundespost\nTelekom"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0419 |Kyouichi Shimizu, Takafumi Kizuki, Toshihiro Maruyama\n|Technical description of JVC's coding algorithm for MPEG-4 audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0425 |Anibal Ferreira |Technical description of INESC audio\ncoding proposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0426 |B. Grill, K. Brandenburg |MPEG-4 technical description\ncontribution of University of Erlangen / FhG-IIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0427 |Hideshi Taki |Technical Description of MPEG-4-Audio\nProposal(1)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0428 |Hideshi Taki |Technical Description of MPEG-4-Audio\nproposal(2)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0431 |Masahiro Iwadare |Technical description of MPEG-4/Audio\nsubmission from NEC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0434 |Davis Pan, Otto Schnurr, Jim Fiocca, Bob Dyas |LBAC\nTechnical Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0448 |Masayo Kawauchi, Kyoichi Shimizu |Technical description of\nJVC's proposal for MPEG-4 speech coding algorithm"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0450 |Ralf Schwalbe, Frank Feige |MPEG-2 Audio bitstream\ncompliance tests at Deutsche Telekom AG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0456 |P. G. Schreiner III |Report of the Ad-Hoc Group to Conduct\nMPEG-2 Audio NBC Reference Model 2 Core Experiment Preparation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0472 |Karlheinz Brandenburg, Martin Dietz, Uwe Gbur, Roland\nBitto, Oliver Kunz |NBC RM2 pre-screening test results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0473 |Karlheinz Brandenburg |Report on activities of the ad-hoc\ngroup on the evaluation of tools for non-tested functionalities of audio\nsubmissions to MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0474 |Marina Bosi, Louis Fielder |Pre-screening Tests Report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0478 |Itaru Kaneko |Status of GCL's experiment for NBC RM2(NBC\nReference Model 2)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0483 |Kenzo Akagiri, Mitsuyuki Hatanaka |MPEG2 NBC pre-screening\ntest result for the 2nd core experiment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0492 |United States National Body |Recommendations for Audio\nConsideration"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0502 |Herman Silbiger, Pete Schreiner |Report of the MPEG-4\nAudio Test Ad-Hoc Group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0506 |G. Stoll |Report on the evaluation of the use of\nprediction and dynamic crosstalk in IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0526 |Kenzo Akagiri, Takashi Koike |Technical description of\nSony's coding algorithm for non-tested functionalities of MPEG-4 Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0527 |Jon Rowlands |Report of the Ad-hoc Group on MPEG-2 Audio\nTechnical Report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0528 |S Doward, J.D. Johnston, S.R. Quackenbush, D. Sinha\n|MPEG-4 Audio Coder Technical Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0529 |S.R Quackenbush |MPEG-4 Speech Coder Technical\nDescription: Waveform Interpolation Coder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0530 |Leon van de Kerkhof |Report of ad-hoc group on editing the\naudio related part of DIS ISO/IEC 13818-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0533 |S.R. Quackenbush |Results of AT&T NBC RM2 Pre-screening\nTests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |0536 |Itaru Kaneko |Preliminary report on the experiments using\narithmetic coding for the \"nbcrm2\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1033 |D. Meares, J. Matsumoto |Guidance notes on the\npreparation of Single Stimulus (MOS) test tapes for MPEG-4 Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1034 |D. Meares |Audio subjective test methods for high quality\ncodec evaluations"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1063 |K. Brandenburg |Report of the Ad-hoc Group on the\nEvaluation of Tools for Non-tested Functionalities of Audio Submissions\nto MPEG-4 (editorial changes only)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1073 |G. Stoll |Report of task group on MPEG-2 Audio\n\u201cprediction plus dynamic crosstalk\u201d solutions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1074 |B. Edler, D. Thom |MPEG-4 audio test minimisation and MOS\ntest time line"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1075 |S. Quackenbush |Complexity of NBC RM2 optional functions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1076 |M. Coleman |Report from the task group on MPEG-2\nNBC/MPEG-4 syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1077 |F. Feige |MPEG-4 audio listening test specification"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1078 |H. Silbiger |Report of the task group on MPEG-4 audio\ntest analysis"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1079 |M. Bosi |MPEG-2 NBC RM and MPEG-4 64 kb/s/ch tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1089 |K. Brandenburg |MPEG-2 NBC work plan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1095 |M. Dietz |Definitions and interface descriptions for NBC\nRM2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1097 |J. Rowlands |Schedule of activities for MPEG-2 audio\ntechnical report until January 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1103 |K. Brandenburg |MPEG-4 Audio detailed workplan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1080 |L. vd Kerkhof |Audio part of MPEG-2 Conformance document"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1091 |G. Stoll |Revised text for Amd 1 \u2018copyright-identifier\u2019"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1122 |L. vd Kerkhof |Audio part of DoC on Conformance"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1090 |G. Stoll |DoC on DAM1 \u2018copyright-identifier\u2019"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95-11 |N1032 |G. Stoll |DoC on NBC and MPEG-4 audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0551 |David Meares, Sang-Wook Kim |NBC Reference Model 2\nsubjective tests: overall results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0558 |S. R. Quackenbush, J. D. Johnston, J. Herre |An Improved\nNBC RM2 Noiseless Coding Kernel"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0559 |S. R. Quackenbush |An Automated Method for Making Tapes\nfor High-Quality Subjective Listening"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0560 |J. Herre, S. R. Quackenbush, J. D. Johnston, D. Sinha |An\nEnhanced Noise Masking Technique for the MPEG-2 NBC RM2 Audio Coder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0561 |Scott Diamond |MPEG4 Audio 64kbps subjective tests:overall\nresults"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0562 |Masayuki Nishiguchi, Jun Matsumoto, Shiro Omori, Kazuyuki\nIijima |Report on tape preparation and MOS tests in Sony for 6.0 and 2.0\nkbps coders for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0563 |Jean-Bernard RAULT |Proposal for changes in the 13818-3\nsyntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0574 |Anibal Ferreira |Re-submission of the INESC audio coding\nproposal (technical update)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0575 |Anibal Ferreira |An improved functionality: static\nselection of the coding delay mode"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0580 |Kenzo Akagiri, Takashi Koike |Technical description of\nSony's coding algorithm for MPEG-4 Audio 24kbps compression coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0581 |Kenzo Akagiri, Takashi Koike |Technical description of\nSony's coding algorithm for MPEG-4 Audio bitrate scalability coding\n(64kbps-24kbps-6kbps)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0584 |Naoki Iwakami, Kazunaga Ikeda, Takehiro Moriya, Satoshi\nMiki, Akio Jin |NTT's improved audio coder for 24 kbit/s and above"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0585 |Takehiro Moriya, Satoshi Miki, Akio Jin, Naoki Iwakami,\nKazunaga Ikeda |NTT's audio/speech coders in harmoney with the ITU-T\nstandardization"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0588 |Daniele SERENO, Michele FESTA |Detailed description of the\nimproved MAVT MPEG-4 audio candidate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0591 |Masayuki Nishiguchi, Jun Matsumoto, Shiro Omori, Kazuyuki\nIijima |Technical description of Sony IPC speech coder for MPEG-4\nadditional call for proposals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0593 |Ah-Peng Tan |Technical Description of Proposal for MPEG-4\nAudio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0606 |Bob Dyas |AMP - Audio Matching Pursuits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0607 |James Thi |Technical Description of The Rockwell Audio\nCoding Proposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0608 |Dr. Huan-yu Su |Technical description of Rockwell's speech\ncoding proposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0610 |I. Kaneko |Chairman\u2019s report on the work of the Audio\nad-hoc group on SNHC/Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0611 |I. Kaneko |Description of GCL\u2019s experiment for NBC core\nexperiment 2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0626 |Karlheinz Brandenburg |Report of the Ad-hoc Group on NBC\nsyntax development"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0628 |Marina Bosi |Report of the Ad-hoc Group on MPEG-2 Audio\nNBC (13818-7) Working Draft Development"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0632 |Bernd Edler, Heiko Purnhagen |Technical Description of the\nMPEG-4 Audio Coding Proposal from University of Hannover and Deutsche\nTelekom AG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0634 |Edler |Ad Hoc Group on MPEG-4 Audio test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0635 |Gerald Schuller, Bernd Edler |Description of a Filter Bank\nwith a Low System Delay as a Tool for Audio Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0638 |Bernhard Grill, Thomas Sporer |Technical description of\nthe Error Resilience Supplement to the Contribution of the University of\nErlangen and FhG-IIS to MPEG-4 Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0640 |P. G. Schreiner III |Report of the Ad-Hoc Group to Conduct\nthe Second Set of MPEG-2 Audio NBC Reference Model 2 Core Experiments\nand the MPEG-4 Audio Listening Test Evaluations for 64kb/s Submissions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0644 |Mike McLaughlin |Speech Coding for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0647 |Kazunaga Ikeda, Naoki Iwakami, Takehiro Moriya |Comparison\nof the candidates of MPEG4 64 kbit/s Error Resilience Test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0648 |J. D. Johnston, S. R. Quackenbush |Stereo Pair Joint\nCoding in the NBC Reference Model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0652 |Kenzo Akagiri |Complexity estimation on NBC preprocessing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0658 |Masahiro Iwadare |Technical description of MPEG-2 NBC\nlossless coding by NEC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0662 |S. R. Quackenbush |Report of the Ad-hoc Group on\nComplexity of NBC RM2 Functions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0668 |William Navarro |Improved MAVT MPEG4 Audio Candidate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0676 |Rowlands |Ad-hoc Group on MPEG-2 Audio Technical Report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0677 |Gerhard Stoll |Report of the Ad-Hoc Group on revisions to\nIS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0680 |Pan |Ad-hoc group on MPEG-4 Audio evaluations"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0681 |Gerhard Stoll |Comment on the ITU-R special rapporteur\ndocument 11-3/88-E (20. October 1995) with the title: \" tutorial\ninformation on multichannel audio coding methods recommended for digital\ntelevision systems\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |0xxx |Leon van de Kerkhof |Report of the Ad-hoc group on editing\nthe audio-related part of DIS ISO/IEC 13818-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |N1135 |David Meares, Sang-Wook Kim |NBC Reference Model 2\nsubjective tests: overall results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |N1136 |Scott Diamond |MPEG4 Audio 64kbps subjective\ntests:overall results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |N1137 |David Meares |Bibliography of Audio Subgroup documents"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96-01 |N1138 |David Meares |A description of the EXCEL 5 spreadsheet\nused for Audio NBC test results analysis\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nDavid J. Meares\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11**N1138**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/xxx"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Audio subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: A description of the EXCEL 5 spreadsheet used for Audio NBC test\nresults analysis"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStatus: Approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthor: D. J. Meares"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIntroduction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSharing the same filename as this document, but with the extension .xls,\nis an example spreadsheet showing how the NBC test results data were\nanalysed. This note is a brief explanation of the contents of that\nspreadsheet. It is the author\u2019s hope that by making this explanation\navailable, the spreadsheet will be more easily usable by other workers\nneeding to do similar analyses."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote, this approach to data analysis is determined in part, and relates\nto, the very specific needs of a\ndouble-blind/triple-stimulus/hidden-reference method of assessment,\nwhere there are many listeners spread over a number of test sites. It\nshould be noted that the statistical analysis is of the simplest of\ntypes, and that rigorous interpretation is not applicable: The approach\nused here is however valuable for examining trends and allows the task\nof carrying out the assessments to be shared amongst several sites."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt is assumed in what follows that the reader has some knowledge of\nExcel 5 and, in particular, is already able to use Pivot Tables and\nMacros."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe notes are organised according to the spreadsheet sheet names, which\nare shown in italics."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Blank*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis sheet is a proforma of the blank results sheet that should be sent\nto each of the test sites and onto which they should record the\nsubjective test results for each listener. Specifically the shaded cells\nneed to be filled in and returned to the analysis centre."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe columns relating to tape number, session number and trial number are\nfor confidence checks that the recording of the results, the\nidentification of the stimuli and the analysis are being done correctly.\nThey should match the way the stimuli groups are recorded onto the test\ntapes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote the column headings and the title are mapped through the rest of\nthe sheets and plots. Any editing of the _Blank_ sheet will effect\nchanges elsewhere. This should ease problems of customising the\nspreadsheet."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe sheet will also need editing to match it to the number of trials\nbeing conducted in a test."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Decode*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis sheet contains the decoding information, to be supplied by the test\npreparation site, about the identity for each trial of the programme\nitem, the identity of stimulus A (coded or hidden reference) and the\ncodec name."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe need for absolute accuracy of this data cannot be stressed too much."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*All results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs the test sites report their results they should be copied into this\nsheet. The user should only take, from the completed results sheets, the\nrange of cells containing listener specific data. These should be\nassembled in a contiguous fashion in columns A to M."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe user should then copy the equations in cells N5:U40 and paste these\nalongside the results of each listener."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn cell U3 is a range rounding factor used to control how the Histogram\ngroups are defined. In the current example the ranges are half a grade\nwide centred on a half grade, i.e."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Means pivot*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCells A7:C33 contain the pivot table which analyses the data into\nvarious subgroups, calculating for each subgroup the"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAverage of diff grade"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCount of diff grade"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStdDev of diff grade"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFrom these values, cells F10:G15 calculate the means and confidence\nintervals of the results. Finally cells I10:L15 prepare this data for\nplotting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDifferent parameters in cells A7:B10 are available to define which data\nfiltering options are invoked."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCells F17:L21 are a working area for two of the macros used elsewhere."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Means and conf interval*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis sheet presents the plot of the results from the Means Pivot Table.\nNote the labels follow those generated in the pivot table."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Histogram pivot*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCells C6:G28 contain the pivot table which analyses the data into\nvarious subgroups, calculating for each test module the number of\ndiff-grade judgements in each Range."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBecause of a feature of Pivot Tables, that they do not list in such an\nanalysis values of Range that do not occur in the source data, the data\nneeds to be extracted from the Pivot Table by a macro and pasted into a\nRange table with no gaps in the sequence. This is achieved by running a\nmacro called \u2018histogram_copy\u2019. This is accessed by pressing \u2018cntrl-h\u2019.\nThe extracted data is pasted into cells D32:I56."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe data is then normalised, in cells D61: I85, and weighted, in cells\nD91:K104. The weighting is a triangular weighting function whose\nparameters are contained in cells B91:B94."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the example, the weighting is applied over a group of five adjacent\nvalues, as follows."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCells B91:B94 also prepare the weighted data for plotting in _Histogram\n1_ and _Histogram 2_."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFinally, cells M10:T25 take the unweighted data and prepare it for\nplotting in _unsmoothed 1_ and _unsmoothed 2_."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Histogram 1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis chart presents the weighted results for the first three modules.\nNote the labels follow those generated in the pivot table."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Histogram 2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis chart presents the weighted results for the second three modules.\nNote the labels follow those generated in the pivot table."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*unsmoothed 1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis chart presents the unweighted results for the first three modules.\nNote the labels follow those generated in the pivot table."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*unsmoothed 2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis chart presents the unweighted results for the second three modules.\nNote the labels follow those generated in the pivot table."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*overview 1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis sheet is used to record an analysis of the data which gives an\noverview of the spread of confidence interval limits for each test\ncentre irrespective of test modules. It thus gives an indication of the\nconsistency of results between test centres: it cannot however give any\nindication of why there might not be such consistency."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo generate the above spreadsheet one needs to run the macro \u2018Overview\u2019.\nThe short cut keys are 'cntrl-o'."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe parameters that are computed are the average of the means, the\nhighest of the upper confidence limits and the lower of the lower\nconfidence limits."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*overview plot 1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis chart presents the graphical form of the data computed in _overview\n1_. Note the labels follow those generated in the source sheet. Note\nalso that, because of the nature of the data analysis, non-symmetrical\nresults can be expected."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*overview 2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis sheet is used to record an analysis of the data which gives an\noverview of the spread of confidence interval limits for the different\nprogramme items irrespective of test centre or test modules. It thus\ngives an indication of the sensitivity of the coding modules to the\nrange of programme material."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo generate the above spreadsheet one needs to run the macro\n\u2018Overview2\u2019. The short cut keys are 'cntrl-p'."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe parameters that are computed are the average of the means, the\nhighest of the upper confidence limits and the lower of the lower\nconfidence limits."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*overview plot 2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis chart presents the graphical form of the data computed in _overview\n2_. Note the labels follow those generated in the source sheet. Note\nalso that, because of the nature of the data analysis, non-symmetrical\nresults can be expected."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*overview 3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis sheet is used to record an analysis of the data to give an overview\nof the spread of confidence interval limits for the different test\nmodules irrespective of programme excerpts. It thus gives an indication\nof the sensitivity of the coding module to the test centre."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo generate the above spreadsheet one needs to run the macro\n\u2018Overview3\u2019. The short cut keys are 'cntrl-q'."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe parameters that are computed are the average of the means, the\nhighest of the upper confidence limits and the lower of the lower\nconfidence limits."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*overview plot 3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis chart presents the graphical form of the data computed in _overview\n3_. Note the labels follow those generated in the source sheet. Note\nalso that, because of the nature of the data analysis, non-symmetrical\nresults can be expected."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3D area*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThough included in the workbook, the author has found little value in\nthis presentation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*macros*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis sheet contains the macros already mentioned above. The macros\nthemselves contain the comments necessary to understand them, as well as\nlabels to indicate which sections of each macro need editing to\naccommodate and increase/decrease in the number of analysis cycles."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Conclusions*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe spreadsheet Results has been used for three groups of test results\nanalysis by Audio for NBC and MPEG-4 tests. In order to make it more\neasily transferable to different applications, the spreadsheet has been\ndescribed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= To HODs\nPeter Schirling\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND ASSOCIATED AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11N1139*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"13%,87%\",]\n|===\n|Source: |Pete Schirling (IBM)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Guidelines for electronic distribution of MPEG and WG11\ndocuments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Status : |Approved at 33nd meeting\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG document handling*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *DOCUMENT SUBMISSION:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWhen you want to submit a document to MPEG, you first need to register\nyour document and then after editing the document number into the text\nand naming the document according to the wishes of the registrar, upload\nit to a ftp server :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *DOCUMENT REGISTRATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn order to get a number for your document, access the following web\nsite :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* http://www.chips.ibm.com/.mpeg/\n* userid : sc29wg11\n* pw : La_Pasta (case sensitive)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSelect - *Request Publication Number*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFill all the information requested on the web page."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis will include -"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Your Email ID*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContribution Title"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthors"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nYour Organization"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGroup & Subgroup category of your contribution"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that additional information requests may be added at the time of\nthis meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nYou will automatically receive your document number. Record it and\nplease DO NOT FORGET to include it on your document header."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nYou can use this facilities to either register for a new document or to\nmodify the registration information of YOUR contributions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPlease DO NOT register a new document if all you need to do is modify\nthe registration information or even to update the contents of a\ncontribution that has already received a number."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo modify registration select -*Update or Delete a Publication Number*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBe sure to select **update (**default) or *delete*."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFill in the information requested. Be sure your document number is\ncorrect and fill all the remaining fields with the correct information.\nYou may submit corrections as often as needed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBe aware that this *update/delete* function is monitored; your *email\nid* is checked against the original registration information. If it does\nnot match, no *update/delete* is performed and the sender is not\nnotified but the originator will be notified of an unauthorized attempt\nto alter the registration information."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *DOCUMENT UPLOAD*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOnce you have received your document number and have edited this number\ninto your document, upload it to the main ftp site : Please ZIP your\nfile regardless of its size after you have virused checked it to be sure\nit does not contain the WORD concept virus."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* address : *drop.chips.ibm.com*\n* userid : *sc29wg11*\n* pw : *La_Pasta* (case sensitive)\n* dir : *incoming*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRemark : documents are NOT available from the \"incoming\" dir"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe ftp manager will move your file in the appropriate directory,\nFirenze in this case."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Document format :*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPlease use Word for Windows V6.0 format only."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFile names shall adhere to the rule - *Mnnnn.DOC* where *nnnn* is the 4\ndigit number assigned when you registered your document. Please ZIP all\nfiles using the naming convention *Mnnnn.zip*. All Mnnnn files will be\nplaced in the \"*Firenze/contrib*\" dir. The document register will the\nlowest number mnnnn.zip in the directory"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Document template :*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA template with the standard header (ISO header, source, title, ...) is\navailable. It is named Mxxxx.doc on the Firenze dir as are scan831.doc\nand scanprot.dot which are the WfW virus detection and protection\nfunctions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*The registration and the uploading of documents have to be completed AT\nTHE LATEST 5 WORKING DAYS before the start of the meeting. In this case\nWed 20 March* *1996.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformation regarding the web site and the ftp sites will be distributed\nvia the WG11 reflector -"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*SC29WG11DOC@dkuug.dk*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe list of email ids included in this reflector is of the\nresponsibility of your HoD (Head of Delegation); this list will be\nupdated at each MPEG meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *DOCUMENT RETRIEVAL*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAny MPEG member can retrieve MPEG and WG11 documents from the main ftp\nsite (in U.S.) or from the 2 mirror sites (in Japan and in U.K.)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*USA site :*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* address : *drop.chips.ibm.com*\n* userid : *sc29wg11*\n* pw : *La_Pasta* ** (case sensitive)\n* dir: *Firenze*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*EUROPE site :*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* address : *shark.elec.qmw.ac.uk*\n* userid : *sc29wg11*\n* pw : *La_Pasta* (case sensitive)\n* dir: *Firenze*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*JAPAN site :*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* address : *tains.comm.waseda.ac.jp*\n* userid : *sc29wg11*\n* pw : *La_Pasta* (case sensitive)\n* dir: *Firenze*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe dir tree for the Dallas meeting is the following :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDallas --"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n--WG11 (for output from the Dallas meeting - Wmmm)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n--contrib (for contribution to the Dallas Meeting -Mnnn)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe dir tree for the Munich meeting is the following :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMunich --"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n--WG11 (for output from the Munich meeting - Wmmm)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n--contrib (for contribution to the Munich Meeting -Mnnn)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll MPEG participants are expected to download the documents they will\nneed in Firenze prior the meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf you do not have access to WWW server / ftp sites, please contact your\nHoD who will do his best to help you."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= 1. Scope of the tests\nISDB\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODED REPRESENTATION OF PICTURE AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11 *N1140*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source* : Tests sub-group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title :* Results of MPEG-2 MP@HL (H-14) video verification test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Purpose* : Report"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. Scope of the tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis report gives the results of the subjective assessments conducted as\n\"verification tests\" on the video quality of MPEG-2 MP@HL and MP@H-14.\nThese tests involved processed pictures prepared in simulation by six\norganizations and subjective assessments at four test sites in Europe\nand Japan."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2. Description of the tests*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.1. Test items."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe assessment tests for MP@HL were conducted for 1125/60 HDTV system.\nThe tests include the following test items :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(1) Basic quality 18, 30, 45 Mbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt 18 Mbps, the test was conducted for MP@H-14."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(2) Film source 18, 30, 45 Mbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe materials were coded in the form of progressive pictures of 24 Hz.\nThe coded pictures were displayed in the interlaced picture format of 60\nHz by 3/2 pull-down technique."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.2. Test material*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe main features of the test sequences selected for the evaluation are\nsummarized in Table 1. Originally Test sub-group intended to use six\nvideo sequences of 10 second duration for the basic quality tests.\nHowever, following simulation problems and editing difficulties, only\nthree sequences of five seconds were available for the video quality\ntest. Consequently, the test sequences did not cover various scenes that\nMPEG intended (e.g. fast movement, saturated color picture)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 1 Main features of the test sequences"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,18%,14%,53%\",]\n|===\n|TV system |Sequence name |Source |Type of picture content"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Green Leaves |BTA / SONY |Loose shot of a path in woods. Outdoor\nshooting ; zoom Detailed structure"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Video (1125/60) |Basketball-1 |IOC / BTA / NHK |Basketball players and\nspectators. Indoor sports; multiple motion, slow pan, strobe lighting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Train |Hughes / SONY |Track shot of running tram. Consist of two\npanning shots, vertically and horizontally. Outdoor shooting of night\nscene"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Plane Ride-2 |Cable Labs./ Kodak |A scene of moving planes in an\namusement park. Multiple rapid motion ; pan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Film (1125/24) |Splash |Cable Labs./ Kodak |Consist of two cuts; both\nclose-up of a woman and a fountain; cross fade"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |Carousel-2 |Cable Labs./ Kodak |Consist of two cuts; both close-ups\nof a woman; rapid motion, cross fade\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.3 Test conditions and assessors*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe DSCQS method was used as described in ITU-R BT. 500-5, in viewing\nconditions according to ITU-R BT. 710-2 (viewing distance: 3H). The\nscores of the observers whose votes did not exhibit sufficient\nconsistency according to the criteria of Rec. 500-5 were excluded from\nthe analysis."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe basic quality test and film source test were combined into a single\nsession. The duration of the session was about 30 minutes including\nstabilizing presentations. There were no training sequences in the\ntests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 2 shows the number of observers and type of the monitor used at\neach site."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 2. Number of observers and types of monitors."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"41%,24%,35%\",]\n|===\n|Test site |No. of observers |Type of monitor\n|YTSC (MPT Japan, JVC, NTV, NHK) |18 |30\u201d SONY 3030 type\n|NHK |24 |41\u201d SONY HDM4130\n|CCETT |17 |30\u201d display\n|DTF |15 |38\u201d display\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3. Subjective evaluation results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.1 Video basic quality test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe results obtained from different test sites showed good correlation.\nThe overall results are shown in Table 3 and Figure 1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 3 Basic quality results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"17%,11%,18%,19%,16%,19%\",]\n|===\n|observers: |74 |Green Leaves |Basketball-1 |Train |Mean\n|18 Mbps |Mean |15.7 |10.3 |1.5 |9.2\n| |S.D. |11.2 |12.1 |12.2 |13.2\n|30 Mbps |Mean |13.6 |4.3 |-0.9 |5.7\n| |S.D. |14.6 |10.5 |8.3 |12.9\n|45 Mbps |Mean |10.1 |6.7 |-0.4 |5.5\n| |S.D. |13.4 |8.8 |8.0 |11.2\n|Reference |Mean |-0.8 |1.1 |1.2 |0.5\n| |S.D. |7.6 |8.7 |7.0 |7.8\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 1 Results of video quality test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2018Green Leaves\u2019 is the most critical and discriminating sequence. The\nsource quality is higher than that for the other video sequences and the\npicture content is more critical (random moves of leaves, higher\nresolution). \u2018Basketball\u2019 is too short and the observers had not enough\ntime to judge quality because of the level of motion. \u2018Train\u2019 is clearly\nnot sufficiently critical to allow observers to judge representative\ndifferences in quality."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3.2 Film source test*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe overall results of film source test are shown in Table 4 and Figure\n2."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 4 Film source results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"16%,10%,19%,20%,20%,15%\",]\n|===\n|observers: |74 |Plane Ride-2 |Splash |Carousel-2 |Mean\n|18 Mbps |Mean |4.7 |1.3 |0.6 |2.2\n| |S.D. |10.3 |9.9 |10.2 |10.3\n|30 Mbps |Mean |1.0 |2.9 |0.0 |1.3\n| |S.D. |10.4 |8.5 |7.9 |9.0\n|45 Mbps |Mean |0.8 |2.2 |2.0 |1.7\n| |S.D. |8.9 |9.2 |9.3 |9.1\n|Reference |Mean |-0.4 |0.7 |-2.6 |-0.8\n| |S.D. |6.7 |10.1 |7.8 |8.4\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEven if the overall quality of the source material can be considered as\npoor, and considering the different transfer processes (e.g. 3/2\npulldown), quality transparency is achieved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 2 Results of film quality test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4. Expert viewing*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExpert viewing was conducted at NHK and EBU. Observations of experts\nwere well consistent with the results of DSCQS tests by non-expert\nviewers. The following comments were raise;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* \u2018Train\u2019 has a defect in the form of a picture skip and it causes some\ndifficulty for observers to assess the quality of decoded pictures.\n* The desirable duration of sequences to perform DSCQS tests is 10\nseconds. Doubling of a 5-second scene (by repetition or palindromic\ndisplay) should be exceptional and did probably not behave correctly in\na scene with fast motion.\n* Scene contents were perhaps not really representative of most usual\nprogram material in terms of shooting, particularly considering very\nfast movements in large areas or saturated color picture.\n* Original film shots exhibited a distinct grain noise sometimes\naccompanied with blur. This might have resulted in a modification of the\ncoding impairments.\n* Judder on the moving area caused by 3/2 pulldown might often prevent\nto observe coding artifacts."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5. Conclusions*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n5.1 Video basic quality test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following conclusions can be driven, although it must be taken into\naccount that only part of the test material that the test group intended\nto use was actually used:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. 45 Mbps showed transparent quality,\n. 30 Mbps showed near-transparent quality,\n. 18 Mbps showed overall good quality."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.2 Film source test*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe may conclude that MP@HL achieved good picture rendition for film\nsources even at 18 Mbps."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nReferences"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. J. Urano: Report of the adhoc group on MPEG-2 verification test for\nMP@HL (H14) (MPEG95/335)\n. NHK: Results of MP@HL (H-14) expert viewing (MPEG95/361)\n. K. Ozawa (JVC), J. Urano (NTV), Y. Sakanaka (MPT Japan): Results of\nMP@HL (H14L) Verification Test in YTSC (MPEG95/400)\n. NHK: Results of MP@HL (H-14) subjective assessment tests (MPEG96/567)\n. D. Nasse: EBU participation to the MP@HL (H-14) verification\n(MPEG96/636)\n. J. Urano: Report of the adhoc group on MPEG-2 verification test for\nMP@HL (H14) (MPEG96/656)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n______________"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= ITU-T SG11 Question 15/11 Rapporteur\nPeter Schirling\n1996-01-31"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANIZATION INTERNATIONALE DE NORMALIZATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC/SC29/WG11 *N1141*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*To: ITU-T SG11 Question 15/11 Rapporteur*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSource: *ISO/IEC JTC1/SC29/WG11 Convenor, L. Chiariglione*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Re: Liaison re- ITU-T DSS2 GIT Fields assigned to DSM-CC*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Expert Group for Coding of Moving Pictures and Associated Audio at\nits meeting in Munich, Germany on January 22-24, 1996, wishes to thank\nITU-T SG11 for the prompt response and the progress made in defining the\nGeneric Identifier Transport (GIT) in answer to an earlier Liaison from\nISO/IEC JTC1/SC29/WG11 \u00d2re- Proposed DSS2 IE to support DSM-CC\nCorrelation ID\u00d3 in June 1995. The Digital Storage Media Command and\nControl (DSM-CC) protocol is defined in ISO/IEC 13818-6 \u00d2MPEG-2 DSM-CC\u00d3\nDraft International standard November/95. The target is to move the\nspecification to International Standard status in July 1996. In order to\nensure that DSM-CC implementations using B-ISDN benefit from the ITU-T\nDSS-2 GIT specification further information is provided below:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* ISO/IEC JTC1/SC29/WG11 wishes ITU SG11 to include initiallyGIT\n(assigned to DSM-CC application) in the ITU-T DSS2 Q.2931 SETUP message\nand the equivalent network signaling message (IAM).Add a third field to\nGIT (beyond Session ID and Resource Number) called Expansion\nSubidentifier with a variable length of up to a maximum of 70 bytes.\n* For future consideration ISO/IEC JTC1/SC29/WG11 wishes ITU SG11 to\ninclude GIT in the RELEASE/RELEASE COMPLETE and ADDPARTY messages."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11 takes this opportunity to thank ITU-T SG11 for\nthe continued cooperation and will follow with interest the progress\nmade on GIT in the ITU-T DSS2 recommendations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSincerely,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nL. Chiariglione"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nConvenor, ISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANIZATION FOR STANDARDIZATION\n**********\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IECJTC1/SC29/WG11 *N 1142*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source* : Test subgroup"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title* : ** Ad-hoc group on test methodology for formal NBC test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To review the test methods reported in WG11/N0685 and to\ndefine procedures for future formal NBC audio test."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMeetings: No meetings shall be held."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDuration: until next MPEG meeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChairman: H. Suzuki JVC suzukihr@krhm.jvc-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMembers:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAkagiri, K. Sony ken@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBosi, M. Dolby Laboratories mab@dolby.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBrandenburg, K. FhG - IIS bdg@iis.fhg.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHotani, S. NTTDoCoMo hotani@mlab.nttdocomo.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIwadare, M. NEC sc29a@dsp.cl.nec.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJohnston, J. AT&T jj@research.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLueck, C. TI lueck@hc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMainard, L CCETT lmainard@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMeares, D. J. BBC david.meares@rd.bbc.co.uk"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOikawa, J Sony oikawa@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOomen, W. Philips oomena@prl.philips.nl"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nParladori, G. Alcatel Telettra gparladori@tlt.alcatel.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nQuackenbush, S. AT&T srq@research.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSchreiner, P. G. Scientific Atlanta pgs@sciatl.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSchwalbe, R. Deutsche Telekom AG schwalbe@audio.fz.telekom.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTan, Ah-Peng Asia Matsushita Electric aptan@avirc.ams.com.sg"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThom, D. Mitsubishi dthom@msm.mea.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWatanabe, K. NHK watanabk@strl.nhk.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nYin, Lin Nokia lin.yin@research.nokia.fi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFuchs, H University of Hannover fuchs@tnt.uni-hannover.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFeige F. Telekom"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nL. Kerkhof Philips kerkhofl@ce.philips.nl"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nD.Nasse CCETT(EBU) nasse@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nT.Alpert CCETT(EBU) alpert@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nV.Baroncini FUB mc4853@mclink.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nL.Contin CSELT laura.contin@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nR. Koenen KPN-Research r.h.koenen@research.kpn.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nE. Miyasaka NHK miyasaka@strl.nhk.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= MPEG/Audio Dallas Meeting Participant List (November 1995)\nBernd Edler\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*N1143*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Audio Subgroup"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Preliminary Draft of MPEG4 ** Audio Verification Model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Introduction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBased on the first analysis of the technical descriptions of submitted\nproposals, three classes of coding schemes were defined: The results\nshow that for different bit rates and/or functionalities different\nschemes seem to be the most suitable. Therefore block diagrams for the\nthree classes were built and a draft VM was constructed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Analysis of test results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe three classes of codecs are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Codecs based on time/frequency mapping\n* LPC-based Analysis/Synthesis codecs\n* Codecs based on a parametric description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA brief analysis of the results of the subjective tests was carried out\nin order to obtain information about the suitability of the three\nclasses for the required functionalities. The results are shown in the\nfollowing table. \u201c+\u201d, \u201c0\u201d and \u201c-\u201d give an indication for the suitability\nin decreasing order. The best performing codec was considered for each\nof the three classes. The capability of \u201cLow-Delay\u201d was evaluated based\non the one-page summaries provided by the proponents."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,15%,50%,10%,9%,9%\",]\n|===\n| | |Bit rates |Speed |Pitch |Delay\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSince the proposals for the functionality \u201cScalability\u201d in most cases\nincorporated different schemes, the possible combinations are addressed\nseparately"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Coding scheme based on time/frequency mapping"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following figure shows the block diagram for a coding scheme based\non time/frequency mapping:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis scheme consists of the following 7 modules. Typical processing\nexamples are attached to each module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. preporocessing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwindow switching decision"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nband limitting filetring"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsampling rate conversion"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngain control"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntime domain feature extraction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsignal classification"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. time-frequency mapping"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMDCT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhybrid subband"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMDCT+flattening"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMOT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDFT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. Feature extraction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nharmonic detection"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstandard speech codec"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninterveve samples"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njoint channel coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4. Quantization and coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nscalar quantization + bit alloc. + entropy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npredictive coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmulti-quantizer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVQ (Tree-structure, weighted)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScalability by calculating and encoding the frequency domain difference\nsignal between original and quantised signal (\"f\" type scalability)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScalability by increasing the bandwidth or accuracy of the signal (\"e\"\ntype scalability)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnoise injection"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5. Feature coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngain quantization/coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nparameters quantiztion/coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}6. Psychoacoustic model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n7.Bit multiplexer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbuffering, rate control"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nerror detection/protection code"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Coding scheme based on LPC analysis/synthesis"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following figure shows the block diagram of the coding scheme based\non LPC analysis/synthesis codecs:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe basic functions of the LPC ( A/S)-VM are the following:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1) Preprocessing:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExamples of preprocessing of the input signal are framing, noise and\nDC-component suppression, low-pass filter and high-pass filter."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2) LPC analyzer and quantizer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPossible subcomponents are windowing, LPC analysis, conversion to LSP,\nlinear quantization, VQ, interpolation, bandwidth expansion, signal type\n(e.g. voiced/unvoiced) identification"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3) Excitation signal generation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExamples are different types of codebooks (adaptive, stochastic, fixed,\ngain etc) whether existing singularly or in hybrid form, pitch\nprediction filter, gain quantization."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4) Perceptual weighting filter"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExamples are different variants of a weighting filter depending on the\ntype of perceptual model used."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5) Distortion minimization"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nComputation of the error and selection of excitation signal based on a\npredetermined error minimization criteria, preselection method and\ndelayed decision."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}6) Post Processing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(only in decoder)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExamples are speech enhancement, low-pass filter, high-pass filter,\npitch control, speed control etc"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Coding scheme based on a parametric signal description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe block diagram for a coding scheme based on a parametric signal\ndescription:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFeature / Parameter extraction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExamples :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Spectral shape of unvoiced signals\n* Harmonic structure of voiced signals\n* Individual spectral line estimation\n* Dimension conversion of feature vectors"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. The proposals used different approaches to implement the\nscalability functionality:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBy calculating and encoding the time domain difference signal between\noriginal and quantised signal (\"t\")"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBy calculating and encoding the frequency domain difference signal\nbetween original and quantised signal (\"f\")"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBy increasing the bandwidth or accuracy of the signal (\"e\")"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBy means of simulcast (\"s\")"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. The proposals also used different coding techniques for each\nbit-rate layer:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTime/frequency based coding technique (\"A\")"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLPC based coding technique (\"B\")"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCoding by parametric representation (\"C\")"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. Three scalability modes have been tested:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScalability 1: 6 kbps - 64 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScalability 2: 6 kbps - 24 kbps - 64 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScalability 3: 2 kbps - 6 kbps - 16 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4. The following tables contain the coding and scalability\ntechniques used by each of the proponents for each of the scalability\nmodes:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,85%,,\",]\n|===\n| |Scalability 1 | |\n| |64 kbps | |6kbps\n|#1 |A |? |B\n|#2 |A |t |C\n|#3 |A |e |A\n|#4 |A |s |A\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"10%,90%,,,,\",]\n|===\n| |Scalability 2 | | | |\n| |64 kbps | |24 kbps | |6 kbps\n|#1 |A |f |A |t |B\n|#2 |A |f |A |t/e |C\n|#3 |A |t |A |t |A\n|#4 |A |f/e |A |f/e |B\n|#5 |A |f |A |f |A\n|#6 |A |e |A |e |A\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"10%,90%,,,,\",]\n|===\n| |Scalability 3 | | | |\n| |2 kbps | |6 kbps | |16 kbps\n|#1 |B |t |B |t |B\n|#2 |A |t/f |A |t/s |C\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Preliminary draft Verification Model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe block diagram in the following Figure could be considered as a\ngeneral framework for MPEG-4 audio verification model development. The\nframework allows for flexible merging of different audio coding schemes.\nFurhermore, interactions between the different audio coding schemes are\npossible so that this can be exploited in future core experiments. Based\non an input signal analysis and the target system requirements such as\naudio-quality, bit-rate, scalability and error-resiliance, the coding\nschemes are controlled accordingly. The framework consists of a\npreprocessing stage where the signal can be modified or pre-conditioned.\nThe signal partitioning block is responsible for the optimal splitting,\ne.g., time-frequency representation. Different coding schemes can now be\napplied to the output of the partitioning block. In order to allow for\nfurther processing iterations the quantization and coding schemes are\nseparated. The final stage consists of the multiplexer."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-----------------------*Pre-processing*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*T/F*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Feature extraction coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Quantization coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Bit Mux*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Psychoacoustic Model*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Feature Coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPre-processing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLPC analyzer & Quantizer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExcitation Signal Generation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPerceptual Weighting Filter"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDistortion Minimization"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInput Speech"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1/A(z)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n+"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n+"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nU"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nX"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBit Stream"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Pre-processing*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Signal Partitioning*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Signal Analysis & control*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Coding scheme #1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Coding scheme #n*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*M*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nU"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nX"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Quantisation*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n& coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Quantisation & coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContents (Draft!):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nw1144.doc       Introduction\nw1144a.xls      Tables (Tukey-Test, ranking), add. item-type specific orders\nw1144b.xls      Graphs in original form (and corresponding tables)\nw1144c.xls      Additional graphs (reordered for common functionalities)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= 1. Introduction\nBernd Edler\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*N1144*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Audio Subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title: MPEG-4 Audio Test Results (MOS Tests)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the Dallas meeting of the MPEG Audio Subgroup, November 1995, the\nad-hoc group on MPEG-4 audio test was mandated to prepare the MOS test\nfor MPEG-4 codecs, prepare procedures for test analysis and prepare a\ntest result report for the Munich MPEG meeting. The purpose of the test\nis to identify potential codecs to be used in the MPEG-4 audio\nverification model."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe details relating to test tape preparation were outlined in ISO/IEC\nJTC1/SC29/WG11/N1033, while ISO/IEC JTC1/SC29/WG11/N1074 was used as a\nguideline to minimize test requirement. The procedures for running the\ntest at each test center were outlined in ISO/IEC JTC1/SC29/WG11/N1077\nand ISO/IEC JTC1/SC29/WG11/N1078 outlined procedures for test results\nanalysis."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMany people contributed to the activities of this group. Takehiro\nMoriya, Masayuki Nishiguchi and Jun Matsumoto prepared the test tapes\nwith different randomization orders for the test items and distributed\nthe tapes to the different test labs. After the test they collected the\nscores from the different labs and formatted them for further\nprocessing. The tests were organized and conducted by Johannes Hilpert\nat FhG, Davis Pan at Motorola, David Thom at Mitsubishi America,\nMasayuki Nishiguchi and Jun Matsumoto at Sony IPC and by Takehiro Moriya\nat NTT. Thanks to them and to their colleagues who spent a big amount of\ntime for listening. Thanks also go to Mike Coleman for processing and\nconverting the results into a format which could be used for the\nstatistical analysis. Special thanks go to Laura Contin for preparing\nand coordinating the statistical analysis and for her big effort in\nediting the test report, and to her colleagues at CSELT for the support\nof the statistical analysis. David Thom and many other ad-hoc group\nmembers also contributed significantly to the drafting of the test\nreport. Finally the ad-hoc group thanks the IRT for hosting the meeting\nand Gerhard Stoll for the logistic and technical support."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2. Tape Format*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe final format of the tapes was DAT with all stimuli presented at a\nsampling rate of 48 kHz. This required the up-conversion of some\nstimuli, based on the up-conversion filter provided by FhG, available on\nthe Hannover ftp site."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere were no announcements on the tape. The test stimuli were\nsubdivided by delimiters in the form of audible beeps. The beeps were 1\nkHz tones at 30 dB below full scale, with duration \u2018single\u2019 = 0.5 sec\nand \u2018double\u2019 = 1 sec. The sequences on the tape were: before stimuli\nnumber 1, 11, 21, 31 etc a double beep was included, and a short beep\nwas included in front of each of the other stimuli. The double beep thus\nacts as a guide to the test subject that he/she is still in step with\nthe test sequence. The sequence of stimuli will therefore be"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBeep"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStimulus 1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2 sec gap (for scoring)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBeep"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStimulus 2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2 sec gap (for scoring)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBeep"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\netc, etc"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBetween blocks of tests (say 20-30 minutes in duration) a longer gap was\nincluded to help locate the tape with reference to the time code."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3.0 Reference Coders*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nReference signals used in each test are listed below."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"42%,58%\",]\n|===\n|rate of test coder |reference coder\n|2kbps |FS1016(4.8kbps)\n|6kbps |G.729(8kbps)\n|16kbps |G.722(64kbps)\n|24kbps |MPEG-2 Layer III(Low Sampling Frequency Mode)\n|40kbps |MPEG-1 Layer III\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese reference coder choices are fixed for all functionalities."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4.0 Anchor signals*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExisting bandlimited MNRU were used for tests with 2 and 6 kbps/ch. The\nMNRU were repeated only once per programmed item."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNew versions of MNRU were prepared by NTT for use with assessments at\n16, 24, 40, and 64 kbps."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MNRU signals were included as if they were additional reference\ncoders, i.e. the MNRU stimuli was included in the randomization of the\nstimuli."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4.1 MNRU description:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n8 kHz sample & 16 kHz sample MNRU is used for 2,6,16 kbps tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMNRU signal Y (n) is generated by Y(n) = X (n) ( (X(n)( N(n), where X(n)\nis original input. N(n) is a unit power gaussian noise, and E is a\nconstant to give a specified SNR."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn case of 24 kbps and above 48 kHz sample MNRU is used. In this case"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nY(n) = X (n) + E(sqrt( ( (X(n)(^2^/M) ) ( (n) is used."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n** ^M^"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( (n) is a 8kHz band limited gaussion noise and the amplitude of the\nnoise is multiplied by the RMS values of the input averaged over M =\n(128) samples."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4.2 MNRU*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 2k,6kbps*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMNRU 10, 20, 30, and 40dB signals of all the items were used for the\nanchors of both 2.0 and 6.0kbps tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 16kbps*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMNRU 10,17,24,31,38 and 45dB signals of all the items were used for the\nanchors of 16kbps tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 24/40/64bps*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMNRU 17 24, 31,38 and 45 dB signals of all the items were used for the\nanchors of 24/40/64kbps tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.0 Training stimuli*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach test tape started with a selection of items specifically for the\npurpose of training the subjects. This comprises ten program items which\ncover the full range of expected artifacts and the range of program\nitems."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe required stimuli were: MNRU at 40, 30, 20,10 and 0 dB each using a\ndifferent program item."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6.0 Test tape preparation*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 2k,6kbps*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nListening tapes for 6.0 and 2.0 kbps MOS tests were prepared by Sony\nIPC. The tapes were prepared based on the method described in N1033. A\ntotal of 20 tapes were made using different randomization orders; five\ntapes for 6.0 kbps English/German version, five for 2.0 kbps\nEnglish/German version, five for 6.0 kbps Japanese version, and five for\n2.0 kbps Japanese version. Copies of ten English/German version tapes\n(five 2.0 kbps and five 6.0 kbps) were sent to each of the listening\nLabs. (FhG, Motorola, and Mitsubishi US)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRepetition was not included in each of single tapes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 16,24/40/64kbps*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nListening tapes for 16 and 24/40/64 kbps MOS tests were prepared by NTT.\nThe tapes were prepared based on the method described in N1033. A total\nof 22 tapes were made using different randomization orders; five tapes\nfor 16 kbps English/German version, six for 16 kbps Japanese version,\nand eleven for 24/40/64 kbps music version."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCopies of English/German version tapes and music version were sent to\neach of the listening Labs. (FhG, Motorola, and Mitsubishi US)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRepetition was already included in each of single tapes at 16,24/40/64\nkbps."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6.1 Randomization*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tapes were prepared such that all stimuli at a particular bit rate\nwere included in one tape, regardless of functionality. There was no\nrepetition of the stimuli in the recorded tapes for 2 kbps and 6 kbps.\nTo compensate for this the tape preparation centers prepared at least 5\ndifferent randomizations of all stimuli for 2kbps and 6kbps. For 16, 24,\n40 and 64 kbps the randomization was built into one set of tapes. In\nthese cases, the treatement of repetition was not in full compliance\nwith N1033. Instead of having 2 independent randomizations of all codec\nitems and making a test tape of the 2 randomizations to provide for\nrepetition, the codec items were doubled and a single randomization was\nused. With this approach both items of a given codec could be presented\nin the first half of a test tape."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6.2 Training sequences*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 2, 6 kbps*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n10 items for listener training were recorded at the beginning of each\ntape. Training items include MNRU 10,20,30,40 dB signals, reference\nsignals, and coded signals by test coders."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 16kbps*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n12 items for listener training were recorded at the beginning of each\ntape. Training items include all types of MNRU signals, reference\nsignals, and coded signals by test coders."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 24/40/64 kbps*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n11 items for listener training were recorded at the beginning of each\ntape. Training items include all types of MNRU signals, reference\nsignals, and coded signals by test coders."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*7.0 Source material:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSource material was selected in order to cover three types of content\ncomplexity, i.e. single sources, single sources with background, and\ncomplex sources. Source material will be available with a sampling\nfrequency of 48 kHz for high-quality tests. For tests which are based on\nband limited test material, they also can be used after down-sampling to\na specified reference frequency. In order to support intelligibility\ntests additional test items are available sampled at 8 kHz for both\nJapanese and Europe/American listeners."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe items used in the test are listed in the following table. For each\nitem an item type is assigned, indicating whether it is used at test\nsites as well in Japan as in Europe/USA (\u201cs\u201d), only in Japan (\u201cj\u201d), or\nonly in Europe/USA (\u201ce\u201d)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,64%,16%\",]\n|===\n|item number |signal |item-type\n|01 |harpsichord |s\n|02 |female vocal |s\n|03 |haydn |s\n|04 |castanets |s\n|05 |german male speech |s / e 1\n|06 |english female speech |e\n|08 |2 english talkers |e\n|10 |english female speech with car noise |e\n|11 |japanese male speech |j\n|12 |japanese female speech |j\n|13 |japanese male speech with background noise |j\n|14 |2 japanese talkers |j\n|15 |japanese female speech (sentence pair) |j\n|16 |japanese female speech with car background noise |j\n|21 |english male speech |e\n|23 |german female speech |e\n|26 |japanese male speech (sentence pair) |j 2\n|27 |japanese female speech |j\n|28 |japanese female speech |j\n|29 |japanese male speech |j\n|30 |japanese male speech |j\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nItems and item types"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n^1^ item type \u201cs\u201d in ranking groups marked \u201cs\u201d, \u201ce\u201d in ranking groups\nmarked \u201cm\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n^2^ this item was only used at 2 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*7.1 Listening items*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDown-loaded audio files were grouped into English/German version and\nJapanese version by the item numbers. Music items were included for both\nversions. Total number of listening items in each tape is shown below."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<6k English/German>"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n296 including (4[pic]MNRU+G729) [pic]9(items)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<2k English/German>"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n89 including (4[pic]MNRU+FS1016) [pic]9(items)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<6k Japanese>"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n396 including (4[pic]MNRU+G729) [pic]13(items)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<2k Japanese>"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n149 including (4[pic]MNRU+FS1016) [pic]14(items)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<16k English/German>"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n224 (6[pic]MNRU+G722+9) [pic]7(items)[pic]2(repetition)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<16k Japanese>"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n352 (6[pic]MNRU+G722+9) [pic]11(items)[pic]2(repetition)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<24/40/64k(error)>"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n320 (5[pic]MNRU+2[pic]MPEG-1+13+8+4) [pic]5(items)[pic]2(repetition)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*8.0 Functionalities:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe functionalities for which the codecs were submitted are indicated by\nthe \u201cfunctionality codes\u201d given in the following table. In cases where\nthere was more than one proposal from one company, an integer multiple\nof 25 is added to the functionality code. For the statistical analysis\nat a particular bit rate all funtionalities which were tested with the\nsame sets of items were combined in ranking groups. The tables and\ngraphs presenting the test results are based on these ranking groups.\nThis means that one graph or table may contain the results of different\nfunctionalities. In the cases where different item types were used, the\nresults for the individual item types are also presented. For\nfunctionalities where the following table shows an item type \u201cs\u201d items\n1...5 were used in the test, in all other cases indicated by item type\n\u201cm\u201d, the item type is taken from the item list as described above."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"35%,18%,15%,14%,18%\",]\n|===\n|functionality |bitrate (kbps) |funct. code |iem.type 1 |ranking group\n|compression |2 |00 |m |A\n|compression |6 |01 |m |B\n|compression |16 |02 |m |C\n|compression |24 |03 |s |D\n|compression |40 |04 |s |E\n|error res. \u201cno errors\u201d |6 |06 |m |B\n|error res. \u201cno errors\u201d |16 |07 |m |C\n|error res. \u201cno errors\u201d |64 |08 |s |-\n|speed change \u201cnormal speed\u201d |2 |09 |m |A\n|speed change \u201cnormal speed\u201d |6 |10 |m |B\n|scalability 1 |64 |12 |s |-\n|scalability 1 |6 |13 |s |F\n|scalability 2 |64 |15 |s |-\n|scalability 2 |24 |16 |s |D\n|scalability 2 |6 |17 |s |F\n|scalability 3 |16 |19 |m |C\n|scalability 3 |6 |20 |m |G\n|scalability 3 |2 |21 |m |H\n|error res. \u201cburst errors\u201d |6 |06_b |m |I\n|error res. \u201crandom errors\u201d |6 |06_r |m |J\n|error res. \u201cburst errors\u201d |16 |07_b |m |K\n|error res. \u201crandom errors\u201d |16 |07_r |m |L\n|error res. \u201cburst errors\u201d |64 |08_b |s |M\n|error res. \u201crandom errors\u201d |64 |08_r |s |N\n|speed change \u201cspeed up\u201d |2 |09_su |m |O\n|speed change \u201cspeed up\u201d |6 |10_su |m |P\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities and ranking groups"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n^1^ \u201cm\u201d: item types according to item list, \u201cs\u201d: only items of type \u201cs\u201d."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*9.0 Test rating system:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe specific test method used was the Absolute Category Rating (ACR)\ntest. In this test a five point rating scale was used by the subjects to\ngive a quality judgment of the presented test material. The following\nrating scale is used:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"78%,22%\",]\n|===\n|Quality rating of the speech |Score\n|Excellent |5\n|Good |4\n|Fair |3\n|Poor |2\n|Bad |1\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe numerical scores for each condition were averaged over replications\nand subjects to arrive at the Mean Opinion Score (MOS) for that\ncondition."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex 1 shows a sample test form."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*10.0 Test center conditions*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Subjects_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNumbers of listeners in each test sites are shown below."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,13%,13%,13%,27%\",]\n|===\n|Rate(kbps) |2 |6 |16 |24/40/64\n|FhG |10 |10 |10 |8\n|Motorola |5 |5 |5 |5\n|Mitsubishi |3 |3 |3* |3*\n|NTT | | |24 |24\n|Sony |35 |35 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3 subjects listened to the 16/24/40/64 kbps tapes twice."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*FhG* - 10 volunteer male subjects participated in the MOS tests of\nEnglish/German version of 2,6,16 kbps, and 8 out of these 10 subjects\nalso participated in the MOS tests of 24/40/64 kbps. 5 are between 21\nand 30 years old, and 5 are between 31 and 35 years old. 6 out of the 10\nlisteners and 4 out of the 8 listeners are experienced listeners. 10\nsubjects listened two 2 kbps tapes, two 6 kbps tapes and one 16 kbps\ntape. 8 out of them also listened to one 24/40/64 kbps tape."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Motorola* - 5 volunteer subjects (4 Male, 1 Female) participated in the\nMOS tests of English/German version of 2,6,16 kbps, and 24/40/64 kbps.\nThe ages of the subjects are 29,33,37,37,40 years. Four of them are\nhigh-fidelity audio experts but all of them including the rest are na\u00efve\nat low rate speech evaluation. Each subject listened to two 2 kbps\ntapes, two 6 kbps tapes, one 16 kbps tape and one 24/40/64 kbps tape."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mitsubishi* - 3 volunteer male subjects participated in the MOS tests\nof English/German version of 2,6,16 kbps, and 24/40/64 kbps. The ages of\nthe subjects are 32,34,41 years. Each subject listened to two 2 kbps\ntapes, two 6 kbps tapes, one 16 kbps tape twice, and one 24/40/64 kbps\ntape twice."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*NTT* - 24 subjects (90% of them are female) participated in the MOS\ntests of Japanese version of 16 kbps, and 24/40/64 kbps. All the\nsubjects were hired people and younger than 30 years old. They are music\ninstruments player or music students, but, have no experience at audio\nevaluation. Each subject listened to one 16 kbps tape and one 24/40/64\nkbps tape."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Sony* - 35 subjects (15 Male, 20 Female) participated in the MOS tests\nof Japanese version of 2 and 6 kbps. 20 are hired people, and 15 are\nvolunteers from Sony. Most of the subjects are between 20-35 years old.\nAll the subjects are ordinary people and do not have any hearing\nproblems. Each subject listened to two 2.0 kbps tapes and two 6.0 kbps\ntapes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*11.0 Listener training:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 0 dB and 40 dB conditions were presented to the subjects as anchor\nconditions for the judgments of _Excellent_ and _Bad_ respectively."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*FhG* - Training sequences of each tape ware used for listener training."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Motorola* - Training sequences of each tape were used for listener\ntraining."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mitsubishi* - Training sequence of each tape were used for listener\ntraining first, then the same sequences were included in real tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*NTT* - Original signals and training sequences were used for listener\ntraining."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Sony* - Training sequences of each tape were used for listener\ntraining."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*12.0 Listening room*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"30%,30%,40%\",]\n|===\n|Site |size(m x m) |noise level\n|FhG |5x3 |audio listening room\n|Motorola |8x8 |sound shielded\n|Mitsubishi |4x8 |approx.28dB(A)\n|NTT |4x3 |sound shielded\n|Sony |8x8 |approx.30dB(A)\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*13.0 Headphones*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"25%,75%\",]\n|===\n|Site |headphone type\n|FhG |STAX Lambda pro , STAX Sigma pro\n|Motorola |STAX Lambda pro , Lambda nova signature\n|Mitsubishi |STAX Lambda pro\n|NTT |STAX Lambda pro\n|Sony |STAX Lambda pro, STAX Lambda nova classic\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*14.0 Digital audio tape deck*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"44%,56%\",]\n|===\n|Site |model name\n|FhG |Panasonic SV-3700\n|Motorola |???\n|Mitsubishi |Sony DTC-75ES\n|NTT |Sony DTC-77ES\n|Sony |Sony DTC-55ES\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*15.0 Manual Tuning of coders:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach proponent was requested to send a report on the manual tuning that\nwas performed for each of the delivered bit streams. The responses of\neach of the proponents to the email reflector are listed below. For two\nof the 16 proposers no report was received."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNTT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eNTT would like to report on the item dependent manual tuning. Detailed\ninformation is not available today. I will report it next week if it is\nneeded."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn case of NBC, manual tuning may have a considerable effect on the\nquality, since the algorithm is going to freeze and the quality\ndifference is already very small. In case of MPEG-4, however, all\nalgorithms may be still premature. So if we obtain good quality by\nmanual tuning, we will have a good possibility to attain the quality\nwith an automated process."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMOS test:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe had manual tuning for the two coders."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(1) perceptual model parameters,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(2) window selection threshold and"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(3) postfilter flag are tuned"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndepending on the input sources."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n40 kbit/s, 24 kbit/s compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe had no manual tuning for the following coders,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n16 kbit/s, 6 kbit/s, 2 kbit/s compression,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n6/24/64 kbit/s, 2/6/16 kbit/s Scalability,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n64 kbit/s, 16 kbit/s, 6 kbit/s error resilience.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_University of Hannover / Deutsche Telekom AG_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eI would like to state that for the MPEG-4 proposal from Uni Hannover /\nDeutsche Telekom AG no manual tuning was performed.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Motorola_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eThis note is to inform the group that no special manual tuning was\nperformed for any of Motorola's proposals. One item of note is that we\nhad trouble making the block switching mechanism work in our encoder so\nwe used all long blocks for everything except castanets. We used all\nshort blocks for castanets. We do not consider this manual tuning since\nit is clear that better, automatic, methods of block switching already\nexist, even within MPEG1.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Alcatel/Philips/RAI_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eFor the Alcatel/Philips/RAI coder, no manual `per-item' tuning has\ntaken place for the compression-only submissions at 64, 40 and 24 kb/s\nand the Scalability functionalities 1 and 2. The only tuning performed\nis the two pass encoding to obtain the required bit rate(s). This is a\nprocedure which can be easily automated in the future.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Philips Research Labs_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eFor the Philips MPEG-4 audio coding proposal for 16 kbit/s/channel and\na sampling frequency of 16 kHz no manual programme-item dependent\noptimisations have been used except for one parameter which influences\nthe average bit rate of our variable bit rate system. This parameter has\nbeen adjusted for each program item such that the average bit rate is\nexactly 16 kbit/s.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_MAVT (Bosch-Cselt-Matra)_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eWith reference to the request of information on the per-item tuning, we\nwish to clarify that the Bosch-Cselt-Matra candidate did not implement\nany tuning of parameters for specific items, meaning that all the\ninternal tables and parameters are always the same for any bit-rate,\neither for scalability and for multiple concurrent objects\nfunctionalities. However, due to the object oriented architecture\nemployed, the core algorithm for music signals is different from the\ncore algorithm for speech signals. The decoder is the same. \u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_University of Erlangen / FhG_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eThis is to inform the group of what type of manual tuning was performed\nfor University of Erlangen's / FhG's proposal."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOn some items a more advanced iteration strategy was used, which wasn't\nstable enough at that time to be used for all items. This is marked in\nthe following list as cit2."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n24 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nno manual tuning, except cit2 for item 4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n40 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nslightly reduced audio bandwidth for item 5, cit2 for item 4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScalable 64 - 6 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInner layer codec based on FS1016 CELP for Items 2,4,5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInner layer codec based on University of Hannover Coder for items 1,3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSlightly reduced audio bandwidth for item 5 (only 64 kbps Layer)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScalable 64 - 24 - 6 kbps"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInner layer codec based on FS1016 CELP for items 2,4,5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInner layer codec based on University of Hannover's MPEG4 coder for\nitems 1,3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSlightly reduced audio bandwidth for Items 2,3 (only 24 kbps Layer)\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Sony and Sony IPC_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eNo manual tuning has been done for any of the MPEG4 proposals from Sony\nand Sony IPC.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_NTT DoCoMo_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eNo manual tuning was done in encoding for all the MPEG-4 bitstreams by\nNTT DoCoMo.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_NEC_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eNo manual tuning was done in encoding for all the MPEG-4 bitstreams by\nNEC.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_INESC_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eFollowing your request, I must say the INESC audio coding proposal to\nthe MPEG4-Audio tests involves only one single decoder for all bit rates\n(16, 24, 40, and 64 Kbit/s/channel-although the INESC proposal will not\nbe tested for this particular bit rate) and all sampling frequencies (16\nkHz and 48 kHz, among other possibilities). Besides these two\nparameters, other parameters were used according to the test conditions,\nnamely the length of the basic audio frame and one out of four possible\nwindow switching modes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor each test condition, and according to the nature of each test item,\ntwo additional coding parameters were used minimize *minor* coding\nartifacts. As such it must be said that there was manual tuning but this\nwas for the compression functionality only, not for the error resilience\nfunctionality to which the INESC audio coding proposal will be\nre-submitted in January.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_AT&T_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eAT&T did not do any per-item tuning of its 2kbps or its 6kbps MPEG-4\nsubmissions.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Samsung_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201eSamsung did not do any per-item tuning for 64 kbps MPEG-4 submission.\nSamsung do not have MOS test this round of the test.\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Matsushita_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo report was sent. Personal communication with Mr. K. Yoshida revealed\nthat no manual tuning was used."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_JVC_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo information was available at the time of writing this report."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*16.0 Special events during decoding and test tape preparation*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDuring the tape preparation clicks were detected in the decoded signals\nof the proposal of University of Erlangen /FhG at all bit rates.\nCross-checks with the proponent figured out two reasons:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\na.) Clicks at the beginning of all decoded signals:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis effect could not be reproduced by the proponent. There was a\ndifference in the signals decoded by the proponent and decoded at\nHannover using exactly the same executables and bit streams just in four\nof the first 18 samples. In Hannover four samples always were set to the\nsame value for all test items and bit rates ( Sample 0/1: 0x0fac 0x0388;\nSample 17,18: 0x0fb6 0x081c). All other samples were exactly the same.\nTwo hours of common investigations could not solve this problem."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nb.) Clicks at the End of all decoded signals:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn inconsistent length in the AIFF-header, lead to clicks at the end of\neach signal. The AIFF \u201eCOMM chunk\u201c, which is located at the end of an\nAIFF audio file, is not recognized for this reason and played as audio\ndata instead. These \u201echunk\u201c could also be found by the proponent in the\nlocally decoded files, although they could not be heared, since probably\nthe audio player of the proponent fades out at the end of a file."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese clicks could have had a serious effect on the test results and\nwould also have been very annoying for the listeners. In order to remove\nthem, a patch program was provided by the proponent as an executable\nprogram and (for verification of the procedure) in source code. This\nprogram was used to set the 4 samples at the beginning to zero and to\nremove the AIFF \u201eCOMM chunk\u201c at the end of the file."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLater also clicks at the end of the decoded signals of Samsung were\ndetected. Although they did not show the problem at the beginning, the\nsame patch program could be used to remove the AIFF \u201eCOMM chunks\u201c at the\nend of the decoded files, which had caused the clicks."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*17.0 Proponent indentification keys:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe proponent names are given in an abbreviated form as shown in the\nfollowing table."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"54%,46%\",]\n|===\n|Proponent |Name Abbreviation\n|Alcatel/Philips/RAI |APR\n|AT&T |ATT\n|Bosch/CSELT/MATRA/MAVT |MAV\n|CCETT |CCE\n|INESC |INE\n|JVC |JVC\n|Matsushita |MAT\n|Mitsubishi |MIT\n|Motorola |MOT\n|NEC |NEC\n|NTT |NTT\n|NTT DoCoMo |DCM\n|Philips |PHI\n|Samsung |SAM\n|Sony |SON\n|U Erlangen/FhG |UER\n|U Hannover/Deutsche Telekom |UHD\n|Sony IPC |IPC\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAbbreviations for proponent names."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*18:0 Processing of Results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe scores of the listeners recorded at the individual test sites were\nsent to the tape preparation sites for the corresponding test. Here the\ninformation about the randomization orders on the test tapes was used to\nintroduce the coded names of the codecs and the item numbers. These\npre-processed data sets were sent to another processing center, where\nthe information about functionality codes, bit rates, ranking groups and\nitem types was added. The obtained data set was sent to the center which\nperformed the statistical analysis."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*19.0 Statistical analysis:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe statistical analysis was made separately for each ranking group.\nWithin each ranking group the Mean Opinion Score (MOS) and the 95%\nconfidence interval were calculated both over the item types (i.e:\nEnglish/German speech, Japanese speech and sound) and for each item\ntype. These data are summarized in tables and charts of Annexes II and\nIII respectively."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn Annex II, for each ranking group, five tables are reported: the first\none includes the global results obtained by combining the results from\neach test site, the next four tables include the results from each test\nsite separately (FHG, MIT, MOT and SONY/NTT respectively)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll these tables have a common structure: the names of the proposals\nappear in the first column and the item type at the top of each table."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBesides the results detailed for each item type, the tables also give\nthe performance for each proposal averaged over all item type. The\ncodecs are ordered starting with the codec having the best MOS at the\ntop of the table and going down in the table in order of decreasing MOS.\nThe tables also show, in the far right columns, the result of the Tukey\ntest [1]for the significance of differences between means."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis test has been done on the averages over the item type."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach letter identifies a group of codecs that are not Statistically\nSignificantly Different (SSD) one to eachother."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor example in the first table of ranking group \u201c6 kbps compression,\n....\u201d, MNR2-40 is SSD to all the other codecs. The same applies to\nMNR2-30. Codec IPC59 is not SSD to IPC00, but it is SSD to MNR2-20. This\nmeans that nothing can be concluded, based on the statistical analysis,\nabout the the relative performance of IPC59 and IPC00."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the same way it comes out that MNR2-20 and RF5 are not SSD, MNR2-20\nand ATT75 are SSD, and RF5 and ATT75 are not SSD."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor those ranking groups that include only the sound item type, Annex II\nalso provides a table with the MOS detailed for each item."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn Annex III, for each ranking group ten graphs are provided. The first\ntwo graphs show the global MOS and CI (calculated over the laboratories)\nfor each codec belonging to the ranking group. In the first graph the\nresults are detailed for each item type, while in the second graph only\nthe averages over the item types are reported. Similar pairs of graphs\nare given for each test site."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn analysis of variance (ANOVA) was performed both on the overall\nresults and systematically on each ranking group. The main goal of the\nfirst ANOVA was to check for unwanted effects due the test. The\nparameters taken into account in this case have been the codec, the item\ntype and the test site."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe main goal of the second ANOVA was to check for unwanted dependency\non the stimuli presentation order. The parameters taken into account\nwere the codec, the item type, the order and the repetition."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*20.0: The results:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe ANOVA on the whole results shows that, within each ranking group,\nthe test site is a significant source of variation. Nevertheless, in\nsome ranking group, like \u201c2 kbps compression..\u201d and \u201c16 kbps\ncompression...\u201d, the factor \u201ctest site\u201d is significant, but its\nsignificance level is very low with respect to the significance level of\nthe factor \u201ccodec\u201d."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn most of the other cases, the significance level of the factor \u201ctest\nsite\u201d was quite high. This result is not surprising, taken into account\nthe difference among test sites: different test material, different\nnumber of listeners, etc."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTherefore, before combining the results, a more detailed analysis of the\ndata must be done."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe graphs in Annex III show that, within each ranking group, MOSs of\ndifferent test sites have a same trend. Sometimes a systematic deviation\nof the MOSs can be observed for a particular test site, in other cases\nthe distances between the MOSs are reduced."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn these conditions, the MOS avaraged over all the laboratories cannot\nbe considered as an absolute performance measure of the codecs under\ntest, even because the weight of each laboratory is completely\ndifferent, considering the number of listeners used. Nevertheless,\ntaking into account that the goal of this experiment was mainly to rank\nthe proposal, it makes sense to consider for each ranking group the\nglobal MOSs."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe ANOVA also showed that the factor \u201citem type\u201d is generally a\nsignificant source of variation, except for ranking group \u201c2 kbps\ncompression ...\u201d and \u201c16 kbps compression\u201d."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPossible improvements:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- just one test site to increase the precision of the statistical\nestimates"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif this is not possible:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- increase the number of subjects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- use the same number of subjects per test site"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- find a useful representation of the data (similar to the Q-value)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- find a criterium to reject listeners or test sites"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*21.0: Specific comments about test results:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 2kbps test results comments:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition to the combined table, individual ranking tables are shown\nfor the individual items types. This has been done in order to show the\ndifferent ranking orders relevant to different item types."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 6 kbps test results comments:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition to the combined table, individual ranking tables are shown\nfor the individual items types. This has been done in order to show the\ndifferent ranking orders relevant to different item types. The different\nranking could depend on the variability of the number of subjects used\nacross different labs for the various items, as well as to item\ndependent codec performance. The variability across labs and item types\nis also reflected in the ANOVA."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 16 kbps test results comments:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition to the combined table, individual ranking tables are shown\nfor the individual items types. This has been done in order to show the\ndifferent ranking orders relevant to different item types. The different\nranking could depend on the variability of the number of subjects used\nacross different labs for the various items, as well as to item\ndependent codec performance. The variability across labs and item types\nis also reflected in the ANOVA."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 24 kbps test results comments:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition to the combined table, individual ranking tables are shown\nfor the individual items types. This has been done in order to show the\ndifferent ranking orders relevant to different item types. The different\nranking could depend on the variability of the number of subjects used\nacross different labs for the various items, as well as to item\ndependent codec performance. The variability across labs and item types\nis also reflected in the ANOVA."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*( 40 kbps test results comments:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition to the combined table, individual ranking tables are shown\nfor the individual items types. This has been done in order to show the\ndifferent ranking orders relevant to different item types. The different\nranking could depend on the variability of the number of subjects used\nacross different labs for the various items, as well as to item\ndependent codec performance. The variability across labs and item types\nis also reflected in the ANOVA."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 6 kbps - Reference signals & MNRU were not available. This data could\nbe calculated from currently unused values in the data base. Comparison\nto 6kbits compression is only is not possible, since castanets were not\nincluded in the 6kbps compression only test. For UER only scalability 1\nwas tested at 6kbits, since the decoder output was exactly identical to\nthe output of the 6 kbps decoder at scalability 2."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex I: Example Test Form*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Test site : Session No. : Tape No. :*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDate : Subject name:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 5-point opinion scale"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"60%,40%\",]\n|===\n|Opinion |Score\n|Excellent |5\n|Good |4\n|Fair |3\n|Poor |2\n|Bad |1\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,15%,17%,16%,17%,17%\",]\n|===\n|Sequence number |Opinion score |Sequence number |Opinion score\n|Sequence number |Opinion score"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1 | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2 | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3 | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4 | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5 | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|... | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= MPEG Audio Subgroup Meeting Report\npgs\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11/N1145*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Ad-Hoc Group to Conduct the of MPEG-2 Audio NBC Reference Model 3\nCore Experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To conduct the of NBC RM3 (WG11/N1132) core experiment\nmonophonic and stereophonic listening tests according to (N1150), to\nperform the analysis of the test results, and to prepare the report of\nthe results for the March 1996 MPEG meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings:* One meeting will be held 22-24 March 1996 in Florence, Italy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOther business will be conducted by E-mail, FAX or Telephone."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* P.G. Schreiner III"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"22%,11%,26%,41%\",]\n|===\n|Name |Country |Affiliation |e-mail address"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Akagiri, K. |J |Sony |ken@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Bont F. d. |NL |Philips CE |debontf@ce.philips.nl"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Bosi, M. |USA |Dolby Laboratories |mab@dolby.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Brandenburg, K. |DE |FhG - IIS |bdg@iis.fhg.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Coleman, M. |USA |FiveBats |mc@fivebats.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Diamond, Scott |USA |Tektronix |scott.k.diamond@tek.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dietz, M. |DE |FhG-IIS |diz@iis.fhg.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dimino, G. |I |RAI |dimino@crrai.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Feige, F. |DE |Deutsche Telekom AG |feige@audio.fz.telekom.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Fielder, L. |USA |Dolby Labs |ldf@dolby.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Fuchs, H. |DE |Univ. Hannover |fuchs@tnt.uni-hannover.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Fukuchi, H. |J |Nippon Steel Corp |fukuchi@elelab.nsc.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Grill, B. |DE |Univ. of Erlangen |grl@lte.e-technik.uni-erlangen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Hatanaka, M. |J |Sony |hatanaka@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Hotani, S. |J |NTTDoCoMo |hotani@mlab.nttdocomo.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Iwadare, M. |J |NEC |sc29a@dsp.cl.nec.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Johnston, J. |USA |AT&T |jj@research.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kaneko, I. |J |GCL |itaru-k@gctech.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kerkhof, L. v. d. |NL |Philips CE |kerkhofl@ce.philips.nl"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kim, S-W. |KR |Samsung |swkim@dspsun.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kim, Y.B. |KR |Samsung |kimyb@dspsun.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Koike, T. |J |Sony |koike@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Laczko, F. |USA |TI |flaczko@ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Lueck, C. |USA |TI |lueck@hc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mainard, L |FR |CCETT |lmainard@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Maruyama, T. |J |JVC |toshi@krhm.jvc-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Matsumoto, J. |J |Sony |jun@pcrd.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Meares, D. J. |UK |BBC |david.meares@rd.bbc.co.uk"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Moriya, T. |J |NTT |moriya@splab.hil.ntt.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Nishiguchi, M. |J |Sony |nishi@pcrd.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Noll, Peter |DE |Tech. Univ. Berlin |noll@ftsu00.ee.tu-berlin.d400.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Oikawa, J. |J |Sony |oikawa@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Oomen, W. |NL |Philips |oomena@prl.philips.nl"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Paley, Mark |USA |TI |mpaley@ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Pan, D. |USA |Motorola |pan@ukraine.corp.mot.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Parladori, G. |I |Alcatel Telettra |gparladori@tlt.alcatel.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Quackenbush, S. |USA |AT&T |srq@research.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Rault, J-B. |FR |CCETT |jbrault@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Rowlands, J. |USA |TI |rowlands@ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Schnurr, O. |USA |Motorola |schnurr@ukraine.corp.mot.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Schreiner, P. G. |USA |Scientific Atlanta |pgs@sciatl.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Shen, Janice |USA |Rockwell |tjs@risc.rockwell.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Silbiger, H. |USA |AT&T |hsilbiger@attmail.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Spille, J. |DE |Thomson Multimedia |spillej@tcernd1.hanover.tce.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Stoll, G. |DE |IRT |stoll@irt.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Schwalbe, R. |DE |Deutsche Telekom AG |schwalbe@audio.fz.telekom.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Suzuki, H. |J |JVC |suzukihr@KRHM.JVC-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Suzuki, M. |J |Pioneer |masa@crdl.pioneer.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Tan, Ah-Peng |J |Asia Matsushita Electric |aptan@avirc.ams.com.sg"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Thom, D. |USA |Mitsubishi |dthom@tao.mea.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|V\u00e4\u00e4n\u00e4nen, M. |FIN |Nokia Res. Center |mauri.vaananen@research.nokia.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Walker, Karen |USA |TI |klw2@msg.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Watanabe, K. |J |NHK |watanabk@strl.nhk.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Yin, Lin |FIN |Nokia |lin.yin@research.nokia.fi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Leonardo Chiarilione(correspondence copy) |I |CSELT\n|leonardo.chiariglione@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Contin, Laura Test Group |I |CSELT |laura.contin@cselt.stet.it\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nDavid J. Meares\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11**N1146**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/xxx"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Audio subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* *Ad Hoc Group on MPEG-4 Verification Models*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMandate: To continue the evaluation of the results of the MPEG-4 audio\nproposal tests, the evaluation of the proposal technical descriptions,\nand the development of the detailed VMs. This task includes the\ncollection of more detailed technical descriptions for nine of the\nproposals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* B. Edler"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings:* None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Communications:* E-mail and fax.."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Membership:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,9%,28%,43%\",]\n|===\n|Name |Country |Affiliation |e-mail address"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Akagiri, K. |J |Sony |ken@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Bont F.d. |NL |Philips CE |debontf@ce.philips.nl"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Bosi, M. |USA |Dolby Laboratories |mab@dolby.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Brandenburg, K. |DE |FhG - IIS |bdg@iis.fhg.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Contin, Laura |I |CSELT |laura.contin@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Edler, B. |DE |University Hannover |edler@tnt.uni-hannover.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Ekudden, E. |S |Ericsson |erik.ekudden@era-t.ericsson.se"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Ferreira, A. |PT |INESC |ajf@inescn.pt"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Grill, B. |DE |Univ. of Erlangen |grl@lte.e-technik.uni-erlangen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Hong, J.W. |KR |ETRI |jwhong@audio.etri.re.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Hotani, S. |J |NTTDoCoMo |hotani@mlab.nttdocomo.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Iwadare, M. |J |NEC |sc29a@dsp.cl.nec.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kim, S-W. |KR |Samsung |swkim@dspsun.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Koike, T. |J |Sony |koike@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Mainard, L |Fr |CCETT |lmainard@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Matsumoto, J. |J |Sony |jun@pcrd.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miki, S. |J |NTT |miki@splab.hil.ntt.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miyasaka, S. |J |Matsushita |miyasaka@ arl.drl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Moriya, T. |J |NTT |moriya@splab.hil.ntt.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Muller, J-M. |DE |Bosch Telekom |jmm@bk.bosch.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Navarro W. |Fr |Matra Communication |wnavarro@matra-com.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Nishiguchi, M. |J |Sony |nishi@pcrd.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Oomen, W. |NL |Philips |oomena@prl.philips.nl"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Parladori, G. |I |Alcatel Telettra |gparladori@tlt.alcatel.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Schreiner, P. G. |USA |Scientific Atlanta |pgs@sciatl.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Schwalbe, R. |DE |Deutsche Telekom AG |schwalbe@audio.fz.telekom.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Sereno, D. |I |CSELT |daniele.sereno@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Suzuki, M. |J |Pioneer |masa@crdl.pioneer.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Tan, Ah-Peng |RS |Asia Matsushita Electric |aptan@avirc.ams.com.sg"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Thom, D. |USA |Mitsubishi |dthom@msm.mea.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|V\u00e4\u00e4n\u00e4nen, M. |FIN |Nokia Res. Center |mauri.vaananen@research.nokia.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Watanabe, K. |J |NHK |watanabk@strl.nhk.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Yin, Lin |FIN |Nokia |lin.yin@research.nokia.fi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Yoshida, K. |J |Matsushita |Kyoshida@telecom.mci.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Fuchs, H |DE |University of Hannover |fuchs@tnt.uni-hannover.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Norimatsz. T |J |Matsushita |norimat2@arl.drl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Suzuki, H |J |JVC |suzukihr@KRHM.JVC-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Leonardo Chiarilione(correspondence copy) |I |CSELT\n|leonardo.chiariglione@cselt.stet.it\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= MPEG/Audio Dallas Meeting Participant List (November 1995)\nportable\n1996-01-23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATIO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11N1147*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Convenor*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,85%\",]\n|===\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on MPEG-2 Audio NBC (13818-7) Reference Model 3\n(RM3) Specification and Working Draft Development"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"22%,78%\",]\n|===\n|Mandate: |To progress the work on the preparation of the first Working\nDraft for MPEG-2 NBC (13818-7) Audio Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chair |Marina Bosi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Vice-Chair |Martin Dietz"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Meetings: |None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Communications: |E-mail"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Membership: |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName |Country |Affiliation |e-mail address | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,12%,28%,40%\",]\n|===\n|Akagiri, K. |J |Sony |ken@av.crl.sony.co.jp\n|Bont F.d. |NL |Philips CE |debontf@ce.philips.nl\n|Bosi, M. |USA |Dolby Laboratories |mab@dolby.com\n|Brandenburg, K. |DE |FhG - IIS |bdg@iis.fhg.de\n|Dietz, M. |DE |FhG-IIS |diz@iis.fhg.de\n|Hong, J.W. |KR |ETRI |jwhong@audio.etri.re.kr\n|Hotani, S. |J |NTTDoCoMo |hotani@mlab.nttdocomo.co.jp\n|Iwadare, M. |J |NEC |sc29a@dsp.cl.nec.co.jp\n|Johnston, J. |USA |AT&T |jj@research.att.com\n|Kim, S-W. |KR |Samsung |swkim@dspsun.sait.samsung.co.kr\n|Mainard, L |Fr |CCETT |lmainard@ccett.fr\n|Matsumoto, J. |J |Sony |jun@pcrd.sony.co.jp\n|Meares, D. J. |UK |BBC |david.meares@rd.bbc.co.uk\n|Miki, S. |J |NTT |miki@splab.hil.ntt.jp\n|Miyasaka, S. |J |Matsushita |miyasaka@ arl.drl.mei.co.jp\n|Moriya, T. |J |NTT |moriya@splab.hil.ntt.jp\n|Muller, J-M. |DE |Bosch Telekom |jmm@bk.bosch.de\n|Navarro W. |Fr |Matra Communication |wnavarro@matra-com.fr\n|Nishiguchi, M. |J |Sony |nishi@pcrd.sony.co.jp\n|Oikawa, J |J |Sony |oikawa@av.crl.sony.co.jp\n|Oomen, W. |NL |Philips |oomena@prl.philips.nl\n|Pan, D. |USA |Motorola |pan@ukraine.corp.mot.com\n|Parladori, G. |I |Alcatel Telettra |gparladori@tlt.alcatel.it\n|Quackenbush, S. |USA |AT&T |srq@research.att.com\n|Schreiner, P. G. |USA |Scientific Atlanta |pgs@sciatl.com\n|Schwalbe, R. |DE |Deutsche Telekom AG |schwalbe@audio.fz.telekom.de\n|Sereno, D. |I |CSELT |daniele.sereno@cselt.stet.it\n|Stoll, G. |DE |IRT |stoll@irt.de\n|Suzuki, M. |J |Pioneer |masa@crdl.pioneer.co.jp\n|Tan, Ah-Peng |RS |Asia Matsushita Electric |aptan@avirc.ams.com.sg\n|Thom, D. |USA |Mitsubishi |dthom@msm.mea.com\n|V\u00e4\u00e4n\u00e4nen, M. |FIN |Nokia Res. Center |mauri.vaananen@research.nokia.com\n|Watanabe, K. |J |NHK |watanabk@strl.nhk.or.jp\n|Yin, Lin |FIN |Nokia |lin.yin@research.nokia.fi\n|Yoshida, K. |J |Matsushita |Kyoshida@telecom.mci.mei.co.jp\n|Fuchs, H |DE |University of Hannover |fuchs@tnt.uni-hannover.de\n|Kerkhof, L |NL |Philips |kerkhofl@ce.philips.nl\n|Chiariglione, L |I |CSELT |leonardo.chiariglione@cselt.stet.it\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nDavid J. Meares\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11**N1148**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/xxx"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Audio subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* *Ad Hoc Group on finalising* *revisions to IS 13818-3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMandate:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* To review editorial changes to IS 13818-3 contained in WG11/N1152\n* To ensure that details relating to the use of prediction with\ndynamic\u00a0crosstalk, and LFE syntax are correctly assimilated\n* To prepare and approve an informative Annex which provides information\nhow to use MPEG-2 BC multichannel coding or the MPEG-2 NBC mode together\nwith 2-channel Layer II, e.g. simulcast.\n* To present to the March 1996 meeting of MPEG a final version of the\nrevised IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* G. Stoll (E-Mail: stoll@irt.de)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings:* None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Communications:* E-mail and fax. An ad-hoc group meeting immediately\nprior to the March 1996 MPEG meeting may be called."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Membership:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"21%,11%,27%,41%\",]\n|===\n|M. Dietz |DE |FhG-IIS |diz@iis.fhg.de\n|H. Fukuchi |J |Nippon Steel Corp. |fukuchi@elelab.nsc.co.jp\n|B. Grill |DE |Univ. of Erlangen |grl@lte.e-technik.uni-erlangen.de\n|S-W. Kim |KR |Samsung |swkim@dspsun.sait.samsung.co.kr\n|D. J. Meares |UK |BBC |david.meares@rd.bbc.co.uk\n|J-B. Rault |FR |CCETT |jbrault@ccett.fr\n|J. Spille |DE |DTB |spillej@tcernd1.hanover.tce.de\n|G. Parladori |I |Alcatel |gparladori@tlt.alcatel.it\n|G. Dimino |I |RAI |dimino@crrai.it\n|L. van de Kerkhof |NL |Philips |kerkhofl@ce.philips.nl\n|K. Walker |USA |TI |klw2@msg.ti.com\n|H. Fuchs |DE |Univ. Hannover |fuchs@tnt.uni-hannover.de\n|S. Forshay |USA |Dolby |sef@dolby.com\n|M. Bosi |USA |Dolby |mab@dolby.com\n|L. Fielder |USA |Dolby |ldf@dolby.com\n|Mainard, L |Fr |CCETT |lmainard@ccett.fr\n|Oomen, W. |NL |Philips |oomena@prl.philips.nl\n|Schwalbe, R. |DE |Deutsche Telekom AG |schwalbe@audio.fz.telekom.de\n|Hong, J.W. |KR |ETRI |jwhong@audio.etri.re.kr\n|Tan, Ah-Peng |RS |Asia Matsushita Electric |aptan@avirc.ams.com.sg\n|Yin, Lin |FIN |Nokia |lin.yin@research.nokia.fi\n|cc: L. Chiariglione |I |CSELT |Leonardo.Chiariglione@cselt.stet.it\n|cc: P. Schreiner |USA |Scientific Atlanta |pgs@sciatl.com\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= Assessing the quality of MPEG 2 Backwards Compatible Codecs\nDavid J. Meares\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11/*N1149*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary, 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Audio subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStatus: Draft"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title: Adhoc Group on the SNHC/Audio*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMandate: To disseminate SNHC Notice of a Call for Proposal (CFP), to\ngenerate the interest for contributions to the first CFP and to\nco-ordinate discussion about the first experiments among the experts.\nJoint with SNHC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings:* No meeting will be held."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBusiness will be conducted by E-mail."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman: I. Kaneko*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,12%,28%,40%\",]\n|===\n|Name |Country |Affiliation |e-mail address"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Akagiri, K. |J |Sony |ken@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Bosi, M. |USA |Dolby Laboratories |mab@dolby.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Brandenburg, K. |DE |FhG - IIS |bdg@iis.fhg.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dimino, G. |I |RAI |dimino@crrai.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Edler, B. |DE |University Hannover |edler@tnt.uni-hannover.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Fukuchi,H |J |Nippon Steel Corporation |fukuchi@elelab.nsc.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Grill, B. |DE |Univ. of Erlangen |grl@lte.e-technik.uni-erlangen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Hong, J.W. |KR |ETRI |jwhong@audio.etri.re.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Hotani, S. |J |NTTDoCoMo |hotani@mlab.nttdocomo.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kaneko, I. |J |GCL |itaru-k@gctech.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kim, S-W. |KR |Samsung |swkim@dspsun.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Koike, T. |J |Sony |koike@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Laczko, F. |US |TI |flaczko@ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Lueck, C. |USA |TI |lueck@hc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Maruyama, T. |J |JVC |toshi@krhm.jvc-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Matsumoto, J. |J |Sony |jun@pcrd.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miki, S. |J |NTT |miki@splab.hil.ntt.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Miyasaka, S. |J |Matsushita |miyasaka@ arl.drl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Moriya, T. |J |NTT |moriya@splab.hil.ntt.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Nishiguchi,M. |J |Sony |nishi@pcrd.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Parladori, G. |I |Alcatel |gparladori@ tlt.alcatel.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Schnurr, O. |US |Motorola |schnur@ukraine.corp.mot.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Silbiger, H. |US |AT&T |hsilbiger@exit109.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Tan, Ah-Peng |RS |Asia Matsushita Electric |aptan@avirc.ams.com.sg"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|V\u00e4\u00e4n\u00e4nen, M. |FIN |Nokia Res. Center |mauri.vaananen@research.nokia.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Watanabe, K. |J |NHK |watanabk@strl.nhk.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Yin, Lin |FIN |Nokia |lin.yin@research.nokia.fi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Yoshida, K. |J |Matsushita |Kyoshida@telecom.mci.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Rawlands, J. |US |TI |rawlands@pocomoco.hc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Norimatsu, T. |J |Matsushita |norima2@ari.drl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Abe, N. |J |NTT |ave@nttspch.hil.ntt.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Doenges, P. |US |Evans & Sutherland |pdoenges@es.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Reader, C. |US |Samsung |creader@ssi.samsung.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Luthra, A. |US |GI |ALUTHRA@GI.COM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kim, Y.H. |Korea |ETRI |yhkim@video.etri.re.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Homma, T. |J |Toppan |homma@itl.toppan.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Perun, P. |Portugal |IST |fp@amalia.ist.ute.pt"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Rossignal, J |US |IBM |JAREK@WATSON.IBM.COM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Powell, B. |US |Microsoft |billpow@microsoft.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Colin Campbell |US |Microsoft |colinc@microsoft.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Takikawa, K |J |NTT Software |takikawa@yh.ntts.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Fujii, S |J |Yamaha |fujii@edc3.yamaha.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kameyama, W |J |GCL |wak@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kouno, S. |J |ASCII |shin-k@ascii.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Yamashita, R |J |ASCII |rick-y@ascii.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Shen, J |US |Rockwell |tjs@risc.rockwell.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Takamizawa, Y. |J |NEC |takami@dsp.cl.nec.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Hattori, Y |J |ASCII |yasu-h@ascii.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Hasegawa, K |J |NiftyServe |pbi00312@niftyserve.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Kubota |J |NiftyServe |sci00391@niftyserve.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Noll, P. |DE |Tech. Univ. of Berlin |noll@ftsu00.ee.tu-berlin.d400.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chiraglione, L. (copy correspondence) |I |CSELT\n|leonardo.chiariglione@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANIZATION FOR STANDARDIZATION\nS. R. Quackenbush\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11/N1150*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMunich, January 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Audio Subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: MPEG-2 NBC RM Audio Test Plan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStatus: Approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthor: Schuyler Quackenbush, AT&T Bell Laboratories"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHendrik Fuchs, University of Hannover"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. MPEG-2 NBC RM Core Experiment Tests*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis document describes the work plan for the next phase of the core\nexperiments for the optimization of the NBC reference model. The current\nRM block diagram is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[pic]*FIG. 1 -* MPEG-2 NBC RM3 Block Diagram (Doc WG11/N1132)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.1. Description of RM3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBased on prior listening tests reported in document WG11/1135, RM3 has\nbeen derived from RM2 by the addition of these elements:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Improved features from FHG-QC described in WG11/N1135\n* NBC target syntax, described in WG11/N1132\n* DOL-TF adaptive window shaping described in WG11/1135\n* AT&T lossless coding described in WG11/N1132, MPEG95/154 and\nMPEG96/558\n* NEC lossless coding described in WG11/N1132 and MPEG96/658"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition, RM3 will be extended using well-known techniques to code\nstereo signals (see 1.5)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.2. Core Experiments*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe next stage of core experiment tests will be to conduct subjective\nlistening tests to evaluate the following five systems"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. RM2 (FHG-D1), as a reference to the previous test results\n. RM3, as described above.\n. DOF_T1, using advanced block switching as in DOF_TF, but modified to\nbe based on RM3.\n. SON_P1, using pre-processing as in SON_PP, but modified to be based on\nRM3.\n. ATT_NS, time domain noise shaping as described in MPEG96/560, based on\nRM2 or RM3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.3. Additional Experiments*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTI will conduct a subjective listening pre-screening experiment relative\nto RM2 on trellis coded quantization based on RM2. GCL will conduct a\nnumerical compression pre-screening experiment relative to RM3 on\nnoiseless coding based on RM3. Subjective pre-screening evaluations will\nbe conducted by the proponents according to WG11/N1034; specifically\nAnnex 2 for listener response sheets, Annex 3 for listener instructions\nand listener training and Annex 5 for the procedure for the\npre-screening tests. It is necessary that the recommended response sheet\nbe used and essential that the listeners be given a training session and\nthat listeners receive verbal instructions prior to both the training\nsession and the listening test. The results will be documented by the\nproponents and presented at the next MPEG meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.4. Monophonic Listening Tests*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe three proposals plus RM2 and RM3 (see 1.2) will code mono materials\nat a rate of 64 kbps. The sampling rate of these materials is 48 kHz.\nThe items to be used are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,30%,27%,14%\",]\n|===\n|Program item code |signal description |source |filename\n|1 |Harpsichord |SQAM |tk1\n|2 |Castanets |SQAM |tk2\n|3 |German Male Speech |SQAM |tk3\n|4 |Bagpipes |BBC |tk4\n|5 |Glockenspiel |SQAM |tk5\n|6 |Pitch Pipe |MPEG 3/2 (Dolby) |tk6\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that item 3, German Male Speech, has replaced the German Female\nSpeech item that was used in the previous tests. H. Fuchs, Univ. of\nHannover, will provide this test item. This material should be edited\nsuch that it is approximately 15 seconds in length and contains no more\nthan 1 percent zero samples. All of this material will be available on\nthe Univ. of Hannover FTP site by February 8th"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the mono listening tests there will be a total of 5 * 6 = 30 trials.\nThe total duration of the test, allocating two minutes per trial, is 60\nminutes and will be divided into three sessions of 10 trials each. The\npresentation format of the tapes and the test methodology is described\nin. WG11/N1034. The tape generation will be done by H. Fuchs, Univ. of\nHannover, and may use the methods described in MPEG96/559. The data\nanalysis will be done as in WG11/1135."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nListening will be done using Stax Lambda Pro headphones or the\nequivalent Stax headphones listed in WG11/1135, Section 7. The following\nsites will participate in the mono listening tests: AT&T, Dolby, FhG,\nGCL, NHK, Philips, and Sony. Listening tests will be conducted according\nto WG11/N1034; specifically Annex 2 for listener response sheets and\nAnnex 3 for listener instructions and listener training. It is necessary\nthat the recommended response sheet be used and essential that the\nlisteners be given a training session and that listeners receive verbal\ninstructions prior to both the training session and the listening test."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.5. Stereophonic Listening Tests*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe first experiment to test the performance of NBC RM in coding stereo\nmaterials will evaluate two systems. They are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* RM3 operating as a dual-mono coder with no joint bit allocation\nbetween channels.\n* RM3 extended to incorporate M/S stereo techniques (as described in\nWG11/N1132) with joint bit allocation between channels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese systems will code stereo materials at a rate of 128 kbps."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe materials to be used for the stereo tests are sampled at 48 kHz and\nare:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"9%,40%,30%,12%,9%\",]\n|===\n|item |signal description |source |filename |notes\n|1 |Dorita |Lou Reed, \u201cMagic & Loss\u201d |S1 |+\n|2 |We shall be happy |Ry Cooder \u201cJazz\u201d |S2 |+\n|3 |Castanets |SQAM |S3 |*\n|4 |Harpichord |SQAM |S4 |*\n|5 |Pitch pipe |MPEG 3/2 tests (Dolby) |S5 |*\n| |(front left and front right channels) | | |\n|6 |Glockenspiel |SQAM |S6 |*\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* H. Fuchs, Univ. Hannover, to prepare and copy to the Univ. of Hannover\nFTP site by 8 Feb."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n+ S. Quackenbush, AT&T to convert to 48 kHz sampling frequency and copy\nto FTP site by 8 Feb."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis material should be edited such that it is approximately 15 seconds\nin length and contains no more than 1 percent zero samples."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the stereo listening tests there will be a total of 2 * 6 = 12\ntrials. The total duration of the test, allocating two minutes per\ntrial, is 24 minutes and will be one session. Presentation format, test\nmethodology, tape generation and data analysis will be as in the mono\nlistening test, described in 1.4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe stereo tests will have a separate training session composed of 2 * 6\n= 12 trials composed of the same stimuli and coders as in the listening\ntest. However the presentation format of each trial will be: item\nannouncement, reference, 2-second pause, coded, 10-second pause, denoted\nas \u201cR C.\u201d The coder position is not hidden; this permits the listeners\nto learn the range of impairments in the coded signals. There is no\nrepetition within the trial. The training session will be preceded by\nthe announcement \u201cstart of stereo training session.\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe mono and stereo listening tests will be treated as two separate\nexperiments having separate randomization and data analysis. However\nthey will be put on a single 120-minute DAT, beginning with the mono\ntest sessions, followed by the stereo training session and lastly the\nstereo test session."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe stereo subjective listening tests will be conducted twice, once\nusing headphones and once using loudspeakers. As in the mono tests the\nheadphones will be Stax Lambda Pro or equivalent. However, as there are\nno BS1116 compliant listening rooms available, nor are there even\nsimilar listening rooms at the test sites, the loudspeaker tests will be\nrun in whatever rooms are available, assuming reasonable acoustic\ncontrol. Details of room size and acoustic treatment are to be provided\nby all test centers. Annex I presents details on recommended listening\nroom configuration."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following sites will participate in the stereo listening tests using\nheadphones: Dolby, AT&T, FhG GCL, NHK, Phillips and Sony. A subset of\nthese sites, Dolby, AT&T, FhG, GCL, and Sony will participate in the\nstereo loudspeaker listening tests. Listening tests will be conducted\naccording to WG11/N1034; specifically Annex 2 for listener response\nsheets and Annex 3 for listener instructions and listener training. It\nis necessary that the recommended response sheet be used and essential\nthat the listeners be given a training session and that listeners\nreceive verbal instructions prior to both the training session and the\nlistening test. The training for listening using speakers must be done\nfirst as group training followed by individual training. In group\ntraining listening should be stopped after each trial and the nature of\nthe coded impairments discussed amongst the group."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.6. MPEG-2 NBC RM Core Experiments Work Plan*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"30%,70%\",]\n|===\n|20 January |BBC to provide Excel listener response template to test\ncenters"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Before 24 January |BBC to provide Excel spreadsheet example to TI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8 February |Mono and Stereo materials available on Univ. Hannover FTP\nsite"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|19 February 1996 |AT&T to provide tape generation scripts and\nannouncement files to H. Fuchs, Univ. of Hannover."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3 March 1996 24:00 hrs CET (23:00 hrs GMT) |Bitstreams and decoders to\nUniv. of Hannover FTP site."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4-5 March 1996 24:00 hrs CET |Bitstreams decoded, master listening tape\ncreated and tapes duplicated and sent to listening sites by H. Fuchs,\nUniv. of Hannover"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5 March 1996 24:00 hrs CST |Data from codec developers to TI. Required\ninformation is: codec item by item optimization detailed descriptions of\ntest rooms and their acoustic treatment, including loudspeakers details\nroom dimensions room treatment acoustic measurements, if any room layout"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6 March 1996 |Hannover to provide system identity test randomization\ninformation to TI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|11-12 March 1996 |Test centers conduct listening tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|13 March 1996 09.00 hrs CST (15:00 hrs GMT) |Test data from test sites\n(AT&T, Dolby, FhG, GCL, NHK, Philips, Sony) to TI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|18 March 1996 |Results and draft test report by TI posted on NBC\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|22 March 1996 |Ad-hoc group meeting\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBy 19 February listening sites must provide H. Fuchs, Univ. of Hannover\n(in person or see email address below) with Federal Express address\ndetails for tape posting. Contacts for listening tests at AT&T, Dolby,\nFhG, GCL, NHK, Philips, Sony are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"31%,27%,42%\",]\n|===\n|Name |Affiliation |e-mail address\n|Bosi, M. |Dolby Laboratories |mab@dolby.com\n|Hilpert, J. |FhG - IIS |hlp@iis.fhg.de\n|Kaneko, I. |GCL |itaru-k@gctech.co.jp\n|Oomen, W. |Philips |oomena@prl.philips.nl\n|Quackenbush, S. |AT&T |srq@research.att.com\n|Watanabe, K. |NHK |watanabk@strl.nhk.or.jp\n|Oikawa, Y |Sony |oikawa@av.crl.sony.co.jp\n|Fuchs, H. |University of Hannover |fuchs@tnt.uni-hannover.de\n|Lueck, C. |TI |lueck@hc.ti.com\n|Meares, D. J. |BBC |david.meares@rd.bbc.co.uk\n|Schreiner, P. G. |Scientific Atlanta |pgs@sciatl.com\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex I"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll references are to ITU-R Recommendation BS1116."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. Speakers and Listening Environment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1.1 Reference Monitor Loudspeakers (Ref 8.5)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"64%,36%\",]\n|===\n|Reference monitor loudspeaker (Ref.: 7.2) |preferred configuration\n| |\n|Amplitude versus frequency response |40 Hz..16 kHz \u00b1 4 dB\n|Difference from main axis |3 dB (\u00b110 degree)\n| |4 dB (\u00b130 degree)\n|Linearity |3% for 40 Hz to 250 Hz\n| |1% for 250 to 16 kHz\n|Transient Fidelity |ts<5/f\n|Time delay differences between the channels |<100 ms\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1.2 Reference listening room (Ref. 8.2)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"53%,47%\",]\n|===\n|Listening room |preferred configuration\n|Room size |20..60 m2\n|Room proportions |l:length, w:width, h:height\n| |1.1 w/h ( l/h ( 4.5 w/h - 4\n|Reverberation time |List of room materials\n|Operational room response time |List of room materials\n|Background noise |Less than 30 dBA\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1.3 Reference Speaker layout (Ref. 8.5)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"58%,42%\",]\n|===\n|speaker layout |preferred configuration\n|height |1.2m\n|Minimum distance from the wall |1m\n|Base width (B |2 to 3 m\n|Listening distance |B to 1.7*B\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1.4 Listening position (Ref. 8.5.3.3)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSpeaker arrangement and listening position as Figs. 1 and 2 (Reference\nlistening position)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nListening Radius < 0.7 m around reference point."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2. Stereo Tests*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.1 Two channel Stereophonic system's attribute.(Ref. 5.2)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nListed below are attributes specific to stereophonic evaluations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Basic audio quality\n* Stereophonic image quality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBasis of assessment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe subjects should be asked to give a single overall assessment of the\naudio stimulus based on all factors including stereo imaging."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3. Miscellaneous*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.1 Size of listening panel (Ref. 3.3)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAlthough BS1116 recommends 20 listeners per test, a minimum of 5\nlisteners per test is acceptable for these initial tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.2 Test Method (Ref. 4)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuditoin of pre-recorded sequence (Although BS1116 recommends active\nswitching)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tests will be conducted for one listener at a time."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.3 Reference listening level (Ref. 8.4)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAdjustment of gain is allowed in the training period only. If the\nsubjects do adjust the gain, this fact should be noted in the test\nresults."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure 1. Listening Room Layout*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure 2. Speaker Height*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= Accredited Standards Committee\nportable\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11* *N1151*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Audio Subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Preliminary *MPEG-2 Audio NBC (13818-7) Working Draft*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Status: Approved*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthor: Marina Bosi, Dolby Laboratories"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.0 Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis document describes the preliminary organization and section\nassignements for the MPEG-2 Audio non-backwards compatible (NBC) Working\nDraft (WD), 13818-7."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.0 Organization of the NBC WD Document (13818-7)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformation Technology - Generic Coding of Moving Pictures and"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAssociated Audio-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPart 7:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNon Backwards Compatible Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 1:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScope"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNormative references"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDefinitions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSymbols and abbreviations"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoder/Encoder block diagram"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 2: (K. Brandenburg, Fraunhofer Gesellschaft)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMethod of describing the syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAudio bitstream syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSemantics for the audio bitstream syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 3: (S.Quackenbush, AT&T)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNoiseless coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTool description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNormative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntax (when applicable)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 4: (M.Dietz, Fraunhofer Gesellschaft)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScale factors"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTool description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNormative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntax (when applicable)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 5: (M.Dietz, Fraunhofer Gesellschaft)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nQuantization"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTool description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNormative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntax (when applicable)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 6: (S.Quackenbush, AT&T)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJoint coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTool description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNormative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntax (when applicable)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 7: (H.Fuchs, University of Hannover)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPrediction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTool description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNormative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntax (when applicable)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 8: (M.Bosi, Dolby)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFilterbank"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTool description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNormative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntax (when applicable)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 9: (M.Bosi, Dolby Laboratories)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBlock switching"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTool description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNormative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntax (when applicable)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*(?) Section 10: (Akagiri/Oikawa, Sony)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPost-processing (?)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTool description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNormative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntax (when applicable)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 11:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPsychoacoustic model(s)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative part:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoding process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiagrams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nGerhard Stoll\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11 *N1152*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Gerhard Stoll, Chairman of Task Group on revisions to IS\n13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Status:* Approved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Draft Revisions to IS 13818-3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis document consists of a short report on the activities of the Task\nGroup on revisions to IS 13818-3 and the draft revisions to IS 13818-3\nwhich are contained in the Annex."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe task group had the following tasks:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2022\u00a0To review and incorporate into IS 13818-3 the editorial changes,\nprovided in UK NB input document to the MPEG Tokyo 1995 meeting\u2022\u00a0To\nmodify the relevant subclauses in order to resolve the conflict in\nLayer\u00a0II between the use of prediction together with dynamic\ncrosstalk\u2022\u00a0To verify that these are the only required technical changes\nfor Layer II\u2022\u00a0To review Layer II LFE syntax\u2022\u00a0To modify the relevant\nsubclauses in order to resolve the conflict in the mpeg1_ancillary_data\ndefinition for Layer III\u2022\u00a0To clarify the Layer III Syntax\u2022\u00a0To do\neditiorial changes in the Layer III description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Membership of the Task Group:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nG. Stoll DE IRT Chairman"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nM. Dietz DE FhG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nG. Dimino IT RAI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nB. Grill DE FhG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nI. Kaneko J GCL"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nR. Schwalbe DE Deutsche Telekom"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nS. Ritscher DE IRT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Task Group reviewed Doc. MPEG96/677 and ISO/IEC JTC1/SC29/WG11\nN0972. These documents contain proposals for editorial and technical\nchanges to the IS 13818-3. All proposals have been verified by the task\ngroup and accepted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex A: Proposals of Document N0972*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_A general comment, relating to a large number of entries in ISO/IEC\n13818-3, is the difficulties caused to the user of the standard by the\nconstant cross-referencing to ISO/IEC 11172-3, e.g_. __\u201c__2.4.1.1 Layer\nI, II see ISO/IEC 11172-3, subclause 2.4.1__\u201d. Assuming changes are to\nbe made, it would make the document far more usable if many of the\nrelevant sections of ISO/IEC 11172-3 were replicated in ISO/IEC\n13818-3.__"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIntroduction, Section 0.2.1 Universal multichannel audio system,\nparagraph 3, line 1. Either the word stereophonic _or the word_ stereo\n_should be deleted._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIntroduction, Section 0.2.3.4 Encoder and Decoder Parameters. The term\nFs _is introduced here and is used extensively throughout the document,\nbut is never formally defined. Either in 0.2.3.4 or, better still, in\n0.1 the definition should be stated_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFs is the signal sampling frequency for the main audio channels."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n__Section 1.2 Normative references, paragraph 1, line 3. There should be\na space between \u2018__13818__\u2019 and \u2018__are__\u2019.__"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_In Section 2.2.6 Mnemonics, there should be an entry for nmlch_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnmlch Number on multilingual channels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Section 2.3 Method of describing bit stream syntax, under Definition of\nnext_start_code function, the syntax box should show zero_bit has No of\nbits =1, rather than \u20181\u2019._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThoughout Sections 2.4 and 2.5 a large number of data items are given\nthe mnemonic bslbf and then used in condiitional statements with a\nmixture of binary and unsigned integer notations. Bit string data\nelements should be constrained to use only binary notations as defined\nin 2.2.6: i.e. if (scfsi[mlch][sb]==\u201800\u2019) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPage 13, 14. Sections 2.4. to 2.4.1.2 inclusive."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* When compared to IS 11172-3 and IS 13818-3 Section 2.4.2, several\nsubsections have been omitted. These should be re-instated to give the\nfollowing sequence."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.4.1.1 Audio Sequence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.4.1.2 Audio Frame"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.4.1.3 Header"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.4.1.4 Error Check"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.4.1.5 Audio Data Layer I"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.4.1.6 Audio Data Layer II"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.4.1.7 Audio Data Layer III"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.4.1.8 Ancillary Data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* In old section 2.4.1.2 (new section 2.4.1.7), *block_type* _has the\nmnemonic bslbf. If this is a correct assignment (and it then matches\nISO/IEC 11172-3), then subsequent usage of_ *block_type* _within\nconditional statements should use the binary notation, i.e.\nif(block_type[ch]==\u201810\u2019 . This affects 2.4.1.2 (2.1.4.7) and several\nsections within 2.5.1 and 2.5.2._\n* In general, the notation for bit string data element usage should be\nstandardised to that defined in Section 2.2.6."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nN.B. The full corrected text for sections 2.4 to 2.4.1.8 is replicated\nin Annex 1 for the convenience of editing."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_On Page 16, Section 2.4.2.8, there is a minor error in the cross\nreference._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *2.4.2.8 Ancillary Data*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSee ISO/IEC 11172-3, subclause 2.4.2.8."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_In multiple locations in sections 2.5.1 and 2.5.2 there are errors in\nthe representation of multidimensional arrays. In section 2.3 \"Method of\ndescribing bit stream syntax\", the format data_element[l][m][n] is\ngiven. However, in the sections listed below, an undefined format with\ncommas is used, data_element[l,m,n], for the arrays listed. These need\nto be corrected. These corrections are already included in the Annexes._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{\\{\\{Note for the editing team: With care, a search and replace method\ncan speed up editing many of these sections. Search for \u201c,\u201d replace with\n\u201c][\u201c }}}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.10 MC Composite Status Information Layer I, II*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_predsi_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.12 MC Audio Data, Layer I and Layer II*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_centre_limited, dyn_cross, allocation, scfsi, predsi, delay_comp,\npred_coeff, scalefactor, grouping, samplecode, sample._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.14 ML Audio Data, Layer I and Layer II*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_allocation, scfsi, scalefactor, grouping, samplecode, sample._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2.8 MC Header*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_centre_limited_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2.10 MC Composite Status Information Layer I, II*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_dyn_cross, predsi_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2.11 MC Composite Status Information Layer III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_predsi, pred_coef_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2.12 MC Audio Data Layer I, II*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_allocation, scfsi, delay_comp, pred_coef, scalefactor, samplecode,\nsample_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2.14 ML Audio Data Layer I, II*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_allocation, scfsi, scalefactor, samplecode, sample_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Many changes are recommended in Section 2.5.1._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* The title for section 2.5 should have the same style as section 2.4\n* The definition of Audio Sequence should include ext_frame.\n* _All_ _sub-sections which include syntax definitions should show them\nin a boxed format._\n* _The notation for bit string data element usage should be standardised\nto that defined in Section 2.2.6._\n* _Excessive use of bold in 2.5.1.2, 2.5.1.3 and 2.5.1.4 needs to be\ncorrected. (Bold format is reserved, see 2.3 first paragraph, for data\nitems in the bit stream.)_\n* _In section 2.5.1.3 and elsewhere, the expression \u201cif (layer<3)\u201d is\nsyntactically incorrect. Even the correct \u201cif(layer<\u201811\u2019)\u201d is confusing,\nbecause of the binary notation and because \u201811\u2019=Layer I, \u201810\u2019=Layer II,\nand \u201801\u2019=Layer III. More obvious, and less prone to error, would be\n\u201cif(layer<Layer_III)\u201d or in this particular case \u201cif(layer==Layer_II)\u201d._\n* _The conditional statements should have a consistent style with\nbrackets as defined in Section 2.3- e.g. if (parameter ==1)_\n* _The current definition of mc_extension is confused and split between\n2.5.1.3 and 2.5.1.4. These should be amalgamated and refined._\n* _In 2.5.1.11 MC Composite Status Information, Layer III, segment_list\nshould not be in bold._\n* T__he definitions of MC Audio Data Layer III, LFE Header Layer III and\nLFE Main Data Layer III should be split into different sections\n(consistency with ML Header and ML Main Data)__\n* _As already stated the multidimensional arrays in MC Audio Data Layer\nI, II and ML Audio data Layer I, II need to be reformatted_\n* As already stated the usage of *block_type* _within conditional\nstatements should use the binary notation, i.e. if(block_type[ch]==\u201810\u2019\n._\n* In line 5 of ML Header, Layer III the wrong variable has been used: it\nshould read for (ch=0; ch<nmlch; ch++) \\{\n* _In ML Main Data, Layer III, the cross reference to syntax in other\nsection can be misinterpreted because those other section contain Header\nsyntax which is here separately defined. Minor changes can overcome\nthis:-_ __ If multilingual_fs==0, see main_data syntax in ISO/IEC\n11172-3, subclause 2.4.1.7. If multilingual_fs==1, see main_data syntax\nin subclause 2.4.1.7 of this part of ISO/IEC 13818.\n* _In Ext Ancillary Data, the upper bound of the \u2018for\u2019 statement should\nbe_ __ b<no_of_ext_ancillary_bits__.__\n* As the syntax, particularly of the extension components, is so\ncomplicated a top down sequence of definitions should be used. This will\nrequire changing the sequence of the sub-sections."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Once again Annex 2 gives a complete re-presentation of Section 2.5.1 to\naid electronic editing. The following subsections are not altered apart\nfrom their sequence: the reference style is new section number (old\nsection number)_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* 2.5.1.5 (2.5.1.5)\n* 2.5.1.6 (2.5.1.6)\n* 2.5.1.7 (2.5.1.7)\n* 2.5.1.9 (2.5.1.19)\n* 2.5.1.10 (2.5.1.20)\n* 2.5.1.12 (2.5.1.8)\n* 2.5.1.13 (2.5.1.9)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Additional changes are needed to section 2.5.2 as follows:-_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* If the sequence of sub-sections in 2.5.1 has been changed, section\n2.5.2 needs reordering to reflect the new order of 2.5.1.\n* Additional semantic descriptions are needed for Ext Ancillary Data\n(new section 2.5.2.10) and ML Header, Layer III (new section 2.5.2.21.)\n* The formatting of the multidimensional arrays has been included in the\npresentation in Annex 3.\n* In sections 2.5.2.2 and 2.5.2.3, the paragraphs commencing\n\u201cmc_extension_data_part1\u201d have been corrected to read \u201cplus optional\next_data from the extension bit stream frame\u201d.\n* For consistency with Section 2.5.1.22, the title of Section 2.5.2.22\nshould be changed from ML Audio Data Layer III _to_ ML Main Data, Layer\nIII__.__"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo aid electronic editing the full text is reproduced in Annex 3, except\nfor Section 2.5.2.21 ML Header, Layer III where new descriptions are\nrequired."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Consequential on changes to the section numbers in 2.4.1, 2.5.1 and\n2.5.2 references elsewhere in the document need amending._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* In section 2.2.6 Mnemonics"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnpred Number of allowed predictors according to the tables in 2.5.2.14."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsbgr Groups of individual subbands according to subbandgroup table in\n2.5.2.14."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* _In section ML Main Data Layer III (old number 2.5.1.16, new number\n2.5.1.22)_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf multilingual_fs==1, see 2.4.1.7 of this part of ISO/IEC 13818."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* _In section 2.5.2.10 MC Composite Status Information Layer I, II:\ndefinition of_ *dyn_cross_mode[sbgr]*_: just above the table A) 3/2\nconfiguration_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhere lim1 and lim2 stand for the subband group bounds (see the table in\nthe beginning of 2.5.2.14)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* _In section 2.5.3.2.1 Transmission Channel Switching: Line 6_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf dematrix_procedure '11' (see 2.5.2.12) is chosen, all signals can be\ndirectly derived from........"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* _In section 2.5.3.2.3 MC_Prediction: Line 21_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor other configurations and the different dynamic crosstalk modes, the\ncorrespondence of the predictor coefficients to the transmission\nchannels has to be adapted to the dynamic crosstalk tables (see\n2.5.2.14), e.g."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_As already stated, bit string data elements should be constrained to\nuse only binary notations as defined in 2.2.6: e.g._\nscfsi[mlch][sb]==\u201800\u2019 . _On this basis further changes are needed in the\nlater text as follows._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Section 2.5.3.2.3, the variables predsi and dyn_cros_mode.\n* Section 2.5.3.6, the variable dematrix_procedure\n* Section 2.5.3.8.1, the variable dematrix-procedure\n* Section 2.5.3.8.2, the variables block_type, predsi,\ndematrix-procedure and surround\n* Section 2.5.3.8.3, the variable block_type\n* Section C.2.1.8, the variable predsi\n* Section C.2.2.1, the variable dematrix_procedure\n* Section C.2.2.3, the variable dematrix_procedure\n* Section C.2.2.5, the variable dematrix_procedure"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAppendix A, Figure A.2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe reason for the upper diagram is not apparent as the two diagrams are\nnot separately referred to in the body of the document, and the lower\ndiagram appears to be self-sufficient and is certainly the more\ndetailed. It is suggested that the upper figure be removed. However if\nit is retained, two changes are necessary."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1) After \"MC CRC\" there should be a zone labeled \"MC Composite\nStatus Info\"."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2) The section currently labeled \"MC Ancillary Data\" should be\nlabeled \"Ancillary Data\" as it is in the lower diagram."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the lower diagram, the section currently labeled \"MC Ancillary Data\nPointer\" should be labeled \"MC Composite Status Info\". The term \u201cMC\nAncillary Data Pointer\u201d is not used in the body of the document."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe complexities of Layer I and Layer III are such that the user of this\nIS would be greatly assisted by similar diagrams. Such diagrams should\nbe added."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex B: Proposals of Document MPEG96/677 for Layer II*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition to the editorial changes mentioned in this document some\nadditional proposals concerning a clear understanding of IS 13818-3 were\nmade. These proposals refer to"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- length of tc_allocation field"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- length of dyn_cross_mode field."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- low frequency enhancement channel"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Layer III in general"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nConcerning the conflict between the use of prediction together with\ndynamic crosstalk, the Task Group on MPEG-2 Audio \"Prediction plus\ndynamic crosstalk solutions\" came during the MPEG meeting in Dallas\nNovember to the conclusion that:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Proposal 1, which needs a modification of the last paragraph of\nsubclause 2.5.3.2.3 \"MC_Prediction\","
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nand"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Proposal 3, which needs a re-calculation of the scale factors of\ntransmission channels Txy or Txyz in the decoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshould not be adopted due to the reasons given in document MPEG95/N1073\n(November 95)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHowever, the"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Proposal 2, which means a restriction of the number of combinations\nbetween dynamic crosstalk and prediction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshould be considered for a revision to IS 13818-3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Modify in Section 2.5.2.8 MC Header_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor those subbands, where centre_limited [mch,sb] is true, only\ntransmission channel allocation that include the centre signal can be\nused."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_to_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor those subbands, where centre_limited [mch,sb] is true, only\ntransmission channel allocation that include the centre signal can be\nused. In the case of dynamic crosstalk which includes the centre\nchannel, no scalefactors are transmitted for those subbands."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Modify in Section 2.5.2.10 MC Composite Status Info Layer I, II_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_To avoid any confusion, the length of the tc_allocation field should be\nexplicetely listed for the cases A), B), C), D), E), F) and G)._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0,3,4,5 in 3/2 mode,0,3,4 in 3/1 mode,0 in 3/0 and 3/0 + 2/0 mode."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}A) 3/2 configuration (nmch==3):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"31%,23%,23%,23%\",]\n|===\n|tc_allocation |T2 |T3 |T4\n|0 |Cw |LSw |RSw\n|1 |Lw |LSw |RSw\n|2 |Rw |LSw |RSw\n|3 |Cw |Lw |RSw\n|4 |Cw |LSw |Rw\n|5 |Cw |Lw |Rw\n|6 |Rw |Lw |RSw\n|7 |Lw |LSw |Rw\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLength of tc_allocation field: 3 bits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}B) 3/1 configuration (nmch==2):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"41%,29%,30%\",]\n|===\n|tc_allocation |T2 |T3\n|0 |Cw |Sw\n|1 |Lw |Sw\n|2 |Rw |Sw\n|3 |Cw |Lw\n|4 |Cw |Rw\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLength of tc_allocation field: 3 bits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}C) 3/0 (+ 2/0) configuration (nmch==1 in 3/0 mode, nmch==3 in\n3/0+2/0 mode):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"58%,42%\",]\n|===\n|tc_allocation |T2\n|0 |Cw\n|1 |Lw\n|2 |Rw\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLength of tc_allocation field: 2 bits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the case of a second stereo programme, T3 contains L2 and T4 contains\nR2 of the second stereo programme"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}D) 2/2 configuration (nmch==2):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"41%,29%,30%\",]\n|===\n|tc_allocation |T2 |T3\n|0 |LSw |RSw\n|1 |Lw |RSw\n|2 |LSw |Rw\n|3 |Lw |Rw\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLength of tc_allocation field: 2 bits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}E) 2/1 configuration (nmch==1):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"58%,42%\",]\n|===\n|tc_allocation |T2\n|0 |Sw\n|1 |Lw\n|2 |Rw\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLength of tc_allocation field: 2 bits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}F) 2/0 (+ 2/0) configuration (nmch==0 in 2/0 mode, nmch==2 in\n2/0+2/0 mode):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLength of tc_allocation field: 0 bits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the case of a second stereo programme, T2 contains L2 and T3 contains\nR2 of the second stereo programme."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}G) 1/0 (+ 2/0) configuration (nmch==0 in 1/0 mode, nmch==2 in\n1/0+2/0 mode):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLength of tc_allocation field: 0 bits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the case of a second stereo programme, T1 contains L2 and T2 contains\nR2 of the second stereo programme."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Modify in Section 2.5.2.10 MC Composite Status Info Layer I, II_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_To avoid any confusion, provide the field length for dyn_cross_modenot\nonly for the cases A), B), C), D) and E), but for F) and G) as well._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}F) 2/0 (+2/0) configuration, field length 0 bit."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}G) 1/0 (+2/0) configuration, field length 0 bit."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Accordingly, modify the syntax in Section 2.5.1.10 MC Composite Status\nInfo Layer I, II_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n./."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"76%,12%,12%\",]\n|===\n|if tc_sbgr_select == 1 | |\n|\\{ tc_allocation |0..3 |uimsbf\n|for (sbgr=0; sbgr<12; sbgr++) tc_allocation[sbgr] = tc_allocation | |\n|} | |\n|else for (sbgr=0; sbgr<12; sbgr++) | |\n|tc_allocation[sbgr] |0..3 |uimsbf\n|if dyn_cross_on==1 | |\n|\\{ | |\n|dyn_cross_LR |1 |bslbf\n|for (sbgr=0; sbgr<12; sbgr++) | |\n|\\{ | |\n|dyn_cross_mode[sbgr] |0..4 |bslbf\n|if surround==3 | |\n|dyn_second_stereo[sbgr] |1 |bslbf\n|} | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n./."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Regarding prediction and dynamic crosstalk used simultaneously, the\nfollowing modification of subclause 2.5.2.10 \"MC Composite Status Info\nLayer I, II\" is necessary:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}A) 3/2 configuration, field length 4 bits :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"28%,36%,,,36%\",]\n|===\n|dyn_cross_mode[sbgr] |transmission channel | | |Remarks\n|0 |T2 |T3 |T4 |\\{ No dynamic crosstalk }\n|1 |T2 |T3 |- |\n|2 |T2 |- |T4 |\n|3 |- |T3 |T4 |\n|4 |T2 |- |- |\n|5 |- |T3 |- |\n|6 |- |- |T4 |\n|7 |- |- |- |\n|8 |T2 |T34 |- |Prediction only for T2\n|9 |T23 |- |T4 |Prediction only for T4\n|10 |T24 |T3 |- |Prediction only for T3\n|11 |T23 |- |- |No prediction\n|12 |T24 |- |- |No prediction\n|13 |- |T34 |- |No prediction\n|14 |T234 |- |- |No prediction\n|15 |forbidden | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}B) 3/1 configuration, field length 3 bits :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"33%,26%,,41%\",]\n|===\n|dyn_cross_mode[sbgr] |transmission channel | |Remarks\n|0 |T2 |T3 |\\{ No dynamic crosstalk }\n|1 |T2 |- |\n|2 |- |T3 |\n|3 |- |- |\n|4 |T23 |- |No prediction\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}C) 3/0 configuration, field length 1 bit :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo restricitions necessary!"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}D) 2/2 configuration, field length 3 bits :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"33%,26%,,41%\",]\n|===\n|dyn_cross_mode[sbgr] |transmission channel | |Remarks\n|0 |T2 |T3 |\\{ No dynamic crosstalk }\n|1 |T2 |- |\n|2 |- |T3 |\n|3 |- |- |\n|4 |T23 |- |No prediction\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}E) 2/1 configuration, field length 1 bit :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo restrictions necessary!"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAccording to these modifications, the last table of subclause 2.5.2.10\nhas to be changed to:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,82%\",]\n|===\n| |dynamic crosstalk\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nModify in Section 2.5.2.12 MC Audio Data Layer I, II"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_The paragraph on lfe_allocation refers to the first line (i.e. subband\n0) of two allocation tables (Table B.2.a of ISO/IEC 11172-3 and table\nB.2.b of IEC 11172-3) depending on the sampling frequency. In fact these\ntwo lines are the same. Therefore the reference to two different tables\nmay be confusing. To make it clear, the paragraph on lfe_allocation\nshould be changed to:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*lfe_allocation* - Contains information on the quantiser used for the\nsamples in the low frequency enhancement channel. The 4 bits in this\nfield form an unsigned integer used as an index to the following table,\nwhich gives the number of bits per sample as well as the number of\nlevels used for quantisation. Further, lfe_allocation indicates the\nnumber of bits used to code the samples in the low frequency enhancement\nchannel. The following table is valid for all sampling frequencies."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|lfe_allocation |bits per sample |number of levels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 |0 2 3 4 5 6 7 8 9 10 11 12 13 14\n15 16 |- 3 7 15 31 63 127 255 511 1023 2047 4095 8191 16383 32767 65535\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote : for lfe_allocation equals \u201e0\u201c no lfe samples and no scalefactors\nare transmitted."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Regarding prediction and dynamic crosstalk used simultaneously, the\nfollowing modification of subclause 2.5.3.2.3 \"MC_Prediction \" is\nnecessary:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChange sentence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\"3/2 configuration, dyn_cross_mode[sbgr]=9, npred=4\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_to_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\"3/2 configuration, dyn_cross_mode[sbgr]=2, npred=4\"."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Change sentence_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn those cases of the dynamic crosstalk modes, where combined signals -\nindicated by Txy or Txyz - are transmitted in one of the transmission\nchannels T2, T3 or T4, the reconstruction is as follows:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_to_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn those cases of the dynamic crosstalk modes, where combined signals -\nindicated by Txy or Txyz - are transmitted in one of the transmission\nchannels T2, T3 or T4, no prediction can be applied."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_The following 5 equations at the end of subclause 2.5.3.2.3\n\"MC_Prediction\" shall be deleted:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTxy: Tx(n) = Tx^ (n) + eTx(n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTy(n) = Ty^ (n) + eTy(n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTxyz: Tx(n) = Tx^ (n) + eTx(n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTy(n) = Ty^ (n) + eTy(n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTz(n) = Tz^ (n) + eTz(n)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Modify in Section 2.5.3.5 Decoding of Low Frequency Enhancement\nChannel_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChange second sentence to:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe requantisation of the transmitted samples and application of the\nscalefactors are as in ISO/IEC 11172-3 for Layer I. See ISO/IEC 11172-3,\nsubclause 2.4.3.2.1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex C: Proposal for Layer III changes (updated because of merge with\nN0972, former version in MPEG96/677)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.) Bug in C-like bitstream description*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Section 2.4.1.2 Layer III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn second box (main_data syntax):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchange \u201e_for (sfb=0; sfb<8; sfb++ )_\u201c -> _\u201efor (sfb=0; sfb<6;sfb++)\u201c_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.) Clarify Description for Low Sampling Frequencies*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.4.2.1 Audio Sequence General*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAdd Sentence:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_A Layer III Lower Sampling Rate frame, however, only contains\ninformation for 576 samples in opposition to the 1152 samples of a\nISO/IEC 11172-3 Layer III frame._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3.) Bug in description for Low Sampling Frequenciy intensity coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.4.3.2 Audio Decoding Layer III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSecond Paragraph (Starting with As in ISO/IEC 11172-3 the last ...):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChange"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201e_Unlike ISO/IEC 11172-3 decoding_ ...\u201c -> \u201e _Like ISO/IEC 11172-3\ndecoding_ ...\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nand"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201e_This means that, unlike in ISO/IEC_ ...\u201c -> \u201e_This means that, like in\nISO/IEC_ ...\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4.) Bug in Ancillary data in Layer III multichannel audio*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMost of the following is just reorganization to better explain the real\nstructure, which is not very good covered by the current syntax. There\nare new main levels for the bitstream frame description as well as a\nseparation of larger syntax parts and renaming of other elements of the\ncurrent IS 13818-3 description."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere are two main topics covered by the following:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1.) Ancillary data description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\na.) Mpeg-1 ancillary data could not work as described currently."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nb.) Mpeg-2 ancillary data where not mentioned although they exist"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nc.) There are no ancillary data in the Extension stream for Layer III"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.) The lfe_main_data and ml_main_data access via the mc_data_begin\npointer was described very misleading. It is not really wrong but on the\nother hand dosn\u2019t tell really where these elements are located."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFootnote:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf agreed by the group, we would recommend to rename mc_header,\nmc_error_check and mc_extension to mpeg2_header, mpeg2_error_check,\nmpeg2_extension. This would be more logical and straight forward,\nbecause these elements contain information not only about mc, but also\nabout lfe and ml."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.3 Audio Frame Layer II, III / 2.5.1.11 MC_extension*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmake separate Layer II/III frame and mc-extension descriptions.\nProposal: split 2.5.1.3 in 2.5.1.3.1 Audio Frame Layer II 2.5.1.3.2\nAudio Frame Layer III split 2.5.1.11 in 2.5.1.11.1 MC_extension Layer I\nand II 2.5.1.11.2 MC_extension Layer III"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.5.1.11.3 MC_extension_data location"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe chapters 2.5.1.3.1 and 2.5.1.11.1 are then only valid for Layer I\nand II. Therefore the parts conditional for Layer III can be removed\nthere."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe changes in detail:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* 2.5.1.3.1 Audio Frame Layer II"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsame text as \u201eframe\u201c in former 2.5.1.3, only the line \u201e_if layer<3_\u201c has\nto be removed"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* 2.5.1.3.2 Audio Frame Layer III"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nadd:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nframe()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg1_header()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg1_error_check()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg1_audio_side_info()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg1_main_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg1_main_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg1_audio_main_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmc_extension_data_part1()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg1_ancillary_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* 2.5.1.11.1 MC_extension Layer I and II"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsame text as in former 2.5.1.4, only the lines \u201e_if layer==3\nmpeg1_ancillary:data_\u201c and \u201e_if layer<3_\u201c have to be removed"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* 2.5.1.11.2 MC_extension Layer III"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nadd:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmc_extension()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmc_header()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmc_error_check()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmc_composite_status_info()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg2_audio_side_info()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhile( !bytealigned )"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*byte_align_bit* 1 bslbf"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg2_audio_main_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg2_audio_side_info()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmc_side_info()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (lfe==1)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlfe_side_info ()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif(no_of_multi_lingual_ch!=0)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nml_side_info ()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg2_audio_main_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmc_audio_main_data ();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (lfe==1)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlfe_audio_main_data ()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif(no_of_multi_lingual_ch!=0)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nml_audio_main_data ()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg2_ancillary_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* 2.5.1.11.3 MC Extension Data Location"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsame text as \u201emc_extension_data()\u201c in former 2.5.1.3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.4 Ext_frame*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere are no ancillary data of Layer III in the extension stream.\nTherefore remove ext_ancillary_data(), if Layer III: \u201e_if layer<3\next_ancillary_data()_\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.8 MPEG1 Ancillary Data*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchange all occurences of \u201eif ext_bit_stream_present==1\u201c to \u201e_if\next_bit_stream_present==1 || layer ==3_\u201c and \u201eif\next_bit_stream_present==0\u201c to \u201e_if ext_bit_stream_present==0 && layer\n<3_\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.12 MC Header*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLayer III needs to know the length of MPEG1 ancillary data also if there\nis no ext_bit_stream. Therefore"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nthe line \u201eif ext_bit_stream_present==\u20181\u2019\u201c hast to be replaced by \u201eif\next_bit_stream_present==\u20181\u2019 || layer==Layer_III\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.18 MC Audio Data, Layer III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRename the first box to mc_side_info. In this box remove LFE_Header,\nML_header, mc_main_data, lfe_main_data and ml_main_data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRename box mc_main_data to mc_audio_main_data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRemove description before the syntax description of mc_audio_main_data\n(old name: mc_main_data). A corrected version of this description is now\nin the Semantics section."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.19 LFE Side Info, Layer III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRename chapter and box LFE_header to lfe_side_info()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.20 LFE Audio Main Data, Layer III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRename chapter and box lfe_main_data to lfe_audio_main_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.21 ML Header, Layer III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRename Chapter to _ML Side Info, Layer III_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRemove complete box and replace it by the following text:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_If multilingual_fs==0, see audio_data() syntax in ISO/IEC 11172-3,\nsubclause 2.4.1.7, but without main_data_begin, private_bits and\nmain_data()._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf multilingual_fs==1, see audio_data() syntax in subclause 2.4.1.2 of\nthis document, but without main_data_begin, private_bits and main_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor use as ML Side Info, nch is set to no_of_multi_lingual_ch."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.1.22 ML Main Data*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRename chapter to _ML Audio Main Data, Layer III_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInsert \u201e_audio_\u201c after \u201eFor use as ML\u201c in last sentence."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2 Semantics*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.5.2.3 Audio Frame Layer II, III"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRename section to \u201e_2.5.2.3.1 Audio Frame Layer II_\u201c"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAdd section \u201e_2.5.2.3.2 Audio Frame Layer III_\u201c:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mpeg1_header* - See 2.5.2.2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mpeg1_error_check* - See 2.5.2.2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mpeg1_audio_side_info* - This is the same as the syntax element\naudio_data() in ISO/IEC 11172-3, section 2.4.1.7 but without main_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mpeg1_main_data* - This is the same as the syntax element main_data()\nin ISO/IEC 11172-3, section 2.4.1.7. This data is accessed using\nmain_data_begin (see syntax element audio_data() in ISO/IEC 11172-3,\nsection 2.4.1.7 ) and contains MPEG-1 audio data as well as MPEG-2 audio\ndata (multichannel and multilingual) and ancillary data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mpeg1_audio_main_data* - This is the same as the syntax element\nmain_data() in ISO/IEC 11172-3, section 2.4.1.7 but without ancillary\ndata."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mc_extension_data_part1* - This part plus an optional extension bit\nstream frame forms the multichannel extension field, containing the\nmc_header, mc_error_check, mc_composite_status_info,\nmpeg2_audio_side_info and mpeg2_audio_main_data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mpeg1_ancillary_data* - See 2.5.2.2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2.4 Extension Frame*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChange description of ext_ancillary_data:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ext_ancillary_data* - Part of the extension bit stream that can be used\nfor carrying ancillary data _for Layer I and II. For Layer III the\nadditional ancillary data for the multichannel/multilingual extension\n\u2018mpeg2_ancillary_data\u2019 is located in the mpeg2_audio_main_data,\nindependent wether the extension bit stream is used or not (see\nsubclause 2.5.1.11.2)._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2.11 MC_extension*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRename section to \u201e_2.5.2.11.1 MC_extension Layer II\u201c_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAdd section \u201e_2.5.2.11.2 MC_extension Layer III_\u201c:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mc_header* - see 2.5.2.11.1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mc_error_check* - see 2.5.2.11.1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mc_composite_status_info* - see 2.5.2.11.1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mpeg2_audio_side_info* - Part of the bit stream containing information\nneeded for decoding the multichannel extension and the multilingual\nextension"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*byte_align_bit* - Private bits used to do a byte alignment of the\nmpeg2_audio_main_data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mpeg2_audio_main_data* - Part of the bit stream containing information\non the audio samples of the multichannel and multilingual extension.\nThis data is accessed via the mc_data_begin element in the syntax\nelement mc_composite_status_info (see section 2.5.1.15). Because of the\nvariable nature of Huffman coding in Layer III and the bit reservoir\ntechnique, the mpeg2_audio_main_data for a frame does not generally\nfollow the mpeg2_audio_side_info of that frame. The\nmpeg2_audio_main_data for a frame starts at a location in the bit stream\npreceding the mc_header and mpeg2_audio_side_info of a frame at a\nnegative offset given by the value of mc_data_begin (see definition of\nmain_data_begin in ISO/IEC 11172-3, section 2.4.2.6). The number of\nbytes used for information other than mpeg2_audio_main_data is not taken\ninto account when applying mc_data_begin."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mc_side_info* - Part of the bit stream contain information needed for\ndecoding of the full bandwidth channels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*lfe_side_info* - Part of the bit stream containing information needed\nfor decoding of the low frequency enhancement channel."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ml_side_info* - Part of the bit stream containing information needed\nfor decoding of the multi lingual channels."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mc_audio_main_data* - Part of the bit stream contain information on the\naudio samples of the full bandwidth channels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*lfe_audio_main_data* - Part of the bit stream contain information on\nthe audio samples of the low frequency enhancement channel"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ml_audio_main_data* - Part of the bit stream contain information on the\naudio samples of the multi lingual channels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*mpeg2_ancillary_data* - This is the ancillary data of the\nmultichannel/multilingual extension part. The number of ancillary data\nbits corresponds to the distance between the end of the\nmultichannel/multilingual Huffman data and the location in the\nmpeg2_audio_main_data where the next frame\u2019s mc_data_begin pointer\npoints to"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2.12 MC Header*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChange description of n_ad_bytes:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*n_ad_bytes* - 8 bits that form an unsigned integer indicating how many\nbytes are used for the MPEG-1 compatible ancillary data field if an\nextension bit stream exists _(Layer I and Layer II) or if Layer III is\nused (with or without extension bit stream)._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2.18 MC Audio Data Layer III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRemove description of byte_align_bit"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.2.21 ML Header, Layer III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChange title to _ML Side Info, Layer III_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAdd:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_If multilingual_fs==0, see audio_data() syntax in ISO/IEC 11172-3,\nsubclause 2.4.2.7, but without main_data_begin, private_bits and\nmain_data()._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf multilingual_fs==1, see audio_data() syntax in subclause 2.4.2.7 of\nthis document, but without main_data_begin, private_bits and main_data()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.5.3 The Audio Decoding Process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.5.3.1 General"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChange 3rd paragraph:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis part of ISO/IEC 13818 provides the possibility to extend the bit\nrate beyond the bit rates defined in ISO/IEC 11172-3 for the three\nLayers, while preserving backwards compatibility with this standard.\nThis is achieved by using an extension bit stream that contains the\nremainder of the data of the multichannel/multilingual data. The\nstructure of this bit stream for _Layer II_ is depicted in Figure A.2 of\nAnnex A. Within the MPEG-2 bit stream, the MPEG-1 compatible bit stream\ncontains at least the MPEG-1 Audio Data and MC header. _The\ncorresponding structure for a Layer III bit stream is shown in Figure\nA.3 of Annex A._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.5.3.8.2 Decoding Process for Layer III*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChange first paragraph:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf an extension bit stream is available, its access units may contain\nparts of mc_composite_status_info and mc_audio_data. Their contents are\nconcatenated to the mc_composite_status_info and/or mc_audio_data in the\nmain data part of the MPEG-1 compatible bit stream. The target of the\nmc_data_begin pointer is calculated in the buffer containing the\nconcatenated bit stream. _The structure of a Layer III multi channel\n/multi lingual bit stream can be found in Annex A.3._ ** _A possible\next_data (indicated by the ext_bit_stream_present flag in mc_header)\nmust be inserted between mpeg2_main_data and mpeg1_ancillary data._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Add the following figure to Annex A:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[pic]*Figure A.3 Structure of the ISO 13818-3 Layer III multichannel\nextension.A possible ext_data must be inserted between mpeg2_main_data\nand mpeg1_ancillary data.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= AHG on core experiments on coding efficiency\nJan De Lameillieure\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ISO**/IEC JTC1/SC29/WG11**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*CODING OF MOVING PICTURES AND AUDIO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO-IEC/JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/N1153*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996 / M\u00fcnchen"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Video group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on core experiments on efficient\ncoding in MPEG-4 video* (Prediction, Frame texture coding, quantiser and\nbit-rate control)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair:* John Muller (jmuller@iterated.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* 1) To collect core experiments description __(deadline : 2nd\nweek after the 33rd MPEG meeting)__2) Editing a document with all core\nexperiments __(deadline : 3rd week after the 33rd MPEG meeting)__3)\nDistribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n__ 4) Development of evaluation criteria for results of core\nexperiments5) Coordination of common conditions for appropriate core\nexperiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Duration* : Until the Florence meeting (3/96)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings* : None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Communications* : E-mail"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: L.Chiariglione"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: T.Sikora"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= AHG on core experiments on content-based coding\nJan De Lameillieure\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ISO**/IEC JTC1/SC29/WG11**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*CODING OF MOVING PICTURES AND AUDIO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO-IEC/JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/N1154*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996 / M\u00fcnchen"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Video group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on core experiments on\ncontent-based coding and access* *in MPEG-4 video* (Shape and Alpha\nchannel coding, Object/Region texture coding)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair:* Touradj Ebrahimi (ebrahimi@epfl.ch)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIbrahim Sezan (co-chair ; sezani@sharpsla.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* 1) To collect core experiments description __(deadline : 2nd\nweek after the 33rd MPEG meeting)__2) Editing a document with all core\nexperiments __(deadline : 3rd week after the 33rd MPEG meeting)__3)\nDistribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n__ 4) Development of evaluation criteria for results of core\nexperiments5) Coordination of common conditions for appropriate core\nexperiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Duration*: Until the Florence meeting (3/96)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Communications*: E-mail"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: L.Chiariglione"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: T.Sikora"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nhhi\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ISO**/IEC JTC1/SC29/WG11**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*CODING OF MOVING PICTURES AND AUDIO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO-IEC/JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/N1155*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996 / M\u00fcnchen"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Video group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on core experiments on error\nresilience aspects in MPEG-4 video*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChair: James Brailean (brailean@areaplg2.corp.mot.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* 1) To collect core experiments description __(deadline : 2nd\nweek after the 33rd MPEG meeting)__2) Editing a document with all core\nexperiments __(deadline : 3rd week after the 33rd MPEG meeting)__3)\nDistribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n__ 4) Development of evaluation criteria for results of core\nexperiments5) Coordination of common conditions for appropriate core\nexperiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Duration*: Until the Florence meeting (3/96)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Communications*: E-mail"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: L.Chiariglione"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: T.Sikora"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= AHG on core experiments on multifunctional coding\nJan De Lameillieure\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ISO**/IEC JTC1/SC29/WG11**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*CODING OF MOVING PICTURES AND AUDIO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO-IEC/JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/N1156*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996 / M\u00fcnchen"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Video group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on core experiments on\nmultifunctional coding aspects in MPEG-4 video* (spatio-temporal\nscalability, multi-view and model manipulation, pre-, mid- and post-\nprocessing)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair:* Atul Puri (ap@big.att.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* 1) To collect core experiments description __(deadline : 2nd\nweek after the 33rd MPEG meeting)__2) Editing a document with all core\nexperiments __(deadline : 3rd week after the 33rd MPEG meeting)__3)\nDistribution of the core experiments document to the video group\nreflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n__ 4) Development of evaluation criteria for results of core\nexperiments5) Coordination of common conditions for appropriate core\nexperiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Duration*: Until the Florence meeting (3/96)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Communications*: E-mail"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: L.Chiariglione"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: T.Sikora"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= AHG on core experiments on coding efficiency\nhhi\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ISO**/IEC JTC1/SC29/WG11**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*CODING OF MOVING PICTURES AND AUDIO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO-IEC/JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/N1157*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996 / M\u00fcnchen"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Video group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on software development for the\nVideo Verification Model*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair:* Henri Sanson (Henri.Sanson@ccett.fr)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To prepare the development of software for the video\nverification model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: Until the Florence meeting (3/96)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Communications*: E-mail"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: L.Chiariglione"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: T.Sikora"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= The MPEG-2 standard provides a broad range of compression tools that\nallow its use in a variety of different applications. Forcing... On the\nother hand, letting each user arbitrarily pick his own tools can cause\ninteroperability problems. Therefore MPEG\nWarren Kafer\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11**N1158**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary, 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Disposition of National Body Comments on 4:2:2 Profile"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSource: Video"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn response to the Australian National Body, the Video Group agrees that\nproper processing of the vertical interval is required. In order to\nfacilitate this, a description of the 608 line capability of the Profile\nwill be included in the Informative Annex. The processing required for\nthis vertical interval is, however, outside MPEG\u00d5s area of expertise. In\norder to avoid any confusion with the progression of this matter, we\ntherefore suggest that the Australian National Body contact ITU-R\ndirectly."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn response to the Swedish National Body, the request is addressed in\nthe Informative Annex."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= PDAM: 422 profile\nSakae OKUBO\n1996-01-30"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND ASSOCIATED AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11**N1159**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Video*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INFORMATION TECHNOLOGY -*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGENERIC CODING OF MOVING PICTURES AND ASSOCIATED AUDIO**: VIDEO**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC 13818-*2 Amendment 2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*International Standard*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDraft of: *01/27/96 5:34 AM*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL STANDARD*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nITU-T RECOMMENDATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INFORMATION TECHNOLOGY -- GENERIC CODING OF MOVING PICTURES AND\nASSOCIATED AUDIO INFORMATION: VIDEO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAMENDMENT 2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_1) Replace table 8-4 in clause 8:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00ca8-4 - Escape profile_and_level_indication identification*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"50%,50%\",]\n|===\n|profile_and_level_indication |Name\n|10000000 to 10000100 |(Reserved)\n|10000101 |4:2:2 profile @ Main level\n|10000000 to 10000110 |(Reserved)\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2) Add the following text as a note after table 8-4, in clause 8:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote - on 4:2:2 Profile: The ITU-T Rec. H.262\u00a0|\u00a0ISO/IEC 13818-2\ncompression algorithm exploits temporal redundancy, spatial redundancy,\nand human psycho-visual properties and is not a lossless algorithm. For\nsequences with substantial spatial and temporal redundancies, or without\nmany sharp lines/edges, the quality of the sequences obtained after\ndecompression will be higher than that obtained for sequences with lower\nredundancy, or with a large number of sharp lines/edges."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 4:2:2 profile can provide higher video quality, better chroma\nresolution and allows a higher bitrate (at Main level, up to 50 Mbit/s)\nthan MP@ML. It also provides the capability to encode all active lines\nof video."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAlthough it is not part of the hierarchy of profiles and levels, the\n4:2:2 profile @ Main level decoder is required to decode all the\nbitstreams decodable by MP@ML decoders."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 4:2:2 profile does not support scalability. This allows\nimplementation architectures to be similar to those of MP@ML."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis profile can be used for applications requiring multiple generations\nof encoding and decoding. In the case of multiple generations without\npicture manipulation or change in picture coding type between\ngenerations, the quality remains nearly constant after the first\ngeneration. Use of picture manipulation or change in picture coding type\nbetween generations causes some degradation in quality. Nevertheless,\nthe resulting quality is acceptable for a broad range of applications."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 4:2:2 profile permits all I-picture encoding. This enables fast\nrecovery from transmission errors and can simplify editing applications.\nThis profile allows the high bit rates required to maintain high quality\nwhile using only I-picture coding. The 4:2:2 profile also allows the use\nof P- and B-picture coding types which can further improve quality or\nreduce bit rate for the same quality."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSee Annex J for more information on the picture quality of the 4:2:2\nprofile."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3) Replace table 8-5 in clause 8.2:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00ca8-5 - Syntactic constraints of profiles*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n| |Profile\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_4) Replace table 8-6 in clause 8.2:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 8-6 - Maximum number of bits in a macroblock*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"50%,50%\",]\n|===\n|chroma_format |Maximum number of bits\n|4:2:0 |4608\n|4:2:2 |6144\n|4:2:2 (in 4:2:2 Profile) |Unconstrained\n|4:4:4 |9216\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5) Add the following text in clause 8.2.1 following:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif *vertical_size* > 480 lines frame_rate shall be \u00d225Hz\u00d3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAdditionally, the following constraints exist for 4:2:2 profile @ Main\nlevel only:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00b7 if *vertical_size* > 512 lines"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nthen if **picture_coding_type**=011 (i.e. B-picture),\n*repeat_first_field* shall be 0."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00b7 if *vertical_size* > 512 lines frame_rate shall be \u00d225Hz\u00d3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_6) Replace table 8-11 in clause 8:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00ca8-11 - Upper bounds for sampling density*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"13%,13%,13%,61%\",]\n|===\n| |Spatial resolution | |Profile\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}7) Replace table 8-12 in clause 8:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00ca8-12 - Upper bounds for luminance sample rate (samples/sec)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"11%,14%,75%\",]\n|===\n| |Spatial resolution |Profile\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}8) Replace table 8-13 in clause 8:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00ca8-13 - Upper bounds for bit rates (Mbit/s)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"12%,88%\",]\n|===\n| |Profile\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}9) Replace table 8-14 in clause 8:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00ca8-14 - VBV buffer size requirements (bits)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"14%,15%,71%\",]\n|===\n| | |Profile\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_10) Replace table 8-15 in clause 8:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00ca8-15 - Forward compatibility between different profiles and\nlevels*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"22%,78%,,,,,,,,,,\",]\n|===\n| |Decoder | | | | | | | | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_11) Replace table E.2 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.2 - Sequence header*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}12) Replace table E.3 in Annex E:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.3 - Sequence extension*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_13) Replace table E.4 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.4 - Sequence display extension elements*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}14) Replace table E.5 in Annex E:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.5 - Sequence scalable extension*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"6%,62%,5%,27%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}15) Replace table E.6 in Annex E:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.6 - Group of pictures header*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_16) Replace table E.7 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.7 - Picture header*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_17) Replace table E.8 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.8 - Picture coding extension*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_18) Replace table E.9 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.9 - Quant matrix extension*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_19) Replace table E.10 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.10 - Picture display extension*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_20) Replace table E.11 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.11 - Picture temporal scalable extension*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_21) Replace table E.12 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.12 - Picture spatial scalable extension*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*\"*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_22) Replace table E.13 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.13 - Slice layer*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"6%,63%,5%,26%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_23) Replace table E.14 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.14 - Macroblock layer*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}24) Replace table E.15 in Annex E:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.15 - Macroblock modes*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_25) Replace table E.16 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.16 - Motion vectors*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_26) Replace table E.17 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.17 - Motion vector*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_27) Replace table E.18 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.18 - Coded block pattern*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_28) Replace table E.19 in Annex E:_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table\u00caE.19 - Block layer*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"7%,64%,4%,25%\",]\n|===\n| |Status | |Type\n| |4:2:2 | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}29) Add the following Annex:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex J4:2:2 Profile test results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(This annex does not form an integral part of this Recommendation |\nInternational Standard)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *J.1 Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis annex provides guidance to users regarding the applicability of the\n4:2:2 Profile at Main Level to applications which may require:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* higher quality than Main Profile at Main Level\n* better chroma resolution than Main Profile at Main Level\n* post processing after compression and decompression\n* multiple generations of compression and decompression\n* short Group of Pictures (GOP) for editability\n* capability to pass all active video\n* capability to pass vertical blanking interval information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt should be noted that application of this Profile is an area of\nongoing progress. Results presented here reflect varying degrees of\nalgorithm refinement, so further improvement can be expected."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== J.1.1 Test sequences"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe test sequences were generated using computer simulation of the ITU-T\nRec. H.262\u00a0|\u00a0ISO/IEC 13818-2 compression and decompression. For 525/60,\nthe test material included:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Gwen\n* Trailblazers\n* Mobile and Calendar\n* Dissolve"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor 625/50, the test material included:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Balls of Wool\n* Cactus and Comb\n* Basketball\n* Wall\n* Renata and Butterfly\n* Mobile and Calendar"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\"Gwen\" is a chroma key test sequence with a woman in the foreground\nkeyed over a forest scene in the background. \"Gwen\" is a difficult\nsequence to chroma key but an easy sequence to compress. Both \"Cactus\nand Comb\" and \"Balls of Wool\" are chroma key sequences which were used\nwith a colored background. \"Trailblazers\" is a rapid motion basketball\nsequence shot with an un-shuttered CCD camera. \"Basketball\" is also a\nrapid motion sports sequence. Both are typical program material and\nmoderately difficult to compress. \"Wall\" consists of a woman standing in\nfront of wall made of many small stones. \"Renata\" consists of a woman in\nfront of a complex background with a dissolve to a complex image of\nbutterflies. \"Mobile and Calendar\" is a particularly difficult\ncompression test sequence with saturated colors and complex motion.\n\"Dissolve\" consists of two segments of \"Mobile and Calendar\" with a one\nsecond fade between the two segments and is also difficult to compress."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest sequences were supplied by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* ITU-R\n* Portland Trailblazers\n* SMPTE\n* Tektronix"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== J.1.2 Test procedures"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG has conducted experiments to verify the performance of the 4:2:2\nProfile. The results of those experiments are presented here. There are\nseparate tests for 525/60 and 625/50. The 525/60 tests explore a broad\nrange of data rates and GOP structures, while the 625/50 tests include\nmore variety of test material but less combinations of data rate, GOP\nstructure, and number of generations. The parameters chosen for the\nexperiments are for example only, and do not cover the entire range of\nallowed parameter values. The examples are not intended as specific\nrecommendations. Each application should use the combination of\nparameters that is most appropriate, depending on its requirements for\nquality, editability, and cost."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tests include both a single generation and eight generations of\ncascaded compression and decompression. For the eight generation tests,\nseparate tests were done with no shifts, with two spatial shifts, and\nwith two temporal shifts. Spatial shifting means that the picture was\nshifted horizontally and vertically by two pixels and two spatial lines\nbetween the first and second generations and then back between the fifth\nand sixth generations. Spatial shifting represents the effects of\npicture repositioning which might occur in a DVE. Temporal shifting\nmeans that the GOP structure was shifted one frame between the first and\nsecond generations and again between the fifth and sixth generations.\nTemporal shifting represents the effect of multiple generations which\nhave different GOP alignment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChroma key experiments were done by processing the foreground with blue\nscreen through compression and decompression. After decompression the\ncomponent digital signal was chroma keyed to add the background. The\nbackground image was not compressed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMixed environment tests for 525/60 used ITU-T Rec. H.262\u00a0|\u00a0ISO/IEC\n13818-2 4:2:2 compression and decompression cascaded with a compressed\ndigital VTR using 2:1 intra-field compression. The tests used a total of\neight generations of compression. The four odd number generations were\nMPEG and the four even number generations were compressed digital VTR.\nThere were no shifts between generations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMixed environment tests for 625/50 used only MPEG compression. The tests\nused a total of three generations of compression. The first and third\ngenerations were ITU-T H.262 Rec. \u00a0|\u00a0ISO/IEC 13818-2 4:2:2 compression\nwith IBBP GOP structure at 20 Mbits/s, while the second generation was\nITU-T Rec. H.262\u00a0|\u00a0ISO/IEC 13818-2 4:2:2 compression with I-only GOP\nstructure at 50 Mbits/s. A temporal shift of one frame was included\nbetween the second and third generations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompression and decompression processing were contributed by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* CCETT\n* FTZ\n* IRT\n* JVC\n* Sony\n* Technical University of Braunschweig/BTS\n* Tektronix"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEditing and duplication of test tapes were contributed by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* RAI\n* Tektronix"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== J.1.3 Subjective assessment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe subjective assessment used the DSCQS method described in ITU-R Rec.\nBT.500-6. Both expert and non-expert viewing sessions were conducted at\na number of sites around the world. All of the expert viewing results\nwere combined, and all of the non-expert viewing results were combined.\nBoth expert and non-expert results are presented here. Only subjective\ntest results are presented, as signal to noise is not regarded as a\nreliable measure of picture quality in these cases."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExpert subjective assessment viewing sessions were conducted by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* NHK\n* SMPTE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNon-expert subjective assessment viewing sessions were conducted by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* CCETT\n* JVC/MPT/NHK/NTV\n* RAI\n* Technical University of Braunschweig/BTS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== J.1.4 Test results"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest results are presented in the following order:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* 525/60 Homogeneous Environment\n* 525/60 Non-Homogeneous Environment\n* 625/50 Homogeneous Environment\n* 625/50 Non-Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tables of test results are organized with higher data rates\npresented first and lower data rates presented last. Within a given bit\nrate, results are organized by GOP structure, number of generations, and\ntype of shifting. The mean and confidence interval are given for each\ntest sequence."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that while subjective viewing tests often use a five point\nimpairment scale, these tests used the continuous quality scale\nspecified in ITU-R Rec. BT.500-6. The subjective assessments were done\non a continuous 0 to 100 scale. The mean differences between original\nand compressed sequence ratings were calculated, on a 0 to 100 scale,\nwith 0 representing no degradation through compression and 100 being the\nworst possible rating. The results presented here are based on the\nfollowing quality definitions:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* 0 to 12.5 Transparent\n* 12.5 to 20 Nearly Transparent\n* 20 to 40 Good"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThree quality ratings appear in the tables of test results.\n\"Transparent\" is the best quality, followed by \"Nearly Transparent\", and\nthe lowest quality observed was \"Good\"."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table J.1 - Subjective test results for the 525/60 system*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"57%,43%\",]\n|===\n|Compression parameters |Viewer ratings\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table J.2 - Subjective test results for the 625/50 system*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"58%,42%\",]\n|===\n|Compression parameters |Viewers\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\"_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nZFE T SN 22\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND ASSOCIATED AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11 *N1160*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSource: Leonardo Chiariglione"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Ad Hoc Group on Synthetic/Natural Hybrid Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthor: Peter K. Doenges, Evans & Sutherland"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOfficial mandate:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. Solicit community expertise and participation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. Complete final Call for Proposals with PPD."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. Develop Virtual Playground and Test Data Set."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4. Develop Media Model proposal evaluation criteria."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: No meetings held."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members of the Ad Hoc Group*:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n100337.232@Compuserve.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(Dr. Gerald Knabe, Q-Team)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n71207.3244@Compuserve.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(Alfred Riccomi, Multimedia PC Systems)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\najt@casablanca.LABS.TEK.COM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\naluthra@gi.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nap@big.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\narturo.rodriguez@sciatl.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\narun@vela.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbdg@iis.fhg.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbeuker@natlab.research.philips.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbillpow@microsoft.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbj@rnd.sec.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncaspar@mediamatics.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchiu@m2sun3.ccl.itri.org.tw"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchou@parc.xerox.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncliff@reader.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncorset@lep-philips.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncourtney@csc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncrinonr@indy.tce.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndelmot@tele.ucl.ac.be"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndimino@crrai.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndj@panda.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndufour@lep-philips.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndufourd@elec.enst.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nebrahimi@epfl.ch"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nedler@tnt.uni-hannover.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nedp@research.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\neferbper@beta.ist.utl.pt"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\neleft@ctr.columbia.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\neliot@sense8.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\netoh@crl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfabio@dist.dist.unige.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfazadegan@gte.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nflaczko@ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfujii@edc3.yamaha.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfukuchi@elelab.nsc.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngaryd@alumni.caltech.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngeorge@clix.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nghpark@super5.hyundai.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngparladori@tlt.alcatel.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngrajan@gi.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngrl@lte.e-technik.uni-erlangen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nguillemo@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhanspeter.poffet@alcatel.ch"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhdchang@video.etri.re.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nherpelc@tcernd1.hanover.tce.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhomer@big.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhomma@itl.toppan.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhotani@mlab.nttdocomo.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhoyo@kjist.kjist.ac.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhsilbiger@exit109.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhyungk@dspsun.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nishizuka@src.ricoh.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nitaru-k@gctech.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njedrzeje@efp.poznan.pl"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njez@argonaut.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njimh@sgi.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njmuller@world.std.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJohn_Sweeney@UK.IBM.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njordan@patpserv.epfl.ch"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njozawa@nttvdt.hil.ntt.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njrobinso@es.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njsshin@saitgw.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njun@pcrd.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nkawauchi@krhm.jvc-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nken@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nknoll@fz.telekom.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nkoike@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nleray@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlimin.wang@crc.doc.ca"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmark@sense8.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmin@corvette.crl.goldstar.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmisezan@kodak.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmiyamoto@dsp.cl.nec.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmoriya@splab.hil.ntt.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnaveent@pictorial.labs.tek.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nneil@int.rdc.ricoh.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnishi@pcrd.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnoll@ftsu00.ee.tu-berlin.d400.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnsuzuki@ctr.columbia.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noconnell@areaplg2.corp.mot.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noehler@hc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nohm@ftsu00.ee.TU-Berlin.DE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nolivier.avaro@issy.cnet.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nolle@fou.svrr.se"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nosterman@big.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npaul@bristol.st.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npbi00312@niftyserve.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npdoenges@es.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npgs@sciatl.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nP_Kuhn@lis.e-technik.tu- muenchen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nr.h.koenen@research.ptt.nl"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrick-y@ascii.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrowlands@hc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRUGGERO.DE-LUCA@st.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nschnurr@ukraine.corp.mot.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nschulz@ftsu00.ee.tu-berlin.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsci00291@niftyserve.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nscott@disney.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshin-k@ascii.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshson@panda.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsivan@vnet.ibm.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsjhuang@dvs.comsr@nt.e-technik.uni-dortmund.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstefano.battista@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstuj@escapesoft.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsushil@ltssg4.epfl.ch"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nswkim@dspsun.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nT.Einarsson@etxdn.ericsson.se"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntakami@dsp.cl.nec.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntakikawa@yh.ntts.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntalluri@csc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntjs@deathstar.risc.rockwell.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntktan@avirc.ams.com.sg"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntong@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntoshi@krhm.jvc-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntravagli@vnet.ibm.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvandyckr@systems.gec.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvideo@lis.e-technik.tu- muenchen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvsathe@gi.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwatanabk@strl.nhk.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWataru.Kameyama@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwiza@efp.poznan.pl"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nyasu-h@ascii.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nyasuda@plan.isl.ntt.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nyhkim@video.etri.re.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nyllee@saitgw.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCC:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nleonardo.chiariglione@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncreader@samsung.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= AHG on core experiments on coding efficiency\nhhi\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ISO**/IEC JTC1/SC29/WG11**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*CODING OF MOVING PICTURES AND AUDIO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO-IEC/JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/N1161*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996 / M\u00fcnchen"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Video group"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Establishment of *ad-hoc group on MPEG-4 Video Verification\nModel Document Editing*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chair:* Touradj Ebrahimi (ebrahimi@epfl.ch)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To maintain a consistent version of the verification model\n(VM) document through"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- coordination of the definition of the VM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- continuing Editing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: Until the Florence meeting (3/96)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Communications*: E-mail"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: L.Chiariglione"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncc: T.Sikora"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANIZATION FOR STANDARDIZATION\nJoern Ostermann\n1996-01-31"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND ASSOCIATED AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11 N1162"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG 96/0679"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"19%,81%\",]\n|===\n|Source: |J\u00f6rn Ostermann (AT&T Bell Laboratories)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Report on the Ad Hoc Group on Evaluation of Tools and\nAlgorithms of video submissions for MPEG-4 in January 1996\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMandate: to define means for the evaluations and to perform evaluation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nof tools and algorithms submitted for MPEG-4 in January 1996."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMeetings: One meeting, 20-21 January 1996 at Deutsche Telekom in Munich,\nGermany"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMembership: see Annex 1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe adhoc group exchanged email defining the process of the evaluation\nof tools and algorithms as well as the structure for the evaluation of\ntools and algorithms."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDuring the meeting (participants in Annex 8), 17 tools and 19 algorithms\nwere evaluated. Annex 2 gives the list of documents evaluated. It should\nbe noted that algorithm submissions which did not include documentation\nand a tape were not evaluated. The organization of the meeting as well\nas the evaluation criteria are outlined in Annex 3. The evaluation of\nthe submission was carried out in four groups. Annex 4 gives the\nassignments of submissions to the groups."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe recommendations of this group are detailed in Annex 5. To the video\ngroup, several video tapes are recommended for viewing. Furthermore,\ncore experiments were extracted from the submitted algorithms and tools.\nA brief evaluation of each tool and algorithm is provided in Annex 6 and\n7, respectively. As far as evaluation of picture quality is concerned,\nthis group was not able to perform subjective tests which ensure a\nproper evaluation of the submitted algorithms in terms of picture\nquality. Therefore, the evaluation of picture quality is not comparable\nwith the results provided by the MPEG-4 subjective tests carried out in\nNovember 1995 (ISO-IEC/JTC1/SC29/WG11/N1056). However, the tools were\nevaluated just as the tools submitted in November 1995, so these results\nare comparable (ISO/IEC/JTC1/SC29/WG11/N1064rev)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe adhoc group thanks Deutsche Telekom and especially Mr. Pr\u00f6sch and\nhis team for hosting the meeting. The Adhoc group would like to thank\nSiemens AG, Institut f\u00fcr Rundfunktechnik and Technische Universit\u00e4t\nM\u00fcnchen for providing video monitors and two D1-VCRs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex* __ *1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*AdHoc Group Membership*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n100337.232@compuserve.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nArturo.Rodriguez@Sciatl.COM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDelmot@tele.ucl.ac.be"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nK.J.Rijkse@research.kpn.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nP.J.Czerepinski@bristol.ac.uk"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nP_Kuhn@lis.e-technik.tu-muenchen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nR.H.Koenen@research.kpn.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStathis.Panis@zfe.siemens.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nT.Einarsson@clab.ericsson.se"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTom_Nunan@qm.sri.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWL03@Lehigh.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\na_hutter@lis.e-technik.tu-muenchen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nali.tabatabai@tek.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\naluthra@gi.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nanastas@ctr.columbia.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nap@big.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\narakawa@crl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\narnaud@research.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\narun@vela.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nauyeung@areaplg2.corp.mot.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbanham@areaplg2.corp.mot.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbenzler@tnt.uni-hannover.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbernardd@NCR.DISA.MIL"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbernardd@ner.disa.mil"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbeuker@natlab.research.philips.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbgh@big.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbillpow@microsoft.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbj@rnd.sec.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbob.eifrig@tek.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbonnard@UNIVERS.matra-com.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nboon@drl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbradyn@teltec.dcu.ie"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbrailean@areaplg2.corp.mot.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncaspar@mediamatics.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncchuang@iterated.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncgu@ltssun4.epfl.ch"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchien@frodo.ece.usu.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchristel.ekvall@haninge.trab.se"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchuanggu@microsoft.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncliff@reader.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncorset@lep-philips.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncrinonr@indy.tce.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nctchu@ctr.columbia.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndelmot@tele.ucl.ac.be"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndelnot@tele.ucl.ac.bc"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndeyu@bresson.ift.fhg.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndiana@hitchcock.dcf.scg.hac.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nram@hitchcock.dcf.scg.hac.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndufaux@crl.dec.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nebrahimi@epfl.ch"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\neferbper@beta.ist.utl.pt"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\neishi@flab.fujitsu.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\neleft@ctr.columbia.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\netoh@crl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\neude@issy.cnet.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfalcon@sina.eecs.berkeley.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfazadegan@gte.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfechter@ifn.ing.tu-bs.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfhg@tid.es"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nflaczko@ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfritz.seytter@zfe.siemens.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfukuhara@atom.isl.melco.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngarys@pictel.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngeorgec@clix.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngerard.fernando@sun.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngerken@tnt.uni-hannover.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngersho@ece.ucsb.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nghpark@super5.hyundai.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngisle.bjontegaard@fou.telenor.no"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngo@okilab.oki.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngparladori@tlt.alcatel.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngrajan@gi.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngrinnell@pictel.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngrm@dcs.warwick.ac.uk"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhakki@ee.bilkent.edu.tr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhana@gctech.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nharald.brusewitz@era-t.ericsson.se"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhayder@inuxs.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhdchang@video.etri.re.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nheidi@sarnoff.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nherpelc@tcernd1.hanover.tce.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhibi@trl.mkhar.sharp.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhomer@big.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhoyo@kjist.kjist.ac.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhrt@research.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhslee@erc.goldstar.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhsun@mcea.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nhyyoo@cadvax.etri.re.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nillgner@ient.rwth-aachen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nimura@adl.mci.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\niole@hc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\niraj@sarnoff.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nitoh@trdc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njan@hhi.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njhmoon@super5.hyundai.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njmuller@iterated.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njozawa@nttvdt.hil.ntt.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njsshin@saitgw.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njunglee@sarnoff.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\njwchung@vissol.kaist.ac.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nkatata@imgsl.mkhar.sharp.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nkaup@bsun11.zfe.siemens.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nkklee@saitgw.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nkoufum@atom.isl.melco.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nksc@philabs.philips.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlaurian.margarit@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nleonardo.chiariglione@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nleray@ccett.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlimin.wang@crc.doc.ca"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlist@fz.telekom.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nm.kar@cablelabs.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmiki@mlab.nttdocomo.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmin@corvette.crl.goldstar.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmingcl@microsoft.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmisezan@kodak.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmiya@tom.comm.waseda.ac.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmiyamoto@dsp.cl.nec.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmmartins@inescn.pt"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmmodena@tlt.alcatel.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmpeg4@hic334.decnet.bosch.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmroser@tid.es"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmzeug@iterated.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnakai@kansai.oki.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nneil@int.rdc.ricoh.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnieweglo@research.nokia.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noconnell@areaplg2.corp.mot.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noehler@hc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nogata@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nohm@hhi.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nolivier.avaro@issy.cnet.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nolle@fou.svrr.se"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nonural@ee.bilkent.edu.tr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noosa@elelab.nsc.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nostermann@big.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npaulo.correia@amalia.ist.utl.pt"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npchiang@daldd.sc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npcs@phoenix.dwe.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npmulroy@visual.bt.co.uk"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrjf@cs.strath.ac.uk"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrowlands@ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrusso@fub.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsakaida@strl.nhk.or.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nseno@drl.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nserkan@ee.bilkent.edu.tr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsfchang@ctr.columbia.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsikora@HHI.DE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsmita@clix.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsr@nt.e-technik.uni-dortmund.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsriram@nb.rockwell.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstefano.battista@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstuhl@nt.e-technik.uni-erlangen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsyo@comtech.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nt.einarsson@clab.ericsson.se"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nt.naveen@tek.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntalluri@csc.ti.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntchiang@sarnoff.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntekalp@ee.rochester.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntjs@risc.rockwell.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntktan@avirc.ams.com.sg"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntong@av.crl.sony.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntrgardos@ibeam.jf.intel.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntsuhan@big.att.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvialjf@tcetbs1.thomson.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvittorio@fub.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvsathe@gi.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwchen@microsoft.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwl03@lehigh.edu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwtnb@eel.rdc.toshiba.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ny-nakaya@crl.hitachi.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nyllee@saitgw.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nymachida@adl.mci.mei.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nymdkn@krhm.jvc-victor.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nyscho@dspsun.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nysseo@saitgw.sait.samsung.co.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nysw@nca.or.kr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nzmr@iis.fhg.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex* __ *2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Evaluated Documents*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"14%,25%,14%,47%\",]\n|===\n|Number |Source | |Title"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0552 |University of Hannover |tool |Motion and aliasing compensating\nprediction with quarter-pel accuracy and adaptive overlapping blocks as\nproposal for MPEG-4 tool evaluation - Technical description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0553 |Iterated Systems Inc. |algorithm |Iterated Systems, Inc. MPEG-4\nVideo Submission Technical Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0554 |Daewoo |algorithm |Daewoo algorithm for object scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0555 |Daewoo |tool |Daewoo proposal for region texture coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0557 |Phillips Research Laboratories |tool |Adaptive filter banks with\nsegmentation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0564 |Samsung AIT |algorithm |Video Compression Algorithm using Motion\nSegmentation and Color Perception"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0565 |Samsung AIT |tool |Shape Coding Tool: Using polygonal\napproximation and reliable residue error sampling method"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0566 |Samsung AIT |tool |Rate Control Tool: Based on Human Visual\nSensitivity for Low Bitrate Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0571 |Fondazione UGO BORDANI, University of RIME III |tool |Moving\nobjects versus still background classification: a spatial temporal\nsegmentation tool for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0573 |EPFL |algorithm |Improved Implementation Dynamic Coding of Visual\nInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0582 |Sharp Corporation |algorithm |Video coding algorithm for\ncompression efficiency"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0583 |Sharp Corporation |algorithm |Wavelet based video coding\nalgorithm for object scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0586 |Sharp Corporation |algorithm |Video coding algorithm using\nadaptive 2D-triangle mesh based prediction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0587 |Sharp Corporation |algorithm |Wavelet based layered algorithm for\nerror resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0592 |Vision Vector, Lehigh University, David Sarnoff Research Center\n|algorithm |A Video Coding Algorithm Using Vector-Based Techniques"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0595 |NHK |tool |Spatial Segmentation using K-means algorithm"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0596 |NHK |tool |Region Support DCT(RS-DCT)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0599 |NEC |algorithm |Video Coding Algorithm using Adaptive Warping\nPrediction - Technical Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0600 |Ericsson |tool |A tool for generating bit error resilient fixed\nlength code tables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0601 |Ericsson |algorithm |Low complexity encoder and error resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0602 |Universit\u00e4t Dortmund |tool |Grid Based Motion Compensation and\nShape Coding Using Curved Triangles"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0609 |Hitachi |algorithm |Technical description of Hitachi\u2019s proposed\nvideo coding algorithm Ver. 2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0615 |NTT |algorithm |Technical description of video proposal for\nMPGE-4 algorithm evaluation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0616 |Telenor Space R&D |tool |An error resilience method based on back\nchannel signaling and FEC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0617 |Telenor Space R&D |tool |A simple edge loop filter to reduce\nblocking and mosquito noise"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0620 |EPFL |tool |Arbitrarily shaped region interior coding using\nembedded zerotrees"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0623 |GTE Laboratories |tool |Use of inter-block compression to improve\ncoding efficiency of intra-coded frames"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0624 |GTE Laboratories |tool |Alternative to Border Extension in\nImage/Object Filtering"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0625 |Thomson Multimedia R&D France |algorithm |Technical description\nof the video coder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0637 |David Sarnoff Research Center |algorithm |Very Low Bit Rate Video\nCoder (Algorithm submission to MPEG4)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0639 |Microsoft Corporation |algorithm |Microsoft Proposal for MPEG4\n2nd Evaluation Phase"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0646 |PictureTel Corp. |algorithm |An MPEG-4 Video Coding Proposal\nUsing a Modulated Lapped Transform Enhancement of H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0650 |Hughes Electronics |tool |Low Bit Rate Object Based video coding\nusing Warping techniques"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0653 |Digital Equipment Corporation |tool |Background mosaicking"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0654 |Mitsubishi Electric Corp. |algorithm |Core Experiments of Video\ncoding with block-partitioning and adaptive selection of two frame\nmemory (STFM / LTFM)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0657 |U.C.L. /BELGACOM |algorithm |Region-enhanced H.263 coder : A\nTrial\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex* __ *3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Organization of the ad hoc group meeting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. Tools*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*For submitted tools, the adhoc group decided to achieve the following\ngoals during the meeting:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Suggest core experiments and group them into the context of core\nexperiments as suggested in the report of the adhoc group on\nCoordination of future experiments in MPEG-4 Video\n(ISO/IEC/JTC1/SC29/WG11/ MPEG96/0669) (Annex 5).\n* Classify tools according to the technical area they address (Annex 6).\n* Evaluate tools according to the evaluation criteria (Annex 6).\n* Provide a short abstract for each tool (Annex 6)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs far as classification and evaluation of tools is concerned, the group\nagreed to use the criteria adopted for the tools evaluation in November\n1995 (ISO/IEC/JTC1/SC29/WG11/N1064rev). These criteria are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Functionality: Which functionality is addressed?\n. Efficacy: How effective is the tool at meeting the goal of the\nfunctionality it addresses?\n. Encoder/Decoder: Is the tool to be used in the encoder or decoder?\n. Adaptability: Is the tool/algorithm applicable to a wide range of\nscenes, bitrates, error conditions, resolutions, delay?\n. Coding environment: Does the success of the tool/algorithm depend on\nparticular coding schemes? Has the tool/algorithm been presented as part\nof a coding scheme?\n. Standardization: Does the tool/algorithm require standardization?\n. Syntax: Does the tool/algorithm require or benefit from special\nsyntactic elements?\n. Added value: What are the merits of the tool/algorithm compared to\nother submitted or known tools/algorithms?\n. Margins for improvement: What are the margins and time frame for\nimprovements?\n. Complexity: What is the implementation complexity?"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach tool is evaluated according to these criteria (Annex 6)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. Algorithms"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*For submitted algorithms, the goals of the adhoc group are as follows*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Suggest video tapes for viewing by the video group (Annex 5)\n* Evaluate algorithms according to the evaluation criteria for\nalgorithms (Annex 7)\n* Provide a short abstract for each algorithm (Annex 7)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs far as evaluation of algorithms is concerned, the group agreed to use\nthe following criteria:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Functionality addressed\n. Picture quality (Better, similar, worse than the anchor), Frame rate\nof tape, Buffer control, Dominant artifact\n. Efficacy (How well are functionalities other than compression\naddressed?)\n. Adaptability: Range of scenes, Bitrates, Error conditions,\nResolutions, Delay\n. Algorithm characterization: Motion estimation, Motion compensation,\ntexture coding, Shape coding, syntax , others\n. List of relevant core experiments\n. Implementation Complexity: Encoder (Benchmark), decoder (Benchmark),\nreal time implementation available (Video DSP, ASIC, PC)\n. Additional advantages"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}9. Margin and time-frame for improvement"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. Evaluation process"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*In order to manage the evaluation of all the tools and algorithms in 2\ndays, the group decided to split up into subgroups each subgroups\naddressing one or more technical areas. It was decided that each group\nshould be populated by experts in the technical areas of the group.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe meeting was split into 4 groups addressing the technical areas of\nthe submitted tools and algorithms. The groups were addressing the\nfollowing technical areas:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGroup 1: Object functionality (Touradj Ebrahimi)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGroup 2: H.263++ (Boon Choong Seng)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGroup 3: Error resilience and others (Jim Brailean)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGroup 4: Wavelet and Mesh (Ya Qin Zhang)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVideo tapes were evaluated by looking at the results on a monitor\nwithout specified conditions. The results were compared against the\nanchors. In many cases, it was not possible to show the anchor and the\nproposal one after each other for the same bitrate."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 4*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Assignments of Submissions to Evaluation Groups*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"50%,50%\",]\n|===\n|Classification |Documents\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 5*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Recommendations of the AdHoc Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. Procedures*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Since all the proposers for the algorithms and tools were supposed to\nbe present at the meeting, the adhoc group recommends to present this\nreport to the MPEG-meeting for approval.\n. {blank}\n. *Tapes for viewing by the video group*\n. The adhoc group recommends several video tapes to be looked at by the\nvideo group. For algorithms addressing compression only, they had to\noutperform the anchor or provide inherent functionalities which are not\nor only difficult to be achieved using H.263 or MPEG-1. From the range\nof proposals that satisfied the conditions above examples were selected\nwhich cover the main ideas presented.\n. The adhoc groups recommends to look at all the coded MPEG-4 test\nsequences submitted by Microsoft (639), Iterated Systems (553), Sharp\n(583), Lehigh (592).\n. *New core experiments*\n. Only core experiments on areas currently not covered by the adhoc\ngroup on coordination of future experiments in MPEG-4 video are\nrecommended.\n. The adhoc group recommends to conduct a core experiment on\nobject-based temporal scalability (582).\n. The adhoc group recommends to conduct a core experiment on modulated\nlapped transform (MLT) (646, 557)\n. The adhoc group recommends to conduct a core experiment on automatic\nsprite generation (653).\n. The adhoc group recommends to conduct a core experiment on adaptive\ninter-coded I-frame (623).\n. *Syntax*\n. The adhoc group recommends to consider the following observation:\nAlgorithms addressing new functionalities tend to require a syntax\nsignificantly different from existing video coding standards.\n. *Others*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe adhoc group recommends that principles as employed by the tool\nproposal 600 be considered when designing fixed length codes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe adhoc group recommends to develop a proper complexity metric in\ncollaboration with the implementation group."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 6*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Evaluation of tools*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 552"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : motion and aliasing compensating prediction with\nquarter-pel accuracy and adaptive overlapping blocks"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Ulrich Benzler (University of Hannover)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: H.263++ *Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: This tool addresses motion compensation with quarter-pel\nprecison. It also incorporates an adaptive switching between overlapped\nMC and non-overlapped MC. The tool is implemented on the basis of the\nMPEG-2 TM5. For each 16x16 block, one (for P-frame) or two (for B-frame)\nmotion vectors of quarter-pel accuracy are estimated by conventional\nblock matching. Luminance amplitudes for estimation and prediction on\nfractoinal pel locations are calculated by using special anti-aliasing 8\ntap interpolation filters. The estimated motion vectors are applied\neither to block or to overlapped block motion compensating prediction.\nCompared to MPEG-2 one additional macroblock attribute is introduced\nwhich indicates if overlapped block motion compensation is enables or\nnot. While increasing the amount of motion vector data, this tool can\nsuppress the prediction error to be coded. The simulation results show\nthat 1.0 dB gain in the PSNR can be obtained at the constant bitrate of\n1.0 Mbit/s compared to MPEG-2 TM5."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |statistically 0.9 dB increase at maximum, subjectively\nbetter than the reference provided for some sequences misgiving of the\nreference (MPEG2 gives more overheads)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |both"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |generic"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |block-based coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |minor modification of H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |delay = MPEG-1/2 + delay due to overlapped MC\ncomputation: interpolation 8 weighted addition : overlapping 9 weighted\naddition overall moderate increase in complexity\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRecommendation : need to evaluate performance of quarter pel MC only.\nUncertain whether the improvements come from quarter pel MC or\noverlapped MC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo recommended core experiment without further contribution"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 555"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Daewoo proposal for texture based coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Choong-Soo Park (Daewoo Electronics Co. Ltd. and KAIST)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object Functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: The purpose of this proposal is to introduce an efficient\nextension method for coding pels in arbitrarily shaped image segments\nusing normal block DCT. The proposed method, called\nExtension-interpolation make arbitrarily shaped objects within NxN image\nblocks into an NxN square shaped region. It successively extends each\nrow data into data of size N, and extends each column. The exclusion is\ndone by interpolation (changing sampling rate) in frequency domain."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |content-based functionalities, coding\nefficiency"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |not enough evidence available"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |both - need something more than conventional IDCT\nat decoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |generic"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |region based"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |1D to 2D extensions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |lower than SA-DCT and higher than DCT.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 557"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Variable Size Lapped Transforms with Segmentation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Rob Beuker (Philips Research Lab.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: H.263++ *Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe proposed method aims at adapting the transformation to the scene\ncontent locally. The method is applied to the full frame in intra-frame\nmode and to the frame difference in inter-frame mode. The adaptation,\ncalled segmentation, is done in three steps. In the first step the best\nlapped transform in the Rate-Distortion sense is obtained. In the second\nstep regions with the same transform are taken together. In the last\nstep each region will be coded separately. The resulting segmentation\nhas to be transmitted to the decoder. The proposed tool works in\nprinciple with any combination of transforms and coding methods. The\nonly requirement is that there is a provision in the coding process to\nswitch between the transforms while maintaining (near) perfect\nreconstruction. For example, using linear-phase transforms, this is\neasily accomplished by mirroring at the region boundaries. Current\nresults show that blocking artifacts are removed without introducing\nadditional ringing artifacts."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |Compression."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |Reduction of the block noise, introduced overhead lower\nthan 3%."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |Both."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |Generic."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |Variable block-based scheme."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |Yes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |Integrated into H.263."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |Parameters optimization, inter frame."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |2 times for intra encoder, comparable for decoder.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCore experiments: recommended for core experiment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 565"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Shape Coding Tool: Using polygonal approximation and\nreliable error residue sampling method"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Jae-Seob Shin (Samsung AIT)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object Functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: Tools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: A scheme of shape contour coding, which uses a simple and\nreliable eror sampling method polygonal aproximation (PA) error. Since\nPA codes a given shape contour into a polygon, it gives a continuous\nerror signal along the polygon."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |content-based functionalities"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |should be compared to other similar tools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |both"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |generic; bitrate independent"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |object/VOP based environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |yes; spatial shape coder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |bitstream scalability,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |absolute to relative addressing, interframe\ncoding, initial choice of vertices"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |more complex than chain coder or quadtree coder; less\nthan perpendicular error distance measuring method.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues: Implications on quality by using horizontal-vertical\ndistance versus perpendicular distance."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 566"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : rate control based on Human Visual Sensitivity"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Jae-Seob Shin (Samsung AIT)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: H.263++ *Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: generic"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: This proposal addresses a new rate control strategy conforming\nto the MPEG/H.263 syntax that assigns quantization step sizes adaptively\nbased on the human visual sensitivity for luminance and color components\nin the macroblock. The new rate control strategy allocates the target\nnumber of bits and adaptively assigns quantization step size based on\nthe human visual sensitivity and the complexity of the picture to be\ncoded. The proposed rate control strategy consists of the following\nsteps. First, a 16x16 macroblock is classified into one of 8 macroblock\nclasses based on human visual sensitivity for luminance and color\ncomponents in the macroblock and then an 8x8 block is classified into\none of block classes by its variance. Next, the target number of bits is\nallocated to a block and the quantization step size is assigned to a\nmacroblock. The result of subjective tests showed that the proposed rate\ncontrol strategy considerably improve the picture quality of the\nreconstructed video sequences over the conventional strategy. Especially\nin the proposed strategy, the subjective picture quality between frames\nwas more constant and hence was less degraded than conventional rate\ncontrol strategies."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |compression\n|2. Efficacy |no evaluation\n|3. Encoder/Decoder |encoder\n|4. Adaptability |generic\n|5. Coding Environment |generic\n|6. Standardization |no\n|7. Syntax |no modification\n|8. Added Value |no\n|9. Margins for improvement |refinement of MB clssification\n|10. Complexity |comparable or lower than TM5 rate control\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 571"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Moving objects versus still background\nclassification: a spatial temporal segmentation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntool for MPEG-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: S. Colonnese (Fondazione Ugo Bordoni)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: Tools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis spatial-temporal segmentation method exploits advanced Higher Order\nMoments (HOM) based motion detection techniques. The spatial-temporal\nobject evolution is represented by the warping of flexible meshes,\narranged by a collection of adjacent quadrilaterals, whose vertices are\ntracked along the group of frames."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVarious coding strategies can be envisaged. The mapping of the\nquadrilateral patches of the meshes into fixed size square blocks by\nmeans of perspective transformations is suggested in order to apply\nsimple block based 3D or Hybrid 2D transforms to the obtained regular\ndomain."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |content-based scalability, coding\nefficiency"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |not enough evidence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |both"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |suitable for still backgrounds"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |3D coding technique using warping and 3D\northogonal transforms may give more efficiency"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |Yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |Yes (not completely defined yet in the proposal)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |temporal tracking"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |improvements on all steps possible:\ntracking of objects, 3D warping and orthogonal coding; extensions to\nmore generic scenes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |could be large + delay\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues: Arbitrary shapes as opposed to 8x8 blocks"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAccuracy of cumulants estimation over 8x8 blocks"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 595"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Spatial Segmentation using K-means clustering"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Shinichi Sakaida (NHK)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: tool"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: This tool is a method of image segmentation using the K-means\nclustering algorithm. The segmented regions are merged by a\nmorphological filtering and small isolated regions removed. The final\nboundaries are driven from the results which are obtained by different\ninitial conditions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |automatic spatial segmentation for\npreprocessing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |only two scenes were tested - may be effective as\npreprocessing for content based functionality but not enough evidence\ngiven to prove it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |to be used in the encoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |do not know"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |no; not been presented as a part of the coding\nscheme"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |no"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |no"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |not tested sufficiently with other sequences - not\nenough evidence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |maybe simpler than other segmentation tools.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 596"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Region Support DCT (RS-DCT)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Shinichi Sakaida (NHK)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object Functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: Tools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: This is a tool for an arbitrarily shaped texture coding. High\ncoding efficiency is achieved by modified transform basis vectors\naccording to the shape of regions, maintaining the compatibility with\nconventional rectangular IDCT schemes. Although an iteration process is\nemployed in the encoder, the technique requires easily implementable\ncomputations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |content-based functionalities, coding\nefficiency"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |at larger block sizes (16x16 and 32x32) it seems to\nimprove the coding efficiency"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |Encoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |Is applicable to a wide variety of conditions?"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |useful for region based coding schemes (like\nSA-DCT ); tool not been presented as a part of a coding scheme"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |framework of the took requires standardization but\nthe detailed procedure does not"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |yes - end of section 3.1 seems to indicate that 2 sets of\nDCT coefficients may have to be sent - shape info is needed at the\ndecoder end in order to synthesize the image"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |high energy compaction; high frequency analysis\ncapability (see section 5)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |improve coding efficiency can be improved\nby optimal selection of the coefficient set taking quantization and VLC\nprocesses int account."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |encoder: requires more computation than a 2D-DCT\ndecoder: conventional 2D-DCT used.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 0600"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Tool: Ericsson"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Harald Bruewitz"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Group 3: Error Resilience and Others"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Error Resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn FLC can be designed to minimize effects from transmission errors. If\ndata to be coded has a peaky PDF document number 600 provides a method\nto design such FLCs. Matlab source code to generate FLCs will be\nprovided to MPEG members on request."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Error Resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |Error resilience properties enhanced with peak PDF"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |Design tool for encoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |Not required"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |real time implementation cost in performance. Scalable\ncomplexity"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |could be made adaptive, this may impact\nboth encoder and decoder.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 602"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Grid Based Motion Compensation and Shape Coding Using\nCurved Triangles"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: K. Schroder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Mesh/warping and wavelets"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: A"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis tool proposal provides a technique for automatic construction of\ntriangular grids for video objects defined by a given segmentation mask.\nWhereas the contour of an object is described by the outline of the\ncorresponding grid, the displacement vectors of all grid points are used\nto predict the objects\u2019s motion. Contour description is enhanced by the\nuse of curved triangles, which consist of two straight lines and one\narc. A modified block matching scheme which disfavors luminance\ndifferences for pixels close to a grid point is used for motion\nestimation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |Object Scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |N/A"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |Mainly encoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |Scene with small number of objects, applicable to\nClasses A/B"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |Not tested"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |Needed"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |Major modification required (shape coding)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |Coding efficiency has room for improvement"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |The complexity Grid construction in the first frame is\nin the same magnitude as full-search BM. It is much simpler for the\nfollowing frames, depending on # of objects.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 0616"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Tool: Error method based on back channel signalling and FEC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: :Gisle Bjontegaard"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: 3: Error Resilience and Others"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Error Resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis tool submission combines back channel signalling with Forward Error\nCorrection (FEC) to provide improved video quality when operating over\nseverely degraded channels. The video encoding algorithm is based on\nH.263 and requires a \u201cGOB-like\u201d structure. The proposal utilizes the\nfollowing elements: confined prediction range (i.e., within a GOB), mux\npackets are aligned to the GOB boundaries, error detection is performed,\npackets in error are discarded. Based on the ability to signal the\nencoder through a back channel, this tool attempts keep the encoder and\ndecoded synchronized by requesting that certain GOBs be encoded using\npreviously decoded frames that were received without errors. That is,\nthe decoder can request that the encoder use a previously received,\nerror free, frame to predict the GOB receieved in error. The assumption\nis that the encoder still has this frame. If this is not true, then the\nencoder may transmit a GOB of all intra blocks."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Errorr Resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |Very Effective at removing the effects of both randaom and\nburst errors. Quality is similar to H.263."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |Tool effects both encoder and decoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |scalable delay effects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |yes, also requires localization of within a frame\n(i.e., GOB structure)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |Minor changes to H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |New frame localization approaches\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues: Additionl frame memories could increase complexity."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 617"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : A simple edge loopfilter to reduce blocking and\nmosquito noise."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Gisle Bjontegaard (Telenor)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: H.263++ *Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA loop filter is used to reduce blocking artifact and mosquito noise.\nThe filter reduces pixel differences across block edges. The filter has\n4 taps and is applied only to edge pixels. The filter is not used in\nstationary parts and if pixel differences are large. The filter is based\non 8x8 blocks and applied to"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nluminance and chrominance."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |0.3 dB for intra mode, 0.1-0.2 dB for inter mode.\nSubjectively reduce blocking artifacts."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |Loop filter at both the encoder and the decoder\nside."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |Generic scenes, wide range of bit rates and\nresolutions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |Block-based coding schemes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |Yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |No"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |No"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |Left to core experiments."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |More memory access and additional computation are\nrequired compared to H.263.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCore experiment: N1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: M0620"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Arbitrarily Shaped Region Interior Coding Using\nEmbedded Zerotrees"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Touradj Ebrahimi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Wavelet, Mesh/Warping Based Techniques"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis tool submission addresses the problem of coding the interior\ntexture of arbitrarily shaped regions. The key novelty of this tool is\nthe use of an arbitrarily-shaped subband transform followed by a\ngeneralized embedded zerotree wavelet algorithm. This approach has been\nshown to perform better than the shape-adaptive DCT for coding\narbitraily shaped region texture. In addition to the good compression\nresults, the tool provides a progressive bitstream for the texture\ninformation within the objects. Additionally, the tool can provide for a\nlossless compression mode by using an appropriate filter bank."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |compression, object scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |better than shape adaptive DCT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |both"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |independent from bitrate and scene, shape coding may\nset a lower limit on bitrate"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |region/VOP based coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |progressive bitstream for texture coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |improved padding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |comparable to shape adaptive DCT\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues: How to distribute bits among different objects in a\ncomplete system. Detailed comparison with shape adaptive DCT is not\nprovided."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 623"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Inter-Block Compression to Improve Coding Efficiency\nof Intra-Coded Frames"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Faramarz Azadegan (GTE Laboratories)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: H.263++ *Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: This tool is an approach for exploiting the spatial redundancy\nof an intra-frame coder, in particular, by extending the current H.263\ncoding system to further incorporate inter-block redundancy of I-frames.\nThe only variation, which is used for I-frame coding, is to incorporate\nuse of inter macroblock (MB) spatial redundancy for possible further\nreduction in the encoding system. The frame level and GOB level\nstructure remain the same as H.263. At each MB, a decision is made as to\nwhether to encode the MB in intra format or to encode its difference\nfrom the MB directly above, or its difference from the MB to its\nimmediate left. The difference is coded in the DCT domain. A separate\nVLC table can be designed for encoding of residual blocks both for DC\nand other coefficients which can provide a better match to the\nstatistics of these blocks. The simulation results indicate that a\nsaving of about 5% to 30% in total number of bits for intra frame can be\nachieved by this procedure, for the CIF sequences considered. The\nresults for QCIF sequences indicate savings between 2.5% to 28%."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |4% - 30% reduction in bit for Q=10 good enough as\npotential technique"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |both"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |sequences class A and B"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |block-based coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |minor modification of H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |extension to intra-macroblock coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |comparable to H.263\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 624"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Alternative to border extension in image/object\nfiltering"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Faramarz Azadegan (GTE Laboratories)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object Functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: Tools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA method for handling the borders of a picture or an object is\ndiscussed. The tool can be specifically useful in filtering for\nmulti-resolution representation of objects."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |object based coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |experiments only on images - should be experimented on\nobjects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |both"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |restricted at this stage to convex objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |used in the context of subband/wavelet\nrepresentation/coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |no"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |scanning for non-convex objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |not complex\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues: No tests on objects yet."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 650"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Object based video coding using warping prediction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: N. Nagarajan, R. Burns, and P. Au"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Mesh/warping and wavelets"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: A"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe proposal outlines a coding technique which uses image warping for\nmotion compensation and a combination of DCT and an adaptive Lempel-Ziv\nalgorithm for residual coding. The first frame of the a sequence is\nencoded with JPEG; following frames are predicted by image warping based\non manually selected control points. No details on the motion estimation\nare given."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTarget bit rates for the Akiyo sequence are in the range from 24..48\nkbits/sec, but no specific data rates are given which were achieved with\nthe proposed tool. The information provided is not sufficient to\nevaluate the technical contents."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |Cmpression\n|2. Efficacy |N/A\n|3. Encoder/Decoder |Minely encoder\n|4. Adaptability |Uclear\n|5. Coding Environment |JPEG for the 1st frame, and DCT+LZW for residual\n|6. Standardization |Needed\n|7. Syntax |Major change of H.263\n|8. Added Value |Potential Object-based scalability\n|9. Margins for improvement |Uclear\n|10. Complexity |Could be very complex\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues: Not enough information provided."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 0653"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of the Tool : Background Mosaicking"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Frederic Dufuax (Digital Equipment Corporation)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object Functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass: Tools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tool proposes a technique to construct a background mosaic by\nsegmentation of the background and foreground, camera motion estimation,\nand temporal integration of the background content. The tool is\nappropriate for a layered representation and can be used to construct a\nhigh resolution panoramic view of the background."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|1. Functionality Addressed |content-based functionalities"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Efficacy |a video tape would be desired"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Encoder/Decoder |both"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability |depends on the model used for motion description -\ndominant motion is needed in the scene"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Coding Environment |VOP based or block based"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Standardization |Yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Syntax |Yes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |automatic segmentation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |segmentation of background/foreground"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10. Complexity |comparable to sprite generation\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(1) What happens when there is no dominant motion in the scene ?"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(2) Estimation of accurate motion"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(3) How large the background memory should be ?"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 7*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Evaluation of Algorithms*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 0553"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Iterated Systems Algorithm"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: John Muller"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Group 3: Error Resilience and Others"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis is a variable block size forward prediction coder. It uses H.263 to\ncode the first frame in intra mode. After the first frame all frames are\ncoded using variable block size forward prediction. The prediction data\nfor each block consists of an address, (x,y), on the previous frame, an\nintensity shift, q, and a mask that determines which quadrants of the\nblock use this (x,y) and q data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|The results produced by the algorithm was considered to be better than\nthe anchor for most of the class A and B sequences. The algorithm was\nnot as good as the anchor for many of the sequences at the lowest\nbitrates."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Generic input, has some problems with uncovered background when\ndealing with low bitrates. Was shown to be effective over a wide range\nof bitrates (ClassA, B, C, and E). Limited delay due to forward\nprediction."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax |Variable block-size motion\nestimation with overlapping motion compensation. When motion fails,\ntexture coding is limited to intensity displacement parameter. Would\nrequire major modifications to known standards\u2019 syntax."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of relevant core experiments: |Recommended for further review\nby the Video Group."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |Complexity is scaleable.\nHigher than H.263. Less complex than H.263. Not for submitted algorithm,\nbut a Real-Time implementation using video processors exists."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |Although not implemented for this submission, the\nauthors briefly sketch how the coder could address some object based\nfunctionalities, such as using segmentation data and coding arbitrarily\nshaped regions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |To improve quality the coder should benefit\nfrom a better first frame coding , and half pixel motion vectors. To\nreduce encode complexity the coder should use more efficient search\nstrategies.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues: Potential difficulties in making error resilient."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 554"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Daewoo proposal for object scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Jin-Hun Kim (Daewoo Electonics Co.Ltd and KAIST)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object Functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: This algorithm is based upon H.263 and accomodates additional\nfunctions which can effectively solve the problems in object\nscalability. We approximate the contour efficiently using polygonal\napproximation and error compensation using DST. And, this proposal uses\na new arbitrary shape coding method called ZSFD (zero stuffing in\nfrequency domain), which outperforms existing arbitrary shape coding\nincluding shape-adaptive DCT."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |object scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|( similar or worse than the anchor) but func. is NOT compression 10 no\nBlocking and shape of objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |Good approximation to object shapes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |only class A demonstrated - may be possible for other classes.\ndemo only at 48 kbps - may be possible at other bitrates too. not\ndemonstrated resolution independent similar to H.263 (could be one delay\nframe higher)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax Other |Textures similar but contours\ndifferent from H.263 Similar to H.263 Different from H.263 - uses ZSFD\npolygon + DST + compensation major extensions to H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Accommodated by the following Core Experiments: |S4, O4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |More complex than H.263\nSlightly more complex than H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |Coding of shape/contours can\nbe improved. Texture coding:\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues: Fast deformation of moving objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 564"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: video compression algorithm using motion segmentation\nand color perception"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Jae-Seob Shin (Samsung AIT)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: H.263++ *Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: The proposed algorithm has a block-based MC-DCT structure that\nis equipped with motion analysis, DCT, fixed block size based\nquantization (like as Macro Block), but one of key feature is the motion\nsegmentation which merge several blocks into a processing unit as the\nresult of motion analysis. For reducing the amount of bits, this scheme\nextracts the accurate motion information and motion segment by using the\nembedded interaction between motion information and motion segment.\nMoreover, the residue suppression technique uses the Human Perceptual\nSensitivity(HVS) characteristic for the chrominance signal with the\nresidue signal after motion compensation. Rate control strategy is very\nsimilar to H.263 except small additional features."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |compression A, B, C"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|similar to worse similar to anchor TMN5 rate control chroma shift"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |generic scene, wide range of bitrates and resolution lower than\nthe anchor, same as TMN5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax Others |affine motion\nestimation/compensation DCT modified chain coding minor modification to\nH.263 motion segmentation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of relevant Core Experiments: |P4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |twice of H.263 for\naffine ME (encoder)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |expected for block based\nobject scalability\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 573"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Dynamic Coding of Visual Information: Improved\nImplementation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Touradj Ebrahimi (EPFL)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object Functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe dynamic coding concept consists of a joint content-based image\npartitioning and representation. The specific implementation proposed\nhere is dedicated to low bitrate applications and is based on a\nrate-distortion optimization of a quadtree partition populated with\nseveral compression techniques (DCT with different quantizations, motion\nestimation, DFD coding, fractal, bi-level representation). It can\nprovide either full frame compression or object scalable compression.\nThe corresponding syntax is by nature flexible and opened enough to\ninclude new compression techniques."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression and Object Scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|similar or worse than the anchor 6 Hz No smoothiness"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |precise shape"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Classes A and B demonstrated Lower bitrates No Independent of\nresolutions similar to H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax |YUV space - block matching similar\nto H.263 but with quadtree and variable sized blocks several techniques\nChained coding on filtered contours fully different from H.263;\nobject/VOP based syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Accommodated by the following Core Experiments: |P5, S4, N1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |Much higher than in\nH.263 Higher than H.263 No (real time implementation not available\ntoday)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |flexibility"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |arbitrary shapes, enhanced\npartitioning, still based on quadtree shapes, new techniques for coding\nof every region, a priori selection of coding techniques; short to\nmedium term\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 582"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of algorithm: Video Coding Algorithm for Compression Efficiency"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Hiroyuki Katata (Sharp Corporation)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: An algorithm for improved coding efficienty and object based\ntemporal scalability is proposed. The basic idea of the algorithm is\nthat the selected region is coded with higher frame rate than that of\nthe other regions. This algorithm is based on the temporal scalability\nmethod proposed for MPEG-4 first round of test in November 1995."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Temporal scalability, compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|similar to the anchor 3-5 for Base layer and 10-15 for Enhanced layer\nno Same as H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |temporal scalability is very good for scenes with\nstationary backgrounds, eg, Hall monitor . It is targeted towards low\nbitrate applications with stationary backgrounds - not sure about higher\nbit rates with moving backgrounds (panning, zoom )"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |slow moving backgrounds low to medium ? no independent Higher\nthan H.263 depending on the base layer frame rate."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax Other |same as H.263 same as H.263\nsame as H.263 rectangular representation same as H.263 with some\nextentions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Accommodated by the following Core Experiments: |New core experiment\n\u00d4object based temporal scalability\u00d5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |slightly higher than\nH.263 slightly higher than H.263 no"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |Rectangles for shape\nrepresentation could be reduced from macroblock size to object size.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMoving background"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLarge number of moving objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nArbitrary shape representations"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: M0583"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Wavelet based video coding algorithm for object\nscalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Tomoko AONO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group Wavelet and Mesh/Warping*)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Compression and Scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis document proposes a wavelet based video scheme for object\nsacability. The objects\u2019 boundry information is assumed to be provided\nto the coder in the form of video object planes (VOP). To encode each\nframe, first object wavelet transform (OWT) is applied to each object of\nthat frame. OWT is combination of arbitrary shaped wavelet transform\n(ASWT) and coding coeffiecnet selection (CCS). Then, one of two\ndifferent zero-tree coding is used to encode the wavelet coeeficient of\neach object. This proposal uses EZW for objects in intra frame and\nnon-embedded zero-tree coding (doc #441) for inter frames."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo remove the temporal redundancy the H.263 motion estimation shceme is\napplied here to each object, but only the motion vector corresponding to\nthat object is coded and transimitted. The decoder also uses H.263\nmotion compensation. The segmentation information is chain coded and\ntransmitted to the decoder. The submitted proposal has not employed any\nrate control scheme yet. Demonstrated video quality is similar to that\nof H.263."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Object Scalability, Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|similar 10fps No Noticable separation of object from background"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |effective coding of pre-segmented objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |as long as segmentation is provided tested for 48kbps, shape\ncoding may impose a lower limit not tested yet no restriction similar to\nH.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax of H.263 |similar to H.263 similar to\nH.263 object wavelet coding chain coding with DPCM overall syntax is\nVOP, new syntax for texture coding, motion part could use syntax of\nH.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Accommodated by the following Core Experiments: |O3 and O2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |if segmentation is\nprovided, complexity depends on number of VOPs depend on number of VOPs,\nfor 4 VOPs, similar to H.263 No"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |No"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |can use better segmentation\nand/or post-processing within MPEG-4 time-frame\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 586"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Adaptive 2D-triangle mesh based prediction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: K. Hibi, N. Ema, and S. Sato"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Mesh/warping and wavelets"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis algorithm proposes a video coding method using a novel motion\ncompensation technique which uses an adaptive 2-D triangle mesh based\nprediction. There are two main contributions in this proposal. The first\nmajor contribution is the use of different segmentation types for each\nmacroblock. There are totally eight additional segmentations modes which\nconstitutes several various shapes of triangle meshes. A macroblock can\nbe divided into two, five or eight regions. Each region is warped using\nthe affine transformation. Additional motion vectors (at most three more\nvectors) are encoded and transmitted to the decoder for reconstruction.\nThe second major contribution is the technique to evaluate the cost of\nmotion estimation. The proposal gives a new cost function which is\nreferred to as SWAD( Sum of Weighted Absolute Difference). This new cost\nfunction are composed of a sum of product. The product is composed of\nweight function mask, weight function and absolute difference. It is\nrecommended that the algorithm be futher experimented in \"P6\" core\nexperiment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|Worse 10 fps Same as TMN5-1.6 Reduced block artifacts, pronounced\nmosquito noise"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |Potential object scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Same as H.263 with PB frames"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax Others |Switching between block\nmatching and triangular mesh 9 estimation modes DCT No shape coding\nMinor change of H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of relevant core experiments: |P6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |4 times more complex\nSlightly more complex N/A"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |Potential object scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |Non-trivial improvement maybe\npossible before next meeting Optimization of motion estimation modes\nMore efficient motion vector coding\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 0587"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Wavelet-Based Layered Coding Algorithm for Error\nResilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Keiichi Hibi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Error Resiliency and Others."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Error Resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWavelet based layered coding; subband by subband transmission. Wavelet\ncoefficients are directly quantized and then scanned and 2-D VLC coded.\nError detection by CRC-16. Insertion of resynch word in horizontal block\nline in subband with multiple of 4 byte length. No FEC in case of burst\nerror, lower 4 subbands are protected by FEC for random errors."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Error Resiliency"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|Video able to resynchronize, but quality suffers. 5 fo Akiyo. 3 for all\nothers. fixed stepsize"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Tested for generic input at Class A. 24kbps. 10e-3 random and\nburst. Tested for QCIF, extensible to higher dimensions. Low, 1/3 of\ncoded frame interval."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax |Block Matching 16x16 Block based MC\n(as in basic mode of H.263) Wavelet-Based No Major changes to H.263\nrequired."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of relevant core experiments: |E1. E2 - layered FEC. Texture\nCoding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |Similar to H.263. No."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |Low delay. Scalability."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |Could improve - prediction efficiency -\nWavelet coefficient coding method - by using some kind of intra refresh,\nperhaps subband refresh Could be combined with other preoposed error\nresilience methods.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: M0592"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Video Coding Algorithm using Vector-based Techniques"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Weiping Li, Lehigh University"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Wavelet and Mesh/Warped-Based Motion Techniques"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe proposed algorithm mainly addresses the functionality of improved\ncoding efficiency for compression. It demonstrates vector-based\ntechniques for coding intraframes (the first frame and subsequent\nrefreshing key frames). In the demonstration, interframes are coded\nusing H.263. Each intraframe is first decomposed into a set of vector\nbands using a vector transform or a vector filter bank. This stage of\nvector-based signal processing makes subsequent vector quantization in\nthe vector bands very efficient. Adaptive lattice vector quantization is\nthen used in the vector bands. A 100% labeling efficiency is achieved\nfor lattice vector quantization by using a set of generalized labeling\nalgorithms for various important lattices with pyramid and sphere\nboundaries. A quantization table is used to specify the scaling factors\nfor lattice vector quantization in various vector bands. An adaptive\nalgorithm is used to determine the number of stages of lattice vector\nquantization in every vector band and the vector dimensions at every\nstage of lattice vector quantization to insure a desired image quality\nwhile using just enough bits. A threshold table is used to control the\nquality/bitrate tradeoff in the adaptive algorithm in the vector bands.\nFinally, entropy coding is used to code the indexes generated from\nlattice vector quantization. Intraframe results show a PSNR gain of 3 to\n8 dB over H.263 at bitrates of 20 Kb per frame and 16 Kb per frame.\nSubjectively, the algorithm shows \"grainy\" type noise rather than the\nblocky artifacts common to DCT. This method could also be used to encode\ninterframes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|Similar to H.263. 10 Fr/sec. None Grainy quality with some block edges\nappearing at lower bitrates."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |Limited spatial scalability due wavelet-based approach"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Generic input Tested for Class A, can scale to higher bitrates.\nNot tested. No restrictions. Similar to H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax |Same as H.263 Same as H.263\nVector-Wavelet Coding Not applicable Require new syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of Relevant Core Experiments: |T5, and T6."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |On SPARC 20, 2\nFrames/per minute (encode and decode) No"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |No codebook training required."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |Expected that coding\nefficiency can be doubled by optimizing coding parameters, within MPEG-4\ntime-frame.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 599"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Adaptive warping prediction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Y. Miyamoto (NEC Corp.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Mesh/warping and wavelets"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis algorithm proposes an adaptive warping video coding scheme based on\nthe H.263 framework. The algorithm includes prediction mode selection,\nand such conventional prediction modes as Intra, block-based MC and\nbackground prediction are incorporated. Although the warping prediction\nis effective for most of picture region, the additional modes are\nvaluable for use on the boundaries of moving objects. In a test\nsimulation, they demonstrate the ability of the proposed method to\nproduce subjective quality equivalent to that of H.263. It is\nrecommended that the algorithm be further experimented in \"P6\" core\nexperiment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|similar picture quality 5 fps same as TMN5-1.6 jerky motion and block\nartifacts"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |potential object scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |same as H.263 without PB frames"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax Others |adaptive prediction with 3\ndifferent modes 3 estimation modes (Warping, BMC, and Background\nprediction) DCT coding minor change of H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of Relevant Core Experiments: |P6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |encoder: 2-3 times more\ncomplex decoder: similar"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |potential object scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |non-trivial improvement maybe\npossible before next meeting bi-directional warping prediction\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 0601"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Ericsson"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Harald Bruewitz"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Group 3: Error Resilience and Others"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Error Resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe algorithm uses a DCT outside predictive loop, such that frame memory\nstores DCT components. Motion compensation is not used. Inter/Intra\ncoding is selected by the encoder on a DCT component basis. It turns out\nthat the best compression is achieved with only a few low frequency\ncomponents coded as inter (the number is signalled by VLC) and the\nremainder coded as intra. This fact automatically provides error\nresilience, as earlier errors are continuously cleaned up."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Error Resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|Lower than anchor. However, has the potential to out-perform the anchor\nwithout motion compensation (i.e., low complexity mode of H.263)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |waveform coder can handle generic input performance degrades for\nsequences where motion compensation is very effective. Limited delay, no\n\u201cB-type\u201d frames."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax |None None DCT, outside predictive\nloop. Intra/inter decision made on DCT coefficients. None Simplified\nH.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of relevant core experiments: |Error resilience"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |Complexity is low.\nSuitable for low power designs. Less complex than H.263. Comparable to\nH.263. None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |Low power applications can be accommodate."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues: Complexity should be considered when evaluating core\nexperiments."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRecommendations: Once a suitable metric is defined for measuring\ncomplexity, a core experiment should be defined to investigated a low\ncomplexity mode with acceptable quality."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 609"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Multi-mode Motion Compensation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Y.Nakaya (Hitachi, Ltd.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: Mesh/warping and wavelets"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis algorithm proposes a multi-mode motion estimation and/or\ncompensation scheme based on the H.263 framework. The multi-mode motion\nE/C switches between 4 different modes : (1) 16x16 block matching, (2)\nfour 8x8 block matching, (3) the average of (1)+(2), and (4) bilinear\ntransformation, based on the SAD. The algorithm has been tested in the\nTMN5-1.6,and shows similar subjective performance in class A/B\nsequences. It is recommended that the algorithm be futher experimented\nin \"P6\" core experiment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|similar picture quality 10 fps same as TMN5-1.6 block artifacts as in\nTMN5-1.6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Wide Wide as H.263 the same as PB-mode in H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax Others |multi-mode including\n(BM,4blocks,Average,Bilinear formation) substraction DCT coding N/A\nminor extension of H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of Relevant Core Experiments: |P6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |encoder: 2-3 times more\ncomplex decoder: similar N/A"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |non-trivial improvement maybe\npossible before next meeting (1) non-uniform mode selection with miniumn\nimage performance penalty with reduction on Mode selection overhead (2)\nsmoothing across block boundary, such as O BMC\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 615"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: H.263 based video coding algorithm using two-stage\nmotion compensation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Hirohisa Jozawa (NTT)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: H.263++ *Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: This technique is based on the H.263 and additionally employs a\ntwo-stage motion compensation (MC). The first stage is global MC and the\nsecond one is local MC employing overlapped block affine MC. The\nalgorithm is the modified version of the proposal submitted for MPEG-4\nfirst round of video tests (see MPEG95/0421). The coding algorithm is\ncomposed of several techniques, block-based prediction with two-stage\nMC, block transformation, quantization, coding of quantized transform\ncoefficients, motion parameter coding and rate control. Although\noverlapped block MC is used in H. 263, an affine motion model is adopted\nto compensate for rotation and scaling in addition to translational\nmotion. Global MC is effective especially for sequences with fast\nmotion, and local affine MC is effective for sequences with scaling or\nrotation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|strong majority similar, better for some sequences with fast motion\nrelative to the reference. Variable frame rate. similar to reference\nprovided by NTT CBR, TMN5 rate control No"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |efficient for global motion"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |generic wide range of bitrate, resolution comparable to reference\nprovided"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax Others |global ME, overlapped affine\nME global MC, overlapped affine MC DCT, adaptive VLC (same as LA) no\nminor modification to H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of relevant Core Experiments: |P1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |twice of H.263 for\nglobal ME/MC four times of H.263 for global & affine ME/MC almost the\nsame as the reference for global & affine MC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 615 continued"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDescription of reference condition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nReference Proposal"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Global MC OFF - _Global MC_ _ON_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- OBMC ON, but no 8x8 MC - OB__A__MC ON, but no 8x8 MC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Unrestricted MV mode ON - Unrestricted MV mode ON"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- No PB-frames - No PB-frames"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- No SAC - No SAC, but _adaptive VLC_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- _Adaptive quantization_ using block activity and segmentation mask"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe same rate control was used both for the reference and for the\nproposal. The video demonstration purely compares the effectiveness of\nthe proposed tools: 1) global MC, 2) local affine MC, 3) adaptive VLC,\nand 4) adaptive quantization."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 0625"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Region-Based Motion Compensated Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Jean-Francois Vial"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: 3: Error Resilency and Others."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe algorithm is a region-based coding scheme that relies on the\nsegmentation of the dense motion field of the image."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe dense motion field is estimated by a gradient-based algorithm,\nembedded in a hierarchical framework. Practically, the motion field is\nsuccessively refined at each level of a pyramid of down-sampled images,\ntaking into account the predictions done at previous time, at previous\npyramid level, and at neighbouring positions within the current level."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe resulting field is segmented as follows. The previous segmentation\nis first projected on the current field in order to insure the temporal\nstability of the segmentation, and the projected contours are refined by\ndeterministic relaxation. This segmentation is further adapted to the\ncurrent field by allowing regions splitting or merging, controlled by a\nleast square technique used to compute an affine representation of the\nmotion field on each region."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe segmentation map is transmitted by a lossless coding of region\ncontours, using chain-codes. The affine motion model of each region is\nrepresented by three displacement vectors appropriately chosen."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFinally, the prediction error on each region is encoded by\nShape-Adaptive DCT. The quantization step applied to the coefficients is\ncontrolled by the _motion confidence_ criterion, relying on the\nprediction quality of the current region, and by the motion excursion.\nCoefficients in each SA-DCT block are scanned in an adaptive order\u00a0: the\nnext coefficient position to be scanned is predicted by the positions\nand values of the coefficients already transmitted. The coefficients are\ncoded using MPEG2 VLC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nB-frames are coded without sending any further motion information. To\nbuild the prediction, the decoder interpolates the motion field between\nthe two surrounding P-frames, and identifies covered or discovered areas\nin order to locally select backward or forward prediction. When\nquantizer stepsizes are so high that no prediction error is to be coded,\nnothing at all is transmitted for the B-frame."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWhen periodic I-frames are used (which was the case for November 95\ntests, but not for January 96), the motion analysis is processed for\nI-frames as for P-frames, in order to insure objects tracking. Contours\nand SA-DCT intra coefficients are coded."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe coded picture format is SIF, 60 (or 50) frames per second."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 0625 continued"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|Performed similar to the anchor for medium and Class C. Provided high\nframe rate (60Hz). Boundary problems."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Generic input, not designed for very low bitrates. Delay incurred\ndue to B-frames."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax |Pixel-based motion estimation\nRegion-based. Spatially-Adaptive DCT. Lossless chain coding, Major\ndeparture from known standards."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of relevant core experiments: |Shape Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |Complexity significantly\ngreater than H.263. None."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Added Value |Information about object shape can be extracted. Object\ntracking possible."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margins for improvement |Room for optimization.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: M0637"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Very Low Bit Rate Video Codec"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Iraj Sodagar"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group Wavelet and Mesh/Warping* )"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Compression, Scalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis proposal describes a hybrid motion-compensated wavelet transform\ncoder. It addresses the functionalities of compression and scalability.\nThe significant features of the proposed coder are: (1) optional global\nmotion estimation; (2) fixed block size motion estimation to track local\nmotion; (3) optional variable block size motion estimation; (4)\noverlapping block motion compensation; (5) discrete wavelet transform of\nresidual frames; (6) quantization of wavelet coefficients; (7) optional\nsignificant measure used to vary quantizer dead zone as a function of\nvisual significance of data; (8) optional object-oriented quantizer step\nsize adjustment; (9) use of zerotrees and arithmetic coder; and (10) a\nrate control scheme. It provides an easy path to spatial scalability,\nobject scalability, and bitstream scalability. Demonstrated video\nquality, without using features (1), (7), (8), and (10), is similar to\nthat of H.263 anchor. According to the results of tool submission in\nNov. 1995, further improvement in coding efficiency can be achieved by\nusing the above features."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression, Spatial and bitstream\nscalability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|Simlilar to H.263 anchor Same frame rate as P-frame rate of anchor No\nRinging, blurring, very big block in some cases, less blocky than anchor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |Provide scalability for intraframes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |wide range of scenes tested for Class-A and B (10-112kbps) and\nscalable to higher bitrates not tested yet no restrictions similar to\nH.263 P-mode"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax of H.263 |similar to H.263 advanced\nmode (-D -F) similar to H.263 advanced mode wavelet, zero-tree no same\nmotion syntax as H.263 but different syntax for texture coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Accommodated by the following Core Experiments: |T1 and T2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |similar to H.263 no\nreal-time implementation yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |continuous bitstream scalabilty for\nintraframes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |can be improved within MPEG-4\ntime-frame rate control, variable block size ME, global ME and MC, and\nvisual significant measures, object-based bit-allocation\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 639"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Microsoft proposal for MPEG4 2nd Evaluation Phase"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Ming-Chieh Lee (Microsoft)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: (*Group* ) Object Functionality"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis document describes an object-based video coding scheme that\nMicrosoft proposes to the MPEG-4 standardization effort. This scheme\nuses a layer decomposition of video frames and codes each layer as a\ngroup of blocks (GOB) in H.263, except for sprites that are coded using\na wavelet coder. This scheme has the capability to code alpha channels\nand sprites. Content-based functionalities, improved coding efficiency\nand an object oriented syntax are the other features of this proposal."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |compression/content based functionality;\nsnhc"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|Better or similar than the anchor >=15 frames per second No shape of\nobjects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |snhc - very good; spatial scalability not fully\ndemonstrated; temporal scalability not demonstrated"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Generic >= 48 kbps No Independent of resolution depending upon\nsprite accretion, could be much greater than MPEG-1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax |affine block based same as classical\nmethods (not classical block based) H.263 simplified chain codes +\npolygonal approx. + 8-bit alpha coding VOP based using H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. Accommodated by the following Core Experiments: |P4, S1, S2, O1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |More complex than H.263\nfor natural VOPs; less for synthetic VOPs as above No"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional advantages |flexibility of representation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |real time sprite accretion in\n6 months better shape and alpha channel coding\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 646"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: ** An MPEG-4 Video Coding Proposal using a Modulated\nLapped Transform Enhancement of H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Gary Sullivan (PictureTel Corp.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: H.263++ *Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe proposed algorithm is based on H.263, where the DCT has been\nreplaced by Modulated Lapped Transform (MLT). The MLT can be implemented\nby the butterfly windowing of the input data followed by an 8x8 DCT type\nIV. Intra frames and macroblocks are simply butterfly windowed,\ntransformed by an 8x8 DCT type IV, and then quantized. Inter macroblocks\ninformation is produced from the difference between the windowed input\ndata and the windowed prediction data. Afterward, an 8x8 DCT type IV is\napplied. Mode selection is performed in the windowed domain. As the\noverlapped butterfly can not be performed at the border of the image,\nthe window and the DCT type have been modified for border blocks. DCT\ncoefficients have been scaled by a constant factor and intra d.c.\ncoefficients have been off-set to maintain their range for quantization\nand VLC coding. Although the transformation has been changed, none of\nthe syntax has been modified. VLC, quantization, and rate control also\nare unchanged with respect to H.263. The main advantage of this scheme\nis no blocking artifacts appear in the decoded sequence. Complexity\ndepends mainly on motion estimation. The current implementation is\ncomplex because windowing is performed during motion estimation.\nHowever, using the standard pixel based H.263 motion estimator still\nyielded good results."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Picture quality Frame rate of tape Buffer control Dominant artifact\n|Block artifacts have been removed. Strong majority votes for quality\nsimilar to that of the provided reference. Same as the rate of the\nprovided reference (lower than the anchor). No buffer control.\nChrominance artifacts and ringing effects."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Generic."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax Others |Windowed domain ME. Windowed\ndomain MC. MLT. No. No changes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of relevant Core Experiments: |Recommended as core experiments\nin Frame Texture Coding class."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |10 x complexity of H.263\nin current implementation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |Better window could\nreduce/avoid ringing artifacts. Better handling of image edges.\nIntroduce optional modes of H.263. Need farther work to eliminate\nchrominance artifacts. Complexity can be reduced by a factor of 8 to 9.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nReference: the proposed algorithm was compared to H.263, namely Telenor\n1.6 software version with no options on. The proposed algorithm was also\nrun without any of the H.263 options enabled. The proposers assert that\nno difficulties are foreseen in implementing the options."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 654"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Core Experiments of Video Coding with\nBlock-Partitioning and Adaptive Selection of Two Frames Memories\n(STFM/LTFM)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Takahiro Fukuhara (Mitsubishi)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: H.263++ *Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary: Our core experiment contains two major components. One is\nadaptive selection of two time-differential frame memories (2FMs:\nSTFM/LTFM). The other is block partitioning motion compensation (BPMC).\nMain goal for the two components is the improvement of motion prediction\nover some existing schemes. Motion compensation using LTFM(Long Term\nFrame Memory) is expected to improve the prediction efficiency when\nthere are some occlusion areas. In addition it also works as temporal\ninterpolation filter which reduces prediction noises. On the other hand,\nBPMC is expected to greatly reduce prediction errors, because two\nseparated segments in a macroblock are compensated respectively. In such\na case, approximate shape of the segments are also detected. This will\nhelp make the prediction gain even better. Details of technical contents\nare presented in the technical description (MPEG95/340) submitted to\nMPEG4 Dallas Meeting in November 1995."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|The majority judge the picture quality similar to that of the provided\nreference, few judged it better than that of the provided reference.\nSame as the provided reference. No buffer control."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Better improvement achieved for sequences with still background.\nImprovements achieved for a wide range of bit rates."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax Others |BP ME with two temporal frame\nmemory. BP MC. DCT. No. H.263 minor modifications."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of relevant Core Experiments: |P2, P3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |4-5 x complexity of\nH.263 (both encoder and decoder side). One extra frame memory required\ncompared to H.263."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |Block-based object scalability."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |Motion estimation complexity\ncan be reduced (encoder issue).\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nReference: H.263 (Telenor 1.6) encoder with 3 options on but no PB\nframes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDocument Number: 657"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName of Algorithm: Region enhanced H.263 coder: a trial"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContact Person: Thierry Delmot (UCL/Belgacom)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEvaluation Group Name: H.263++ *Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFunctionalities: Compression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSummary:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis proposal provides the implementation of the _Interesting Regions\nDetection_ tool (MPEG95/372 Dallas) into the H.263 version 1.6 codec.\nThis tool provides a description of the subjectively interesting regions\nof the sequence. The interface of the proposed tool and H.263 is defined\nin terms of blocks. The proposed implementation requires little\nmodification of the H.263 syntax in order to allow the quantization step\nswitching. Two values of the PQUANT and GQUANT parameters are allowed.\nThe decoder have to chose one of the two quantization values whether or\nnot a given macroblock belongs to the interesting region."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,66%\",]\n|===\n|1. Functionality Addressed |Compression."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. Picture quality Frame rate of tape Buffer control Dominant artifact\n|Mixed results. 10 Hz. As in H.263 (TMN 1.6 by Telenor). Background\ndegradation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. Efficacy |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. Adaptability: Range of scenes Bitrates Error conditions Resolutions\nDelay |Generic."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. Algorithm Characterization: Motion estimation Motion compensation\nTexture coding Shape coding Syntax Others |Conventional. Conventional.\nConventional. No. Minor modifications. Provide automatic segmentation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6. List of relevant Core Experiments: |For quantization: Q1. For\nsegmentation see Dallas recommendation (Doc. MPEG/N1064rev)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7. Implementation Complexity Encoder (Benchmark) Decoder (Benchmark)\nReal time implementation (Video DSP, ASIC, PC) |Double the encoding time\nrequired by H.263."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8. Additional Advantages |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9. Margin and time-frame for improvement |Same as H.263\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nReference: The reference provided to evaluate the performance of the\nproposed algorithm was generated using H.263, namely Telenor 1.6 with\nunrestricted motion vectors, PB frames, and advanced prediction modes\noptions on."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRecommendation: The group acknowledges that the tool can be integrated\ninto H.263."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpen Issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Annex 8*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Participants of the AdHoc Group Meeting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"27%,28%,45%\",]\n|===\n|Last name |First name |Email\n|Azadegan |Faramarz |fazadegan@gte.com\n|Banham |Mark |banham@areaplg2.corp.mot.com\n|Beuker |Rob |beuker@natlab.research.philips.com\n|Bhattacharjee |Sushil K. |sushil@ltssg4.epfl.ch\n|Bjontegaard |Gisle |gisle.bjontegaard@fou.telenor.no\n|Boon |Choong Seng |boon@drl.mei.co.jp\n|Brailean |James |\n|Brusewitz |Harald |harald.brusewitz@era-t.ericsson.se\n|Buhan |Corinne |lebuhan@ltssg4.epfl.ch\n|Castagno |Roberto |castagno@ltssg4.epfl.ch\n|Chen |Wei-ge |\n|Chiang |Tihao |tchiang@sarnoff.com\n|Choi |Diana |diana@hitchcock.dcf.scg.hac.com\n|Chuang |Roger |CCHUANG@iterated.com\n|Corset |Isabelle |Corset@lep-philips.fr\n|Danielsen |Robert |rdi@nta.no\n|Date |Akira |akira@crl.hitachi.co.jp\n|Delmot |Thierry |delmot@tele.ucl.ac.be\n|Dufaux |Frederic |dufaux@crl.dec.com\n|Ebrahimi |Touradj |ebrahimi@epfl.ch\n|Einarsson |Torbjorn |T.Einarsson@clab.ericsson.se\n|Ekval |Christel |Christel.Ekvall@haninge.trab.se\n|Etoh |Minoru |etoh@crl.mei.co.jp\n|Faerber |Niko |\n|Franceschi |Olle |olle@fou.svtt.se\n|Fryer |Richard |rjf@cs.strath.ac.uk\n|Fujimura |Kouta |kouta@tsukuba.rd.sanyo.co.jp\n|Fukuhara |Takahiro |fukuhara@atom.isl.melco.co.jp\n|Gardos |Tom |trgardos@ibeam.jf.intel.com\n|Grinnell |Rick |grinnell@pictel.com\n|Hamada |Hiroyuko |hamada@fou.svrr.se\n|Hibi |Keiichi |hibi@trl.mkhar.sharp.co.jp\n|Hutter |Andreas |a_hutter@lis.e-technic.tu-muenchun.de\n|Hwang |Duckdong |ddh@eagle.dwe.co.kr\n|Itoh |Yuji |itoh@trdc.ti.com\n|Jeannin |Sylvie |jeannin@eep.philips.fr\n|Jeon |Byeungwoo |bj@rnd.sec.samsung.co.kr\n|Jozawa |Hirohisa |jozawa@nttvdt.hil.ntt.jp\n|Kari |Jarkko |\n|Katata |Hiroyuki |katata@imgsl.mkhar.sharp.co.jp\n|Kaup |Andre |\n|Kim |Jin Hun |jhkim@sirius.dwe.co.kr\n|Kim |Yong Han |yhkim@video.etri.re.kr\n|Klungsoyr |Gunn Kushn |gunn.klungsoyr@fou.telenor.no\n|Koenen |Rob |r.h.konen@research.kpn.com\n|Kuhn |Peter |p_kuhn@lis.e-technik.tu-muenchun.de\n|Lameiure |Jan |jan@hhi.de\n|Lee |Ming-Chieh |mingcl@microsoft.com\n|Lee |YoungLyul |yllee@saitgw.sait.samsung.co.kr\n|Lei |Shawmin |leis@sharpsla.com\n|Li |Weiping |wl03@Lehigh.EDU\n|Liang |Gang |Gliang@iterated.com\n|List |Peter |peter_list@fz.telekom.de\n|Lobato Correia |Paulo |Puls.Correia@amalia.ist.utl.pt\n|Machida |Yutaka |ymachida@adl.mci.mei.co.jp\n|Miki |Toshio |miki@mlab.nttdocomo.co.jp\n|Miyamori |Hisashi |miya@tom.comm.waseda.ac.jp\n|Miyamoto |Yoshihiro |miyamoto@dsp.cl.nec.co.jp\n|Morimatsu |Eishi |eishi@flab.fujitsu.co.jp\n|Muller |John |jmuller@iterated.com\n|Mulroy |Patrick |pmulroy@visual.bt.co.uk\n|Nakasu |Eisuke |nakasu@strl.nhk.or.jp\n|Nakaya |Yuichiro |y-nakaya@crl.hitachi.co.jp\n|Neff |Ralph |falcon@eecs.berkeley.edu\n|Nieglowski |Jacek |joecek.nieweglowski@research.nokia.f\n|O'Connell |Kevin J. |oconnell@areaplg2.corp.mot.com\n|Oehler |Karen |oehler@hc.ti.com\n|Ogata |Masami |ogta@av.crl.sony.co.jp\n|Olsson |Sofie |sol@fou.svrr.se\n|Oosa |Kinya |oosa@elelab.nsc.co.jp\n|Ostermann |J\u00f6rn |ostermann@big.att.com\n|Park |Gwang Hoon |ghpark@super5.hyundai.co.kr\n|Pereira |Fernando |eferbper@beta.ist.utl.pt\n|Piron |Laurent |piron@ltssg4.epfl.ch\n|Rajan |Ganesh |grajan@procy.gi.com\n|Russo |Guisseppe |russo@fub.it\n|Sakaida |Shinichi |sakaida@strl.nhk.or.jp\n|Schroeder |Karsten |sr@nt.e-technik.uni-dortmund.de\n|Seytter |Fritz |sey@bsun3.zfe.siemens.de\n|Sezan |Ibrahim |sezanie@sharpsla.com\n|Shin |Jae-Seob |jsshin@dspsun.sait.samsung.co.kr\n|Sikora |Thomas |sikora@hhi.de\n|Sodagar |Iraj |iraj@sarnoff.com\n|Sullivan |Gary |garys@pictel.com\n|Turker |Mustafa Ali |ali.turker@research.nokia.com\n|Vial |Jean-Francois |vialjf@tcetbs1.thomson.fr\n|Watanabe |Toshiaki |wtnb@eel.rdc.toshiba.co.jp\n|Wiegand |Thomas |wiegand@uf-.e-technik-erlangeu.de\n|Winder |Simon |simonw@bristol.st.com\n|Wu |Zhixiong |go@okilab.oki.co.jp\n|Zeug |Michael R. |mzeug@iterated.com\n|Zhang |Ya-Qin |zhang@sarnoff.com\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= The HoDs have received the JNB resolution and\nRob Koenen\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND ASSOCIATED AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11 *N1163*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n** *MPEG 96/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"12%,88%\",]\n|===\n|Source: |Leonardo Chiariglione - Convenor\n|Title: |Response to NB Contributions\n|Status: |Draft\n|Author: |HoDs\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Response to JNB Contribution mpeg96/0597, which states:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs the MPEG-4 Video Verification Models (VMs) are scheduled to be\nestablished in the Munich meeting, JNB recommends WG11 to adopt the\nfollowing actions in the course of developing VMs."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. In considering the time frame given to MPEG-4, JNB recommends\nthat"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- a minimum number of VMs, preferably a single one, be established,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- the VM has to be concrete and well defined to enable core experiments\nto be conducted without delay,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- the VM should provide a platform for conducting experiments covering\nall the three main functionalities: content based capability, coding\nefficiency and error robustness as described in the PPD(ISO/IEC\nJTC1/SC29/WG11 Document N998), and"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- core experiments be conducted under a wide range of conditions\nconsidering applications of high industry interest including A/V data\nbase access and A/V communication."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. The results of the November 1995 subjective test, as well as\nthe January 1996 proposals, should be reflected in establishing the VM.\nPreferably the commonality observed in the results of the subjective\ntest should be adopted as the skeleton of the VM. The tremendous efforts\nput into the whole process would not be justified if the results are not\nfully utilized."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. The establishment and development of the VM should be closely\nrelated to MSDL. MSDL is expected to incorporate various tools and\nalgorithms into a single framework. The feasibility and implementability\nof such a solution should be carefully studied in the course of\ndeveloping VMs and MSDL. In a single frame work integrated by MSDL, core\nalgorithms and common tools should be considered as a standardized part\nof MPEG4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*The response is as follows:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThank you for your comments concerning the MPEG-4 Verification Model\ndevelopment procedure. The HoDs ascertain that the recommended actions\nas expressed in the contribution are in line with the way the MPEG-4\nstandard will be developed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Response to AFNOR Contribution mpeg96/665, which states:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe French National Body recommends that the Verification Model that is\nexpected to be defined in Munich, provides a flexible enough framework\nto achieve both compression and content-based functionalities."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn particular, it should permit to test non-block-based techniques and\nrepresentations, and to fairly compare them to the main reference in\nfuture core experiments."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe FNB believes that only an open VM structure, fully consistent with\nthe generic MPEG4 syntax, will allow the development of good solutions\nleading to the new functionalities."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*The response is as follows:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe HoDs thank AFNOR for its contribution, and for the explanation given\nat the HoD meeting, from which they understand that AFNOR recommends the\nVM, mentioned in the first paragraph, to provide a \u2018framework to achieve\nboth content-based functionalities and compression simultaneously.\u2019 The\nHoDs agree with this point of view."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= 1. Introduction.\nAVARO\n1980-01-03"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ORGANISATION INTERNATIONALE DE NORMALISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*CODING OF MOVING PICTURES AND AUDIO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11 N1164*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1995*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: MSDL AHG*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title: MSDL specification. Version 1.0*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Status: Proposal*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Disclaimer :_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis document is a working draft of MPEG-4 SDL. It should be understood\nthat this is not the definitive version and as such, this document is\nlikely to undergo major changes. Thus, it is open to new ideas,\ncomments, and revisions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table of content*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTRODUCTION 3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. SCOPE* 3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. MSDL AREAS OF WORK 3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. METHODOLOGY FOR DEVELOPING THE LANGUAGE 4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4. SCHEDULE 4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5. STRUCTURE OF THIS DOCUMENT 4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPART 1 : ARCHITECTURE (MSDL-A) *5*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1 SCOPE* 5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2 GENERAL POINT OF VIEW 5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3 TERMINOLOGY 6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n4 INPUT INFORMATION AT THE DECODER 7"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n4.1 BASIC DATA STRUCTURES _7_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_4.2 Input Streams 8_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_5 System structure_ 11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPART 2 DEFINITION OF THE MSDL CLASS HIERARCHY (MSDL-O) *13*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1 SCOPE* 13"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2 CLASS HIERARCHY 13"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.1 CONTENT AND PRESENTABLE OBJECTS _13_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_2.2 Process Objects 17_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Part 3 : READABLE LANGUAGE SPECIFICATION (MSDL-R)_ *19*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*SCOPE OF THIS SECTION* 19"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. MSDL-R SPECIFICATION 19"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPART 4 : BINARY LANGUAGE SPECIFICATION (MSDL-B) *20*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*SCOPE OF THIS SECTION* 20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. DEFINITION OF MSDL-B 20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPART 5 : SYNTACTIC DESCRIPTION LANGUAGE *21*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1 ELEMENTARY DATA TYPES* 22"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1.1 CONSTANT-LENGTH DIRECT REPRESENTATION BIT FIELDS _22_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_1.2 Variable Length Direct Representation Bit Fields 23_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_1.3 Constant-Length Indirect Representation Bit Fields 23_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_1.4 Variable Length Indirect Representation Bit Fields 23_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_1.5 Arithmetically Coded Bit Fields 24_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_2 Composite Data Types_ 24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3 ARITHMETIC AND LOGICAL EXPRESSIONS 25"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n4 SYNTACTIC CONDITIONAL CONSTRUCT 25"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n5 SPECIAL CONSTRUCTS 27"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n6 REFERENCES AND SCOPING RULES 28"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPART 6 : MULTIPLEX SPECIFICATION (MSDL-M) *29*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*SCOPE OF THIS PART* 29"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBIBLIOGRAPHY *30*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*EARLY DOCUMENTS ON MSDL (BEFORE NOVEMBER 95)* 30"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDALLAS MEETING (NOVEMBER 95) INPUT DOCUMENTS ON MSDL 30"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDALLAS MEETING (NOVEMBER 95) OUTPUT DOCUMENTS 30"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMUNICH MEETING (JANUARY 96) INPUT DOCUMENTS ON MSDL 31"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nREFERENCES ON RELATED MATERIAL 31"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nGLOSSARY OF TERMS *32*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*APPENDIX 33*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*APPENDIX A : DESCRIPTION OF NBC AUDIO* 33"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA.1. NBC AUDIO SYNTACTIC DESCRIPTION _33_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_A.2. NBC Audio derived class library 36_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Appendix B : Description of Video Verification Model_ 38"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA.1. VIDEO VM SYNTACTIC DESCRIPTION _38_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_A.2. Video VM derived class library 38_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Appendix C: Description of SNHC elements_ 38"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nC.1. SNHC ELEMENTS SYNTACTIC DESCRIPTION _38_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_C.2. SNHC elements derived class library 38_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Appendix D : General Class library for AV objects_ 38"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAPPENDIX E: MSDL-R AND MSDL-B EXAMPLES 39"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEXAMPLES REFERING TO M0393 _39_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Examples refering to M0622 45_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 1. Scope"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG-4 has converged on two issues"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* the coded representation of audio-visual information.\n* the description of the tools and algorithms used for retrieving the AV\nobjects."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MPEG-4 Syntactic Description Language (MSDL) is a language for\ndescribing audiovisual scenes based on algorithms for *decoding* the\naudiovisual objects, and algorithms for *compositing* of these objects\nin a scene, describing inter-relationships between them. It is aimed to\nsupport the different functionalities addressed by MPEG-4, mainly\ncontent-based functionalities (manipulation, scalability...) and the\nrequirements of extensibility and flexibility of the MPEG-4 standard."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo this end, it intends to put *presentable* objects (audio frames,\nvideo frames, sprites, 3D objects, natural or synthetic...) and their\n*processing* methods (waveform representation, spline representation...)\nin the center of its design. The decoder is described as an AV scene\ncompositor that organizes the content objects in time and space and\nprovides means for interaction. The possible decoding process for a\ncontent object itself is described with different possible levels of\nprogrammability."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnother concern of MSDL is to ensure the flexibility of the MPEG4\nstandard. We have defined 3 levels of flexibility. Level 0 means that no\nprogrammability is enabled, and that the decoding algorithm is present\nat the decoder side. In level 1 programmability, the algorithm is fixed,\nbut individual tools might be programmed, if they are present on the\ndecoder side. In level 2, we enable the coder to use some new\nalgorithms, even if all the required tools are not present at the\ndecoder side. In that case, the coder will be able to send in a format\nthat MSDL should define the missing tools or data structures."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe aim of this document is to specify the features (syntax and\nsemantics) of the MSDL. The final language that will be standardised\nwill be a binary language. However, to facilitate understanding of the\nlanguage a textual (readable) version is also provided. The proposal is\nintended to stimulate further work on the definition of programming\nlanguages for audio-visual representation algorithms. The proposal is\nalso intended as a recommendation for using the same language for the\nspecification of the Verification Model(s) decoders developed in MPEG-4,\nat least at the higher level of content."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 2. MSDL areas of work"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL deals with the following areas of work:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* a description of the global architecture of the MPEG-4 system. This\nincludes the role of the MPEG-4 system in a complete working\naudio-visual application as well as the conceptual objects to be\nexchanged between coder and decoder and their data content. This area of\nwork will be refered as MSDL-Architecture (or MSDL-A).\n* a description of the specific objects that will be usefull for\nspecific audio-visual applications. This work will define what are the\nparticular objects that need to appear in the standard. It covers the\ndefinition of the objects libraries of MSDL. This area of work will be\nreferred as MSDL-Objects (or MSDL-O).\n* a description on a readable format for transmission of decoder\nscripts. The important feature is the readibility. This area of work\nwill be referred as MSDL-Readable (or MSDL-R).\n* a description of an executable format for the scripts or descriptions.\nThis will be the executable binary language understood by the decoder.\nEven if binary is only the use of the ascii format, this description\ngoes down to the definition of the binary level. This area of work will\nbe refered as MSDL-Binary (or MSDL-B).\n* a description of a syntactic description language that will be used in\na first step to describe the specification of the bitstream syntax. The\nidea is to extend the MPEG-2 syntactic description, into a formalism\nthat is well-defined and amenable for machine interpretation. This area\nof work will be referred as MSDL-Syntax (or MSDL-S).\n* a description of multiplexing procedure for the high level objects.\nThis area of work will be referred as MSDL-Multiplex (or MSDL-M)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 3. Methodology for developing the language"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL has to support previous and new formats of coded representation of\naudio-visual objects foreseen by MPEG-4. To guarantee that the new\nstandard will be flexible and extensible, and provide also real-time\nperformance, two main inputs shall be considered:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* from developers of tools, algorithms, profiles (software): identify\nthe set of content objects to be supported and their possible processing\nmethods;\n* from platform manufacturers (hardware): identify the basic set of\nobjects that need specific implementation to guarantee real-time\nperformance."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt is expected from software developers to verify whether their AV\nsoftware can be written using the specifications of the MSDL.\nAdditionally, the requirements for real-time performance of the tools\nand algorithms proposed shall be also verified."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 4. Schedule"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe timing for the development of the MSDL shall be consistent with\nother MPEG-4 activities. The following schedule for the MSDL is proposed\n:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* January 96 : WD V1.0, NBC Audio syntax in MSDL\n* March 96 : WD V1.1\n* July 96 : WD V1.2\n* November 96 : WD V2, implementation of VMs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5. Structure of this document"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe document is structured as follows: each area of work constitutes a\npart of the document. Appendices A through C contain descriptions of\nalgorithms (NBC Audio, Video Verification Model, SNHC) at the syntactic\nlevel and at the semantic level. The schedule precises the time frame\nfor developing MSDL. A bibliography of relevant contributions integrates\nthe various evolution of MPEG work on the topic."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Part 1 : Architecture (MSDL-A)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 1 Scope"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe scope of MSDL Architecture (MSDL-A) is"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1) defining an integrated framework for decoding, compositing,\nand presenting audio, video, and synthetic elements, and"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2) defining the collection of logical subsystems, their\nrelationships, and the interfaces between them."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThus, MSDL Architecture provides a foundation on which the MSDL library\n(MSDL-O) can be built, and the set of interfaces that must be defined by\nthe remaining MSDL elements (MSDL-R, -B, -S, and -M)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 2 General point of view"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor the purposes of defining an integrated framework for decoding,\ncompositing, and presenting audio, video, and synthetic elements, we\nadopt an object oriented point of view. Thus, all components in the\nframework are regarded as objects. An object encapsulates both state\n(data structure) and behavior (procedural methods) in the same entity.\nOur design methodology is fundamentally object-oriented."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOur point of view on the system is that MSDL-A defines the interfaces\nbetween components; these interfaces are specified by languages, defined\nin MSDL-S and MSDL-R."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAudio-visual data are encoded and then multiplexed using they\nspatio-temporal informations. present in the bitstream. At the decoder\nside, the transmitted data are parsed and decoded to give a presentable\nobject which is rendered by the composer. Negociation information allow\ncoder and decoder interactions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *3 Terminology*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL uses a terminology that aims to be consistent with object oriented\nconception. In that sense MSDL objects are entities that combines both\ndata structure and behavior in a single entity. Objects with the same\nbehavior and data attributes are grouped into class. The methodology and\nnotation to describe the set (library) of classes and their\ninter-relations use OMT [].Note that MHEG 5 [] has made the same choices\nto design a class hierarchy. The class hierarchy does not aim at\nspecifying a particular language. Such a task will be done in MSDL-R.."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn object oriented theory we will use three basic kinds of interactions\nbetween objects: Inheritence means that a child object has all the data\nand processing of his parent object, and some other that are specific to\nit. Association means that one object interacts with another object,\nusually implemented as a pointer to another object. Aggregation means\nthat one object contains another. The construction of this aggregated\nobject is thus performed by the embeding object. We will now describe\nhere some basic concepts of OMT notation:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Child Class inherits form parent Class:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Association between Class 1 and Class 2:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Class 1 is associated with several Class 2:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Association of Class 1 with zero or one Class 2:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Aggregation of Class 1 with several Class 2:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Aggregation of Class 1 with zero or one Class 2:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe should also bear in mind that what we will be define is a set of\nclasses of objects, and not objects themselves, which are an\ninstanciation of one class. This does not refer to C++ but is general\nand does not suggest any programming language for the implementation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn a class hierarchy, the base class from which all the others are\nderived is usually abstract. This means it only stored the shared data\nfor all the derived classes. In an abstract class, methods are usually\nvirtual, which means that when they are called on the base class, they\nwill be actually executed in one derived class."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 4 Input Information at the decoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 4.1 Basic data structures"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe cornerstone of MSDL-Architecture is the definition of a base class\nfor audiovisual objects. The audiovisual objects represented by this\nbase class are conceived as existing in four dimensions: three spatial\ndimensions and one temporal dimension (3D+T). Thus, an audiovisual\nobject is a time-varying 3D object in general. However, some objects may\nbe lower dimensional objects (e.g., 2D+T video objects) embedded in\n3D+T, or may actually be constant in time. Audiovisual objects have a\nlocal (x,y,z,t) coordinate system. Affine coordinate transformations can\nbe used to transform an audiovisual object from its local coordinate\nsystem in a global coordinate system, and from its global coordinate\nsystem to a logical device coordinate system."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe defining characteristic of audiovisual objects is that they can be\nrendered through a rendering system, or synthesizer, for ultimate\npresentation on a display and audio device. Hence audiovisual objects\nare renderable, or presentable, and support a corresponding method. In\nthis working draft, audiovisual objects are called PresentableObjects."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor this purpose, we have defined a number of base classes from which\nstandard MPEG4 classes will be derived: The MPEG4 class is the base\nclass, and is derived in the Presentable class, the process and content\nclasses, as illlustrated by the following diagram:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 4.1.1 MPEG4 Objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG4 objects will contain the ID of each derived object, and the method\nto access this ID . The whole MPEG4 class hierarchy, either already\ndefined (level 0 and 1), or user defined (level 2), will be derived from\nthis class."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 4.1.2 Presentable Objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA Presentable Object is an abstract class derived from the MPEG4 base\nclass. All objects derived from this class will have the property that\nthey can be presented through the audio video sub-system in time and\nspace. They have an intrinsic coordinate system, and will be mapped to\nthe presentation coordinate system. In that purpose, they will all\ncontain a _Present_() method."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 4.1.3 Process Objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe _ProcessObject_ class is an abstract class that derives from the\nMPEG4 base class. All derived objects from this class will have the\nproperty that they can be applied to an MPEG4 object and return a\npresentable object. For example, an InverseDCTTransformer Process object\nwill have an Apply method that will take a _DCTCoefficient_ content\nobject as input, and will return an Image Presentable Object."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 4.1.4 Content Objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe _ContentObject_ class is an abstract class that derives from the\nMPEG4 base class. The objects derived form this abstract base class are\naimed at storing the necessary parameters that represent one Presentable\nObject. For example, the _DCTCoefficient_ Content Object will\n\u00ab\u00a0represent\u00a0\u00bb an Image part. In MSDL level 2, other classes may be\nderived from the above classes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *4.2 Input Streams*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis section describes the structure of the input stream at the decoder\nside. This might be transmitted as a traditional single multiplexed\nbitstream, but might also be sent in multiple streams.The following\ndiagram details the information that has to be sent to the decoder in\norder to reconstruct the original source (audio-visual) data:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere is the meaning of the above acronyms:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- SSC: Session Start Code"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- Profile ID: This informs the decoder about the decoding profile of the\nincoming audio-visual data (such as MPEG2 XP@XL or H.263)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- NI: Negotiation information. Using the profile ID and this information\nthe decoder verify that the needed data structures and tools are present\nin the decoder, so that it is able to decode the following coded audio\nvisual data. If this is not the case, some request should be sent back\nto the coder, asking to transmit the missing elements. This request\nprotocol will be addressed by level 2 MSDL."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- CS: Compositing Stream"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- DS: Decoding Stream"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- PI: Process Information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- DI: Content Information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- SEC: Session End Code"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe main part of the bitstream is composed of the four main streams\nidentified above. The reason for having this information in four\ndifferent types of streams is to enable in future the needed flexibility\nin MSDL, the object accessibility and manipulation. In general, there\nmight be a repeated sequence of the above input streams sent to the\ndecoder that have to be parsed, decoded or interpreted in order to\nrecover the original information. We will now define in more details the\nfour main types of identified streams."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 4.2.1 Compositing script"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe compositing script contains sequences of commands for presenting the\nPresentable Object in space and time through the rendering process to\nthe audio video sub system. These commands specify coordinate\ntransformations from objects\u2019 local coordinate systems into the\ncoordinate systems of video and audio frame buffers."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVideo and audio frames, onto which audiovisual objects are rendered for\npresentation, also have coordinate systems. A video frame, which can be\nregarded as a finite 2D array of pixels, has a local 2D coordinate\nsystem whose spatial origin is at the lower left corner, with x\nincreasing (in units of pixels) toward the right of the frame and y\nincreasing (in units of pixels) towards the top of the frame.\nConceptually, a video frame is embedded in the subspace of 3D+T defined\nby the subspace z=0, t=0. An audio frame, which can be regarded as a\nfinite 1D array of samples, has a 1D coordinate system whose time origin\nis at the first sample of the array, with t increasing towards the end\nof the array. Conceptually, an audio frame is embedded in the subspace\nof 3D+T defined by x=0, y=0, z=0."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOrthogonal or perspective coordinate transformations are used to\ntransform an audiovisual object from a world coordinate system into the\ncoordinate systems of video or audio frames. Such coordinate\ntransformations are used to composite PresentableObjects together at a\nsingle time. Repeated transformations at different time translations can\nbe used to play a movie or animate a figure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 4.2.3 Decoding script"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe decoding script contains the sequence of expected data at the\ndecoder, and the necessary information for parsing and decoding them.\nThe compressed data will be parsed and decoded from the Information\nstreams, according to these commands. The output of this procedure will\nbe a presentable object, that will be treated by the Composer. This\nscript will be defined in details in the MSDL-P part of the document."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 4.2.4 Content Information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContent Information is a bitstream that contains sequences of compressed\ndata representing some Content or Presentable Objects. For instance, the\nWavelet coefficients compressed with Huffman Coder and quantized with\nuniform scalar quantization."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 4.2.5 Process Information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe methods for decoding the Content Information are present here. These\ncan either be default set that resides in the decoder (like H.263\ndecoder) or a sequence of Instructions on how to decode the content\ninformation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 4.2.6 Decoder structure"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUsing the data and stream structures we have previously defined, we are\nnow able to describe a more detailed architecture of the MPEG4 decoder.\nThis also refers to section 2.1 on the global architecture. The decoder\nwill either use a known and pre defined decoding process, or a new one,\nthat is sent in the decoding script. This script shall be interpreted if\npresent by the Parser. The content and process information will then be\nsequentially read, decoded and de-quantized if necessary. A\ncorresponding Content and Process Object will then be constructed thanks\nto the parameters that have just been constructed. Finally, the process\nobject will be applied to the content object, to generate a Presentable\nobject. This stored presentable object will then be rendered by the\ncomposer, in a spatio temporal position specified either by the\ncompositing script, or by some parameters of the object directly\nexctracted from the bit stream. The reason for having this separate\ncompositing stream is to enable future interaction of the user with the\nrendering information in the composer. In other cases, such as a\ntraditional video coder, the time stamps migh be read directly from the\nbit-stream. The following diagramm shows this decoder architecture:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* = Can be optional"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following example shows how an image object (coded using the wavelet\ntransform) can be decoded using the content information, process\ninformation, decoding script and compositing script."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 5 System structure"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis section is an attempt to capture a global view of how MSDL defines\nan architecture proper, as a set of interfaces. This architecture\nincludes aspects of a software architecture, a network architecture, and\na hardware architecture."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe diagram below is an attempt to represent the decomposition of an\nMPEG4 decoder system into more elementary entities, and their interplay\nthrough a set of interfaces. Each of these MSDL interfaces defines its\nown language, which is the way entities on both sides of the interface\nspeak to (and hopefully are understood by) each other."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis diagram is a way to represent all the languages which are relevant\nas interfaces to be standardized (white text in small black boxes)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere are two directions of information flow, which are represented here\nas orthogonal:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00a5\u00cahorizontally from right to left, we move from the more abstract levels\nof programming an MPEG4 application in high level language to its real\nhardware implementation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00a5\u00cathe vertical direction matches the classical way to represent stacked\nprotocol layers in a communication environment : from the upper layers\nwhich are closest to the application and the end-user, to the lower\ntransport and network layers, closest to the physical communication\nmedium."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEntities corresponding to level 2 (downloadable tools and correponding\nrun-time engine) are represented as distinct from those that correspond\nto level 1 (boxes in a lighter shade of grey)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe notion of run-time engine for both level 1 and level 2 could\ncorrespond to either interpretation in the classical sense or on-the-fly\ntranslation of an intermediate-level representation. It is represented\nas distinct from compilation which performs global processings (usually\nmultipass) on the whole body of a program."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Part 2 Definition of the MSDL class hierarchy (MSDL-O)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 1 Scope"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn this section, we will define a set of MPEG4 objects that will have to\nbe constructed at the decoding process in order to render and manipulate\nthe audio visual scene. We will first define some presentable and\nassociated content objects, and then focuss on the definition of\nassociated process objects. Note that these data structures have to take\ninto account the work of SNHC, audio and video, since they will be the\ndata and tools structures that will be supported by any MPEG4 decoder.\nAlthough MSDL2 is aimed at offering possibilities to download new data\nor tool structures, the ones present in the basic class hierarchy will\ncorrespond to the minimum set of structures needed for a basic MPEG4\nsession. We have mainly addressed in this document the problem of 2D\nvideo, while being open to requirements from SNHC (mainly by introducing\n3D objects in the visual scenes), and Audio. The enhance this class\nhierarchy, a feedback from the video groups and interaction with the\nSNHC and Audio groups are thus required."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 2 Class hierarchy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 2.1 Content and presentable objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPresentable objects are the output of the decoder part, and correspond\nto data structures that can actually be rendered by the composer."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 2.1.1 Audio visual Scene model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG 4 is dealing with audio visual data. The first objects that we will\ndefine are hence the audio visual scenes. An audio visual scene is\noptionnaly linked to an audio scene, and a visual scene. An optional\nlink is used, since in some applications only an \u00ab\u00a0audio scene\u00a0\u00bb or a\n\u00ab\u00a0visual scene\u00a0\u00bb is used, other times both. An audio visual scene can be\nhierarchical. In that case the hierarchical audio visual scene will\ncontain a tree of scenes. The parent scene will thus contain a list of\nchildren scenes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 2.1.2 Hierarchical model for a spatio temporal scene"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA visual scene contains a collection of spatial objects, according to\nthe temporal sampling. A Spatial Object can be two dimensional or 3\ndimensional. A Spatial Object can be hierarchical, in which case it is\n_composed of_ several other spatial objects, and can be _part of_\nanother containing object. In the simple case of a regular block based\nstructure, the first level of the hierarchical scene will be represented\nby a 2 dimensional object representing the whole video frame, and at a\nsecond level by a list of blocks, which are themselves represented by a\n2D object. These concepts are illustrated by the following model:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *2.1.3 Two Dimensional Object modelization*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe will now focus on the definition of a two dimensional object. A two\ndimensional object optionally associates a depth information, an opacity\ninformation, a position (in the reference scene), a shape information, a\ntexture information, and some motion parameters. Each association is\noptional, because one or several of the above objects might not be\nneeded to represent a 2 dimensional object. So here is an OMT model for\nthese objects:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote ** that all of the associated classes with the 2d object class are\nContent objects and not presentable objects. All of these classes will\nbe linked to an exact representation of the data, most of the time in a\n\u00ab\u00a02DComponent\u00a0\u00bb class. It will also be linked to a set of coded\nrepresentations, such as DCT coefficients or wavelet coefficients for a\n\u00ab\u00a0TextureInformation\u00a0\u00bb object."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 2.1.4 Texture information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe texture information is linked to set of 2D components, according to\nthe color space used, that stores the pixel values. In parallel, some\ncoded representation are also available, such as DCT coefficients,\nfractal transform parameters..."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 2.1.5 Shape Information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA shape is associated with one or several shape representations\n(according to the algorithm used), which can either be a collection of\npoints, a binary mask, or an edge representation. A binary mask is\nsimply a 2D component. There are also some special cases of regions,\nsuch as a rectangle, a triangle, for which you do not always need\nanother representation. In the case of a generic VOP, a link to a\nbounding box is needed between the shape information and a rectangle."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *2.1.6 Motion information*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA motion information object stores the motion parameters. A coded\nrepresentation is associated, as for the previous classes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 2.1.7 Depth and opacity information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDepth and opacity information are derived from a 2D component. In the\ncase in which only one information is needed, a single integer value is\nstored."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 2.1.8 2D Position"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA 2D position just stores the x and y relative position of the object."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *2.2 Process Objects*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProcess objects correspond to process that will be applied on content or\npresentable objects and will return a new presentable object. They hence\nall contain an _Apply()_ method."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 2.2.1 Quantizer object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe quantizer object will transform a quantized event source in a non\nquantized event source. The Quantizer object will thus have an _Apply_\n(namely in this case inverse quantize) method taking an event source as\ninput and returning another event source. The quantizer can be derived\nin a scalar quantizer and a vectorial quantizer, which themselves can\nhave some special implementations. This is the corresponding OMT model:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *2.2.2 Transformer object*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn inverse transformer object is defined in order to map the texture\ncoded representation to a texture information object. This object will\nhave an _Apply_ method (InverseTransform method in this case), that\ntakes a texture coded representation as input and return a texture\nrepresentation. Some special cases of transformations are IDCT\ntransforms and IWavelet transforms:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *2.2.3 Compensator Object*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe compensator process object will map a spatial object to another\nspatial object, according to the motion parameters included in the first\nobject:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Part 3 : READABLE LANGUAGE SPECIFICATION (MSDL-R)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Scope of this section"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_This section is a draft specification of a tentative Level 1 MSDL-R. We\npropose the use of a subset of C and C++ as a starting point. This\nprovides a textual representation of the algorithm. methods to derive a\nbinary from this description are described. In its present version, the\ndocument is far from being complete. Extensions of the language to\nsupport new capabilities not provided by C++ may be necessary (e.g.\nmultithreading, message processing, etc)._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *1. MSDL-R specification*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL-R features include:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* C variable names, expressions and function calls\n* C constructs: if-else, for, while, for which conditions are limited to\nconstants, variables and function calls\n* return statements"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL-R excludes:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* the definition of functions, procedures and global variables\n* preprocessor directives\n* goto, break and continue statements\n* virtual functions\n* structures or classes and access to structures or classes, replaced by\nfunction calls in the library\n* type casts"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL-R is strongly typed for security reasons: no casts, function\nparameter type checking, no implicit type change. A source code example\nis provided below."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA MSDL-R program segment is a procedure. It has local parameters, local\nvariables, global variables which are predefined in the decoder\nenvironment, and instructions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo new data structure can be defined in MSDL-R. Only standard elementary\ntypes and decoder-known types are allowed. Among these, individual slots\nin complex structures, e.g. pieces of the bitstream, are not directly\naccessible. They are accessible through library function calls. Arrays\ncan be defined, but are accessed also through library functions. It is\nexpected that the future extension of MSDL-R for level 2 will include\nnatural C-like access to slots and array elements but keep these library\nfunctions for compatibility."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMore complete examples (a MPEG1 and a NBC audio decoder) have been\nimplemented as described in M0393 with this restricted syntax without\nproblems, thus demonstrating the validity of the approach. The only\nconstruct that could possibly be added is break."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Part 4 : BINARY LANGUAGE SPECIFICATION (MSDL-B)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Scope of this section"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_This section is a draft specification of a tentative Level 1 MSDL-B.\nThe purpose of MSDL-B is to provide a bit efficient representation of\nMSDL-R that is common to all decoder platforms._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 1. Definition of MSDL-B"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL-B can be generated from MSDL-R. Two fundamental approaches have\nbeen identified. MSDL-B can be either a coded version of the high-level\nlanguage MSDL-R (using e.g. hufman coding of MSDL-R keywords) _or_ a\ncompilation of MSDL-R to a platform independent low-level\nrepresentation. Both concepts allow to either interpret or translate\nMSDL-B at the decoder. The various concepts still have to be evaluated.\nCurrently two concrete proposals are available."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe first proposal is based on M0393 and proposes a compilation to\nMSDL-B at the encoder side. The compiler presented in that document is\nbased on \u201clex\u201d and \u201cyacc\u201d which are textual syntax analysis tools. The\nactual choice of the MSDL-B code may be suboptimal in terms of\ncompactness but can subsequently be optimised. Instructions are 32 bits\nlong. They are interpreted by a Forth-like stack-based interpreter.\nForth-interpreters are claimed to be among the fastest existing\ninterpreters. The interpreter and the tools library are written in C++\nand linked together. In order to make the system non-interpretive a\ncompilation of MSDL-B to native machine code is also possible. A couple\nof examples of the proposed MSDL-B and its corresponding textual\nrepresentation (MSDL-R) are given in Appendix E describing the MPEG1\nvideo and the NBC audio algorithms."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe second proposal is based on M0622 and suggests a direct compression\nof the MSDL-R code. MSDL-R keywords, arithmetic operators as well as\nvariables are mapped to predefined codewords. The decoder can\nreconstruct the original MSDL-R code, albeit without the symbolic names\nthat have been given to class instances, variables, methods, etc. if\nreadability at the decoder is required. For execution the MSDL-B code\ncan be interpreted directly or can be translated to native machine code.\nAs an example a part of the compression tool is specified in Appendix E.\n(For a complete description refer to M0622.) Additionally, a MSDL-R code\nexample together with its reconstruction at the decoder side is given."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Part 5 : Syntactic Description Language"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis syntax originates in the C-like syntax that has been successfully\nused to describe the structure of coded audio-visual components in\nMPEG-1 and MPEG-2. This syntax has two different levels: a textual one,\nfor purposes of specification and documentation, and a binary one for\npurposes of inclusion in the bitstream. Since the binary level is only\nneeded for level-2 operation, the description of the binary level is\ndeferred."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe features added to the old scheme include object-orientation and\nthoroughly defined semantics that can be used for potential machine\ntranslation. The work has been done along a set of requirements and\npolicies, among which are the following:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* the formalism should be implementable but should not suggest any\nparticular implementation.\n* the syntax of the data within the bitstream is orthogonal to the\nprocessing that has to be done to recover the AV objects. So one thing\nis to describe the syntax, another to describe the processing.\n* there should be as few constructs as possible,\n* the declarative part should be predominant, and data dependent parsing\nshould be kept at a minimum,\n* the use of variables and anything non declarative in nature should be\nbanned if not strictly necessary: in natural language, this means that\nanything that looks like a program instruction is either a suggested\nimplementation of the parser or even an action that belong to decoding\nand not to data specification,\n* the interchange format should be described from the channel point of\nview, not from either the decoder or the encoder point of view, so that\nno side is preferred and no unnecessary constraint is put on\nimplementation,\n* the general feeling of the syntax should be C-like."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following requirements emerged during collaboration with the NBC\nAudio team:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* description of the syntax of the bitstream in as readable a format as\npossible.\n* definition of some basic data entities (coefficients, parameters,\nmodes, synchronization, padding data, byte alignement...).\n* definition of some basic data types (int, char, ...).\n* possibility to include header at fixed interval in variable length\nframe.\n* possibility to describe data parsing dependent on the previously\nparsed and processed elements.\n* possibility to include alignment indication data and to indicate\nwhether an object can be chopped.\n* description of alignment and chopping up capabilities to the\ndemultiplexer.\n* possibility to describe \u00abhierarchical VLC\u00bb."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe formal rules defined here bring the following added value:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* the syntax is described in a more formal way. The consistency of this\ndescription can be tested contrary to the pseudo-C code approach. This\nwill allow to process automatical bitstream conformance and consistency\nchecking.\n* the formal description used is simpler and will improve its\nreadibility.\n* the description does not describe a coding or a decoding process. It\nis really the description of the interchange format."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt this stage, all the syntactic features to satisfy the request have\nnot been developped but they are sufficient to describe the complete NBC\nsyntax."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe first describe elementary constructs, moving to composite syntactic\nconstructs, arithmetic and logical expressions, and finally address\nsyntactic control flow. The latter is needed to take into account\ncontext-dependent data. A full example of the current NBC Audio syntax\nis given in the annex A.1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *1 Elementary Data Types*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe can in general identify the following elementary syntactic elements:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Constant-length direct representation bit fields or Fixed Length Codes\n(e.g., temporal_reference). These include the encoded value as it is to\nbe used in the bitstream.\n. Variable-length direct representation bit fields, sometimes called\nvariable length FLCs. These are FLC for which the length is determined\nby the context of the bitstream (e.g., another parameter).\n. Constant-length indirect representation bit fields (e.g. chroma_format\nor coded_block_pattern). These require an extra lookup into an\nappropriate table or variable, or some algorithmic processing to obtain\nthe desired value (e.g., coded_block_pattern).\n. Variable-length indirect representation bit fields (Huffman codes).\n. Arithmetically coded bit fields."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1.1 Constant-Length Direct Representation Bit Fields"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese can be simply represented as:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[aligned] _type_(_length_) _element_name_ [= _value_]; // C/C++-style\ncomments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe _type_ is one of the following: \u2018int\u2019 for signed integer, \u2018uint\u2019 for\nunsigned integer, \u2018bit\u2019 for raw data, \u2018boolean\u2019 for logical values, and\n\u2018vlc\u2019 for variable length data. \u2018_length_\u2019 indicates the length of the\nelement in bits, as it is stored in the bitstream. It can be a constant\n(e.g., 10), or as we will see below, a variable, or a special construct\nthat indicates VLC decoding. The _value_ is only present when the value\nof the element is fixed (e.g., start or sync codes, or object IDs), and\nit may also indicate a range of values (i.e., \u20180x01 .. 0xAF\u2019). The\nattribute \u2018aligned\u2019, if present, means that the data is aligned on a\nbyte boundary and hence padding bits may have to be discarded before\nparsing."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs an example, a start code would be represented as:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\naligned const(32) picture_start_code=0x00000100;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn entity such as temporal reference would be represented as:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(5) temporal_reference;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhere uint(5) indicates that the element should be interpreted as a\n5-bit unsigned integer (by default with the most significant bit\nfirst\u2014MSBF)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that constants are defined using the \u2018const\u2019 attribute:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst int SOME_VALUE=255;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst bit(3) BIT_PATTERN=1; // this is equivalent to the bitstring \u201c001\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo designate binary values, the \u20180b\u2019 prefix is used, similar to the \u20180x\u2019\nprefix for hexadecimal numbers, and a period (\u2018.\u2019) can be optionally\nplaced every four digits for readability. Hence 0x0F is equivalent to\n0b0000.11111."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 1.2 Variable Length Direct Representation Bit Fields"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis case is covered by the above rule, by allowing the _\u2018length\u2019_ field\nto be a variable included in the bitstream,or an expression involving\nsuch a variable. For example:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(3) precision;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint(precision) DC;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 1.3 Constant-Length Indirect Representation Bit Fields"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere, in addition to the actual element we need to define how it is\nmapped to obtain the actual values that the decoder will use. This can\nbe accomplished by defining the map itself:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap _MapName_ (_idx_type_, _type1 name1_, _type2 name2_, \u2026, _typeN\nnameN_) [sign=__col__] \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_index_[s] _value_1 \u2026 value_M,_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[_index_[s] _value_1 \u2026 value_M, \u2026_]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that this is a multi-dimensional mapping: there is one input\n(index), and zero or more outputs (values), allowing the table to be\nused to specify the value for several different variables. The _type_\nentries in the definition indicate the type of the value columns, which\nare addressed using the _\u2018name\u2019_ information (e.g.,\n_MapName.name1[index])_."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs an example, we have:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// a table that relates the chroma format with the number of blocks per\nsignal component"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap blocks_per_component (uint(2), uint Yblk, uint Ublk, uint Vblk) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0 4 1 1, // 4:2:0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1 4 2 2, // 4:2:2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2 4 4 4 // 4:4:4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap(blocks_per_component) chroma_format; // this is a fictional example"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// you can now access Yblk like: chroma_format.Yblk"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 1.4 Variable Length Indirect Representation Bit Fields"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor a variable length element utilizing a Huffman table, a similar\nspecification is used:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap(_table_) ac_dct_coefficient;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe definition of the table is done in exactly the same way as we saw\nbefore, but here we have the data type \u2018vlc\u2019 as the index data type. In\nother words:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap sample_vlc_map (vlc, boolean(1) value1, int value2) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b0000.001 0 5,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b0000.0001 1 -14"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe vlc codewords are binary strings (starting with \u20180b\u2019), optionally\nusing the period (\u2018.\u2019) every four digits for readability."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVery often, VLC tables are incomplete: due to the large number of\npossible entries, it is inefficient to keep using variable length\ncodewords for all possible values. This necessitates the use of escape\ncodes, that signal the subsequent use of a fixed-length representation.\nTo allow for such exceptions, element specifications are allowed for map\nvalues. This is illustrated in the following example:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap sample_map_with_esc (vlc, uint value1, uint value2) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0000.001 0 5,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0000.0001 1 -14,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0000.0000.1 map(foo) int(32),"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0000.0000.0 0 -20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs written above, when the codeword 0b0000.0000.1 is detected in the\nbitstream, then another VLC table is used for the value for column 1,\nwhile the following 32 bits will correspond to the value for column 2\n(the order is significicant). Using this construct, the complete\nbehavior of the VLC mapping is described in a concise manner in a single\nplace."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA notational convenience that is present in VLC tables is the use of the\nsame codewords for both the negative and positive value of the variable\nrepresented. This can be accommodated by denoting in the codewords the\nposition of the sign bit, using the letter \u2018s\u2019. Typically, the sign\nchange affects only one column (at least this is the case with existing\nMPEG VLC tables). Hence we only need to denote the column that is\naffected by the sign bit. This is done as shown below:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap table_with_signs (vlc, uint, int) sign=2 \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b000 1 5,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b0000.s 2 7,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b0001.00s 3, -10,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b0001.010 4, 4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe above specification says that the sign bit (1 for positive, 0 for\nnegative) affects column 2 of the values. Hence 0b0000.1 results in a\nvalue of 7, while 0b0001.000 results in a value of 10."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 1.5 Arithmetically Coded Bit Fields"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo be determined."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 2 Composite Data Types"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEquipped with the above definitions for fundamental types, we can now\nexamine the definition of composite types or objects. A very useful\nfeature is to be able to immediately identify the type of object that we\nare dealing with; object identifiers are then a particularly attractive\nfeature. In several cases, the desire for bit efficiency precludes their\nuse (this is the case in MPEG-2 below the slice level). The definition\nof a composite object can then be expressed as:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass _object_name_ [is _parent_class_] [:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[aligned] bit(_length_) [_id_name_]= _object_id|id_range_] \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_element_1_;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[_element_2; \u2026_]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe different elements are definitions of elementary bitstream\ncomponents as we saw in section 5.1, or control flow that is discussed\nin the following section. The _object_id_ is optional, and if present is\nthe key multiplexing entity for individual objects. The _id_range_ is\nspecified as _start_id_ .. _end_id_, inclusive of both bounds, to\nexpress that the object can have a range of possible id\u2019s."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe optional \u2018is _parent_class_\u2019 specifies that the class can be used\nwherever a slot of type _parent_class_ has been specified. Using\n_parent_class_ defines an implicit switch on class id\u2019s in the decoding\nprocess. This switch is totally implicit, as it is not needed to define\nthe possible structure of the bitstream, only to decode it."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExamples:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass foo \\{ ..."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbar name_1;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n... }"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass bletch is bar \\{ ... } // this class can be used in the name_1\nslot"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass slice: aligned uint(32) slice_start_code=0x00000101 .. 0x000001AF\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026 // here we get vertical_size_extension, if present"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (scalable_mode==DATA_PARTITIONING) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(7) priority_breakpoint;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} ;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe order of declaration of bitstream components is important: it is the\nsame order in which the elements appear in the bitstream."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe can also encapsulate objects within other objects. In this case, the\n_element_ mentioned at the beginning of this section is an object\nitself."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 3 Arithmetic and Logical Expressions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll standard arithmetical and logical operators of C/C++ are used as is,\nincluding their precedence rules."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 4 Syntactic Conditional Construct"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe syntactic conditional constructs provide for conditional definition\nof slots, depending on context, as well as for definition of repetitive\nstructures. The familiar C/C++ if-then-else construct is used for\ntesting conditions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (condition) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} [ else if (condition) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}] [else \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following example illustrates the procedure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass conditional_object \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(3) foo;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nboolean bar_flag;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (bar_flag) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(8) bar;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(32) bletch;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere the presence of the entity \u2018bar\u2019 is determined by the \u2018bar_flag\u2019.\nAnother example is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass conditional_object \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(3) foo;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nboolean bar_flag;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (bar_flag) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(8) bar;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} else \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap(some_vlc_table) bar;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(32) bletch;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere we allow two different representations for \u2018bar\u2019, depending on the\nvalue of \u2018bar_flag\u2019. We could equally well have another entity instead\nof the second version (the variable length one) of \u2018bar\u2019 (another\nobject, or another variable). Note that the use of a flag necessitates\nits declaration before the conditional is encountered."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the same category of context-dependent objects we have the so-called\nrepetitive objects. These simply imply the repetitive use of the same\nsyntax to parse the bitstream, until some condition is met. It is the\nconditional repetition that implies context, but fixed repetitions are\nobviously treated the same way. The familiar structures of \u2018for\u2019,\n\u2018while\u2019, and \u2018do\u2019 loops could be used for this purpose, but to eliminate\nthe need for temporary variables (counters etc.), we use the following\nstructure:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrepeat (_times_) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026 // repeat exactly _times_ times"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrepeat ([var:] _array_slice_) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026 // repeat exactly length of _array_slice_ times"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// var is an iteration variable to be used only as array index"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrepeat \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026 // repeat at least once, until bitstring is present in the bitstream"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// or while it is not present"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} until ([!] bitstring);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhile ([!] _bitstring_) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026 // repeat 0 or more times, while bitstring is present in the"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// bitstream, or while it is not present"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere we have four different forms: a fixed repetition using the _times_\nargument (which can be a variable), a repeat iterating on an array, a\n\u2018repeat at least once\u2019 construct, and a \u2018repeat zero or more times\u2019\nconstruct. Note that only the second sort allows the use of an iteration\nvariable, to be used only as array index."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExample:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrepeat \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap(ac_vlc_table) ac_coeff;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} while (! 0b011);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis says that \u2018ac_coeff\u2019 is parsed using the VLC table \u2018ac_vlc_table\u2019.\nThere is at least one \u2018ac_coeff\u2019, and parsing should stop when the bit\nstring \u2018011\u2019 is detected in the bitstream."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 5 Special Constructs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA few standard representation methods, namely run length encoding and\nentropy coding, are highly used and very difficult to express elegantly\nin a declarative way (i.e. without lots of lines of code). It has been\ndecided to confine these concepts to special constructs, thus defining\nthe encoding and not the parsing program. Array operations are also\nadded, as they enable a further reduction and greater simplicity in the\nbitstream description."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe first one is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrle(_runbits, valuebits_) _array_[_size_];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis defines an array of \u2018int\u2019, of size _size_. Its values are filled by\nparsing the bitstream reading sequentially _runbits_ bits for the run\nlength and _valuebits_ for the size of the value of the run, and\nproperly keeping track of the correct positions within the array."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnother special construct is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnonzero(_array___slice_)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis yields the number of non-zero elements contained in array_slice. An\narray slice can be specified as _array_[_start .. end_], for an array\nslice. A missing start means from the beginning of the array and a\nmissing end means to the end of the array. For example, _array_[_.._]\nmeans the whole array."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_We may need another construct for array operation, either a\nelement-by-element operator or a stride specifier._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe last construct is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[ascending|descending] list \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class1 name1;_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[class 2 name2; \u2026]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe elements inside the braces (_class1_ etc.) have to be objects with\ndefinitions that include object id\u2019s. The syntax here indicates that the\nbitstream contains any number of the objects contained inside the\nbraces, in any order. The list encompasses all the objects or group of\nobjects obeying to the specification inside the braces."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlist \\{ class1 name1; } groups all consecutive objects of class1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlist \\{ class1 name1; class2 name2; } contains all consecutive pairs,\nbut does not include a repetition of class2 objects (after the first)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the objects specified in the list have id ranges, it makes sense to\nspecify monotonic increase (_ascending_) or decrease (_descending_) of\nthose id\u2019s. This means the list includes the sequence of objects that\nhave monotonically changing id\u2019s and the first violation of ordering\nterminates the list before the violating element."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 6 References and scoping rules"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere is a need for expressions in a limited set of cases. A incomplete\nlist of cases is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* array length specification, as in: _rle_(4, 4)\n*sfb_cb*[number_of_coderbands[window_sequence]];\n* condition in an \u2018if\u2019 clause, as in: _if_ (window_sequence >=\nSHORT_DATA_WINDOW) \\{\n* number of iterations in a repeat clause, as in: _repeat_\n(sd_nelems[window_sequence]) \\{\n* array selection, as in: _map_(hcod_vlc[sfb_cb[i]]) *sval*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn these examples, hcod_vlc is a previously defined array of codebooks,\nwhere codebooks are themselves arrays ; window_sequence is a previously\ndefined bitstream element ; i is a repeat iterator ; SHORT_DATA_WINDOW\nis a constant number ; number_of_coderbands, sd_nelems and sfb_cb are\nlookup tables."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMore formally, an identifier is analyzed as the name of bitstream\nelements when it appears after a type declaration. In any other case,\nthe identifier has to be defined elsewhere in the description as:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* a constant number or array or map,\n* another bitstream element, which means this is a context-dependent\nreference,\n* a repeat iterator, within the defining repeat."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nConstants are global definitions, and no name conflict is allowed with\nany other identifier. Iterators are strictly local to the repeat, and no\nname conflict is allowed with any other identifier."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere may be declarations with the same name in different objects. Thus\nscoping rules have to be defined. The best way to define these rules in\nfew words is to make an analogy with the scoping rules of variables in\nC, if we consider objects composed of other objects as functions calling\nother functions. We thus have a hierarchy of objects and sub-objects,\nand an ambiguous reference is resolved by finding the closest reference\nin the hierarchy of callers."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Part 6 : MULTIPLEX SPECIFICATION (MSDL-M)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Scope of this part"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe view presented in the part 1, about Content Objects, Process Objects\nand Sessions is a theoretical view describing the objects in synthetic\nway. Mapping these objects into the bitstream implies rearranging their\ncomponent parts according to transmission constraints. It is impractical\nto define and transmit an object like a MPEG2 video sequence before it\nis placed on the screen, especially since t could be virtually infinite.\nAs a consequence, the objects as defined in part 1 are cut into one\ndeclaration part and possibly many follow-up data parts, and sent as\nneeded."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA session S1 containing two object streams O1 and O2 and two short\nobject streams O3 and O4 will be sent as:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"16%,12%,12%,12%,12%,12%,12%,12%\",]\n|===\n|S1 Header |O1 Start |O2 Start |O3 all |O4 all |Composit. |O1 ... |O2\n...\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPlaying the session can begin right after the session composition\ninformation is decoded. This is why the session composition should\narrive as soon as possible. The data part of stream objects needs not to\nbe sent before scene composition."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAfter the previous sequence, a new stream object O5 can be added as\nfollows. First, it should be defined, then added to the scene, then\ntransmitted in alternance with the other object streams like O1 and O2:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"16%,12%,12%,12%,12%,12%,12%,12%\",]\n|===\n|... |O4 all |Composit. |O1 ... |O2 ... |O5 Start |Composit. |O5 ...\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Bibliography"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Early documents on MSDL (before November 95)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. *AOE SubGroup \"Proposal Package Description (PPD) - Revision 1.0\"\nISO/IEC JTC1/SC29/WG11 N821*\n. MSDL specification version 0.0 \", ISO/IEC JTC1/SC29/WG11 N1021\n. \"Requirements for the MPEG-4 syntactic description language\", Draft\nrevision 2, ISO/IEC JTC1/SC29/WG11 N1021\n. Paul Shen, Cliff Reader \"OODL for MPEG-4\" ISO/IEC JTC1/SC29/WG11 MPEG\n95/128\n. Stefano Battista (CSELT) \"C++ syntax as possible MPEG-4 SDL\" ISO/IEC\nJTC1/SG29/WG11 MPEG 95/270\n. Peter Sheldon, John Cosmas \"Proposal for an Adaptive Control System\nfor MPEG-4\" ISO/IEC JTC1/SC29/WG11 MPEG 95/259\n. Cheung Auyeung, Mike Danielsen \"An MPEG-4 Object Oriented Syntax\nProposal\" ISO/IEC JTC1/SC29/WG11 MPEG 94/245\n. Hsieh \"Process-Based Description for Object-Oriented Descriptive\nLanguage of MPEG-4\" ISO/IEC JTC1/SC29/WG11 MPEG 94/28\n. Fernando Pereira \"MPEG-4 Seminar Program\" ISO/IEC JTC1/SC29/WG11 MPEG\n95/029\n. Macq, Th. Delmot, J.-J. Quisquater \"Considerations About Security\nRequirements for MPEG-4 [1] [1] Syntactic Descriptive Language\" ISO/IEC\nJTC1/SC29/WG11 MPEG 95/266\n. Knabe \"The MPEG-' Programming Language called 'MPEG-4 Syntactic\nDescription Language' [1] (MSDL)\" ISO/IEC JTC1/SG29/WG11 MPEG 95/213\n. Delmot, B. Macq (UCL, Belgacom) \"MPEG-4 Platform Independent\nDownloading Descriptive [1] Language\" ISO/IEC JTC1/SG29/WG11 MPEG 95/2\n. [AD94] Cheung Auyeung and Mike Danielsen (Motorola), \u201cAn MPEG-4 Object\nOriented Syntax Proposal\u201d (unnumbered contribution), July 11, 1994."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDallas meeting (November 95) input documents on MSDL"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. ISO/IEC JTC1/SG29/WG11 M0316\n. ISO/IEC JTC1/SG29/WG11 M0373\n. ISO/IEC JTC1/SG29/WG11 M0393\n. ISO/IEC JTC1/SG29/WG11 M0395\n. ISO/IEC JTC1/SG29/WG11 M0416\n. ISO/IEC JTC1/SG29/WG11 M0417\n. ISO/IEC JTC1/SG29/WG11 M0452\n. ISO/IEC JTC1/SG29/WG11 M0455\n. ISO/IEC JTC1/SG29/WG11 M0463 \"Semantic aspects of an object-oriented\nrepresentation of audio-visual information for MSDL\", H. Sanson\n. ISO/IEC JTC1/SG29/WG11 M0467\n. ISO/IEC JTC1/SG29/WG11 M0471\n. ISO/IEC JTC1/SG29/WG11 M0494\n. ISO/IEC JTC1/SG29/WG11 M0505\n. ISO/IEC JTC1/SG29/WG11 M0544 : \"A video syntesizer tool and related\nobjects\"\n. ISO/IEC JTC1/SG29/WG11 M0546 : \u201cA Syntactic Description Language for\nMPEG-4\u201d, A. Eleftheriadis"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Dallas meeting (November 95) output documents*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. ISO/IEC JTC1/SG29/WG11 N1109 : \"Requirements for MPEG4\nfunctionalities\"\n. ISO/IEC JTC1/SG29/WG11 N1111 : \"MSDL Working draft,version 0.1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Munich meeting (january 96) input documents on MSDL"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. ISO/IEC JTC1/SG29/WG11 M0598\n. ISO/IEC JTC1/SG29/WG11 M0604\n. ISO/IEC JTC1/SG29/WG11 M0618\n. ISO/IEC JTC1/SG29/WG11 M0621\n. ISO/IEC JTC1/SG29/WG11 M0622 : \"A compression mechanism converting\nsource code in high-level language to MSDL-B\", A. Knoll\n. ISO/IEC JTC1/SG29/WG11 M0627\n. ISO/IEC JTC1/SG29/WG11 M0633 , \"Object-oriented representation of\naudio-visual information for MSDL\", J. Sign?s\n. ISO/IEC JTC1/SG29/WG11 M0665\n. ISO/IEC JTC1/SG29/WG11 M0690 : \"A system view of MSDL Architecture\",\nG. Privat, M. Brelot"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*References on related material*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Rumbaugh, _et al_, \"Object-oriented modeling and design\",\nPrentice-Hall, 1991\n* ISO/IEC Working Draft 13522-3 \"MHEG Part 3 : MHEG Extensions for\nScripting Language Support (or Extensions for Script Object\nInterchange)\" April 95\n* ISO/IEC DIS 13522-5 , MHEG part 5, December 1995\n* MHEG ftp sites : ftp://129.63.26.14/pub/MHEG, or\nftp://devo.uml.edu/pub/MHEG/DIS-[1-3].ps.gz or\nftp://devo.uml.edu/pub/MHEG/DIS-[1-3].rtf.gz.\nhttp://www.fokus.gmd.de/ovna/mheg\n* Kretz and F. Colaitis, \"Standardizing Hypermedia Information Objects\",\nIEEE Communications Magazine, Vol. 30, No. 5, May 1992, pp. 60-70.\n* Gianluigi Castelli \"Architecture Neutral Distribution Format (ANDF)\"\nISO/IEC JTC1/SC29/WG11 MPEG 95/151\n* OMG Address : Object Management Group, Inc. 492 Old Connecticut Path,\nFramingham, MA 01701 USA. Tel +1 508-820-4300. Fax +1 508-820-4303. ftp\n: omg.org. request@omg.org\n* \"Clarity MCode: A Retargetable Intermediate Representation for\nCompilation\" by Brian T. Lewis, L. Peter Deutsch, and Theodore C.\nGoldstein, ACM SIGPLAN Workshop on Intermediate Representations (IR\n'95), 1995, pp 119-128.\n* \"Optimizing an ANSI C Interpreter with Superoperators\" by Todd A.\nProebsting, ACM POPL '95: Symposium on Principles of Programming\nLanguages, 1995, pp 322-332.\n* WD for DSM-MSL, WG 11 doc. 931, March 1995\n* DSM-RSF \"Reference Scripting Format, a decription\" ISO/IEC\nJTC1/SG29/WG11 N0931\n* The Java Language: A White Paper, with other documents to be found on\nhttp://www.java.sun.com\n* [READ94] Cliff Reader (Samsung), Communication in the MSDL AHG\nreflector, describing a C++ class structure for MPEG-2, May 3, 1995"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Glossary of terms*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* *MSDL* : MPEG4 System Description Language**s**, comprising :\n* *MSDL-R* : The human-readable version of the MSDL programming\nlanguage, which is the interface to the programmer. MSDL-R is divided\nfurther into level 1 (MSDL-R1) and level 2 (MSDL-R2)\n* *MSDL-O* : the MSDL class library, as defined in a\nlanguage-independent way using OMT (ref1)\n* *MSDL-B :* the binary version of MSDL-R, which can be directly\ninserted in the coded bitstream and should satisfy constraints of\ncompactness, ease of decoding and efficiency of implementation on the\nrun-time engines\n* *MSDL-S* : the description of the syntax of the bit-stream used for\nparsing and decoding it\n* *MSDL level 1 run-time engine* : the system interface to the\ncompositing script, that makes its execution possible by calling system\nlibraries and rendering tools.\n* *MSDL level 2 run-time engine* : the system interface that permits the\nexecution of downloaded process-objects\n* *content object* : the object encapsulation of the MPEG4 internal\nrepresentaton of audio-visual data\n* *process object* : the object encapsulation of either decoding or\nrendering procedures to be applied to content objects\n* *compositing script* : the description of spatio-temporal\nrelationships between presentable objects that make up the audio-visual\nscene to be rendered\n* *decoding script* : the description of decoding actions (including\ncalls to specific decoding tools) to be performed to extract information\nfrom the parsed bit-stream"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAPPENDIX"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Disclaimer :_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following sections are incomplete. As greater understanding of the\nfeatures needed to complete them is gained, they will be completed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Appendix A : Description of NBC Audio*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== A.1. NBC Audio syntactic description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere is a first try at reformulating the NBC Audio bitstream\nspecification. This work was done while both syntax and specification\nwhere changing. It is expected to change in the near future. It is\nprovided here to help clarify our goals and current state of work."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n________________"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SYNCWORD=?; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ PADDING_VALUE=0x00;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_CP_VALUE=0x01;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_CP_VALUE=0x1F;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_CC_VALUE=0x20;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_CC_VALUE=0x2F;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_LFE_VALUE=0x30;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_LFE_VALUE=0x3F;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_NSEL_VALUE=0xEF;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_DATA_VALUE=0xF0;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_DATA_VALUE=0xFE;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ PADDING_DATA_VALUE=0xFF;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ ONLY_LONG_WINDOW=0x0;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ LONG_START_WINDOW=0x1;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ LONG_STOP_WINDOW=0x2;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SHORT_START_WINDOW=0x3;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SHORT_STOP_WINDOW= 0x4;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ EIGHT_SHORT_WINDOW =0x5;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SHORT_EXT_STOP=0x6;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ NINE_SHORT_WINDOW= 0x7;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ sampling_frequency_table (_int_(2), double rates) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ channel_configuration_table (_uint_(3), ?) ("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ emphasis_table (_uint_(2), ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ bitrate_index_table(_uint_(4), ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ window_sequence_table(_bit_(3), ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ _int_ number_of_coderbands[8]= \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// 8 values go here"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ hcod_sf_vlc ** (_vlc_, ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// scale factor Huffman codebook goes here"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ hcod_vlc ** (_vlc_, ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// Huffman codebook goes here"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ scalefactor_data \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// nonzero(a, b) returns the number of non-zero elements of array a of\nlength b"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (_nonzero_(sfb_cb, number_of_coderbands[window_sequence]) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(hcod_sf__vlc_) *hcod_sf*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ spectral_data \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (i: max_sd[window_sequence]) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (sd_nelems[window_sequence][sfb_cb[i]]) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(hcod_vlc[sfb_cb[i]]) *sval*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass individual_channel_stream \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *predictor_data_present*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (window_sequence >= SHORT_DATA_WINDOW) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *scalefactor_grouping*["
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nscalefactor_group_size[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *first_scalefactor*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_rle_(4, 4) *sfb_cb*[number_of_coderbands[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (predictor_data_present) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(5) *predictor_reset*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *prediction_used*[num_sfb[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nscalefactor_data *ScaleFactorData*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nspectral_data *SpectralData*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ data_element: _bit_(8) MIN_DATA_VALUE .. MAX_DATA_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *n_bytes*; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *data*[n_bytes]; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ lfe_channel_element _is_ syntactic_element:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) MIN_LFE_VALUE .. MAX_LFE_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(4) *n_samples*; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(12) *samples*[n_samples]; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ coupling_channel_element _is_ syntactic_element:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) MIN_CC_VALUE .. MAX_CC_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *number_of_coupled_channel_pairs*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (number_of_coupled_channel_pairs) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(5) *cc_index*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *ccp*[3];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(window_sequence_table) *window_sequence*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *window_shape*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nindividual_channel_stream *IndividualChannelStream*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (_nonzero_(ccp, 3 * number_of_coupled_channel_pairs) - 1) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (_nonzero_(sfb_cb,number_of_scoderbands[window_sequence])) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(scalefactor_vlc) *gain_element*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ channel_pair_element _is_ syntactic_element :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) MIN_CP_VALUE .. MAX_CP_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *two_chan*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(window_sequence_table) *window_sequence*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *window_shape*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (two_chan) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *ms_mask_present*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (ms_mask_present) _bit_(1) *ms_used*[num_sfb[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nindividual_channel_stream *IndividualChannelStream0*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (two_chan) individual_channel_stream *IndividualChannelStream1*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ NBC_raw_data_block \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_list_ \\{ syntactic_element *SyntacticElement*; }"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_list_ \\{ data_element *DataElement*;}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ NBC_raw_data_stream \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_list_ \\{ NBC_raw_data_block *NBCRawDataBlock*;}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ adts0_variable_header \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(bitrate_index_table) *bitrate_index*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *copyright_id*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *copyright_id_start*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (bitrate_index!=0) _uint_(10) *main_data_begin*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_else_ \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(12) *next_header*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) *buffer_fullness*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(2) *number_of_raw_data_blocks_in_frame*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(5) *num_syntactic_elements*[number_of_raw_data_blocks_in_frame];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *padding_bit*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ adts0_fixed_header : aligned _bit_(12)=SYNCWORD \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *ID*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(2) *layer*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *protection_bit*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(sampling_frequency_table) *sampling_frequency*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *private_bit*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(channel_configuration_table) *channel_configuration*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *original_copy*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(1) *home*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(emphasis_table) *emphasis*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ adts0_frame \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nadts0_fixed_header *Adts0FixedHeader*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nadts0_variable_header *Adts0VariableHeader*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (protection_bit==0) _uint_(16) *crc_check*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBC_Raw_Data *NBCRawData*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ audio_sequence \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhile (SYNCWORD) adts0_frame *Adts0Frame*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n____________________"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== A.2. NBC Audio derived class library"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExamples of SyntacticElement are scalefactors, side information, aux\ndata, Huffman coded data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass SyntacticElement"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npublic:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// converts data from transmission bitstream representation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// to natural representation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint Parse();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nData naturalRepresentation;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass BitstreamFrame"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npublic:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint Parse();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecode();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nprotected:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// the virtual methods are overridden"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// if algorithms are changed"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual Dequantize();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual StereoProcess();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual InverseTransform();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual PostProcess();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual WriteSamples();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nList<*SyntacticElements> * elements;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint BitstreamFrame :: Parse()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntacticElement * SE;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif ( !enoughInput() )"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nreturn false;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhile ( SE = elements->next() )"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSE->Parse();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nreturn true;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBitstreamFrame :: Decode()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDequantize();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStereoProcess();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInverseTransform();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPostProcess();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWriteSamples();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBCDecode();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBitstreamFrame frame;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhile ( frame.Parse() )"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nframe.Decode();"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Appendix B : Description of Video Verification Model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== A.1. Video VM syntactic description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== A.1.1. Specific video syntactic requirements"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== A.1.2. Specific formal rules to describe video syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== A.1.3. Video VM syntactic description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== A.2. Video VM derived class library"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Appendix C: Description of SNHC elements"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== C.1. SNHC elements syntactic description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== C.1.1. Specific SNHC syntactic requirements"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== C.1.2. Specific formal rules to describe SNHC syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== C.1.3. SNHC syntactic description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== C.2. SNHC elements derived class library"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Appendix D : General Class library for AV objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nConcerning the representation of AV objects, e.g. 3D representation of\nvisual objects, the language can be used to specify the interfaces of\nthe objects (i.e. class declaration). The following examples represent a\npossible generic declaration of classes for AV objects (with 3 spatial\ndimensions), from which classes for representing special cases are\nderived (e.g. pictures for conventional video). This is an example of\nhow each class of the global class hierarchy should be defined."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass AV_object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nprivate:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nposition;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\norientation;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npublic:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual behave(); // e.g. change_position(), change_orientation(), ..."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass Audio_object : public AV_object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass Video_object : public AV_object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nprivate:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nposition;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshape;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsurface;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nreflectance;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npublic:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual behave(); // e.g. move_position(), deform_shape(),\nchange_reflectance(), ..."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass 2D_Block : public Video_object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nprivate:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nposition; // x, y coordinates on the screen"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nshape;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsurface; // the screen"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npublic:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n..."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Appendix E: MSDL-R and MSDL-B examples"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Examples refering to M0393"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Symbolic example of MSDL-R to MSDL-B correspondance"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"35%,36%,29%\",]\n|===\n|MSDL-R |MSDL-B (textual representation) |comment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|object_start_code->decode( si ); |PDIC_PREFIX_VAR_PARAM +0\nPDIC_PREFIX_VAR_LOCAL + 0 PDIC_FUNCTION_DECODE |si object_start_code"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|temporal_reference->decode( si ); |PDIC_PREFIX_VAR_PARAM + 0\nPDIC_PREFIX_VAR_LOCAL + 1 PDIC_FUNCTION_DECODE |si temporal_reference"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|object_skip->decode( si ); |PDIC_PREFIX_VAR_PARAM + 0\nPDIC_PREFIX_VAR_LOCAL + 2 PDIC_FUNCTION_DECODE |si object_skip\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *Example of an MPEG1 decoder using MSDL-R*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following example will show the principle structure for composing an\nMPEG1 decoder out of the following basic process objects."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- variable length decoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- de-quantizer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- motion predictor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- inverse DCT on MB-layer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- adding unit"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFrom this we derive composed process object:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- slice layer process object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- picture layer process object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- GOP layer process object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n- sequence layer process object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis example is not elaborated in all detail, it is just meant as a\ndemonstration for the MSDL-R structure. The function declarations in\nthis example should be replaced by ProcessObject declarations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"100%\",]\n|===\n|// slice layer process object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|void Slice_Layer_Process::decode( Object_Stream_Input * si,\nObject_Array * slice // decoded slice int quantizer_scale; ) \\{\nMacroblock_MPEG1_Process * mb_mpeg1; ... Object_Array * array //\npointers to the MB\u2019s in the slice with // information as motion\nvector,CBP,MBA, // DCT-information. // array has member function get()\nproviding the // pointers to the MB\u2019s information. Object_Array *\narray_2 = Object_Array( size_of_mb ); // for Macroblock Object_Array *\narray_3 = Object_Array( size_of_mb ); Object_Dummy * tmp; do \\{ tmp =\nmb_mpeg1->decode( si, picture_coding_type, ... ); // in:\\{si,\npicture_coding_type} // out:\\{array} // result: selected MB-information\ndequant->decode( tmp, array_2->get(), quantizer_scale);\ndct_inverse->decode( array_2->get(), array_3->get());\nmotion_prediction->decode( array_4->get(), tmp->get(MV_info)) if\n((tmp->get(INTER_INTRA))->inter()) \\{ adder->execute( array_4->get(),\ntmp, slice->get() ); } else \\{ slice->put( tmp ); // information of\naddressed macroblock in array_out } } while ( si->test(END_OF_SLICE) );\n}\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"100%\",]\n|===\n|// picture layer process object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|void Picture_Layer_Process::decode( Object_Stream_Input * si ) \\{ //\nprocess object Slice_Layer_Process * slice_layer_process; .... //\ncontent object Object_Array * array_out; Object_Array * slice; do \\{\nslice_header->decode( si, quantizer_scale );\nslice_layer_process->decode( si, slice, quantizer_scale );\narray_out->put( slice ); } while( si->test( END_OF_PICTURE ); // create\ncontent object for displaying. }\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"100%\",]\n|===\n|// GOP layer process object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|void GOP_Layer_Process::decode( Object_Stream_Input * si ) \\{ //\nprocess object Picture_Layer_Process * picture_layer_process; do \\{\npicture_header->decode( si ); picture_layer_process->decode( si ); }\nwhile( si->test( END_OF_GOP ); }\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"100%\",]\n|===\n|// sequence layer process object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|void Sequence_Layer_Process::decode( Object_Stream_Input * si ) \\{ //\nprocess object GOP_Layer_Process * gop_layer_process; ...\nseq_header->decode( si ); do \\{ GOP_header->decode( si );\ngop_layer_process->decode( si ); } while( si->test( END_OF_SEQUENCE ); }\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCapital letter values are constant values."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Example of NBC Audio algorithm using MSDL-R"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following is another example of MSDL-R. We present the MSDL-R and\nMSDL-B intermediate code for BitstreamFrame::Parse(), and\nBitstreamFrame::Decode() which constitute the major part of the NBC\nAudio algorithm specification."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe total size of the description of the NBC algorithm this way is about\n2 kbits. However, the encoding process is suboptimised and could be\ngreatly improved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"100%\",]\n|===\n|a example of textual language for BitstreamFrame::Parse()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|int BitstreamFrame_Process::Parse ( ) \\{ SyntacticElement * SE; if (\nthis->test( ENOUGH_INPUT ) \\{ // nothig to do } else \\{ return false; }\nwhile ( SE = this->get(ELEMENT), SE->next()) \\{ SE->Parse(); // call\nBinary Toolkit function } return true }\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"41%,38%,21%\",]\n|===\n|textual language for BitstreamFrame::Parse() |intermediate code\n|comment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|if (this->test( ENOUGH_INPUT) \\{ |PDIC_PREFIX_CONST + 0\nPDIC_PREFIX_VAR_LOCAL+ 0 PDIC_FUNCTION+ 1 PDIC_P_SP_POP PDIC_CONTROL_IF\n|ENOUGH_INPUT this test() if"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} else \\{ |PDIC_CONTROL_ELSE |else"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|return false; |PDIC_PREFIX_CONTROL+ 0 PDIC_CONTROL_RETURN |false return"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} |PDIC_CONTROL_ENDIF |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|while(SE=this->get(ELEMENT), SE->next()) \\{ |PDIC_CONTROL_BEGIN\nPDIC_PREFIX_CONST + 1 PDIC_PREFIX_VAR_LOCAL + 0 PDIC_FUNCTION + 2\nPDIC_CONTROL_P_SP_POP PDIC_PREFIX_VAR_LOCAL + 1 PDIC_CONTROL_ASSIGN\nPDIC_PREFIX_VAR_LOCAL + 1 PDIC_FUNCTION + 0x81 PDIC_CONTROL_REPEAT |//\nstart of while ELEMENT this get() SE = SE next() // check condition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|SE->Parse(); |PDIC_PREFIX_VAR_LOCAL + 1 PDIC_FUNCTION + 0x82 |SE\nParse()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|return false; |PDIC_PREFIX_CONTROL+ 1 PDIC_CONTROL_RETURN |true return\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe next examples shows also the description and the instantiation part\nof the MSDL-B part which is not present in the previous examples."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"100%\",]\n|===\n|a example of textual language for BitstreamFrame::Decode()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|int BitstreamFrame_Process::Decode ( ) \\{ // below objects are given by\nBinary Toolkit Dequantize_Process * dequantize; // if you change\nDequantizer_Process into // New_Dequantizer_Process, // this decoder use\nother Binary Toolkit. Stereo_Process * stereo_process; ...\ndequantize->execute( this->get(ELEMENT) ); stereo_process->execute(\nthis->get(ELEMENT) ); inverse_transform->execute( this->get(ELEMENT) );\npost_process->execute( this->get(ELEMENT) ); write_samples->execute(\nthis->get(ELEMENT) ); }\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following table shows the description part of the MSDL-B."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"41%,36%,23%\",]\n|===\n|textual language for BitstreamFrame::Parse() |MSDL-B local variable\ndescription |comment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dequantize_Process * dequantize |PDIC_PROCESS+NBC+ 0x01 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Stereo_Process * stereo_process |PDIC_PROCESS+NBC+ 0x02 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Inverse_Transform * inverse_transform |PDIC_PROCESS+NBC+ 0x03 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Post_Process * post_process |PDIC_PROCESS+NBC+ 0x04 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Write_Samples * write_samples |PDIC_PROCESS+NBC+ 0x05 |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following table shows the part corresponding to the calling sequence\nof the MSDL-B."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"38%,36%,26%\",]\n|===\n|textual language for BitstreamFrame::Parse() |intermediate code\n|comment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|dequantize->execute( this->get(ELEMENT) ); |PDIC_PREFIX_CONST +1\nPDIC_PREFIX_VAR_LOCAL+0 PDIC_FUNCTION+ 2 PDIC_P_SP_POP\nPDIC_PREFIX_VAR_LOCAL+1 PDIC_FUNCTION+ 4 |ELEMENT this get() dequantize\nexecute"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|dequantize->execute( this->get(ELEMENT) ); |PDIC_PREFIX_CONST +1\nPDIC_PREFIX_VAR_LOCAL+0 PDIC_FUNCTION+ 2 PDIC_P_SP_POP\nPDIC_PREFIX_VAR_LOCAL+1 PDIC_FUNCTION+ 4 |ELEMENT this get() dequantize\nexecute"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|stereo_process->execute( this->get(ELEMENT) ); |PDIC_PREFIX_CONST +1\nPDIC_PREFIX_VAR_LOCAL+0 PDIC_FUNCTION+ 2 PDIC_P_SP_POP\nPDIC_PREFIX_VAR_LOCAL+2 PDIC_FUNCTION+ 4 |ELEMENT this get()\nstereo_process execute"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|inverse_transform->execute( this->get(ELEMENT) ); |PDIC_PREFIX_CONST +1\nPDIC_PREFIX_VAR_LOCAL+0 PDIC_FUNCTION+ 2 PDIC_P_SP_POP\nPDIC_PREFIX_VAR_LOCAL+3 PDIC_FUNCTION+ 4 |ELEMENT this get()\ninverse_transform execute"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|post_process->execute( this->get(ELEMENT) ); |PDIC_PREFIX_CONST +1\nPDIC_PREFIX_VAR_LOCAL+0 PDIC_FUNCTION+ 2 PDIC_P_SP_POP\nPDIC_PREFIX_VAR_LOCAL+4 PDIC_FUNCTION+ 4 |ELEMENT this get()\npost_process execute"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|write_samples->execute( this->get(ELEMENT) ); |PDIC_PREFIX_CONST +1\nPDIC_PREFIX_VAR_LOCAL+0 PDIC_FUNCTION+ 2 PDIC_P_SP_POP\nPDIC_PREFIX_VAR_LOCAL+5 PDIC_FUNCTION+ 4 |ELEMENT this get()\nwrite_samples execute\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Examples refering to M0622*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Modified version of NBC audio as in first part of Appendix E"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following shows the MSDL-R representation of the NBC audio algorithm\nas generated in the encoder, followed by the reconstructed MSDL-R\nrepresentation in the decoder. This compression tool is quite effective,\nthe compressed form will use about 400 bits for transmission."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#include <ctype.h>"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchar * ELEMENT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmain() \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBitstreamFrame_Process * bitstreamframe_process;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDequantize_Process * dequantize;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStereo_Process * stereo_process;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInverse_Transform * inverse_transform;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPost_Process * post_process;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWrite_Samples * write_samples;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBitstreamFrame_Process * bitstreamframe;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntacticElement * SE;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSE=bitstreamframe_process->get(ELEMENT);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndequantize->execute(SE);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSE=bitstreamframe_process->get(ELEMENT);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstereo_process->execute(SE);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSE=bitstreamframe_process->get(ELEMENT);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninverse_transform->execute( SE);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSE=bitstreamframe_process->get(ELEMENT);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npost_process->execute(SE);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSE=bitstreamframe_process->get(ELEMENT);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwrite_samples->execute(SE);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe decompressed program looks the following manner:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#include <ctype.h>"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchar * v0;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmain()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBitstreamFrame_Process * i0;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDequantize_Process * i1;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStereo_Process * i2;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInverse_Transform * i3;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPost_Process * i4;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWrite_Samples * i5;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBitstreamFrame_Process * i6;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntacticElement * i7;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ni7 = i0->get(v0);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ni1->execute(i7);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ni7 = i0->get(v0);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ni2->execute(i7);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ni7 = i0->get(v0);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ni3->execute(i7);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ni7 = i0->get(v0);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ni4->execute(i7);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ni7 = i0->get(v0);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ni5->execute(i7);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Example part of the compression tool"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the following a part of the mapping tool is described. The mapped\nbinary stream mostly consists of fixed length code symbols, to have it a\nlittle bit more robust against transmission errors. This example does\nnot describe the complete set of the C++ language, but only a part of it\nand probably will have to be extended and optimized."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere are several parts of a high level language program. Each part or\nstatement starts with a start code given in the following table"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"72%,28%\",]\n|===\n|#include |00010\n|#define |00011\n|defining global variables |00100\n|defining local variables |00101\n|defining a method |00111\n|call of method of some class |01001\n|call of method of some class with assign |01010\n|making instances of classes |01000\n|start main program |01011\n|end main program or a class |01100\n|execution statement |01101\n|while statement |01110\n|end of while loop |01111\n|for statement |10000\n|end of for loop |10001\n|if statement |10010\n|else statement |10011\n|end of if |10100\n|defining a classs |10101\n|call of a C-function |10110\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStart codes for program parts resp. statements"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt may show up, that there will be more startcodes for mapping a -more\nor less- complete language. It may then be possible, that one or more\nfurther bits are needed. These start codes are not for synchronizing\npurposes, it is thus not necessary to have more bits than needed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that some textual items are represented implicitly in this scheme.\nE.g. for braces (\u201c\\{\u201c, \u201c}\u201d) everything between an \u201cif\u201d and and \u201cend of\nif\u201d is implicitly grouped together."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor all the remaining mapping tables and a more comprehensive\ndescription of the tool refer to M0622."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-----------------------ParentClass"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChildClass"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAssociation Name"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrole -1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrole -2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG4Object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPresentableObject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProcessObject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContentObject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProfile ID"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSSC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSEC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBITSTREAM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nParser /"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nComposer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPresentable Objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContent"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProcess"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScript *"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nV"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDEVICE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAV Scene"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompositing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScript *"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUSER INTERACTION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProcess"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPresent"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nat time t"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlocation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nx,y"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRead"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWavelet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFilter"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCoeff."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContent"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScript"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompositing Script"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWavelet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncoded"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCoeff."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWavelet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFilter"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCoeff."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRead,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecode,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDequant."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWavelet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCoeff"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPresentable"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nObject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nImage"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPart"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContent-object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContent-object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL-S"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL-O"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG4 Class library"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL-B"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEnd user"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAudio-video Subsystem"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRendering Tools : standard"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHost"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCPU"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG4 Level 2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRun-TimeEngine"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVisualization Tools : dwnld"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndownalo"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPresentation layer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLevel 1 Compilation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLevel 2 Compilation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRendering Tools : download"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndownalo"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding Tools : downloaded"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding Tools : standard"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndownalo"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCopro"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncessor(s)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding engine"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTransport layer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNetwork Physical layer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npro"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngram"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDecoding script"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL-R"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMSDL-B"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG4 Level 1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRun-TimeEngine"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompositing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nscript"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProcess-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nobject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nParsing"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProcess-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ninfo"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPresentableObject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAudioVisualScene"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVisualScene"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAudioScene"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncomposed of"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npart of"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHierarchicalAVScene"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVisualScene"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSpatialObject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3DObject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2DObject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncomposed of"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHierarchicalObject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\npart of"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2DObject"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2DPosition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOpacity Information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDepth"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nShape"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMotion"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTexture"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTexture Coded Representation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTransformParameters"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFractalTransformCoefficients"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDCTCoefficients"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTextureInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2D Component"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWaveletCoefficients"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nShapeRepresentation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2DComponent"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCollectionOfPoints"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEdgeRepresentation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nShape Information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRegularShape"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRectangle"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTriangle"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBounding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBox"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nShapeCodedRepresentation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n..."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChainCode"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSpline"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n..."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDCTCodedMotionInfo"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMotionCodedRepresentation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMotionInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAffineParameters"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVectorParameters"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nQuantizer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual event Source"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nApply(eventsource)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVectorialQuantizer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual event Source"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nApply(eventsource)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nScalarQuantizer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual event Source"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nApply(eventsource)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLBGQuantizer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual event Source"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nApply(eventsource)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n...."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n...."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUniformScalarQuantizer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual event Source"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nApply(eventsource)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nITransformer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual TextureInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nApply(TextureCodedRep.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWaveletTransformer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual TextureInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nApply(TextureCodedRep.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n...."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIDCTTransformer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual TextureInformation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nApply(TextureCodedRep.)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompensator"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvirtual SpatialObject Apply(SpatialObject)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n...."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANIZATION FOR STANDARDIZATION\nAVARO\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ISO-IEC/JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== CODING OF MOVING PICTURE**S AND AUDIO**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO-IEC/JTC1/SC29/WG11 *N1165*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996 / Munich"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Leonardo Chiariglione - Convenor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Joint Audio/Video/Integration Ad Hoc Group on Syntactic\nDescription Language"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* INTEGRATION : Alexandros Eleftheriadis (Columbia University)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCo-chairs: AUDIO : James Johnston (AT&T)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVIDEO : Georges Campbell (Compression Lab. Inc)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Official mandate: Complete MSDL Part 5 and related Annexes*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* {empty}1. Collect and complete requirements from MPEG experts\n* 2 Complete and check the formal rules\n* 3 Describe Audio/Video/SNHC syntax with these rules"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: No meeting will be held"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members of the Ad Hoc Group*: General MSDL AHG Reflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nolivier.avaro@issy.cnet.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"24%,20%,22%,17%,17%\",]\n|===\n| | | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nleonardo.chiariglione@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncreader@samsung.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANIZATION FOR STANDARDIZATION\nAVARO\n1980-01-03"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ISO-IEC/JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== CODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO-IEC/JTC1/SC29/WG11 *N1166*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996 / Munich"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Leonardo Chiariglione - Convenor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* Ad Hoc Group on requirements for a possible MPEG-4 virtual\nmachine"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* Jean-Claude Dufourd (ENST)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Official mandate: Document virtual machine aspects in MPEG-4*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* {empty}1. Analyse work in this area\n* 2 Analyse real time aspects (including synchronisation)\n* 3 Analyse possible architecture\n* 4 Issue requirements and recommandations on the topic"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: No meeting will be held"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members of the Ad Hoc Group*: General MSDL AHG Reflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nolivier.avaro@issy.cnet.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"24%,20%,22%,17%,17%\",]\n|===\n| | | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nleonardo.chiariglione@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncreader@samsung.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANIZATION FOR STANDARDIZATION\nAVARO\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== ISO-IEC/JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *CODING OF MOVING PICTURES AND AUDIO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO-IEC/JTC1/SC29/WG11 *N1167*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996 / Munich"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Leonardo Chiariglione - Convenor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title:* MSDL Architecture and Objects Hierarchy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* Olivier AVARO (FRANCE TELECOM CNET)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCo-chair: Julien Sign\u00e8s (FRANCE TELECOM CCETT)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Official mandate: Complete Part1 and Part2 of the MSDL WD and related\nannex.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* {empty}1. Collect requirements from MPEG experts\n* {empty}2. Complete the architecture and class hierarchy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings*: No meeting will be held"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Members of the Ad Hoc Group*: General MSDL AHG Reflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nolivier.avaro@issy.cnet.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"24%,20%,22%,17%,17%\",]\n|===\n| | | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nleonardo.chiariglione@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncreader@samsung.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nDavid J. Meares\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ORGANISATION INTERNATIONALE DE NORMALISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*CODING OF MOVING PICTURES AND AUDIO*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11 N1168*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: MSDL and NBC Audio Groups*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title: Description of NBC Audio Syntax with MSDL*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Status: Proposal*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== 1. Introduction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis document is a first attempt to describe the NBC Audio syntax with\nthe syntactic description language in definition in MSDL. To achieve\nthis, the audio experts produced some specific requirements on the\nneeded syntactic features jointly with the MSDL group. The MSDL group\ntook into account these requirements to produced then some formal rules\nto describe the NBC Audio syntax. This draft is the result of the\ncollaboration."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== 2. Requirements"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese requirements are not exhaustive and can be modified and completed\nlater on, for example during the construction of audio VM. The list of\nrequirements produced together with audio experts are the following :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* description of the syntax of the bitstream in as readable a format as\npossible.\n* definition of some basic data entities (coefficients, parameters,\nmodes, synchronization, padding data, byte alignement...).\n* definition of some basic data types (int, char, ...).\n* possibility to include header at fixed interval in variable length\nframe.\n* possibility to describe data parsing dependent on the previously\nparsed and processed elements.\n* possibility to include alignment indication data and to indicate\nwhether an object can be chopped.\n* description of alignment and chopping up capabilities to the\ndemultiplexer.\n* possibility to describe \u00abhierarchical VLC\u00bb."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese requirements were combined with the following set of policies:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* there should be as few constructs as possible,\n* the declarative part should be predominant, and data dependent parsing\nshould be kept at a minimum,\n* the use of variables and anything non declarative in nature should be\nbanned if not strictly necessary: in natural language, this means that\nanything that looks like a program instruction is either a suggested\nimplementation of the parser or even an action that belong to decoding\nand not to data specification,\n* the interchange format should be described from the channel point of\nview, not from either the decoder or the encoder point of view, so that\nno side is preferred and no unnecessary constraint is put on\nimplementation,\n* the general feeling of the syntax should be C-like."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. Formal rules"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis set of formal rules have been taken from document N1111 and\nimproved by taking the previous requirements into consideration. At this\nstage, all the syntactic features to satisfy the request have not been\ndevelopped but they are sufficient to describe the complete NBC syntax."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompared to the usual pseudo-C code used in MPEG-2, the formal rules\ndefined here bring the following added value :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* the syntax is described in a formal way. The consistency of this\ndescription can be tested contrary to the pseudo-C code approach. This\nwill allow to process automatical bitstream conformance and consistency\nchecking.\n* the formal description used is simpler and will improve its\nreadibility.\n* the description does not describe a coding or a decoding process. It\nis really the description of the interchange format."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe first describe elementary constructs, moving to composite syntactic\nconstructs, arithmetic and logical expressions, and finally address\nsyntactic control flow. The latter is needed to take into account\ncontext-sensitive data. Several examples are used to clarify the\nstructure using the MPEG-2 Video IS. A full example of the current NBC\nAudio syntax is given in the next section."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *3.1 Elementary Data Types*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe can in general identify the following elementary syntactic elements:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Constant-length direct representation bit fields or Fixed Length Codes\n(e.g., temporal_reference). These include the encoded value as it is to\nbe used in the bitstream.\n. Variable-length direct representation bit fields, sometimes called\nvariable length FLCs. These are FLC for which the length is determined\nby the context of the bitstream (e.g., another parameter).\n. Constant-length indirect representation bit fields (e.g. chroma_format\nor coded_block_pattern). These require an extra lookup into an\nappropriate table or variable, or some algorithmic processing to obtain\nthe desired value (e.g., coded_block_pattern).\n. Variable-length indirect representation bit fields (Huffman codes).\n. Arithmetically coded bit fields."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.1.1 Constant-Length Direct Representation Bit Fields"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese can be simply represented as:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[aligned] _type_(_length_) _element_name_ [= _value_]; // C/C++-style\ncomments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe _type_ is one of the following: \u2018int\u2019 for signed integer, \u2018uint\u2019 for\nunsigned integer, \u2018bit\u2019 for raw data, \u2018boolean\u2019 for logical values, and\n\u2018vlc\u2019 for variable length data. \u2018_length_\u2019 indicates the length of the\nelement in bits, as it is stored in the bitstream. It can be a constant\n(e.g., 10), or as we will see below, a variable, or a special construct\nthat indicates VLC decoding. The _value_ is only present when the value\nof the element is fixed (e.g., start or sync codes, or object IDs), and\nit may also indicate a range of values (i.e., \u20180x01 .. 0xAF\u2019). The\nattribute \u2018aligned\u2019, if present, means that the data is aligned on a\nbyte boundary and hence padding bits may have to be discarded before\nparsing."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs an example, a start code would be represented as:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\naligned const(32) picture_start_code=0x00000100;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn entity such as temporal reference would be represented as:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(5) temporal_reference;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhere uint(5) indicates that the element should be interpreted as a\n5-bit unsigned integer (by default with the most significant bit\nfirst\u2014MSBF)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that constants are defined using the \u2018const\u2019 attribute:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst int SOME_VALUE=255;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst bit(3) BIT_PATTERN=1; // this is equivalent to the bitstring \u201c001\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo designate binary values, the \u20180b\u2019 prefix is used, similar to the \u20180x\u2019\nprefix for hexadecimal numbers, and a period (\u2018.\u2019) can be optionally\nplaced every four digits for readability. Hence 0x0F is equivalent to\n0b0000.11111."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 3.1.2 Variable Length Direct Representation Bit Fields"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis case is covered by the above rule, by allowing the _\u2018length\u2019_ field\nto be a variable included in the bitstream,or an expression involving\nsuch a variable. For example:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(3) precision;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint(precision) DC;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 3.1.3 Constant-Length Indirect Representation Bit Fields"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere, in addition to the actual element we need to define how it is\nmapped to obtain the actual values that the decoder will use. This can\nbe accomplished by defining the map itself:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap _MapName_ (_idx_type_, _type1 name1_, _type2 name2_, \u2026, _typeN\nnameN_) [sign=__col__] \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_index_[s] _value_1 \u2026 value_M,_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[_index_[s] _value_1 \u2026 value_M, \u2026_]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that this is a multi-dimensional mapping: there is one input\n(index), and zero or more outputs (values), allowing the table to be\nused to specify the value for several different variables. The _type_\nentries in the definition indicate the type of the value columns, which\nare addressed using the _\u2018name\u2019_ information (e.g.,\n_MapName.name1[index])_."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs an example, we have:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// a table that relates the chroma format with the number of blocks per\nsignal component"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap blocks_per_component (uint(2), uint Yblk, uint Ublk, uint Vblk) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0 4 1 1, // 4:2:0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1 4 2 2, // 4:2:2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2 4 4 4 // 4:4:4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap(blocks_per_component) chroma_format; // this is a fictional example"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// you can now access Yblocks like: chroma_format.Yblocks"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUsing the above declaration, we can access a particular value of the map\nusing: blcoks_per_component.Ublocks[chroma_format]. In other words,\nchroma_format can be used as a regular index into the columns of the\nmap. _(ed.: An alternative representation under consideration is:\nchroma_format.Yblocks)_."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 3.1.4 Variable Length Indirect Representation Bit Fields"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor a variable length element utilizing a Huffman table, a similar\nspecification is used:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap(_table_) ac_dct_coefficient;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(_ed.: alternative: vlc(table) ac_dct_coefficient)._ The definition of\nthe table is done in exactly the same way as we saw before, but here we\nhave the data type \u2018vlc\u2019 as the index data type. In other words:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap sample_vlc_map (vlc, boolean(1) value1, int value2) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b0000.001 0 5,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b0000.0001 1 -14"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe vlc codewords are binary strings (starting with \u2018Ob\u2019), optionally\nusing the period (\u2018.\u2019) every four digits for readability. Boolean\nvariables are equivalent to \u2018int\u2019."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVery often, VLC tables are incomplete: due to the large number of\npossible entries, it is inefficient to keep using variable length\ncodewords for all possible values. This necessitates the use of escape\ncodes, that signal the subsequent use of a fixed-length representation.\nTo allow for such exceptions, element specifications are allowed for map\nvalues. This is illustrated in the following example:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap sample_map_with_esc (vlc, uint value1, uint value2) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0000.001 0 5,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0000.0001 1 -14,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0000.0000.1 map(foo) int(32),"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0000.0000.0 0 -20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs written above, when the codeword 0b0000.0000.1 is detected in the\nbitstream, then another VLC table is used for the value for column 1,\nwhile the following 32 bits will correspond to the value for column 2\n(the order is significicant). Using this construct, the complete\nbehavior of the VLC mapping is described in a concise manner in a single\nplace."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA notational convenience that is present in VLC tables is use of the\nsame codewords for both the negative and positive value of the variable\nrepresented. This can be accommodated by denoting in the codewords the\nposition of the sign bit, using the letter \u2018s\u2019. Typically, the sign\nchange affects only one column (at least this is the case with existing\nMPEG VLC tables). Hence we only need to denote the column that is\naffected by the sign bit. This is done as shown below:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap table_with_signs (vlc, uint, int) sign=2 \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b000 1 5,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b0000.s 2 7,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b0001.00s 3, -10,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n0b0001.010 4, 4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe above specification says that the sign bit (1 for positive, 0 for\nnegative) affects column 2 of the values. Hence 0b0000.1 results in a\nvalue of 7, while 0b0001.000 results in a value of 10 (-(-10))."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 3.1.5 Arithmetically Coded Bit Fields"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo be determined."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 3.2. Composite Data Types"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEquipped with the above definitions for fundamental types, we can now\nexamine the definition of composite types or objects. A very useful\nfeature is to be able to immediately identify the type of object that we\nare dealing with; object identifiers are then a particularly attractive\nfeature. In several cases, the desire for bit efficiency precludes their\nuse (this is the case in MPEG-2 below the slice level). The definition\nof a composite object can then be expressed as:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass _object_name_ [is _property_] [:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[aligned] bit(_length_) [_id_name_]= _object_id|id_range_] \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_element_1_;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[_element_2; \u2026_]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe different elements are definitions of elementary bitstream\ncomponents as we saw in Section 1, or control flow that is discussed in\nthe following section. The _object_id_ is optional, and if present is\nthe key multiplexing entity for individual objects. The _id_range_ is\nspecified as _start_id_ .. _end_id_, inclusive of both bounds, to\nexpress that the object can have a range of possible id\u2019s."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe optional \u2018is _parent_class_\u2019 specifies that the class can be used\nwherever a slot of type _parent_class_ has been specified."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExamples:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass foo \\{ ..."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbar name_1;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n... }"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass bletch is bar \\{ ... } // this class can be used in the name_1\nslot"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass slice: aligned uint(32) slice_start_code=0x00000101 .. 0x000001AF\n\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026 // here we get vertical_size_extension, if present"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (scalable_mode==DATA_PARTITIONING) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(7) priority_breakpoint;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} ;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe order of declaration of bitstream components is important: it is the\nsame order in which the elements appear in the bitstream."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe can also encapsulate objects within other objects. In this case, the\n_element_ mentioned at the beginning of this section is an object\nitself."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 3.3. Arithmetic and Logical Expressions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll standard arithmetic and logical operators of C/C++ are used as is,\nincluding their precendence rules."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 3.4. Syntactic Conditional Construct"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe syntactic conditional constructs provide for conditional definition\nof slots, depending on context, as well as for definition of repetitive\nstructures. The familiar C/C++ if-then-else construct is used for\ntesting conditions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (condition) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} [ else if (condition) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}] [else \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following example illustrates the procedure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass conditional_object \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(3) foo;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nboolean bar_flag;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (bar_flag) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(8) bar;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(32) more_foo;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere the presence of the entity \u2018bar\u2019 is determined by the \u2018bar_flag\u2019.\nAnother example is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass conditional_object \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(3) foo;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nboolean bar_flag;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (bar_flag) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(8) bar;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} else \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap(some_vlc_table) bar;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nuint(32) more_foo;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere we allow two different representations for \u2018bar\u2019, depending on the\nvalue of \u2018bar_flag\u2019. We could equally well have another entity instead\nof the second version (the variable length one) of \u2018bar\u2019 (another\nobject, or another variable). Note that the use of a flag necessitates\nits declaration before the conditional is encountered."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the same category of context-sensitive objects we have the so-called\nrepetitive objects. These simply imply the repetitive use of the same\nsyntax to parse the bitstream, until some condition is met (it is the\nconditional repetition that implies context, but fixed repetitions are\nobviously treated the same way). The familiar structures of \u2018for\u2019,\n\u2018while\u2019, and \u2018do\u2019 loops could be used for this purpose, but to eliminate\nthe need for temporary variables (counters etc.), we use the following\nstructure:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrepeat (_times_) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026 // repeat exactly _times_ times"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrepeat ([var:] _array_slice_) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026 // repeat exactly length of _array_slice_ times"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// var is an iteration variable to be used only as array index"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrepeat \\{ // _ed.: this is really do-while_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026 // repeat at least once, until _bitstring_ is present in the\nbitstream, or"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// while it is not present"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} until ([!] _bitstring_)_;_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhile ([!] _bitstring_) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2026 // repeat 0 or more times, while bitstring is present in the"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// bitstream, or while it is not present"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere we have four different forms: a fixed repetition using the _times_\nargument (which can be a variable), a repeat iterating on an array, a\n\u2018repeat at least once\u2019 construct, and a \u2018repeat zero or more times\u2019\nconstruct. Note that only the second sort allows the use of an iteration\nvariable, to be used only as array index."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExample:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrepeat \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmap(ac_vlc_table) ac_coeff;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} while (! 0b011);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis says that \u2018ac_coeff\u2019 is parsed using the VLC table \u2018ac_vlc_table\u2019.\nThere is at least one \u2018ac_coeff\u2019, and parsing should stop when the bit\nstring \u2018011\u2019 is detected in the bitstream."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 3.5. Special Constructs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn order to accommodate special syntactic structures that cannot (at\nthis time) be elegently represented using the above design, special\nsyntax constructs are defined. The intention is to minimize their number\nto the greatest extend possible."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe first one is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrle(_runbits, valuebits_) _array_[_size_];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis defines an array of \u2018int\u2019, of size _size_. Its values are filled by\nparsing the bitstream reading sequentially _runbits_ bits for the run\nlength and _valuebits_ for the size of the value of the run, and\nproperly keeping track of the correct positions within the array."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnother special construct is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnonzero(_array___slice_)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis yields the number of non-zero elements contained in array_slice. An\narray slice can be specified as _array_[_start .. end_], for an array\nslice. A missing start means from the beginning of the array and a\nmissing end means to the end of the array. For example, _array_[_.._]\nmeans the whole array."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_We may need another construct for array operation, either a\nelement-by-element operator or a stride specifier._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe last construct is:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[ascending|descending] list \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class1;_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[class 2; \u2026]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe elements inside the braces (_class1_ etc.) have to be objects with\ndefinitions that include object id\u2019s. The syntax here indicates that the\nbitstream contains any number of the objects contained inside the\nbraces, in any order. The list encompasses all the objects or group of\nobjects obeying to the specification inside the braces."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlist \\{ class1; } groups all consecutive objects of class1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nlist \\{ class1; class2; } contains all consecutive pairs, but does not\ninclude a repetition of class2 objects (after the first)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the objects specified in the list have id ranges, it makes sense to\nspecify monotonic increase or decrease of those id\u2019s. This means the\nlist includes the sequence of objects that have monotonically changing\nid\u2019s and the first violation of ordering terminates the list before the\nviolating element."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== 4. Description of the NBC Audio Algorithme within MSDL"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere is a first try at reformulating the NBC Audio bitstream\nspecification. This work was done while both syntax and specification\nwhere changing. It is expected to change in the near future. It is\nprovided here to help clarify our goals and current state of work."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n________________"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SYNCWORD=?; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ PADDING_VALUE=0x00;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_CP_VALUE=0x01;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_CP_VALUE=0x1F;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_CC_VALUE=0x20;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_CC_VALUE=0x2F;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_LFE_VALUE=0x30;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_LFE_VALUE=0x3F;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_NSEL_VALUE=0xEF;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MIN_DATA_VALUE=0xF0;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ MAX_DATA_VALUE=0xFE;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ PADDING_DATA_VALUE=0xFF;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ ONLY_LONG_WINDOW=0x0;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ LONG_START_WINDOW=0x1;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ LONG_STOP_WINDOW=0x2;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SHORT_START_WINDOW=0x3;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SHORT_STOP_WINDOW= 0x4;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ EIGHT_SHORT_WINDOW =0x5;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ SHORT_EXT_STOP=0x6;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ NINE_SHORT_WINDOW= 0x7;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ sampling_frequency_table (_int_(2), double rates) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ channel_configuration_table (_uint_(3), ?) ("
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ emphasis_table (_uint_(2), ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ bitrate_index_table(_uint_(4), ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ window_sequence_table(_bit_(3), ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n? // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_const_ _int_ number_of_coderbands[8]= \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// 8 values go here"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ hcod_sf_vlc ** (_vlc_, ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// scale factor Huffman codebook goes here"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_ hcod_vlc ** (_vlc_, ?) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// Huffman codebook goes here"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ scalefactor_data \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// nonzero(a, b) returns the number of non-zero elements of array a of\nlength b"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (_nonzero_(sfb_cb, number_of_coderbands[window_sequence]) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(hcod_sf__vlc_) *hcod_sf*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ spectral_data \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (i: max_sd[window_sequence]) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (sd_nelems[window_sequence][sfb_cb[i]]) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(hcod_vlc[sfb_cb[i]]) *sval*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nclass individual_channel_stream \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *predictor_data_present*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (window_sequence >= SHORT_DATA_WINDOW) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *scalefactor_grouping*["
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nscalefactor_group_size[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *first_scalefactor*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_rle_(4, 4) *sfb_cb*[number_of_coderbands[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (predictor_data_present) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(5) *predictor_reset*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *prediction_used*[num_sfb[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nscalefactor_data *ScaleFactorData*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nspectral_data *SpectralData*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ data_element: _bit_(8) MIN_DATA_VALUE .. MAX_DATA_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *n_bytes*; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *data*[n_bytes]; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ lfe_channel_element _is_ syntactic_element:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) MIN_LFE_VALUE .. MAX_LFE_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(4) *n_samples*; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(12) *samples*[n_samples]; // not defined yet"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ coupling_channel_element _is_ syntactic_element:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) MIN_CC_VALUE .. MAX_CC_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(8) *number_of_coupled_channel_pairs*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (number_of_coupled_channel_pairs) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(5) *cc_index*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *ccp*[3];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(window_sequence_table) *window_sequence*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *window_shape*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nindividual_channel_stream *IndividualChannelStream*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (_nonzero_(ccp, 3 * number_of_coupled_channel_pairs) - 1) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_repeat_ (_nonzero_(sfb_cb,number_of_scoderbands[window_sequence])) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(scalefactor_vlc) *gain_element*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ channel_pair_element _is_ syntactic_element :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) MIN_CP_VALUE .. MAX_CP_VALUE \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *two_chan*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(window_sequence_table) *window_sequence*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *window_shape*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (two_chan) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *ms_mask_present*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (ms_mask_present) _bit_(1) *ms_used*[num_sfb[window_sequence]];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nindividual_channel_stream *IndividualChannelStream0*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (two_chan) individual_channel_stream *IndividualChannelStream1*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ NBC_raw_data_block \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_list_ \\{ syntactic_element *SyntacticElement*; }"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_list_ \\{ data_element *DataElement*;}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ NBC_raw_data_stream \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_list_ \\{ NBC_raw_data_block *NBCRawDataBlock*;}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ adts0_variable_header \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(bitrate_index_table) *bitrate_index*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *copyright_id*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *copyright_id_start*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (bitrate_index!=0) _uint_(10) *main_data_begin*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_else_ \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(12) *next_header*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(8) *buffer_fullness*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(2) *number_of_raw_data_blocks_in_frame*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(5) *num_syntactic_elements*[number_of_raw_data_blocks_in_frame];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *padding_bit*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ adts0_fixed_header : aligned _bit_(12)=SYNCWORD \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *ID*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(2) *layer*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *protection_bit*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(sampling_frequency_table) *sampling_frequency*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_bit_(1) *private_bit*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(channel_configuration_table) *channel_configuration*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_boolean_(1) *original_copy*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_uint_(1) *home*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_map_(emphasis_table) *emphasis*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ adts0_frame \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nadts0_fixed_header *Adts0FixedHeader*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nadts0_variable_header *Adts0VariableHeader*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (protection_bit==0) _uint_(16) *crc_check*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBC_Raw_Data *NBCRawData*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_class_ audio_sequence \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhile (SYNCWORD) adts0_frame *Adts0Frame*;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n____________________"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5. Further time plan for NBC MSDL development"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBC Audio coding will continue to be used as a testbed to do the\ntransition from the MPEG-1 pseudo-C syntax to MSDL. The following plan\nfor this work was agreed:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNBC Audio will be developed using description in MPEG-1 pseudo-C syntax\nand in MSDL in parallel. Since it is part of MPEG-2, the normative part\nof 13818-7 will contain a description in MPEG-1/2 pseudo-C syntax.\nStarting with RM-3, an MSDL description will be a part of the NBC\ndevelopment effort. This will enable the use of the algorithm and tools\nof NBC in the first working draft of MPEG-4 due in November, 1996. The\nfurther plan is to have MSDL frozen in time to have an informative ANNEX\nin 13818-7 containing the description expressed in MSDL."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Bibliography"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* ISO/IEC JTC1/SC29/WG11 N1111 November 1995 MSDL AHG MSDL\nspecification. Version 0.1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nFellows\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/N1169"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Implementation Studies Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Methodology used for assessment of implementation cost and\nperformance for proposals incorporated into the Verification Models of\nMPEG-4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStatus: DRAFT."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSorin C. Cismas sorin@compcore.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNicolas Demassieux demassieux@elec.enst.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPaul Fellows paulf@bristol.st.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMarco Gandini marco.gandini@cselt.stet.it"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAndreas Hutter a_hutter@lis.e-technik.tu-muenchen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nG\u00fcnther Junge 100012,2700 Fujitsu"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPeter Kuhn p_kuhn@lis.e-technik.tu-muenchen.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDavid Molter molter@lep-philips.fr"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAndreas von Ow Studer Professional Audio"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThorsten Selinger selinger@hhi.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJaince Shen tjs@risc.rockwell.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMatthias Sch\u00f6binger ms@mess3.zfe.siemens.de"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMustapha Ali Turker turker@research.nokia.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMichael Zeug mzeug@iterated.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAmedeo Zuccaro amedeo.zuccaro@st.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *1. Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOne of the goals of the ISG is to ensure that the MPEG-4 profiles can be\nimplemented at a reasonable cost, which, with the new functionalities\nprovided by MPEG-4, is one of the key factors influencing how successful\nit will be commercially. The term implementation is to be taken in a\nvery general meaning : ISG considers a whole range of possible\napplications, platforms, processing architectures, I/O systems, software\nand communications infrastructure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo obtain that result, the ISG has defined three action points, aiming\nat different stages of the development of MPEG-4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Developing implementation criteria to offer direction for the MPEG community concerning eventual implementation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt is important that the developers of tools, algorithms, syntax and\nprofiles are made more \u201cimplementation-conscious\u201d than \u201csome\u201d currently\nare. This does not necessarily mean that they have to achieve expertise\non Hardware, Software and Systems. The ISG believes that, the more the\ndevelopers of tools know about the general problems related to\nimplementation, the more they are likely to propose alternative and less\nimplementation costly algorithms and tools for obtaining a given\nfunctionality. It is also important that any further discussion between\nthe audio, video or integration groups and the ISG on a given\nimplementation problem relies on a common ground. To achieve this, the\nISG will develop a methodology and a set of guidelines for\nImplementation, which will be communicated to the MPEG community, and\nalso internally used for conducting the assessments. A first version of\nthis is presented in the section 2 of this document, and a more\ncomprehensive version will be delivered during the Firenze meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Assessing the implementation of the proposed tools"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the early stage of the MPEG-4 development, tools, algorithms and\nbitstream organization will be proposed and evaluated. At this stage, it\nis not possible to estimate any meaningful \u201ccomplexity of\nimplementation\u201d of a given tool or algorithm. Such an estimate has a\nmeaning only when :-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* The targeted application is defined,\n* A particular set of tools is selected,\n* The target system is defined.\n* The implementation has been \u201cported\u201d and optimized for the target\nsystem."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNevertheless, the ISG thinks that it is important to provide a feedback\non a given tool, for a possible iterative reduction in system resource\nconsumptionfootnote:[System resources include :- Memory system,\nprocessing cycles, arithmetic operations, branches etc.]. So, the second\ngoal is to evaluate and deliver information on implementation as early\nas possible on each tool used in a core experiment or upon request from\nthe audio, video or integration groups. To achieve this goal, the ISG\nproposes to develop an instrumentation system that would be incorporated\ninto the VM. This instrumentation system will return global information\n(I/O data rates, computational cost, control cost...) which are\npertinent for assessing the potential implementation difficulties of a\ngiven tool or set of tools. The initial concepts of this instrumentation\nprocedure are presented in the section 3 of this document."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUsing this information, as well as other information provided by the\naudio, video or integration groups, the ISG will conduct during this\nphase an implementation assessment on tools and algorithms, as well as\non the bitstream related functions (MSDL encoding and multiplex) which\nwill be used in the core experiments. This implementation assessment\nwill be communicated to the audio, video or integration groups for being\nused in their decision process. The details of the assessment procedure\nare presented in section 4 of this document."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Assessing the implementation of the profiles"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLater in the development of MPEG-4, it is expected that some application\nclasses will emerge and that a number of profiles will be defined. At\nthis stage, the ISG will perform an in-depth implementation analysis of\nthese profiles for these applications and provide a feedback in due\ntime. There are no further details on this issue at present."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 2. Framework of reference for implementation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis section specifies the categories that are used for assessing the\nimplementation cost of algorithms and tools."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA second part of this section entitled \u201cImplementation Guidelines\u201d will\ncontain background information on implementation issues to help\nalgorithm developers to better understand and pay attention to\nimplementation aspects. It should be understood that this is to aid\npeople to make algorithms simpler where possible but not to constrain\nalgorithm development. Currently just one example is given in this\nsection."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAlgorithms and Tools will be evaluated describing and quantifying their\nimplementation cost based on a set of criteria detailed below:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Analysis categories:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[loweralpha]\n. processing power/cost\n. memory size, organization, control of and bandwidth\n. I/O bandwidth\n. ability to exploit or introduce parallelism and pipelining etc.\n. control cost/overhead\n. system inherent delay"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Results to be achieved by the analysis categories:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*a) processing power/cost*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProcessing power will be specified in terms of operations per second (or\nsample) and will at a first stage be distinguished for two basic\narithmetic operations and data types: Multiplies and adds for integers\nand floats to test the methodology only."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"44%,32%,24%\",]\n|===\n|Arithmetic operations per second |Floating-point arithmetic |Integer\narithmetic"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Multiplies | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Adds/Subtracts | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt a more refined state of the analysis it will be necessary to further\nspecify the arithmetic accuracy and the number representation etc."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*b) memory size, organization and bandwidth*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe minimum amount of memory required to perform the algorithm will be\nspecified in terms of bytes for a specific video input format / audio\nsample rate defined in a core experiment or VM."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor external memory it will be a matter of concern whether the memory\nsize matches the typical RAM organization (powers of two like 1M, 4M,\n...) or not."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe memory bandwidth between a processor/dedicated chip and the external\nmemory will be specified in bits per second"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*c) I/O bandwidth of tools*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe amount of reads and writes of a tool to another tool will be\nspecified in bits per second."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*d) ability to exploit or introduce parallelism and pipelining*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe outcome of this analysis will indicate the degree of parallelism and\npipelining that is inherent to the algorithm/tool or that can be\nintroduced to it. Especially it will be indicated if this ability is\nmissing (or inherently impossible to achieve!)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBeyond that the regularity/complexity of the algorithm will be\nanalysed,. This will include identification of recursive processing\nbottlenecks that might lead to high peak processing requirements."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*e) control cost/overhead*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nControl cost comprises all kind of operations that are not included in\nthe operations specified under a) processing power/cost (e.g. branches).\nThis category is going to be continuously refined in the process of\nreworking this document-"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*f) system inherent delay (encoder to decoder for real-time\napplications)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nImplementation and processing independent delay as introduced by the\nalgorithm like B-pictures in MPEG-2. To be specified in ms."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 3. Instrumentation of the Verification Model"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe instrumentation of the Verification Model will be used to obtain,\nwhen conducting a Core Experiment, metric\u2019s that are useful for the\nimplementation assessment. It operates in a similar way to the profiling\ntools used for software development by measuring, during a simulation,\nseveral parameters. The essential pre-requisite is that the verification\nmodel be coded in either ANSI-C or C++."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe instrumentation environment is currently envisaged to have the\nfollowing features:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* It automatically provides a quantitative evaluation of several global\nparameters of each tool used in a core experiment. The considered\nparameters at this time are the I/O bandwidth of the tool, its\nprocessing power for operations and for control.\n* {blank}\n* The goal is to limit the amount of modification of the simulation\nenvironments used by the developers of the algorithms. Ideally, it\nshould be \u201cplugged\u201d in these environments with as little modification of\nthe sources as possible.\n* {blank}\n* The results of this instrumentation will be evaluated by the ISG and\nbe used as an aid for estimating the cost/performance of the\nimplementation. It is not the intention to distribute the raw data\ngathered as it may not necessarily be indicative of the eventual\nimplementation technique chosen.footnote:[It should be remembered that\nthe VM\u2019s purpose is to aid quality and functionality assessment with\npossiblity of eventually using it as an accurate reference against which\nhighly optimised solutions may verify the results of their outputs!]\nHowever in the spirit of openness (with the approval of the tool\ncontributor) such information could be made available in a legible\nformat similar to table 1. However, to avoid misunderstanding and\nmisuse, the community should be aware of the real meaning of these\nfigures and of the usage that will be made of them (see disclaimer)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_DISCLAIMER_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe results of the instrumentation will represent orders of magnitudes,\nwhich are pertinent, together with many other considerations coming from\nexperts of ISG, to aid the identification of implementation cost or\nperformance.. It is not going to be used per se for assessing the\nimplementation complexity of a given tool."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Core experiment: CCIR601, mobile calendar, content-based interaction\nscript #3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"46%,15%,18%,21%\",]\n|===\n|Tools |I/O Bandwidth (MByte/s) |Processing cost (MOperations/second)\n|Control cost (MOperations/ second)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1. segmentation and trajectories tracking |5 |100 |50"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. mask processing and coding |12 |50 |10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. motion estimation (locally affine) |32 |60 |30"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. sprite warping |700 |1200 |200"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. image padding technique |nil |nil |1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|global Core Experiment |950 |1600 |380\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 1: example of an output from the instrumentation procedure"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(this is an example ; the data are RANDOM)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 4. Implementation Assessment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUsing the information provided by the instrumentation, and also by a\ncareful analysis of the documentation provided by the developers of the\ntools, the ISG experts will evaluate each tool and core experiments.\nThis \u201ceducated experts assessment\u201d will produce, for each tool a number\nof \u201cpoints of concern\u201d for implementation. A point of concern associates\na severity flag, a comment and, in some cases, a pointer to a working\ndocument in which the analysis has been conducted. To keep the system\nsimple, there are only for severity flags:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"10%,14%,76%\",]\n|===\n|Level |Code |Meaning"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|- |Black |No evaluation conducted due to uncompleted documents"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1 |Green |No specific problem foreseen at this stage"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2 |Orange |Some experts find a possible problem in certain conditions.\nThe application range is somehow limited due to constraints on\nimplementation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3 |Red |Experts agree on a severe problem that has to be solved for the\ntool to become implementable. The application range for this tool is\nvirtually nil due to this problem, if no measure is taken. A pointer to\na relevant in-depth analysis is mandatory for a red flag and a\nconvergent view of most experts is necessary for emitting it (formally,\na 2/3 majority) . Expected to be a rare exceptional output (hopefully!)\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"37%,9%,40%,14%\",]\n|===\n|Tools |Flag |Reason |Document"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1. segmentation and trajectories tracking |G | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2. mask processing and coding |G | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3. motion estimation (locally affine) |O |I/O bandwidth could be a\nlimitation |P????"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4. sprite warping |R |unachievable in real-time even at CIF rate for\nnext generation processors due to a too high computational complexity\n|M????"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|sprite warping |O |FPU seem to be required |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5. image padding technique |G | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|global Core Experiment |R |OK if 4 is modified |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 2: example of an output from the assessment procedure"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(this is an example; the data are RANDOM)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis implementation assessment will be communicated to the audio, video\nor integration groups for being used in their decision process."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= MPEG/Audio Dallas Meeting Participant List (November 1995)\nFellows\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11/N1170*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Munich, January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,85%\",]\n|===\n|Source: |Convenor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on defining framework of implementation complexity\nanalysis when performing core experiments."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"22%,78%\",]\n|===\n|Mandate: |To formalize the approach that should be taken when\nperforming implementation complexity analysis. To provide general\ncriteria for simplification of implementation. To define the format of\nassessment reports."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Nicolas Demmassieux"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Vice Chairman: |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Meetings: |None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Communications: |E-mail only"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Membership: |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"22%,11%,28%,39%\",]\n|===\n|Name |Country |Affiliation |e-mail address"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Fellows, Paul. |UK |SGS-THOMSON |paulf@bristol.st.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Nicolas Demassieux. |FR |ENST |demmassieux@elec.enst.com"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Harald Brusewitz |S |Ericsson Radio Systems\n|harald.brusewitz@era-t.ericsson.se"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= MPEG/Audio Dallas Meeting Participant List (November 1995)\nFellows\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11/N1171*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Munich, January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,85%\",]\n|===\n|Source: |Convenor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Title: |Ad-hoc group on defining and implementing instrumentation tools\nfor embedding within VM\u2019s."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"22%,78%\",]\n|===\n|Mandate: |To investigate the feasibility of embedding intstrumentation\nwithin VM\u2019s capture gross performance metric\u2019s. If feasible produce an\ninitial set of tools to demonstrate the technique. Use elements of NBC\naudio as a test bed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Chairman: |Paul Fellows"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Vice Chairman: |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Meetings: |None"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Communications: |E-mail only"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Membership: |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"22%,11%,28%,39%\",]\n|===\n|Name |Country |Affiliation |e-mail address\n|Fellows, Paul. |UK |SGS-THOMSON |paulf@bristol.st.com\n|Nicolas Demassieux. |FR |ENST |demassieux@elec.enst.com\n|Casper Horne |UK |Mediamatics |caspar@mediamatics.com\n|David Molter |FR |LEP |molter@lep-philips.fr\n|Thorsten Selinger |D |HHI |selinger@hhi.de\n|Michael Zeug |US |Iterated Systems |mzeug@iterated.com\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n| | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= VOP_layer\nAVIRC\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND ASSOCIATED AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/*N1172*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Video Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStatus: Draft in Progress"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: *MPEG-4 Video Verification Model Version 1.0*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Author: VM Action Group*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1. Introduction* *2*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2. Video Object Plane (VOP) 3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.1 VOP Definition* 3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2.2 VOP format 4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. Encoder Definition *5*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3.1 Overview* 5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.2 Shape Coding 5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.3 Motion Estimation and Compensation 10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.4 Texture Coding 17"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3.5 Rate Control 18"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4. Bitstream Syntax *19*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4.1 General Structrue* 19"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n4.2 Session Layer 19"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n4.3 VOP Layer 20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n4.4. Motion Texture 23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5. Decoder Definition *24*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5.1 Overview* 24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n5.2Compositer Definition 25"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAppendix A *26*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Shape Coding Tables 26*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Appendix B 33*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Combined Motion Texture Coding 33*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*B.1. Macroblock Layer* 35"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nB.2. Block Layer 42"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 1. Introduction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *2. Video Object Plane (VOP)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 2.1 VOP Definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Video Object Planes (VOP) correspond to entities in the bitstream\nthat the user can access and manipulate (cut, paste...). The encoder\nsend together with the VOP, composition information to indicate where\nand when each VOP is to be displayed. At the decoder side the user may\nbe allowed to change the composition of the scene displayed by\ninteracting on the composition information."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the encoder:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the decoder:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 2.1.1: VM Encoder and Decoder Structure"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe VOP can be a semantic object in the scene : it is made of Y, U, V\ncomponents plus shape information. In MPEG-4 video tests sequences, the\nVOP were either known by construction of the sequences (hybrid sequences\nbased on blue screen composition or synthetic sequences) or were defined\nby semi-automatic segmentation. In the first case, the shape information\nis represented by a 8 bits components, used for composition (see section\n5.2). In the second case, the shape is a binary mask. Both cases are\ncurrently considered in the encoding process. The VOP can have arbitrary\nshape."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe exact method used to produce the VOP from the video sequences is not\ndescribed in this document."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWhen the sequence has only one rectangular VOP of fixed size displayed\nat fixed interval, it corresponds to the frame-based coding technique."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 2.2 VOP format"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll the input library will be available in either 50 Hz or 60 Hz ITU-R\n601 formats. Suggested filters for downsampling are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* for ITU-R 601 to SIF and SIF to QSIF those specified in ISO/IEC DIS\n2-11172 - MPEG-1 [2]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nluminance"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"16%,12%,12%,12%,12%,12%,12%,12%\",]\n|===\n|-29 |0 |88 |138 |88 |0 |-29 |// 256\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchrominance"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"20%,20%,20%,20%,20%\",]\n|===\n|1 |3 |3 |1 |// 8\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure _1_ - _Decimation filters_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* for 60 Hz ITU-R 601 to CIF 30 Hz the filters specified in document\n\u201cStandards conversion to and from single mode 288, 29.97 format\u201d\n[MPEG95/302];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt is suggested the ITU-R to SIF or QSIF conversions are done omitting\nthe first (even) field of a picture (both luminance and chrominance).\nFor example, the ITU-R 601 to SIF conversion is suggested to be done by\nusing three main steps: 1) omission of the first (even) field of a\npicture (both luminance and chrominance); 2) horizontally subsample\nluminance and chrominance using the decimation filters given 3)\nvertically subsample the chrominance using the corresponding decimation\nfilter. In this document, the acronym SIF will be used to designate the\n360x288 and 360x240 formats at 30 Hz while CIF designates only the\n360x288 format at 30 Hz."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWhenever possible the sequences have been provided with the\ncorresponding segmentation. Proposers may use their own segmentation\nsolutions and provide the MPEG group with the new set of masks."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n======"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n======= Class A, B and C sequences"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor class A, B and C sequences, segmentation may have a maximum of 256\nsegments (regions). Whenever possible, the segments should have a\nsemantic meaning and will correspond to the VOP. For these classes of\nsequences, the following formats are used for the files containing the\ndata (class D sequences have two views/files similar to class A, B or C\nsequences):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1) Luminance and chrominance (YUV) -* ITU-R 601 format ** containing\nluminance and chrominance data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* one file per sequence;\n* no headers\n* supply number of files and size in separate README file\n* chain all frames without gaps\n* for each frame, chain Y, U, V data without gaps\n* write component data from 1st line, 1st pixel, from left to right, top\nto bottom, down to last line, last pixel."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2) VOP binary shape format-* The format for the exchange of the VOP\nshape information is similar to the one used for the images, i.e a VOP\nmask has a format similar to ITU-R 601 luminance, where each pixel has a\nlabel identifying the region it belongs."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n======= Class E sequences"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nClass E sequences data is provided through two types of files. The\nnumber of files for each type depends on the number of layers in the\nsequence:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1) Luminance and chrominance (YUV)* files - ITU-R 601 format containing\nthe luminance and chrominance data in the same format as for the class\nA, B and C sequences."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2)* *VOP grey shape foramt (alpha planes)* files - ITU-R 601 format -\ncontaining the alpha values."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor the layered representation of a sequence, each layer has its own YUV\nand alp files."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 3. Encoder Definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 3.1 Overview"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe figure 3.1.1 presents a general overview of the VOP encoder\nstructure. The same encoding scheme is applied when coding all the VOPs\nof a given session."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 3.1.2 : VOP encoder structure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe encoder is mainly componed of two parts : the shape coder and the\ntraditional motion & texture coder"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 3.2 Shape Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 3.2.1Binary Shape Coding - Quadtree without Vector Quantization"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn alpha plane which can be represented by binary is encoded by\nquadtree. Alpha block is converted to binary values _b(i)_ after\nnormalization if necessary. If an alpha value is greater than 127 then\n_b(i)_ = 2, if otherwise _b(i)_ = 0. In this case, an alpha block is\ndivided into 64 sub-blocks of 2x2 samples. This forms the lowest level\nof the quadtree structure. In a sub-block, an _index_ is assigned as\nshown in *Figure 3.2.3.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 3.2.3: Index of the lowest level"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the next level, four sub-blocks in the lower level are grouped to\nform a sub-block. *Figure 3.2.5 depicts the quadtree structure of an\nalpha block. Referring to Figure 3.2.4, the grouping is done as follows\n:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. If _f(upper_index[0])_ is less than _f(upper_index[1])_, then swap\n_index[0]_ with _index[1]_ and _index[2]_ with _index[3]_, except for\nsub-blocks numbered 0, 1, 4, 5, 16, 17, 20 and 21.\n. If _f(left_index[0])_ is less than _f(left_index[1])_, then swap\n_index[0]_ with _index[2]_ and _index[1]_ with _index[3]_ except for\nsub-blocks numbered 0, 2, 8, 10, 32, 34, 40 and 42\n. If _f(upper_index[0])+f(upper_index[1])_ is less than\n_f(left_index[0])+ f(left_index[1])_, then swap _index[1]_ with\n_index[2]_ except for sub-blocks numbered 0, 1, 2, 4, 5, 8, 10, 16, 17,\n20, 21, 32, 34, 40 and 42.\n. _index_ of upper level is computed from _index[0],index[1],index[2]_\nand _index[3]_ as shown in *Figure 3.2.4*."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the decoder the swapping is done in the reverse order (i.e steps 3, 2\nfollowed by 1)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 3.2.4: Grouping of sub-blocks for quadtree without vector\nquantization."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo reduce more bits, we rounded some values at level 2 and level 3 as\nfollows."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if (Sx < 16*255/2)_ /* _x_ is a alpha value of 4x4 block */ \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if (Sx <= TH~QT~)_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_x = 0_ for all alpha of 4x4 block;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_} else_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (_Sx >= 16*255-TH~QT~)_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nx = 255 for all alpha of 4x4 block;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if_ (4x4 block is not rounded) \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_int i, dis[4], alpha[4], sum_dis = 0;_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfor (i = 0;i < 4;++i)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (_Sy < 4*255/2TH~QT~)_ /* _y_ is a alpha value of _i_-th 2x2 block */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_\\{_ _dis[i] =_ _Sy; alpha[i] = 0;}_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nelse"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{ dis[i] = 4*255 - _Sy; alpha[i] = 255; }_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndo \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nint min_dis = 1<<(8*sizeof(int)-1); /* maximum integer value */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_int j;_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nfor (i =0;i < 4;++i) /* search not rounded 2x2 block */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if ((min_dis < dis[i])&&(dis[i] > 0))_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\\{min_dis = dis[i]; j =i;}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (sum_dis+min_dis <= TH__~QT~) \\{__"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsum_dis += min_dis;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ny = alpha[j] for all alpha of __j-__th 2x2 block;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_min_dis=dis[j] = 0;_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} while (min_dis == 0);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFollowing parameters are used in the rate control. The bit rate of alpha\nplane is controlled with threshold _a~TH~_ ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* _TH~QT~_ = 16 * _a~TH~_\n* _a~TH~_ = 0,1,2,4,6 and 8"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn such way, we build a total of 85 (=1+4+16+64) __index\u2019__s for an\nalpha block. Each _index_ is encoded from the highest level (level 0).\nIn each level, the order to encode _index_ is shown by the numbers in\n*Figure 3.2.5*. An _index_ is encoded with variable length codes shown\nin Table 1 *through* Table 4**.**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 3.2.5: Quadtree structure for quadtree coding without VQ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 3.2.2Grey Scale Shape Coding - Quadtree *with Vector Quantization*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*An alpha plane which has continuous values* varying gradually from 0 to\n255 is encoded by quadtree with vector quantization. An alpha block is\ndivided into 16 sub-blocks of 4x4 samples. This forms the lowest level\nof the quadtree structure. Each sub-block of lowest level is encoded by\nvector quantization. The codebook consists of 258 vectors; 256 vectors\nare shown in Table 5 *and the other two vectors are*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n* (255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese two vectors need no vector index to encode because they are\nrepresented by the quadtree structure in upper level. We round some\nsub-blocks to the either one of the two vectors to reduce bit rate, as\nfollows."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_if (Sabs(x) <= TH~VQ~)_ /* _x_ is a sample of sub-block */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nall samples of sub-block are rounded to 0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_else_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nif (_Sabs(x) >= 16*255-TH~VQ~)_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nall samples of sub-block are rounded to 255"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFollowing parameters are used in the rate control. The bit rate of alpha\nplane is controlled with threshold _a~TH~_ ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* _TH~VQ~_ = 16 * _a~TH~_\n* _TH~QT~_ = 16 * _a~TH~_\n* _a~TH~_ = 0,1,2,4,6 and 8"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe position of each component of the vector is shown in *Figure 3.2.6.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 3.2.6: Components of vector."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt the next level, four sub-blocks in the level 2 are grouped to form a\nsub-block. *Figure 3.2.7 depicts the quadtree structure of an alpha\nblock.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 3.2.7: Quadtree structure for quadtree coding with VQ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe grouping is done by first arranging the vector components in\ndecreasing order and then encoded by vector quantization. The _vector\nindex_\u2019s is shown in Table 5."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. If _g(upper_left_index)_ is less than _g(upper_index)_, then swap\nvectors components _y(i)_ with _y((i/4*2+1)*4-i+1)_ as shown in *Figure\n3.2.8 except for sub-blocks numbered 0, 1, 2, 4, 5, 8 and 10 (Figure\n3.2.7).*\n. {blank}\n. {empty}[pic]\n. Figure 3.2.8: Swapping vector components horizontally.\n. If _g(upper_left_index)_ is less than _g(left_index)_, then swap\nvector components _y(i)_ with _y((3-i/4)*4+i%4)_ as shown in *Figure\n3.2.9 except for sub-blocks numbered 0, 1, 2, 4, 5, 8 and 10 (Figure\n3.2.7).*\n. {blank}\n. {empty}[pic]\n. Figure 3.2.9: Swapping vector components vertically.\n. If _g(upper_index)_ is less than _g(left_index)_, then swap vector\ncomponents _y(i)_ as shown in *Figure 3.2.10 excepts for sub-blocks\nnumbered 0, 1, 2, 4, 5, 8 and 10 (Figure 3.2.7).*\n. {empty}[pic]\n. Figure 3.2.10: Swapping vector components diagonally.\n. Note: As in the binary shape coding case, at the decoder the swapping\nis done in the reverse order (i.e steps 3, 2 followed by 1)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Encoding the vector components by vector quantization. The _vector\nindex_\u2019s are shown in Table 5.\n. _index_ of level 1 is computed from the _vector index_\u2019s as shown in\n*Figure 3.2.11.*\n. {blank}\n. {empty}[pic]\n. Figure 3.2.11: Computation of _index_ of upper level.\n. _index_ of level 0 is computed from the _index_ of level 1 in the same\nway shown in *Figure 3.2.4*."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach _index_ is encoded from level 0 to level 1. In each level, the\norder to encode the _index_\u2019s is shown in *Figure 3.2.7*. Each _index_\nis encoded with variable length codes shown Table 1 and Table 2**. Then\nthe** *vector index* *is encoded with 8-bit fixed length code.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbinary shape - macroblock based intra quadtree coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ngrey scale shape - macroblock based intra quadtree with VQ"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 3.3 Motion Estimation and Compensation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn order to perform motion prediction on a per VOP basis, the motion\nestimation of the blocks on the VOP borders has to modified from block\nmatching to polygon matching. Furthermore, a special padding technique,\ni.e., the repetitive padding, is required for the reference VOP when the\nunrestricted motion prediction mode is used. The details of these\ntechniques are described in the following sections."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 3.3.1. Image Padding Techniques"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn image padding technique, repetitive padding, is applied on the\nreference VOP for performing unrestricted motion estimation. The\nquantized alpha plane is used for repetitive padding."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRepetitive padding process consists of five steps:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Consider each undefined pixel outside the object boundary a zero\npixel.\n. {blank}\n. Scan each horizontal line of the original image region. Each scan line\nis possibly composed of two kinds of line segments: zero segments that\nhave all zero pixels within each segment and non-zero segments that have\nall non-zero pixels within each segment. If there are no non-zero\nsegments, do nothing. Otherwise, there are two situations for a\nparticular zero segment: it can be positioned either between an end\npoint of the scan line and the end point of a non-zero segment, or,\nbetween the end points of two different non-zero segments. In the first\ncase, fill all of the pixels in the zero segments with the pixel value\nof the end point of the non-zero segment. In the second case, fill all\nof the pixels in the zero segments with the averaged pixel value of the\ntwo end points.\n. {blank}\n. Scan each vertical line of the original image and perform the\nidentical procedure as described in (1) to each vertical scan line.\n. {blank}\n. If a zero pixel can be filled in by both (2) and (3), the final value\ntakes the average of the two possible values.\n. {blank}\n. Consider the rest of zero pixels. For any one of them, scan\nhorizontally to find the first horizontal non-zero pixel, and scan\nvertically to find the first vertical non-zero pixel. Replace the zero\npixel by the average of the first horizontal and vertical non-zero\npixels."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe figure 3.3.1 illustrates the outcome of each of the steps described\nabove."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}(2) (3) (4) (5)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 3.3.1 Illustration of some steps of repetitive padding."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 3.3.2. Block Matching"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== 3.3.2.1 Modified Block Match"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBlock match is performed on the luminance macro block to compute the\nmotion vector. The bounding rectangle of the VOP is first extened on the\nright-bottom side to multiples of 16x16 blocks. The macroblocks are\nformed by dividing the extended bounding rectangles into 16x16 blocks.\nSAD (Sum of Absolute Difference) is used as error measure. The quantized\nalpha plane for the VOP is used to exclude the pixels of the macro block\nthat are outside the VOP. SAD is computed only for the pixels with\nnonzero alpha value. This forms a polygon for the macro block that\nincludes the VOP boundary."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== 3.3.2.2 Integer pixel motion estimation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the basic H.26P mode the block size for vectors is 16x16. As an\noption 8x8 vectors may be used (Advanced prediction mode). This section\napplies to both 16x16 and 8x8 block sizes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf 8x8 vectors are used, both 8x8 and 16x16 vectors may be obtained from\nthe search algorithm. Only a small amount of additional computation is\nneeded to obtain the 8x8 integer vectors in addition to the 16x16\nvectors."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe search is made with integer pixel displacement and for the Y\ncomponent. The comparisons are made between the incoming block and the\ndisplaced block in the previous original picture. A full search is used,\nand the search area is up to \u00b131.5 pixels in horizontal and vertical\ndirection around the original macro block position."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor the zero vector SAD16(0,0) is reduced by 100 - to favor the zero\nvector when there is no significant difference."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe (x,y) pair resulting in the lowest SAD16 is chosen as the 16x16\ninteger pixel motion vector, V0. The corresponding SAD is __\nSAD16(x,y)_._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLikewise, the (x,y) pairs resulting in the lowest SAD8(x,y) are chosen\nto give the 4 8x8 vectors V1, V2, V3 and V4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 8x8 based SAD for the macroblock is"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf only 16x16 prediction is used: [pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf Advanced prediction is used: [pic][pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== 3.3.2.3 INTRA/INTER mode decision"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAfter the integer pixel motion estimation the coder makes a decision on\nwhether to use INTRA or INTER prediction in the coding. The following\nparameters are calculated to make the INTRA/INTER decision:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nINTRA mode is chosen if: [pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNotice that if SAD16(0,0) is used, this is the value that is already\nreduced by 100 above."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf INTRA mode is chosen, no further operations are necessary for the\nmotion search. If INTER mode is chosen the motion search continues with\nhalf-pixel search around the V0 position."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== 3.3.2.4 Half-pixel search"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHalf pixel search is performed for 16x16 vectors as well as for 8x8\nvectors if the option is chosen. The half-pixel search is done using the\nprevious reconstructed frame. The search is performed on the luminance\ncomponent of the macro block, and the search area is \u00b11 half-pixel\naround the target matrix pointed to by V0, V1, V2, V3 or V4. For the\n16x16 search the zero vector sad, SAD(0,0), is reduced by 100 as for the\ninteger search."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe half pixel values are found using the interpolation described in\nfigure 3.3.2 and which corresponds to bilinear interpolation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\na = A, b = (A + B)//2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nc = (A + C)//2, d = (A + B + C + D)//4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 3.3.2 Interpolation scheme for half-pixel search."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe vector resulting in the best match during the half-pixel search is\nnamed MV. MV consists of horizontal and vertical components (MVx, MVy),\nboth measured in half pixel units."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== 3.3.2.5 Decision on 16x16 or 8x8 prediction mode"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis section applies only if advanced prediction mode is selected."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSAD for the best half pixel 16x16 vector (including subtraction of 100\nif the vector is (0,0)):"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSAD for the whole macro block for the best half pixel 8x8 vectors:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following rule applies:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf: [pic], choose 8x8 prediction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\notherwise: choose 16x16 prediction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== 3.3.2.6 Differential coding of motion vectors."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWhen using INTER mode coding, the motion vector must be transmitted. The\nmotion vector components (horizontal and vertical) are coded\ndifferentially by using a spatial neighborhood of three motion vectors\nalready transmitted (figure 3.3.2). These three motion vectors are\ncandidate predictors for the differential coding."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the special cases at the borders of the current GOB or picture the\nfollowing decision rules are applied in increasing order:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. The candidate predictor MV1 is set to zero if the\ncorresponding macroblock is outside the picture (at the left side)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2. Then, the candidate predictors MV2 and MV3 are set to MV1 if\nthe corresponding macroblocks are outside the current GOB or picture (at\nthe top);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3. Then, the candidate predictor MV3 is set to zero if the\ncorresponding macroblock is outside the picture (at the right side)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4. When the corresponding macroblock was coded in INTRA mode or\nwas not coded (COD=1), the candidate predictor is set to zero."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe motion vector coding is performed separately on the horizontal and\nvertical components."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor each component, the median value of the three candidates for the\nsame component is computed:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor instance, if MV1=(-2,3), MV2=(1,5) and MV3=(-1,7), then Px = -1 and\nPy = 5."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Variable Length Codes for the vector differences MVDx and MVDy are\nlisted in table 6/H.26P."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 3.3.2 Motion vector prediction."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor differential coding of 8x8 vectors, see appendix F in H.26P."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== 3.3.2.7 Unrestricted Motion Estimation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn unrestricted motion estimation mode is used for VOP motion estimation\nand compensation. The technique is to improve the motion estimation\ntechniques, especially for VOP-based coding schemes. In this technique,\nthis error signal is generated by padding the reference VOPs to enough\nsize, applying motion estimation and compensation, and taking the\ndifference of the original and the estimated signals."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe procedure for this unrestricted motion estimation is described as\nfollows:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Extend the reference object by the size of the macro block.\n* {blank}\n* Pad the extended regions using repetitive padding. Use the padded\nimage as the new reference object.\n* {blank}\n* Apply modified block (polygon) match."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== 3.2.2.8. Overlapped motion compensation for luminance"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach pixel in an 8*8 luminance prediction block is a weighted sum of\nthree prediction values, divided by 8 (with rounding). In order to\nobtain the three prediction values, three motion vectors are used: the\nmotion vector of the current luminance block, and two out of four\n\"remote\" vectors:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00b7 the motion vector of the block at the left or right side of the\ncurrent luminance block;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u00b7 the motion vector of the block above or below the current luminance\nblock."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRemote motion vectors from other GOBs are used in the same way as remote\nmotion vectors inside the current GOB."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor each pixel, the remote motion vectors of the blocks at the two\nnearest block borders are used. This means that for the upper half of\nthe block the motion vector corresponding to the block above the current\nblock is used, while for the lower half of the block the motion vector\ncorresponding to the block below the current block is used (see FIGURE\n13/H.263). Similarly, for the left half of the block the motion vector\ncorresponding to the block at the left side of the current block is\nused, while for the right half of the block the motion vector\ncorresponding to the block at the right side of the current block is\nused (see FIGURE 14/H.263)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe creation of each pixel, [pic] in an 8*8 luminance prediction block\nis governed by the following equation:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhere [pic] and [pic] are the pixels from the referenced picture as\ndefined by"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHere, [pic] denotes the motion vector for the current block, [pic]\ndenotes the motion vector of the block either above or below, and\n[pic]denotes the motion vector either to the left or right of the\ncurrent block as defined above."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe matrices [pic] and [pic] are defined in FIGURE 12/H.263, FIGURE\n13/H.263 and FIGURE 14/H.263, where [pic] denotes the column and row,\nrespectively, of the matrix."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf one of the surrounding blocks was not coded, the corresponding remote\nmotion vector is set to zero. If one of the surrounding blocks was coded\nin INTRA mode, the corresponding remote motion vector is replaced by the\nmotion vector for the current block except when in PB-frames mode. In\nthis case (INTRA block in PB-frame mode), the INTRA block\u2019s motion\nvector is used (also see Annex G). If the current block is at the border\nof the picture and therefore a surrounding block is not present, the\ncorresponding remote motion vector is replaced by the current motion\nvector. In addition, if the current block is at the bottom of the\nmacroblock (for block number 3 or 4, see FIGURE 5/H.263), the remote\nmotion vector corresponding with an 8*8 luminance block in the\nmacroblock below the current macroblock is replaced by the motion vector\nfor the current block."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe weighting values for the prediction are given in FIGURE 12/H.263,\nFIGURE 13/H.263 and FIGURE 14/H.263."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"16%,12%,12%,12%,12%,12%,12%,12%\",]\n|===\n|4 |5 |5 |5 |5 |5 |5 |4\n|5 |5 |5 |5 |5 |5 |5 |5\n|5 |5 |6 |6 |6 |6 |5 |5\n|5 |5 |6 |6 |6 |6 |5 |5\n|5 |5 |6 |6 |6 |6 |5 |5\n|5 |5 |6 |6 |6 |6 |5 |5\n|5 |5 |5 |5 |5 |5 |5 |5\n|4 |5 |5 |5 |5 |5 |5 |4\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFIGURE 12/H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Weighting values,* *H~0~* *, for prediction with motion vector of\ncurrent luminance block*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"14%,12%,12%,12%,12%,12%,12%,14%\",]\n|===\n|2 |2 |2 |2 |2 |2 |2 |2\n|1 |1 |2 |2 |2 |2 |1 |1\n|1 |1 |1 |1 |1 |1 |1 |1\n|1 |1 |1 |1 |1 |1 |1 |1\n|1 |1 |1 |1 |1 |1 |1 |1\n|1 |1 |1 |1 |1 |1 |1 |1\n|1 |1 |2 |2 |2 |2 |1 |1\n|2 |2 |2 |2 |2 |2 |2 |2\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFIGURE 13/H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Weighting values,* *H~1~* ** *~,~* *for prediction with motion vectors\nof the luminance blocks*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\non top or bottom of current luminance block"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"16%,12%,12%,12%,12%,12%,12%,12%\",]\n|===\n|2 |1 |1 |1 |1 |1 |1 |2\n|2 |2 |1 |1 |1 |1 |2 |2\n|2 |2 |1 |1 |1 |1 |2 |2\n|2 |2 |1 |1 |1 |1 |2 |2\n|2 |2 |1 |1 |1 |1 |2 |2\n|2 |2 |1 |1 |1 |1 |2 |2\n|2 |2 |1 |1 |1 |1 |2 |2\n|2 |1 |1 |1 |1 |1 |1 |2\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFIGURE 14/H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Weighting values,* *H~2~* *,* *for prediction with motion vectors of\nthe luminance blocks*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*to the left or right of current luminance block*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 3.4 Texture Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe residual data after motion compensation is coded using the 8x8 block\nDCT scheme as in H.263. When shape of the VOP is arbitrary, the\nmacroblocks that lie belong to the arbitrary shape of the VOP are\ncomputed as described in the motion estimation/compensation section.\nThere are two types of macroblocks that belong to an arbitrarily shape a\nVOP: 1) those that lie completely inside the VOP shape and 2) those that\nlie on the boundary of the shape. The macrobblocks that lie completely\ninside the VOP are coded using the a technique identical to the\ntechnique used in H263. The 8x8 blocks that belong to the macroblocks\nlying on the border of the VOP shape are first padded as described in\nthe motion estimation/compensation section. These blocks are then coded\nin manner identical to the interior blocks."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 3.4.1 DCT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA separable 2-dimensional Discrete Cosine Transform (DCT) is used."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 3.4.2 Quantization"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe quantization parameter QP may take integer values from 1 to 31. The\nquantization stepsize is 2xQP."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCOF A transform coefficient to be quantized."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEVEL Absolute value of the quantized version of the transform\ncoefficient."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCOF\u00b4 Reconstructed transform coefficient."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nQuantization:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor INTRA: [pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor INTER: [pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDequantization:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe sign of COF is then added to obtain COF\u00b4: COF\u00b4 = Sign(COF)x| COF\u00b4|"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nQuantization for INTRA DC coefficient"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe DC coefficient of an INTRA block is quantized as described below. 8\nbits are used for the quantized DC coefficient."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Quantization: [pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Dequantization: [pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== 3.4.3 VLC encoding of quantized transform coefficients"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe 8x8 blocks of transform coefficients are scanned with \u201czigzag\u201d\nscanning as listed in figure 3.4.1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1 2 6 7 15 16 28 29"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3 5 8 14 17 27 30 43"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n4 9 13 18 26 31 42 44"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n10 12 19 25 32 41 45 54"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n11 20 24 33 40 46 53 55"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n21 23 34 39 47 52 56 61"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n22 35 38 48 51 57 60 62"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n36 37 49 50 58 59 63 64"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 3.4.1. Zigzag scanning pattern."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA three dimensional variable length code is used to code transform\ncoefficients. An EVENT is a combination of three parameters:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLAST 0: There are more nonzero coefficients in the block."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1: This is the last nonzero coefficient in the block."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRUN Number of zero coefficients preceding the current nonzero\ncoefficient."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEVEL Magnitude of the coefficient."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe most commonly occurring combinations of (LAST, RUN, LEVEL) are coded\nwith variable length codes given in H.263 document. The remaining\ncombinations of (LAST, RUN, LEVEL) are coded with a 23 bit word\nconsisting of :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nESCAPE 7 bit"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLAST 1 bit (0: Not last coefficient, 1: Last nonzero coefficient)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRUN 7 bit"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLEVEL 8 bit"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe code words for these fixed length ESCAPE codes are described in\nH.263 document."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n======"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 3.5 Rate Control"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRate control as in the one used in the anchors for the November 1996\ntest (DOC M0322) on each VOP independently."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 4. Bitstream Syntax"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 4.1 General Structrue"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 4.2 Session Layer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *Session layer*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"64%,18%,18%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|session_start_code |sc+8=32 |\n|more_than_one_VOP |1 |\n|if(more_than_one_VOP) \\{ | |\n|session_width |10 |\n|session_height |10 |\n|} | |\n|while (nextbits() != session_end_code) | |\n|VOP_layer | |\n|session_end_code |sc+8 |\n| | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*session_start_code*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis code cannot be emulated by any combination of other valid bits in\nthe bitstream, and is used for synchronization purpose. Its value is to\nbe find in table *tbd*."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*more_than_one_VOP*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis flag is \u00d21\u00d3 if there is only one VOP in the session, and \u00d20\u00d3 in all\nthe other cases."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*session_width*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*session_height*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese two numerical values define the picture size for the session, in\npixels unit (zero values are forbidden). This is also the size of the\nunique VOP of the session."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *4.3 VOP Layer*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *VOP layer*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"64%,18%,18%\",]\n|===\n|Syntax |No. of bits |Mnemonic"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|\\{VOP_stuff} |0-7 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_start_code |sc +3 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_ID |5 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_temp_ref |8 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_visibility |1 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|if (VOP_visibility & more_than_one_VOP) \\{ | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_composition_order |5 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_horizontal_spatial_ref |10 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_vertical_spatial_ref |10 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_scaling |3 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|if (nextbits() != VOP_start_code & nextbits() != session_end_code) \\{ |\n|"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|if (more_than_one_VOP) \\{ | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_width |10 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_height |10 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_of_arbitrary_shape |1 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|if (VOP_of_arbitrary_shape) \\{ | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|binary_shape | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|if (binary_shape) \\{ | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|do \\{ | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|first_QT_code |1-2 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|if (first_QT_code==\u201d0\u201d) | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|subsequent_QT_codes | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} while (count of macroblock != total number of macroblocks) | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} else \\{ | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|do \\{ | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|first_QT_code | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|if (first_QT_code==\u201d0\u201d) \\{ | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|subsequent_QT_codes | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VQ_codes |0-128 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} while (count of macroblock != total number of macroblocks) | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_prediction_type |2 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|VOP_quantizer |5 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|separate_motion_texture |1 |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|if (!separate_motion_texture) | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|combined_motion_texture_coding | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|else \\{ | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|motion_coding | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|texture_coding | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_startcode*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis code cannot be emulated by any combination of other valid bits in\nthe bitstream, and is used for synchronization purpose. Its value is to\nbe find in table *tbd* (Annex B)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_ID*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis code is used to identify the VOP. Each VOP is assigned a unique ID,\nthat cannot be changed during the session, but may be re-assigned to a\nnew VOP if the previous one has disappeared (in that case, all the data\nrelative to the VOP the ID was previously assigned to, are replaced by\nthe data of the new VOP, which should first be intra-coded)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_temp_ref*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis relative temporal reference is the time (in milliseconds) from the\nlast occurence of the VOP. The temporal rate of each VOP may be\ndifferent and variable. This value is not used for decoding, but should\nbe used for picture composition\u00ca: to produce a picture at a given time\n(according to the display frame rate), the simplest solution is to use\nthe most recently decoded data of each VOP to be displayed. Another\npossibility, more complex and for non real time applications, could be\nto interpolate each VOP from its two occurences temporaly surrounding\nthe needed instant, based on their temporal references."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_visibility*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis flag is \u00d21\u00d3 if the VOP is to be displayed, and \u00d20\u00d3 if not. This is\na composition information, and has no impact on the decoding process."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe main reason for this flag is because, as indicated above, the\ncomposition process is supposed to display the last temporal occurrence\nof each VOP\u00ca; it is therefore necessary to indicate when a VOP has\ndisappeared from the scene and should not remain frozen in the picture.\nAnother use of that flag could be to hide a VOP while it is\nprogressively being reconstructed, and display it only after enough data\nhas been received to reach the desired quality."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis is a script information, that may be changed or ignored under user\nrequest."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_composition_order*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis value is not used for decoding but for picture composition. It\nindicates the place of the VOP in the stack of (possibly) occluding VOPs\nin the scene."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis is a script information, that may be changed under user request."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_horizontal_spatial_ref*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_vertical_spatial_ref*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese values are not used for decoding but for picture composition. They\nindicate the spatial position of the center of the rectangle defined by\n_VOP_width_ and _VOP_height_, in pixels unit, the origin of coordinates\nbeing the top-left corner of the picture."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis is a script information, that may be changed under user request."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_scaling*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis value should not be used for decoding but for picture composition.\nThe width and height of the VOP (shape, texture, and alpha plane if any)\nare to be multiplied by 2 to the power of _VOP_scaling_ before\ncomposition."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis is a script information, that may be changed or ignored under user\nrequest."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_width*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_height*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese two numerical values define the size of the smallest rectangle\nthat includes the VOP, in pixels unit (zero values are forbidden)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_of_arbitrary_shape*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis flag is \u00d21\u00d3 if the VOP shape is not rectangular, and need to be\ncoded."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*binary_shape*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis flag is \u00d21\u00d3 if the VOP shape is binary (i.e. if each pixel of the\nrectangle defined by _VOP_width_ and _VOP_height_ is either part of the\nVOP or not), and \u00d20\u00d3 if the VOP shape is defined by grey scale data\n(i.e. if each pixel of the rectangle defined by _VOP_width_ and\n_VOP_height_ is to be linearly combined with the pixels of other VOPs at\nthe same spatial location)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_prediction_type*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis code indicates the prediction mode to be used for decoding the VOP.\nIts value is to be find in table above."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VOP_quantizer*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis code indicates the quantizer stepsize to be used for decoding the\nVOP, as long as another value is not specified with a given macroblock."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*separate_motion_texture*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis flag is \u00d21\u00d3 if all the coding data of a same type (e.g. motion,\ntexture, etc.) for the VOP are grouped together. It is \u00d20\u00d3 if the coding\ndata are grouped macroblock per macroblock."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*first_QT_code* -- \u20180\u2019 indicates that the subsequent alpha data exist.\n\u201810\u2019 indicates that all samples in the alpha block are \u201c0\u201d and \u201811\u2019\nindicates that all samples are 255."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*subsequent_QT_codes* -- consist of a string of codes indicating the\nquad-tree structure of an alpha block. An alpha block is subdivided into\n4 sub-blocks if it is neither all-255 nor all-zero. The smallest\nsub-block is 2x2 for QT method and 4x4 for QT+VQ method**.**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VQ_codes* -- Each vector is encoded by 8-bit fixed length codes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *4.4. Motion Texture*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *4.4.1 Combined Motion Texture*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe motion texture coding method used is described in Apendix B. The\noptional PB-mode is not used in this version of the VM."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *4.4.2 Separate Motion Texture*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*motion_coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe syntax for the encoded motion vectors of macroblocks that belong to\nthe VOP would be:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1 - 2 N 1 - 2 N bits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo. of Vectors Encoded vector ... No. of Vectors Encoded vector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNo. of Vectors:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHuffman coded number of motion vectors for macroblock (0, 1, or 4)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA `0' No. of Vectors field means that this macroblock is INTRA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ncoded. `1' means motion vectors at 16 x 16 resolution and `4' indicates"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmotion vectors at 8 x 8 resolution."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Huffman codes used to code this No. of Vectors field are"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Value |Length |Code\n|0 |2 |00\n|1 |1 |1\n|4 |2 |01\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEncoded vector:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThese are coded differentially coded using the same prediction scheme\nand Huffman tables as in H.263."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*texture_coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe texture data for thwe macroblocks belonging to the VOP is coded\nusing a DCT coding as in H.263. The syntax is for the texture coding for\neach of the macroblocks in the VOP is as follows:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1-2 2-6 2-3 N bits"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNO_DCT/INTRA/INTER flag CBPY CBPC DCT data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNO_DCT/INTRA/INTER"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis flag indicates whether a macroblock had DCT data or not. If it has\nDCT data, the flag also indicates if it is INTRA coded or INTER coded.\nThe Huffman Codes used to code the NO_DCT/INTRA/INTER field are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Value |Length |Code\n|INTRA |2 |11\n|INTER |2 |01\n|NO_DCT |1 |0\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCBPY"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCoded Bit Pattern Luminance, uses the same Huffman tables as in"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nH.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCBPC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCoded Bit Pattern Chrominance, uses the following Huffman table"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Value |Length |Code\n|00 |1 |1\n|01 |3 |001\n|10 |3 |010\n|11 |3 |011\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDCT data"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nH.263 DCT encoded macroblock data using the same 3D VLC as in H.263"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt is expected that in the next versionof VM, B-pictures will be\nsupported"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 5. Decoder Definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 5.1 Overview"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe figure 5.1.1 presents a general overview of the VOP decoder\nstructure. The same decoding scheme is applied when decoding all the\nVOPs of a given session."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 15.1.1 : VOP decoder structure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe decoder is mainly componed of two parts : the shape decoder and the\ntraditional motion & texture decoder. The reconstructed VOP is obtained\nby the right combination of the shape, texture and motion information."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 5.2Compositer Definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe output of the decoders are the reconstructed VOP\u2019s that are passed\nto the compositor. In the compositor the VOP\u2019s are recursively blended\nin the order specified by the VOP_composition_order."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor binary shape coding, each VOP has its own YUV and binary shape.\nBlending is done sequentially ( two layers at a time). For example, if\nVOP N is overlayered over VOP M to generate a new VOP P, the composited\nY, U, V and binary shape values are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPyuv = (1 - Nbinary) * Myuv + (Nbinary * Nyuv );"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPbinary = 1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor grey-scale shape coding, each VOP has its own YUV and alpha values.\nBlending is done sequentially ( two layers at a time). For example, if\nVOP N is overlayered over VOP M to generate a new VOP P, the composited\nY, U, V and alpha values are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPyuv = ((255 - Nalpha) * Myuv + (Nalpha * Nyuv ))/255;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPalpha = 255."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the case that there exist K (K>2) VOP for a particular sequence, this\nblending procedure recursively applies to YUV components by taking the\noutput picture as background."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Appendix A"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Shape Coding Tables"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 1: Variable length codes for subsequent_QT_codes of level 0."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"27%,73%\",]\n|===\n|index |VLC\n|0 |-\n|1 |1100 11\n|2 |1001 1110 0000 0011\n|3 |1100 10\n|4 |1110 0\n|5 |1001 1110 0010 11\n|6 |1001 1110 0000 0010\n|7 |1001 1110 0011\n|8 |1001 1110 0010 10\n|9 |1111 00\n|10 |0100 11\n|11 |1001 1110 0000 0001\n|12 |1001 1110 01\n|13 |1111 1\n|14 |1111 0101\n|15 |1001 1110 0000 0000\n|16 |1001 1110 0001 10\n|17 |1001 1110 0000 11\n|18 |1001 1110 1111 111\n|19 |1001 1110 1111 110\n|20 |1001 1110 1111 101\n|21 |1001 1110 1111 100\n|22 |1001 1110 0001 110\n|23 |1001 1110 1111 011\n|24 |1001 1110 1111 010\n|25 |1001 1110 1111 001\n|26 |1001 1110 1111 000\n|27 |1001 01\n|28 |1001 1110 10\n|29 |1001 1110 1110 111\n|30 |1001 10\n|31 |1001 00\n|32 |1001 1110 0010 01\n|33 |1001 1110 1110 110\n|34 |1001 1111\n|35 |1001 1110 0001 0\n|36 |1101 0\n|37 |1110 1\n|38 |1001 1110 1110 101\n|39 |0100 10\n|40 |00\n|41 |0110 1\n|42 |1001 1110 1110 100\n|43 |0111 0\n|44 |1010\n|45 |1001 1110 0000 011\n|46 |1111 0100\n|47 |1001 1110 1110 011\n|48 |1001 1110 0000 010\n|49 |0110 0\n|50 |0111 1\n|51 |1001 1110 1110 010\n|52 |1111 011\n|53 |1101 1\n|54 |1001 1110 1110 001\n|55 |1001 1110 1110 000\n|56 |1001 1110 1101 111\n|57 |1001 1110 1101 110\n|58 |1001 1110 1101 101\n|59 |1001 1110 1101 100\n|60 |1001 1110 1101 011\n|61 |1001 1110 0010 00\n|62 |1001 1110 1101 010\n|63 |1001 1110 1100 0\n|64 |1001 1110 1101 001\n|65 |1001 1110 1101 000\n|66 |1001 1100\n|67 |0100 0\n|68 |1001 1101\n|69 |1001 1110 1100 111\n|70 |0101\n|71 |1011 1\n|72 |1001 1110 1100 110\n|73 |1001 1110 0000 10\n|74 |1001 1110 1100 101\n|75 |1001 1110 1100 100\n|76 |1000\n|77 |1100 0\n|78 |1001 1110 0001 111\n|79 |1011 0\n|80 |-\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table* 2: Variable length codes for subsequent_QT_codes of level 1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"27%,73%\",]\n|===\n|index |VLC\n|0 |-\n|1 |1000 10\n|2 |0110 0111 1001 1011 1\n|3 |0110 010\n|4 |0110 00\n|5 |0110 0111 1110\n|6 |0110 0110 1010 1100 0\n|7 |0110 0111 110\n|8 |0110 0111 1111\n|9 |0111 10\n|10 |0011 10\n|11 |0001 1100 1001\n|12 |0001 1101 11\n|13 |0000 001\n|14 |0001 1100 0\n|15 |0110 0111 1001 1011 0\n|16 |0001 1100 1010 0\n|17 |0001 1100 1011\n|18 |0110 0111 1001 1010 1\n|19 |0110 0110 1011\n|20 |0110 0111 1000\n|21 |0110 0111 1001 1010 0\n|22 |0110 0111 1001 1101\n|23 |0110 0111 011\n|24 |0110 0111 1001 1001 1\n|25 |0110 0111 1001 1001 0\n|26 |0110 0111 1001 1000 1\n|27 |0000 11\n|28 |1000 1101 0\n|29 |0110 0111 1001 1000 0\n|30 |0000 01\n|31 |0000 000\n|32 |0110 0110 1010 10\n|33 |0110 0111 010\n|34 |0001 1101 0\n|35 |0001 1101 1011\n|36 |1001\n|37 |0000 10\n|38 |0110 0111 1001 0\n|39 |0011 11\n|40 |11\n|41 |1010 1\n|42 |0001 1100 1010 1\n|43 |1010 0\n|44 |0001 0\n|45 |1000 1100\n|46 |0001 111\n|47 |0001 1100 1000\n|48 |0001 1101 1010\n|49 |0110 1\n|50 |0011 0\n|51 |0110 0110 1010 1111 1\n|52 |1000 111\n|53 |0001 10\n|54 |0110 0111 1001 1100\n|55 |0110 0110 1010 1111 0\n|56 |0110 0110 1010 1110 1\n|57 |0110 0110 11\n|58 |0110 0110 1010 0\n|59 |0110 0110 1010 1110 0\n|60 |0110 0110 100\n|61 |0001 1101 100\n|62 |0110 0111 1001 111\n|63 |0110 0110 0\n|64 |0110 0111 101\n|65 |0110 0110 10101 1011\n|66 |0111 110\n|67 |0010 1\n|68 |0111 111\n|69 |0001 1100 11\n|70 |0100\n|71 |0111 0\n|72 |1000 0\n|73 |1000 1101 1\n|74 |0110 0110 1010 1101 0\n|75 |0110 0111 00\n|76 |0101\n|77 |1011\n|78 |0110 0110 1010 1100 1\n|79 |0010 0\n|80 |-\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 3: Variable length codes for subsequent_QT_codes of level 2.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"27%,73%\",]\n|===\n|index |VLC\n|0 |-\n|1 |0000 01\n|2 |0010 0100 1100\n|3 |0000 111\n|4 |1010 01\n|5 |0011 1100 1\n|6 |1101 1100 1100\n|7 |1000 0011 10\n|8 |1100 0101 0\n|9 |1111 1\n|10 |0011 10\n|11 |0000 1011 1\n|12 |1101 1101\n|13 |0000 001\n|14 |0000 1010\n|15 |0010 0100 1111 110\n|16 |1101 1100 00\n|17 |0000 0000 00\n|18 |1101 1100 111\n|19 |1000 0010 1\n|20 |0000 1011 0\n|21 |0010 0100 1111 10\n|22 |1101 1100 01\n|23 |1010 0011\n|24 |0010 0100 1111 1111\n|25 |1101 1100 1101 1\n|26 |1000 0011 11\n|27 |0010 1\n|28 |0010 0101\n|29 |1101 1100 1101 0\n|30 |1010 1\n|31 |1111 00\n|32 |0000 0000 01\n|33 |1100 0100\n|34 |0011 1101\n|35 |1000 0011 0\n|36 |1110\n|37 |0100 10\n|38 |1100 0101 1\n|39 |1000 10\n|40 |0110\n|41 |0100 11\n|42 |0010 0100 10\n|43 |1000 11\n|44 |1101 0\n|45 |0010 011\n|46 |1100 00\n|47 |0000 0001\n|48 |1010 0010 0\n|49 |0010 00\n|50 |0100 0\n|51 |0010 0100 1111 0\n|52 |1000 011\n|53 |0011 0\n|54 |1101 1100 10\n|55 |0010 0100 1101 1\n|56 |0010 0100 1111 1110\n|57 |1101 111\n|58 |1010 0010 1\n|59 |0010 0100 1101 0\n|60 |0011 111\n|61 |1100 011\n|62 |1000 0010 0\n|63 |1000 000\n|64 |0010 0100 0\n|65 |0010 0100 1110\n|66 |1111 01\n|67 |1100 1\n|68 |0000 110\n|69 |1010 000\n|70 |1011\n|71 |1001\n|72 |1101 10\n|73 |0000 100\n|74 |0000 00001\n|75 |1000 010\n|76 |0111\n|77 |0001\n|78 |0011 1100 0\n|79 |0101\n|80 |-\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 4: Variable length codes for subsequent QT code of level 3.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"47%,53%\",]\n|===\n|index |VLC\n|0 |-\n|1 |-\n|2 |1110\n|3 |-\n|4 |-\n|5 |-\n|6 |1000 0\n|7 |-\n|8 |1111\n|9 |-\n|10 |-\n|11 |-\n|12 |-\n|13 |-\n|14 |-\n|15 |-\n|16 |-\n|17 |-\n|18 |0110\n|19 |-\n|20 |0111\n|21 |-\n|22 |-\n|23 |-\n|24 |1000 11\n|25 |-\n|26 |1001\n|27 |-\n|28 |-\n|29 |-\n|30 |-\n|31 |-\n|32 |-\n|33 |-\n|34 |-\n|35 |-\n|36 |-\n|37 |-\n|38 |-\n|39 |-\n|40 |-\n|41 |-\n|42 |-\n|43 |-\n|44 |-\n|45 |-\n|46 |-\n|47 |-\n|48 |-\n|49 |-\n|50 |-\n|51 |-\n|52 |-\n|53 |-\n|54 |0010\n|55 |-\n|56 |1000 10\n|57 |-\n|58 |-\n|59 |-\n|60 |110\n|61 |-\n|62 |0011\n|63 |-\n|64 |-\n|65 |-\n|66 |-\n|67 |-\n|68 |-\n|69 |-\n|70 |-\n|71 |-\n|72 |000\n|73 |-\n|74 |010\n|75 |-\n|76 |-\n|77 |-\n|78 |101\n|79 |-\n|80 |-\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"100%\",]\n|===\n|\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNOTE : The variable length codes for quadtree without VQ are shown in\n*Table 1*, *Table 2*, *Table 3* and *Table 4*. The variable length codes\nfor quadtree with VQ are shown in *Table 1* and in *Table 2*."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 5: Codebook for VQ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%\",]\n|===\n|index |y(0) |y(1) |y(2) |y(3) |y(4) |y(5) |y(6) |y(7) |y(8) |y(9)\n|y(10) |y(11) |y(12) |y(13) |y(14) |y(15)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0 |129 |59 |11 |0 |5 |0 |0 |0 |0 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1 |80 |74 |42 |15 |5 |4 |1 |0 |0 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2 |114 |27 |0 |0 |31 |0 |0 |0 |1 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3 |129 |23 |0 |0 |50 |0 |0 |0 |27 |0 |0 |0 |14 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4 |151 |60 |8 |0 |61 |10 |0 |0 |7 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5 |174 |74 |11 |1 |75 |12 |0 |0 |16 |1 |0 |1 |2 |0 |0 |2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6 |139 |110 |66 |23 |7 |0 |0 |0 |0 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7 |169 |103 |77 |77 |46 |9 |3 |3 |3 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8 |133 |29 |0 |0 |103 |20 |0 |0 |40 |1 |0 |0 |9 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9 |142 |42 |1 |0 |108 |24 |0 |0 |52 |1 |0 |0 |45 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10 |196 |59 |3 |0 |137 |11 |0 |0 |63 |1 |0 |0 |20 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|11 |147 |44 |1 |0 |144 |45 |3 |0 |113 |33 |2 |0 |38 |2 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|12 |202 |111 |25 |0 |133 |41 |2 |0 |41 |3 |0 |0 |8 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|13 |219 |159 |72 |15 |133 |50 |6 |0 |15 |0 |0 |0 |1 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|14 |222 |154 |61 |8 |153 |70 |16 |1 |56 |12 |4 |1 |7 |1 |2 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|15 |236 |174 |74 |17 |172 |73 |11 |1 |72 |11 |0 |0 |11 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|16 |175 |98 |36 |2 |53 |9 |2 |0 |2 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|17 |198 |136 |54 |8 |61 |10 |0 |0 |3 |0 |0 |1 |0 |0 |0 |1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|18 |196 |158 |80 |19 |84 |44 |6 |0 |4 |4 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|19 |198 |164 |101 |68 |74 |39 |7 |3 |3 |2 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|20 |222 |192 |131 |60 |129 |52 |7 |0 |10 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|21 |233 |194 |120 |48 |164 |81 |18 |1 |45 |5 |0 |0 |3 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|22 |218 |195 |148 |75 |138 |99 |54 |11 |21 |7 |7 |1 |2 |0 |0 |2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|23 |233 |212 |177 |116 |167 |95 |26 |0 |24 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|24 |198 |185 |153 |105 |52 |28 |8 |0 |0 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|25 |199 |193 |155 |78 |83 |86 |66 |16 |9 |11 |11 |2 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|26 |211 |203 |182 |139 |95 |72 |37 |9 |1 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|27 |203 |207 |196 |143 |100 |118 |92 |34 |1 |5 |4 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|28 |199 |186 |194 |199 |55 |29 |64 |91 |12 |1 |0 |3 |9 |1 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|29 |191 |195 |189 |175 |80 |88 |83 |70 |12 |14 |11 |9 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|30 |207 |207 |207 |209 |115 |107 |88 |87 |1 |1 |1 |4 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|31 |206 |208 |207 |206 |119 |122 |128 |129 |1 |1 |2 |5 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|32 |241 |209 |152 |67 |187 |113 |48 |6 |62 |12 |2 |0 |4 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|33 |243 |203 |118 |27 |199 |122 |36 |0 |106 |35 |2 |0 |19 |1 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|34 |247 |225 |165 |75 |207 |144 |57 |8 |103 |40 |5 |0 |14 |2 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|35 |248 |234 |198 |133 |213 |171 |96 |30 |109 |39 |3 |1 |12 |1 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|36 |234 |163 |58 |5 |216 |169 |71 |10 |145 |158 |92 |21 |20 |44 |34 |8"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|37 |246 |211 |125 |32 |227 |143 |42 |0 |197 |100 |23 |0 |130 |32 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|38 |251 |232 |166 |66 |233 |168 |71 |11 |167 |71 |11 |0 |68 |10 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|39 |251 |237 |200 |146 |233 |172 |77 |25 |168 |75 |12 |2 |70 |14 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|41 |243 |229 |205 |158 |199 |149 |73 |17 |51 |8 |0 |0 |2 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|42 |231 |211 |200 |177 |152 |87 |71 |58 |40 |8 |5 |4 |3 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|43 |239 |227 |209 |196 |186 |146 |92 |74 |51 |20 |3 |3 |4 |2 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|44 |247 |239 |221 |201 |207 |182 |124 |68 |89 |42 |7 |2 |3 |1 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|45 |248 |245 |231 |196 |205 |195 |161 |91 |97 |77 |46 |9 |11 |8 |4 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|46 |243 |225 |161 |64 |204 |201 |137 |44 |101 |131 |99 |42 |1 |8 |8 |14"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|47 |251 |245 |222 |170 |233 |199 |141 |63 |163 |79 |25 |3 |49 |7 |2 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|48 |252 |231 |155 |56 |241 |188 |83 |16 |206 |110 |20 |0 |142 |43 |2 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|49 |253 |243 |189 |74 |249 |211 |122 |21 |228 |157 |59 |5 |169 |70 |10\n|0\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 5: Codebook for VQ (continue).*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%\",]\n|===\n|index |y(0) |y(1) |y(2) |y(3) |y(4) |y(5) |y(6) |y(7) |y(8) |y(9)\n|y(10) |y(11) |y(12) |y(13) |y(14) |y(15)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|50 |248 |243 |207 |115 |242 |210 |127 |32 |203 |129 |40 |1 |113 |36 |1\n|0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|51 |254 |249 |229 |174 |245 |218 |157 |72 |196 |135 |55 |9 |82 |30 |3\n|0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|52 |254 |249 |226 |162 |249 |223 |149 |55 |221 |147 |55 |7 |147 |56 |7\n|0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|53 |255 |252 |235 |175 |252 |237 |173 |73 |236 |173 |73 |11 |174 |72\n|11 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|54 |254 |249 |221 |141 |252 |232 |155 |55 |244 |198 |84 |16 |221 |140\n|29 |1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|55 |254 |253 |239 |188 |253 |242 |200 |111 |242 |201 |116 |30 |201 |118\n|34 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|56 |252 |248 |240 |223 |230 |213 |189 |140 |161 |103 |44 |9 |18 |2 |0\n|0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|57 |252 |251 |244 |227 |242 |227 |200 |143 |198 |142 |61 |10 |58 |10 |0\n|0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|58 |250 |248 |247 |246 |230 |205 |200 |199 |160 |85 |72 |90 |68 |18 |12\n|26"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|59 |254 |252 |249 |245 |243 |231 |211 |196 |194 |156 |96 |66 |79 |38 |7\n|3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|60 |254 |253 |243 |213 |250 |236 |197 |130 |224 |167 |76 |18 |141 |56\n|7 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|61 |253 |254 |250 |241 |251 |242 |223 |190 |230 |194 |129 |61 |156 |66\n|10 |2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|62 |254 |254 |252 |249 |246 |243 |232 |208 |201 |193 |151 |81 |90 |75\n|42 |8"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|63 |254 |254 |254 |251 |250 |248 |240 |222 |223 |210 |189 |136 |136 |96\n|49 |11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|64 |7 |11 |30 |52 |0 |0 |2 |14 |0 |0 |0 |8 |0 |0 |0 |4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|65 |0 |2 |37 |115 |0 |0 |2 |35 |0 |0 |0 |12 |1 |0 |0 |6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|66 |61 |80 |94 |83 |7 |8 |8 |6 |1 |0 |0 |0 |2 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|67 |113 |125 |127 |117 |3 |4 |3 |3 |0 |0 |0 |0 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|68 |14 |43 |114 |184 |1 |3 |23 |72 |0 |0 |0 |9 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|69 |23 |47 |131 |201 |24 |16 |44 |118 |24 |16 |10 |36 |21 |9 |3 |8"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|70 |80 |144 |190 |197 |5 |35 |73 |85 |0 |2 |5 |4 |0 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|71 |61 |129 |196 |230 |3 |29 |94 |168 |0 |1 |7 |45 |0 |0 |0 |3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|72 |23 |7 |1 |20 |6 |1 |6 |45 |0 |0 |30 |116 |0 |16 |81 |174"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|73 |2 |2 |44 |145 |0 |0 |41 |145 |0 |0 |41 |143 |0 |0 |37 |132"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|74 |3 |0 |38 |137 |0 |0 |44 |150 |0 |13 |78 |180 |0 |33 |126 |215"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|75 |95 |62 |114 |203 |25 |10 |61 |167 |13 |2 |46 |154 |28 |21 |75 |173"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|76 |0 |34 |127 |213 |0 |13 |73 |167 |0 |0 |29 |110 |0 |0 |0 |33"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|77 |4 |51 |151 |229 |0 |34 |127 |215 |0 |12 |73 |169 |0 |2 |41 |131"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|78 |19 |44 |139 |224 |1 |37 |134 |221 |0 |35 |131 |217 |0 |35 |128 |211"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|79 |0 |26 |108 |200 |0 |40 |143 |227 |14 |79 |178 |240 |35 |129 |215\n|247"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|80 |34 |118 |202 |243 |0 |35 |123 |207 |0 |1 |38 |129 |0 |0 |9 |60"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|81 |108 |180 |227 |246 |23 |71 |146 |201 |8 |15 |47 |109 |6 |1 |7 |35"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|82 |143 |190 |210 |195 |26 |78 |133 |138 |1 |3 |15 |19 |0 |0 |1 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|83 |199 |214 |233 |245 |74 |108 |165 |198 |2 |6 |35 |73 |0 |0 |1 |3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|84 |211 |233 |241 |233 |103 |163 |192 |188 |5 |33 |69 |88 |0 |2 |3 |3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|85 |230 |242 |247 |248 |151 |190 |206 |211 |27 |72 |98 |104 |1 |1 |1 |5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|86 |200 |227 |244 |252 |83 |147 |196 |227 |3 |29 |88 |158 |0 |1 |5 |36"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|87 |207 |236 |248 |253 |102 |171 |203 |234 |6 |43 |90 |165 |0 |4 |8 |49"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|88 |245 |244 |240 |232 |199 |194 |184 |165 |77 |68 |49 |32 |4 |3 |3 |2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|89 |248 |248 |246 |235 |210 |208 |200 |165 |109 |104 |89 |49 |5 |2 |2\n|1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|90 |248 |248 |248 |248 |210 |207 |207 |210 |104 |94 |92 |105 |4 |2 |2\n|6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|91 |244 |248 |248 |243 |200 |211 |214 |203 |107 |130 |137 |116 |2 |9\n|13 |2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|92 |246 |248 |251 |253 |195 |200 |210 |236 |84 |78 |97 |169 |8 |7 |17\n|76"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|93 |240 |249 |253 |255 |185 |210 |233 |246 |53 |98 |162 |200 |2 |4 |34\n|85"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|94 |248 |251 |248 |234 |208 |222 |235 |226 |65 |117 |180 |195 |4 |24\n|78 |119"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|95 |249 |252 |254 |254 |208 |230 |242 |247 |99 |160 |190 |204 |6 |32\n|58 |82"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|96 |62 |161 |232 |252 |18 |87 |189 |240 |0 |21 |111 |200 |0 |0 |34 |118"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|97 |124 |208 |245 |253 |33 |122 |206 |243 |0 |31 |117 |202 |0 |0 |31\n|114"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|98 |57 |176 |237 |253 |20 |127 |218 |250 |0 |49 |165 |236 |0 |21 |118\n|213"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|99 |196 |198 |227 |249 |60 |73 |162 |234 |2 |40 |143 |227 |0 |41 |145\n|229"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|100 |39 |138 |224 |251 |36 |132 |220 |249 |33 |126 |213 |240 |25 |104\n|189 |223"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|101 |63 |146 |228 |252 |38 |132 |225 |252 |40 |143 |229 |252 |71 |170\n|237 |253"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|102 |135 |219 |249 |251 |62 |176 |238 |251 |23 |125 |215 |246 |3 |53\n|161 |227"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|103 |142 |225 |251 |255 |95 |197 |245 |254 |40 |151 |232 |253 |30 |125\n|216 |249"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|104 |191 |233 |248 |250 |79 |165 |222 |246 |6 |51 |136 |202 |0 |5 |44\n|111"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|105 |194 |240 |252 |255 |97 |188 |237 |251 |20 |90 |177 |221 |0 |6 |52\n|125"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|106 |227 |245 |253 |254 |150 |197 |237 |251 |35 |90 |178 |230 |2 |22\n|92 |171"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|107 |218 |246 |253 |255 |134 |211 |245 |253 |34 |123 |206 |243 |0 |33\n|118 |201"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|108 |229 |251 |254 |254 |162 |229 |251 |254 |65 |161 |228 |249 |12 |71\n|164 |220"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|109 |241 |253 |255 |255 |189 |240 |252 |255 |96 |187 |237 |251 |20 |90\n|181 |230\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 5: Codebook for VQ (continue).*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%\",]\n|===\n|index |y(0) |y(1) |y(2) |y(3) |y(4) |y(5) |y(6) |y(7) |y(8) |y(9)\n|y(10) |y(11) |y(12) |y(13) |y(14) |y(15)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|110 |250 |254 |252 |246 |229 |247 |252 |249 |159 |206 |236 |245 |35 |99\n|174 |212"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|111 |240 |253 |255 |255 |207 |244 |253 |255 |127 |211 |246 |254 |38\n|134 |215 |247"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|112 |254 |254 |254 |253 |239 |241 |239 |240 |181 |183 |178 |183 |57 |50\n|47 |64"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|113 |253 |254 |254 |254 |239 |244 |247 |248 |189 |199 |206 |212 |49 |55\n|79 |107"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|114 |246 |252 |254 |255 |202 |233 |248 |253 |96 |167 |210 |237 |3 |37\n|103 |178"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|115 |249 |254 |255 |255 |228 |243 |248 |249 |144 |191 |209 |218 |29 |81\n|121 |143"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|116 |254 |254 |252 |247 |248 |248 |246 |237 |208 |206 |201 |179 |111\n|102 |80 |50"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|117 |252 |254 |254 |255 |250 |251 |251 |251 |204 |205 |205 |205 |99 |97\n|95 |94"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|118 |255 |255 |255 |255 |247 |247 |249 |250 |205 |207 |212 |223 |102\n|92 |113 |152"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|119 |255 |255 |255 |255 |248 |252 |253 |254 |201 |208 |235 |246 |94 |98\n|165 |198"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|120 |199 |243 |253 |252 |147 |227 |251 |253 |87 |197 |244 |254 |30 |141\n|225 |251"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|121 |206 |246 |254 |255 |173 |237 |253 |255 |129 |222 |251 |255 |88\n|202 |246 |254"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|122 |249 |254 |255 |255 |231 |251 |254 |254 |169 |235 |252 |254 |73\n|182 |236 |252"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|123 |254 |255 |254 |253 |247 |253 |254 |253 |206 |234 |246 |250 |101\n|169 |205 |222"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|124 |225 |250 |253 |252 |204 |246 |254 |254 |159 |235 |253 |253 |142\n|226 |251 |252"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|125 |244 |254 |254 |254 |234 |252 |254 |254 |207 |246 |254 |254 |139\n|221 |249 |253"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|126 |254 |255 |254 |254 |251 |254 |255 |254 |230 |249 |253 |254 |163\n|217 |242 |250"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|127 |249 |254 |255 |254 |244 |254 |255 |254 |233 |251 |254 |254 |203\n|240 |250 |252"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|128 |67 |6 |0 |0 |51 |4 |0 |0 |16 |0 |0 |0 |2 |0 |0 |2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|129 |38 |0 |0 |0 |39 |0 |0 |0 |39 |0 |0 |0 |39 |0 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|130 |1 |0 |0 |0 |2 |0 |0 |0 |8 |0 |0 |0 |66 |18 |5 |2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|131 |16 |0 |0 |1 |32 |1 |0 |0 |69 |7 |0 |0 |88 |11 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|132 |0 |0 |0 |0 |0 |0 |0 |0 |7 |4 |1 |0 |109 |106 |84 |45"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|133 |0 |0 |0 |0 |0 |0 |0 |0 |7 |2 |2 |3 |108 |103 |118 |126"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|134 |2 |0 |0 |0 |0 |0 |0 |1 |0 |0 |0 |10 |1 |9 |34 |87"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|135 |17 |4 |0 |0 |9 |0 |3 |5 |5 |19 |49 |73 |49 |107 |169 |186"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|136 |0 |0 |0 |2 |3 |0 |0 |0 |24 |0 |0 |0 |120 |42 |10 |2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|137 |3 |0 |1 |3 |16 |0 |0 |1 |66 |9 |0 |0 |161 |64 |11 |2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|138 |0 |0 |0 |0 |6 |0 |0 |0 |75 |22 |2 |0 |195 |136 |63 |17"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|139 |34 |1 |0 |0 |73 |5 |0 |0 |145 |38 |2 |0 |201 |101 |16 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|140 |0 |0 |0 |0 |13 |0 |0 |0 |122 |51 |8 |0 |221 |193 |133 |59"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|141 |0 |0 |0 |0 |7 |0 |0 |0 |123 |83 |35 |7 |216 |202 |169 |108"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|142 |13 |0 |0 |0 |75 |15 |0 |0 |173 |79 |13 |0 |227 |169 |68 |10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|143 |63 |11 |0 |0 |134 |40 |1 |0 |209 |121 |31 |0 |239 |199 |111 |28"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|144 |78 |3 |0 |0 |97 |1 |0 |0 |99 |1 |0 |0 |65 |1 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|145 |49 |3 |0 |0 |77 |11 |0 |0 |115 |21 |0 |0 |133 |31 |1 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|146 |124 |2 |0 |0 |119 |0 |0 |0 |119 |0 |0 |0 |118 |1 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|147 |141 |40 |1 |1 |138 |38 |0 |0 |135 |37 |0 |0 |129 |35 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|148 |169 |35 |0 |0 |177 |39 |1 |0 |176 |34 |0 |0 |176 |38 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|149 |207 |111 |23 |0 |164 |49 |0 |0 |152 |39 |0 |0 |132 |29 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|150 |210 |108 |10 |0 |178 |56 |0 |0 |128 |21 |0 |0 |58 |2 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|151 |232 |156 |53 |5 |198 |91 |17 |0 |133 |30 |1 |0 |60 |6 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|152 |105 |12 |0 |0 |157 |35 |0 |0 |185 |68 |1 |0 |208 |106 |14 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|153 |163 |25 |0 |0 |179 |41 |0 |0 |209 |95 |13 |0 |218 |128 |21 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|154 |194 |79 |3 |0 |203 |90 |6 |0 |204 |89 |6 |0 |197 |83 |4 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|155 |191 |75 |1 |0 |206 |88 |6 |0 |214 |114 |8 |0 |223 |153 |24 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|156 |213 |133 |4 |0 |209 |120 |0 |0 |207 |112 |0 |0 |207 |112 |1 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|157 |205 |161 |142 |153 |167 |81 |43 |59 |177 |72 |13 |4 |205 |99 |10\n|0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|158 |211 |121 |31 |0 |218 |129 |35 |0 |220 |134 |37 |0 |217 |132 |36 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|159 |238 |160 |45 |0 |237 |160 |43 |0 |234 |157 |40 |0 |226 |149 |37 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|160 |0 |0 |0 |0 |5 |6 |0 |0 |40 |64 |78 |76 |141 |175 |180 |174"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|161 |0 |0 |0 |0 |9 |3 |0 |0 |130 |116 |81 |49 |200 |205 |201 |192"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|162 |1 |0 |0 |3 |3 |0 |0 |8 |104 |86 |96 |124 |210 |209 |210 |213"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|163 |0 |0 |0 |0 |69 |17 |0 |0 |197 |147 |85 |51 |243 |229 |211 |187"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|164 |6 |0 |0 |0 |81 |26 |4 |0 |203 |147 |67 |16 |245 |228 |184 |114"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|165 |67 |13 |0 |0 |172 |83 |17 |0 |235 |180 |88 |19 |252 |236 |181 |90"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|166 |18 |2 |0 |0 |149 |80 |21 |0 |227 |201 |146 |68 |251 |244 |226 |187"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|167 |104 |36 |6 |0 |208 |144 |62 |10 |246 |224 |167 |82 |254 |250 |230\n|177"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|168 |0 |0 |0 |7 |0 |0 |27 |90 |43 |85 |158 |206 |178 |209 |233 |246"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|169 |9 |0 |6 |35 |7 |18 |64 |138 |68 |110 |171 |217 |179 |213 |232 |238\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 5: Codebook for VQ (continue).*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%\",]\n|===\n|Index |y(0) |y(1) |y(2) |y(3) |y(4) |y(5) |y(6) |y(7) |y(8) |y(9)\n|y(10) |y(11) |y(12) |y(13) |y(14) |y(15)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|170 |0 |0 |0 |0 |4 |18 |40 |72 |127 |163 |191 |209 |214 |228 |240 |247"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|171 |0 |0 |3 |19 |12 |53 |108 |144 |119 |179 |208 |220 |218 |237 |247\n|250"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|172 |65 |25 |3 |12 |158 |83 |22 |14 |205 |206 |190 |159 |200 |221 |235\n|231"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|173 |13 |1 |0 |6 |111 |93 |75 |63 |210 |205 |197 |180 |247 |245 |243\n|238"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|174 |2 |1 |1 |3 |113 |113 |117 |121 |208 |208 |208 |209 |247 |247 |247\n|246"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|175 |87 |51 |18 |2 |209 |184 |131 |74 |247 |239 |224 |202 |254 |253\n|250 |245"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|176 |38 |6 |30 |109 |109 |62 |95 |175 |203 |181 |194 |229 |245 |241\n|244 |251"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|177 |0 |5 |37 |93 |35 |99 |172 |210 |173 |212 |236 |247 |235 |248 |253\n|255"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|178 |0 |37 |131 |208 |23 |99 |190 |239 |87 |172 |232 |252 |185 |229\n|250 |254"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|179 |0 |36 |130 |211 |57 |143 |216 |246 |166 |223 |248 |254 |229 |248\n|253 |254"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|180 |7 |33 |71 |93 |123 |177 |203 |211 |219 |237 |245 |248 |249 |253\n|255 |255"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|181 |45 |73 |101 |137 |181 |200 |211 |221 |238 |244 |247 |249 |253 |254\n|254 |254"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|182 |121 |123 |102 |66 |207 |207 |205 |191 |247 |246 |244 |229 |255\n|254 |249 |236"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|183 |164 |137 |105 |91 |218 |219 |212 |203 |239 |248 |248 |246 |239\n|251 |254 |254"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|184 |36 |131 |217 |249 |44 |148 |231 |253 |125 |207 |247 |254 |197 |239\n|253 |254"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|185 |45 |145 |223 |250 |109 |203 |246 |254 |142 |228 |252 |255 |206\n|247 |254 |255"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|186 |27 |104 |183 |224 |124 |200 |237 |247 |210 |243 |252 |251 |246\n|253 |253 |248"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|187 |36 |128 |210 |242 |156 |219 |246 |253 |225 |248 |254 |255 |248\n|254 |255 |255"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|188 |101 |158 |201 |225 |210 |231 |244 |250 |247 |252 |254 |254 |254\n|255 |255 |255"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|189 |157 |202 |225 |238 |231 |245 |251 |253 |252 |254 |254 |254 |255\n|255 |255 |255"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|190 |132 |218 |250 |254 |149 |231 |253 |255 |198 |245 |254 |254 |226\n|251 |254 |254"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|191 |134 |218 |248 |253 |208 |246 |254 |255 |237 |253 |255 |254 |246\n|254 |254 |254"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|192 |223 |139 |31 |1 |208 |104 |18 |0 |170 |47 |0 |0 |144 |32 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|193 |224 |142 |30 |0 |218 |133 |27 |0 |200 |109 |20 |0 |143 |44 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|194 |240 |195 |56 |2 |225 |138 |11 |0 |199 |57 |0 |0 |146 |10 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|195 |245 |201 |100 |18 |219 |137 |35 |1 |154 |53 |3 |0 |89 |18 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|196 |243 |197 |62 |2 |230 |155 |24 |0 |214 |103 |3 |0 |200 |77 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|197 |250 |223 |134 |21 |243 |197 |56 |2 |226 |139 |8 |0 |196 |62 |0 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|198 |248 |209 |106 |20 |239 |170 |48 |0 |229 |153 |35 |0 |212 |121 |22\n|0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|199 |249 |217 |127 |16 |245 |200 |97 |7 |231 |153 |43 |0 |207 |92 |11\n|0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|200 |241 |189 |70 |3 |245 |198 |71 |3 |246 |199 |65 |3 |246 |203 |82 |4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|201 |248 |209 |120 |3 |248 |207 |106 |1 |246 |204 |85 |1 |239 |190 |67\n|1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|202 |245 |202 |77 |1 |246 |206 |101 |0 |244 |207 |121 |3 |238 |205 |120\n|3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|203 |248 |211 |128 |5 |247 |208 |112 |0 |247 |208 |113 |0 |247 |211\n|124 |4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|204 |251 |223 |138 |37 |250 |216 |119 |30 |249 |213 |114 |34 |247 |214\n|128 |50"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|205 |251 |232 |154 |43 |253 |235 |157 |44 |253 |233 |154 |41 |252 |228\n|147 |37"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|206 |249 |214 |121 |15 |253 |233 |165 |38 |254 |242 |187 |58 |255 |248\n|206 |85"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|207 |252 |229 |146 |37 |254 |240 |174 |62 |255 |247 |203 |102 |255 |249\n|213 |116"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|208 |185 |51 |0 |0 |208 |98 |6 |0 |228 |154 |28 |0 |243 |193 |77 |3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|209 |135 |33 |0 |0 |204 |112 |22 |0 |235 |171 |59 |6 |246 |215 |123 |26"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|210 |212 |105 |11 |0 |229 |150 |27 |0 |240 |181 |60 |0 |245 |209 |110\n|11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|211 |217 |122 |18 |0 |235 |168 |42 |0 |247 |206 |102 |9 |251 |224 |143\n|26"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|212 |197 |92 |11 |0 |235 |164 |51 |4 |248 |218 |130 |39 |246 |242 |196\n|103"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|213 |228 |148 |32 |0 |246 |205 |104 |11 |253 |233 |164 |35 |254 |247\n|208 |96"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|214 |234 |161 |49 |2 |247 |200 |94 |16 |251 |218 |124 |27 |254 |235\n|162 |50"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|215 |246 |205 |81 |0 |249 |215 |104 |1 |252 |231 |154 |26 |254 |243\n|196 |80"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|216 |205 |123 |33 |0 |243 |206 |119 |32 |253 |244 |201 |111 |255 |253\n|239 |187"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|217 |229 |169 |60 |7 |250 |228 |153 |58 |254 |250 |225 |159 |254 |254\n|249 |221"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|218 |244 |196 |83 |4 |251 |228 |151 |33 |251 |244 |198 |90 |247 |248\n|224 |150"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|219 |248 |218 |127 |4 |253 |240 |183 |31 |255 |250 |221 |112 |255 |254\n|239 |181"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|220 |251 |228 |147 |41 |254 |246 |203 |106 |254 |252 |228 |151 |253\n|252 |238 |180"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|221 |254 |245 |196 |70 |255 |250 |214 |110 |255 |253 |236 |172 |255\n|254 |247 |209"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|222 |232 |194 |121 |49 |252 |242 |218 |170 |255 |254 |248 |234 |255\n|255 |254 |252"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|223 |250 |241 |204 |114 |254 |252 |238 |189 |254 |254 |249 |222 |251\n|254 |251 |234"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|224 |241 |218 |144 |41 |245 |211 |126 |34 |234 |160 |52 |2 |220 |139\n|37 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|225 |254 |242 |196 |62 |251 |225 |137 |13 |242 |193 |56 |0 |223 |145\n|12 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|226 |253 |233 |160 |43 |251 |218 |127 |22 |247 |204 |98 |14 |238 |171\n|54 |1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|227 |254 |245 |195 |87 |252 |231 |154 |47 |249 |208 |89 |9 |242 |192\n|69 |3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|228 |255 |249 |218 |128 |253 |239 |182 |53 |250 |220 |128 |13 |238 |175\n|50 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|229 |255 |252 |229 |151 |254 |244 |197 |75 |251 |225 |140 |25 |241 |188\n|67 |5\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Table 5: Codebook for VQ (final).*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%,5%\",]\n|===\n|Index |y(0) |y(1) |y(2) |y(3) |y(4) |y(5) |y(6) |y(7) |y(8) |y(9)\n|y(10) |y(11) |y(12) |y(13) |y(14) |y(15)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|230 |250 |246 |208 |66 |249 |237 |185 |23 |245 |221 |139 |3 |237 |201\n|82 |0"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|231 |254 |248 |208 |102 |254 |241 |179 |60 |252 |231 |157 |41 |248 |214\n|119 |20"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|232 |255 |254 |252 |234 |254 |250 |231 |181 |246 |223 |159 |67 |209\n|146 |60 |9"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|233 |254 |254 |248 |215 |253 |251 |229 |158 |251 |236 |168 |67 |241\n|189 |79 |13"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|234 |141 |226 |251 |248 |162 |234 |244 |214 |186 |225 |202 |130 |166\n|161 |98 |33"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|235 |255 |255 |254 |251 |254 |252 |244 |225 |248 |233 |201 |141 |219\n|159 |67 |10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|236 |250 |250 |225 |145 |253 |248 |208 |114 |254 |236 |160 |48 |251\n|222 |135 |34"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|237 |255 |253 |236 |170 |255 |251 |219 |127 |254 |244 |196 |80 |251\n|226 |145 |30"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|238 |255 |254 |248 |214 |254 |253 |235 |161 |253 |247 |203 |83 |245\n|227 |157 |36"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|239 |252 |253 |246 |201 |253 |253 |236 |171 |254 |251 |218 |120 |254\n|247 |201 |83"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|240 |252 |246 |191 |78 |233 |245 |209 |108 |171 |211 |200 |107 |80 |129\n|152 |76"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|241 |252 |248 |212 |113 |253 |248 |207 |100 |253 |247 |203 |89 |250\n|241 |188 |66"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|242 |254 |247 |205 |99 |255 |247 |201 |78 |255 |248 |205 |86 |255 |250\n|221 |133"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|243 |254 |249 |213 |123 |255 |249 |212 |126 |255 |248 |211 |126 |255\n|248 |209 |122"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|244 |254 |251 |226 |144 |254 |252 |225 |141 |254 |252 |226 |143 |253\n|250 |227 |149"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|245 |252 |253 |241 |178 |254 |254 |238 |161 |254 |254 |237 |158 |253\n|253 |234 |156"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|246 |255 |254 |246 |204 |255 |254 |248 |205 |255 |255 |248 |205 |254\n|254 |248 |208"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|247 |237 |233 |224 |194 |252 |251 |249 |238 |254 |254 |254 |252 |253\n|254 |254 |253"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|248 |252 |254 |255 |254 |252 |252 |249 |244 |243 |230 |209 |197 |200\n|149 |85 |75"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|249 |254 |255 |255 |254 |254 |254 |251 |245 |250 |243 |227 |203 |221\n|197 |142 |72"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|250 |254 |254 |254 |247 |254 |254 |249 |223 |252 |248 |225 |157 |242\n|218 |153 |62"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|251 |254 |255 |254 |248 |254 |254 |252 |232 |254 |253 |238 |179 |251\n|240 |184 |78"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|252 |254 |255 |255 |255 |254 |254 |254 |251 |247 |246 |239 |224 |210\n|202 |183 |139"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|253 |254 |255 |255 |255 |254 |254 |254 |254 |244 |246 |248 |249 |198\n|203 |207 |213"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|254 |254 |255 |254 |247 |254 |255 |253 |239 |254 |254 |247 |215 |253\n|247 |222 |151"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|255 |254 |254 |254 |253 |254 |254 |254 |251 |254 |254 |251 |238 |251\n|247 |233 |193\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Appendix B*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Combined Motion Texture Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis appendix describes the combined motion/texture coding. The text was\ntaken from the Draft ITU-T Recommendation H.263 Video Coding for Low\nBitrate Communication sections 5.3 and 5.4. Annexes describing optional\nmodes can be found in that document."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFIGURE B.1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSyntax *diagram for the video bitstream*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *B.1. Macroblock Layer*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nData for each macroblock consists of a macroblock header followed by\ndata for blocks. The structure is shown in FIGURE 9/H.263. COD is only\npresent in pictures for which PTYPE indicates \u2018INTER\u2019, for each\nmacroblock in these pictures. MCBPC is present when indicated by COD or\nwhen PTYPE indicates \u2018INTRA\u2019. MODB is present for MB-type 0-4 if PTYPE\nindicates \u2018PB-frame\u2019. CBPY, DQUANT, MVD and MVD~2-4~ are present when\nindicated by MCBPC. CBPB and MVDB are only present if indicated by MODB.\nBlock Data is present when indicated by MCBPC and CBPY. MVD~2-4~ are\nonly present in Advanced Prediction mode (refer to Annex F). MODB, CBPB\nand MVDB are only present in PB-frames mode (refer to Annex G). For\ncoding of the symbols in the Syntax-based Arithmetic Coding mode refer\nto Annex E."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"12%,9%,8%,7%,8%,10%,7%,7%,7%,7%,7%,11%\",]\n|===\n|COD |MCBPC |MODB |CBPB |CBPY |DQUANT |MVD |MVD2 |MVD3 |MVD4 |MVDB\n|Block Data\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFIGURE B.2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStructure of macroblock layer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.1.1. Coded macroblock indication (COD) (1 bit)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA bit which when set to \"0\" signals that the macroblock is coded. If set\nto \"1\", no further information is transmitted for this macroblock; in\nthat case the decoder shall treat the macroblock as an INTER macroblock\nwith motion vector for the whole block equal to zero and with no\ncoefficient data. COD is only present in pictures for which PTYPE\nindicates \u2018INTER\u2019, for each macroblock in these pictures."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Note_ \u2013 In Advanced Prediction mode, overlapped motion compensation is\nalso performed if COD is set to \u201c1\u201d."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.1.2. Macroblock type & Coded block pattern for chrominance (MCBPC) (Variable length)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA variable length codeword giving information about the macroblock type\nand the coded block pattern for chrominance. The codewords for MCBPC are\ngiven in TABLE and TABLE . MCBPC is always included in coded\nmacroblocks."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn extra codeword is available in the tables for bit stuffing. This\ncodeword should be discarded by decoders."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe macroblock type gives information about the macroblock and which\ndata elements are present. Macroblock types and included elements are\nlisted in TABLE and TABLE ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE B.1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVLC table for MCBPC (for I-pictures)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"19%,18%,18%,18%,27%\",]\n|===\n|Index |MB type |CBPC (56) |Number of bits |Code\n|0 |3 |00 |1 |1\n|1 |3 |01 |3 |001\n|2 |3 |10 |3 |010\n|3 |3 |11 |3 |011\n|4 |4 |00 |4 |0001\n|5 |4 |01 |6 |0000 01\n|6 |4 |10 |6 |0000 10\n|7 |4 |11 |6 |0000 11\n|8 |Stuffing |-- |9 |0000 0000 1\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe coded block pattern for chrominance signifies C~B~ and/or C~R~\nblocks when at least one non-INTRADC transform coefficient is\ntransmitted (INTRADC is the dc-coefficient for INTRA blocks, see section\n5.4.1). CBPC~N~ = 1 if any non-INTRADC coefficient is present for block\nN, else 0, for CBPC~5~ and CBPC~6~ in the coded block pattern. Block\nnumbering is given in FIGURE 5/H.263. When MCBPC=Stuffing, the remaining\npart of the macroblock layer is skipped. In this case, the preceeding\nCOD=0 is not related to any coded or not-coded macroblock and therefore\nthe macroblock number is not incremented. For P-pictures, multiple\nstuffings are accomplished by multiple sets of COD=0 and MCBPC=Stuffing."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE B.2"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVLC table for MCBPC (for P-pictures)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,17%,17%,17%,31%\",]\n|===\n|Index |MB type |CBPC (56) |Number of bits |Code\n|0 |0 |00 |1 |1\n|1 |0 |01 |4 |0011\n|2 |0 |10 |4 |0010\n|3 |0 |11 |6 |0001 01\n|4 |1 |00 |3 |011\n|5 |1 |01 |7 |0000 111\n|6 |1 |10 |7 |0000 110\n|7 |1 |11 |9 |0000 0010 1\n|8 |2 |00 |3 |010\n|9 |2 |01 |7 |0000 101\n|10 |2 |10 |7 |0000 100\n|11 |2 |11 |8 |0000 0101\n|12 |3 |00 |5 |0001 1\n|13 |3 |01 |8 |0000 0100\n|14 |3 |10 |8 |0000 0011\n|15 |3 |11 |7 |0000 011\n|16 |4 |00 |6 |0001 00\n|17 |4 |01 |9 |0000 0010 0\n|18 |4 |10 |9 |0000 0001 1\n|19 |4 |11 |9 |0000 0001 0\n|20 |Stuffing |-- |9 |0000 0000 1\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE B.3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMacroblock types and included data elements for normal pictures"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"16%,12%,12%,10%,10%,10%,10%,10%,10%\",]\n|===\n|Picture type |MB type |Name |COD |MCBPC |CBPY |DQUANT |MVD |MVD2-4\n|INTER |not coded |- |X | | | | |\n|INTER |0 |INTER |X |X |X | |X |\n|INTER |1 |INTER+Q |X |X |X |X |X |\n|INTER |2 |INTER4V |X |X |X | |X |X\n|INTER |3 |INTRA |X |X |X | | |\n|INTER |4 |INTRA+Q |X |X |X |X | |\n|INTER |stuffing |- |X |X | | | |\n|INTRA |3 |INTRA | |X |X | | |\n|INTRA |4 |INTRA+Q | |X |X |X | |\n|INTRA |stuffing |- | |X | | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote: \u201cx\u201d means that the item is present in the macroblock"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE B.4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMacroblock types and included data elements for PB-frames"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"13%,11%,10%,6%,8%,8%,7%,7%,9%,6%,7%,8%\",]\n|===\n|Picture type |MB type |Name |COD |MCBPC |MODB |CBPY |CBPB |DQUANT |MVD\n|MVDB |MVD2-4"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|INTER |not coded |- |X | | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|INTER |0 |INTER |X |X |X |X |(X) | |X |(X) |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|INTER |1 |INTER+Q |X |X |X |X |(X) |X |X |(X) |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|INTER |2 |INTER4V |X |X |X |X |(X) | |X |(X) |X"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|INTER |3 |INTRA |X |X |X |X |(X) | |X |(X) |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|INTER |4 |INTRA+Q |X |X |X |X |(X) |X |X |(X) |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|INTER |stuffing |- |X |X | | | | | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote 1: \u201cx\u201d means that the item is present in the macroblock"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote 2: CBPB and MVDB are only present if indicated by MODB"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote 3: B-blocks are always coded in INTER mode, even if the MB type of\nthe PB-macroblock indicates INTRA"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.1.3 Macroblock mode for B-blocks (MODB) (Variable length)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMODB is present for MB-type 0-4 if PTYPE indicates \u2018PB-frame\u2019 and is a\nvariable length codeword indicating whether CBPB is present (indicates\nthat B-coefficients are transmitted for this macroblock) and/or MVDB is\npresent. In TABLE the codewords for MODB are defined."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE B.5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVLC table for MODB"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,20%,20%,20%,20%\",]\n|===\n|Index |CBPB |MVDB |Number of bits |Code\n|0 | | |1 |0\n|1 | |X |2 |10\n|2 |X |X |2 |11\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote: \u201cx\u201d means that the item is present in the macroblock"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.1.4. Coded block pattern for B-blocks (CBPB) (6 bits)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCBPB is only present in PB-frames mode if indicated by MODB. CBPB~N~ = 1\nif any coefficient is present for B-block N, else 0, for each bit\nCBPB~N~ in the coded block pattern. Block numbering is given in FIGURE\n5/H.263, the utmost left bit of CBPB corresponding with block number 1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.1.5. Coded block pattern for luminance (CBPY) (Variable length)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVariable length codeword giving a pattern number signifying those Y\nblocks in the macroblock for which at least one non-INTRADC transform\ncoefficient is transmitted (INTRADC is the dc-coefficient for INTRA\nblocks, see \u00a7 5.4.1)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCBPY~N~ = 1 if any non-INTRADC coefficient is present for block N, else\n0, for each bit CBPY~N~ in the coded block pattern. Block numbering is\ngiven in FIGURE 5/H.263, the utmost left bit of CBPY corresponding with\nblock number 1. For a certain pattern CBPY~N~, different codewords are\nused for INTER and INTRA macroblocks as defined in TABLE ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.1.6. Quantizer Information (DQUANT) (2 bits)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA two bit code to define change in QUANT. In TABLE the differential\nvalues for the different codewords are given. QUANT ranges from 1 to 31;\nif the value for QUANT after adding the differential value is less than\n1 or greater than 31, it is clipped to 1 and 31 respectively."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE B.6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDQUANT codes and differential values for QUANT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,33%,33%\",]\n|===\n|Index |Differential value |DQUANT\n|0 |-1 |00\n|1 |-2 |01\n|2 |1 |10\n|3 |2 |11\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE B.7"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*VLC table for CBPY*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,23%,23%,14%,22%\",]\n|===\n|Index |CBPY(INTRA) (12 34) |CBPY(INTER) (12 34) |Number of bits |Code\n|0 |00 00 |11 11 |4 |0011\n|1 |00 01 |11 10 |5 |0010 1\n|2 |00 10 |11 01 |5 |0010 0\n|3 |00 11 |11 00 |4 |1001\n|4 |01 00 |10 11 |5 |0001 1\n|5 |01 01 |10 10 |4 |0111\n|6 |01 10 |10 01 |6 |0000 10\n|7 |01 11 |10 00 |4 |1011\n|8 |10 00 |01 11 |5 |0001 0\n|9 |10 01 |01 10 |6 |0000 11\n|10 |10 10 |01 01 |4 |0101\n|11 |10 11 |01 00 |4 |1010\n|12 |11 00 |00 11 |4 |0100\n|13 |11 01 |00 10 |4 |1000\n|14 |11 10 |00 01 |4 |0110\n|15 |11 11 |00 00 |2 |11\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.1.7. Motion vector data (MVD) (Variable length)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMVD is included for all INTER macroblocks (in PB-frames mode also for\nINTRA macroblocks) and consists of a variable length codeword for the\nhorizontal component followed by a variable length codeword for the\nvertical component. Variable length codes are given in TABLE ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE B.8"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVLC table for MVD"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"19%,16%,17%,16%,32%\",]\n|===\n|Index |Vector |differences |Bit number |Codes\n|0 |-16 |16 |13 |0000 0000 0010 1\n|1 |-15.5 |16.5 |13 |0000 0000 0011 1\n|2 |-15 |17 |12 |0000 0000 0101\n|3 |-14.5 |17.5 |12 |0000 0000 0111\n|4 |-14 |18 |12 |0000 0000 1001\n|5 |-13.5 |18.5 |12 |0000 0000 1011\n|6 |-13 |19 |12 |0000 0000 1101\n|7 |-12.5 |19.5 |12 |0000 0000 1111\n|8 |-12 |20 |11 |0000 0001 001\n|9 |-11.5 |20.5 |11 |0000 0001 011\n|10 |-11 |21 |11 |0000 0001 101\n|11 |-10.5 |21.5 |11 |0000 0001 111\n|12 |-10 |22 |11 |0000 0010 001\n|13 |-9.5 |22.5 |11 |0000 0010 011\n|14 |-9 |23 |11 |0000 0010 101\n|15 |-8.5 |23.5 |11 |0000 0010 111\n|16 |-8 |24 |11 |0000 0011 001\n|17 |-7.5 |24.5 |11 |0000 0011 011\n|18 |-7 |25 |11 |0000 0011 101\n|19 |-6.5 |25.5 |11 |0000 0011 111\n|20 |-6 |26 |11 |0000 0100 001\n|21 |-5.5 |26.5 |11 |0000 0100 011\n|22 |-5 |27 |10 |0000 0100 11\n|23 |-4.5 |27.5 |10 |0000 0101 01\n|24 |-4 |28 |10 |0000 0101 11\n|25 |-3.5 |28.5 |8 |0000 0111\n|26 |-3 |29 |8 |0000 1001\n|27 |-2.5 |29.5 |8 |0000 1011\n|28 |-2 |30 |7 |0000 111\n|29 |-1.5 |30.5 |5 |0001 1\n|30 |-1 |31 |4 |0011\n|31 |-0.5 |31.5 |3 |011\n|32 |0 | |1 |1\n|33 |0.5 |-31.5 |3 |010\n|34 |1 |-31 |4 |0010\n|35 |1.5 |-30.5 |5 |0001 0\n|36 |2 |-30 |7 |0000 110\n|37 |2.5 |-29.5 |8 |0000 1010\n|38 |3 |-29 |8 |0000 1000\n|39 |3.5 |-28.5 |8 |0000 0110\n|40 |4 |-28 |10 |0000 0101 10\n|41 |4.5 |-27.5 |10 |0000 0101 00\n|42 |5 |-27 |10 |0000 0100 10\n|43 |5.5 |-26.5 |11 |0000 0100 010\n|44 |6 |-26 |11 |0000 0100 000\n|45 |6.5 |-25.5 |11 |0000 0011 110\n|46 |7 |-25 |11 |0000 0011 100\n|47 |7.5 |-24.5 |11 |0000 0011 010\n|48 |8 |-24 |11 |0000 0011 000\n|49 |8.5 |-23.5 |11 |0000 0010 110\n|50 |9 |-23 |11 |0000 0010 100\n|51 |9.5 |-22.5 |11 |0000 0010 010\n|52 |10 |-22 |11 |0000 0010 000\n|53 |10.5 |-21.5 |11 |0000 0001 110\n|54 |11 |-21 |11 |0000 0001 100\n|55 |11.5 |-20.5 |11 |0000 0001 010\n|56 |12 |-20 |11 |0000 0001 000\n|57 |12.5 |-19.5 |12 |0000 0000 1110\n|58 |13 |-19 |12 |0000 0000 1100\n|59 |13.5 |-18.5 |12 |0000 0000 1010\n|60 |14 |-18 |12 |0000 0000 1000\n|61 |14.5 |-17.5 |12 |0000 0000 0110\n|62 |15 |-17 |12 |0000 0000 0100\n|63 |15.5 |-16.5 |13 |0000 0000 0011 0\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.1.8. Motion vector data (MVD~2-4~) (Variable length)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe three codewords MVD~2-4~ are included if indicated by PTYPE and by\nMCBPC, and consist each of a variable length codeword for the horizontal\ncomponent followed by a variable length codeword for the vertical\ncomponent of each vector. Variable length codes are given in TABLE .\nMVD~2-4~ are only present when in Advanced Prediction mode (refer to\nAnnex F)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.1.9 Motion vector data for B-macroblock (MVDB) (Variable length)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMVDB is only present in PB-frames mode if indicated by MODB and consists\nof a variable length codeword for the horizontal component followed by a\nvariable length codeword for the vertical component of each vector.\nVariable length codes are given in TABLE . For the use of MVDB refer to\nAnnex G."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *B.2. Block Layer*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf not in PB-frames mode, a macroblock comprises four luminance blocks\nand one of each of the two colour difference blocks (see FIGURE\n5/H.263). The structure of the block layer is shown in FIGURE 10/H.263.\nINTRADC is present for every block of the macroblock if MCBPC indicates\nMB type 3 or 4 (see TABLE and TABLE ). TCOEF is present if indicated by\nMCBPC or CBPY."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn PB-frames mode, a macroblock comprises twelve blocks. First the data\nfor the six P-blocks is transmitted as in the default H.263 mode, then\nthe data for the six B-blocks. INTRADC is present for every P-block of\nthe macroblock if MCBPC indicates MB type 3 or 4 (see TABLE and TABLE ).\nINTRADC is not present for B-blocks. TCOEF is present for P-blocks if\nindicated by MCBPC or CBPY; TCOEF is present for B-blocks if indicated\nby CBPB."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor coding of the symbols in the Syntax-based Arithmetic Coding mode\nrefer to Annex E."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"57%,43%\",]\n|===\n|INTRADC |TCOEF\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFIGURE B.3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStructure of block layer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.2.1. DC coefficient for INTRA blocks (INTRADC) (8 bits)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA codeword of 8 bits. The code 0000 0000 is not used. The code 1000 0000\nis not used, the reconstruction level of 1024 being coded as 1111 1111\n(see TABLE)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*TABLE* B.9"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nReconstruction levels for INTRA-mode DC coefficient"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,40%,40%\",]\n|===\n|Index |FLC |Reconstruction level\n| | |into inverse transform\n|0 |0000 0001 (1) |8\n|1 |0000 0010 (2) |16\n|2 |0000 0011 (3) |24\n|. |. . |.\n|. |. . |.\n|126 |0111 1111 (127) |1016\n|127 |1111 1111 (255) |1024\n|128 |1000 0001 (129) |1032\n|. |. . |.\n|. |. . |.\n|252 |1111 1101 (253) |2024\n|253 |1111 1110 (254) |2032\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *B.2.2. Transform coefficient (TCOEF) (Variable length)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe most commonly occurring EVENTs are coded with the variable length\ncodes given in TABLE . The last bit \u201cs\u201d denotes the sign of the level,\n\u201c0\u201d for positive and \u201c1\u201d for negative."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn EVENT is a combination of a last non-zero coefficient indication\n(LAST; \u201c0\u201d: there are more nonzero coefficients in this block, \u201c1\u201d: this\nis the last nonzero coefficient in this block), the number of successive\nzeros preceding the coded coefficient (RUN), and the non-zero value of\nthe coded coefficient (LEVEL)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe remaining combinations of (LAST, RUN, LEVEL) are coded with a 22 bit\nword consisting of 7 bits ESCAPE, 1 bit LAST, 6 bits RUN and 8 bits\nLEVEL. Use of this 22-bit word for encoding the combinations listed in\nTABLE is not prohibited. For the 8-bit word for LEVEL, the codes 0000\n0000 and 1000 0000 are not used. The codes for RUN and for LEVEL are\ngiven in TABLE ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*TABLE* B.10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVLC table for TCOEF"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,6%,6%,7%,6%,12%,3%,7%,8%,5%,7%,6%,12%\",]\n|===\n|INDEX |LAST |RUN |LEVEL |BITS |VLC CODE | |INDEX |LAST |RUN |LEVEL\n|BITS |VLC CODE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0 |0 |0 |1 |3 |10s | |58 |1 |0 |1 |5 |0111 s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|1 |0 |0 |2 |5 |1111 s | |59 |1 |0 |2 |10 |0000 1100 1s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|2 |0 |0 |3 |7 |0101 01s | |60 |1 |0 |3 |12 |0000 0000 101s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|3 |0 |0 |4 |8 |0010 111s | |61 |1 |1 |1 |7 |0011 11s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|4 |0 |0 |5 |9 |0001 1111 s | |62 |1 |1 |2 |12 |0000 0000 100s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|5 |0 |0 |6 |10 |0001 0010 1s | |63 |1 |2 |1 |7 |0011 10s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|6 |0 |0 |7 |10 |0001 0010 0s | |64 |1 |3 |1 |7 |0011 01s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|7 |0 |0 |8 |11 |0000 1000 01s | |65 |1 |4 |1 |7 |0011 00s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|8 |0 |0 |9 |11 |0000 1000 00s | |66 |1 |5 |1 |8 |0010 011s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|9 |0 |0 |10 |12 |0000 0000 111s | |67 |1 |6 |1 |8 |0010 010s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|10 |0 |0 |11 |12 |0000 0000 110s | |68 |1 |7 |1 |8 |0010 001s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|11 |0 |0 |12 |12 |0000 0100 000s | |69 |1 |8 |1 |8 |0010 000s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|12 |0 |1 |1 |4 |110s | |70 |1 |9 |1 |9 |0001 1010 s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|13 |0 |1 |2 |7 |0101 00s | |71 |1 |10 |1 |9 |0001 1001 s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|14 |0 |1 |3 |9 |0001 1110 s | |72 |1 |11 |1 |9 |0001 1000 s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|15 |0 |1 |4 |11 |0000 0011 11s | |73 |1 |12 |1 |9 |0001 0111 s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|16 |0 |1 |5 |12 |0000 0100 001s | |74 |1 |13 |1 |9 |0001 0110 s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|17 |0 |1 |6 |13 |0000 0101 0000s | |75 |1 |14 |1 |9 |0001 0101 s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|18 |0 |2 |1 |5 |1110 s | |76 |1 |15 |1 |9 |0001 0100 s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|19 |0 |2 |2 |9 |0001 1101 s | |77 |1 |16 |1 |9 |0001 0011 s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|20 |0 |2 |3 |11 |0000 0011 10s | |78 |1 |17 |1 |10 |0000 1100 0s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|21 |0 |2 |4 |13 |0000 0101 0001s | |79 |1 |18 |1 |10 |0000 1011 1s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|22 |0 |3 |1 |6 |0110 1s | |80 |1 |19 |1 |10 |0000 1011 0s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|23 |0 |3 |2 |10 |0001 0001 1s | |81 |1 |20 |1 |10 |0000 1010 1s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|24 |0 |3 |3 |11 |0000 0011 01s | |82 |1 |21 |1 |10 |0000 1010 0s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|25 |0 |4 |1 |6 |0110 0s | |83 |1 |22 |1 |10 |0000 1001 1s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|26 |0 |4 |2 |10 |0001 0001 0s | |84 |1 |23 |1 |10 |0000 1001 0s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|27 |0 |4 |3 |13 |0000 0101 0010s | |85 |1 |24 |1 |10 |0000 1000 1s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|28 |0 |5 |1 |6 |0101 1s | |86 |1 |25 |1 |11 |0000 0001 11s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|29 |0 |5 |2 |11 |0000 0011 00s | |87 |1 |26 |1 |11 |0000 0001 10s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|30 |0 |5 |3 |13 |0000 0101 0011s | |88 |1 |27 |1 |11 |0000 0001 01s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|31 |0 |6 |1 |7 |0100 11s | |89 |1 |28 |1 |11 |0000 0001 00s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|32 |0 |6 |2 |11 |0000 0010 11s | |90 |1 |29 |1 |12 |0000 0100 100s\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE B.11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVLC table for TCOEF *(concluded)*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,6%,6%,7%,6%,12%,3%,7%,8%,5%,7%,6%,12%\",]\n|===\n|INDEX |LAST |RUN |LEVEL |BITS |VLC CODE | |INDEX |LAST |RUN |LEVEL\n|BITS |VLC CODE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|33 |0 |6 |3 |13 |0000 0101 0100s | |91 |1 |30 |1 |12 |0000 0100 101s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|34 |0 |7 |1 |7 |0100 10s | |92 |1 |31 |1 |12 |0000 0100 110s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|35 |0 |7 |2 |11 |0000 0010 10s | |93 |1 |32 |1 |12 |0000 0100 111s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|36 |0 |8 |1 |7 |0100 01s | |94 |1 |33 |1 |13 |0000 0101 1000s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|37 |0 |8 |2 |11 |0000 0010 01s | |95 |1 |34 |1 |13 |0000 0101 1001s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|38 |0 |9 |1 |7 |0100 00s | |96 |1 |35 |1 |13 |0000 0101 1010s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|39 |0 |9 |2 |11 |0000 0010 00s | |97 |1 |36 |1 |13 |0000 0101 1011s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|40 |0 |10 |1 |8 |0010 110s | |98 |1 |37 |1 |13 |0000 0101 1100s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|41 |0 |10 |2 |13 |0000 0101 0101s | |99 |1 |38 |1 |13 |0000 0101 1101s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|42 |0 |11 |1 |8 |0010 101s | |100 |1 |39 |1 |13 |0000 0101 1110s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|43 |0 |12 |1 |8 |0010 100s | |101 |1 |40 |1 |13 |0000 0101 1111s"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|44 |0 |13 |1 |9 |0001 1100 s | |102 |ESCAPE | | |7 |0000 011"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|45 |0 |14 |1 |9 |0001 1011 s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|46 |0 |15 |1 |10 |0001 0000 1s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|47 |0 |16 |1 |10 |0001 0000 0s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|48 |0 |17 |1 |10 |0000 1111 1s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|49 |0 |18 |1 |10 |0000 1111 0s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|50 |0 |19 |1 |10 |0000 1110 1s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|51 |0 |20 |1 |10 |0000 1110 0s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|52 |0 |21 |1 |10 |0000 1101 1s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|53 |0 |22 |1 |10 |0000 1101 0s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|54 |0 |23 |1 |12 |0000 0100 010s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|55 |0 |24 |1 |12 |0000 0100 011s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|56 |0 |25 |1 |13 |0000 0101 0110s | | | | | | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|57 |0 |26 |1 |13 |0000 0101 0111s | | | | | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTABLE B.12"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFLC table for RUNS and LEVELS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,13%,16%,11%,13%,13%,19%\",]\n|===\n|Index |Run |Code | |Index |Level |Code\n|0 |0 |000 000 | |- |-128 |FORBIDDEN\n|1 |1 |000 001 | |0 |-127 |1000 0001\n|2 |2 |000 010 | |. |. |.\n|. |. |. | |125 |-2 |1111 1110\n|. |. |. | |126 |-1 |1111 1111\n|63 |63 |111 111 | |- |0 |FORBIDDEN\n| | | | |127 |1 |0000 0001\n| | | | |128 |2 |0000 0010\n| | | | |. |. |.\n| | | | |253 |127 |0111 1111\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Appendix C"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Core Experiments"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*C.1. Experiments List*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn initial list of persons intending to perform core experiments is as\nfollows. At Munich meeting some revisions to this list have taken place\ntaking into consideration new proposals and thus this list will be\nrevised in future."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Table 1_ *List of Core Experiments*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"9%,76%,15%\",]\n|===\n|No. |Core Experiment and Proposer |Scene Class (reference only)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|P1 P2 P3 P4 P5 P6 P7 |Prediction Global and Overlapped Block Affine MC\nPrediction (NTT/Sarnoff) Short/Long Term Memory and MB partitioning for\nMC Prediction (Mitsubishi) Macroblock partitioning for MC prediction\n(Mitsubishi) Motion Segmentation and MC Prediction (TI) Variable Block\nSize MC Prediction (Sarnoff) 2D Triangle Mesh based MC Prediction (U.\nRochester) Motion Prediction Range Extension (Sharp) |B,C,E A,B,C A,B,C\nA,B,C,E A,B,C A,B A,B,C"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|T1 T2 T3 T4 T5 T6 |Frame Texture Coding Wavelet coding of I-pictures\n(TI/Sarnoff) Wavelet coding of P-pictures (Sarnoff) Matching Persuits\nCoding of P-pictures (Motorola) 3D-DCT coding of B-pictures (AT&T)\nVector Wavelet coding of I-pictures (Lehigh U.) Vector Wavelet coding of\nP-pictures (Lehigh U.) |A,B,C A,B.C A,B B,C A,B A,B"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Q1 Q2 |Quantization and Rate Control Improved Coding of Regions of\nInterest (AT&T) Improved Rate Control (Sarnoff) |A,B A,B,C"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|S1 S2 S3 S4 S5 |Shape and Alpha Channel Coding Comparison of Keying\nwith Alpha-channel coding (Matsushita) Geometrical Transformation &\nRepresentation of Sprites (Microsoft) Variable Block Size Segmentation\n(TI-Japan) Comparison of Shape coding Techniques (Motorola/Sharp) Alpha\nChannel coding with MMR code (Toshiba) |E E A,B,C,E A,B,C,E A"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|O1 O2 O3 O4 O5 O6 O7 |Object/Region Texture Coding (includes shape\ncoding overhead) Comparison of coding techniques for Sprite objects\n(Microsoft) DCT coding of macroblocks padded using Alpha-channel\n(Matsushita/Sharp) Wavelet/Subband coding of Region Texture\n(TI/Sony/Sharp) Shape Adaptive DCT for coding of Region Texture (HHI)\nPOCS and DCT for coding of Region Texture (AT&T) Chroma-keying and block\nDCT for coding of Region Texture (AT&T) Mean Replacement DCT coding of\nRegion Texture (Toshiba) |E E A,B,C,E A,B,C,E A,B,C,E A,B,C,E A,B"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|E1 E2 E3 E4 |Error Resilience and Correction Comparison of Error\nResilience Techniques (Motorola/Toshiba) Comparison of Error Correction\nTechniques (DoCoMo/Toshiba) Comparison of Error Concealment Techniques\n(Toshiba/TI) Error Resilience and Correction by Back Channel and FEC\n(Telenor) |A,B,C A,B,C A,B,C A,B,C"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|B1 |Bandwidth and Complexity Scaling Generalized Temporal-Spatial\nScalable Coding (AT&T) |B,C"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|M1 M2 |Multi-view, Model Manipulation and Others Mismatch Corrected\nStereo/Multiview Coding 2-D Triangle Mesh for Object/Content\nManipulation (U. Reochester) |D A,B,C"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|N1 N2 |Pre-, Mid-, and Post-processing Comparison of Coding Noise\nRemoval Techniques (TI-J, Telenor) Comparison of Automatic Segmentation\nTechniques (U. Hannover) |A,B,C A,B\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*C.2. General Experimental Conditions*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExperimenters are advised to follow the experimental conditions as\nsummarized in Table 2. This table is expected to undergo minor revision\nas a result of discusions in Munich meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Table 2_ *Experimental Conditions*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"23%,11%,11%,11%,11%,11%,11%,11%\",]\n|===\n|Bitrate, kbit/s |10 |24 |48 |112 |320 |512 |1024\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-----------------------VOP"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFormation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTexture information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMUX"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBuffer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPrevious Reconstructed VOP"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nShape information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nShape"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCoding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMotion Estimation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMotion Compensation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTexture Coding"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u2013"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMotion information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n+"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= %nullo.doc\n**********\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11/N1173*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title: Liason to ITU-T/SG 15 - WP2/15 - Questions 6/15 and 7/15.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSource: Leonardo Chiariglione (Convenor)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWG 11 being aware of the activities carried out in Question 6/15 (Audio\nand Wideband Speech Coding in Public Telecommunication Networks) and\nQuestion 7/15 ( Encoding of Speech Signals at bit-rate around 4 kbit/s)\nwould like to forward information about the results of the first round\nof audio tests conducted in WG11 for MPEG4."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt is felt to be usefull for both groups to exchange information on the\nrequirements and results for those bit-rates and applications that are\nof common interest, to the aim of harmonizing the activities of both\nbodies."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG4 audio carried out a first round of audio tests between November 95\nand January 96. The tests were designed to evaluate a number of\nfunctionalities. Those include compression at 2, 6, 16, 24, 40, 64\nkbit/s; bit-rate scalability (from 2 up to 64 kbit/s); error resiliance;\nspeed control. The results of these preliminary tests are reported in\nthe annexed document (WG11/N1144)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG4 audio activities will continue with the definition of a first set\nof Verification Models to achieve the functionalities specified in the\nproposal package description. Any information on the requirements\nconsidered in ITU-T would be useful at this point of time."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= MPEG Liaison Document to SG11\nDavid J. Meares\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11**N1174**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG96/\u00ca\u00ca\u00ca\u00ca\u00ca\u00ca\u00ca\u00ca\u00ca\u00ca"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title :* Liaison statement to ITU-R Study Group 11, Task Group 11/3 and\nStudy Group 10"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Leonardo Chiariglione (Convenor)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11 (MPEG) recognises that the ITU-R Study Group 11\nis currently working on systems for digital television, including the\nassociated sound system. This fact has been drawn to our attention, in\npart, by documents such as ITU-R TG 11-3/67, 11-3 82, 11-3/88. The\npurpose of this liaison is to offer to ITU-R such expertise as MPEG has,\nin order to assist ITU-R in this important work."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProbably the most relevant work that WG11 has carried out is that which\nwas reported in document ISO/IEC JTC1/SC29/WG11/N0685 \u201cReport on the\nMPEG/Audio Multichannel Formal Subjective Listening Tests\u201d in March\n1994. This recorded the most thorough tests conducted on multichannel\nsound systems and gave a good indication of the range of coded sound\nqualities delivered by what were then considered to be the best codecs\navailable (both MPEG and non-MPEG codecs were assessed). Worrying though\nit was, even the best codecs at the time could not offer what was\nconsidered to be sufficient quality for the all-important broadcasting\napplication. It is WG11\u2019s pleasure to enclose a copy of that report for\nreference to ITU-R\u2019s experts."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSince the time of the aforementioned tests, as codec optimisation has\ntaken place, WG11 has conducted briefer assessments of MPEG-2 backwards\ncompatible compliant codecs at higher bit rates, in order to achieve\nbroadcast sound quality. WG11 will be pleased to make the results of\nthese tests available."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG will continue to conduct listening tests with the multichannel\naudio coding system, standardised in IS 13818-3 and the non-backwards\ncompatible reference models, and will provide you with the results of\nthese tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf there are any other specific areas of work or contributions that you\nwish, WG11 will be delighted to consider your requests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe wish you well in your endeavours toward the recommendation of digital\ntelevision systems for broadcasting applications."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWe look forward to your continuing interest in these matters."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= 2d & 3d\nBillPow\n1996-01-29"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11N1175*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"15%,85%\",]\n|===\n|Source: |MPEG Integration Group\n|Title: |SNHC Advance Notice of the Call For Proposals\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG4 Synthetic-Natural Hybrid Coding*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAdvance Notice of the Call For Proposals"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *0. Abstract*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG is currently working on the MPEG4 standard. MPEG4 will be a\nstandard that includes coding of synthetic and natural, audio and video\ndata. This is an advance notice of a Call For Proposals for coding of\nsynthetic data and for methods of combining synthetic with natural data.\nThe full Call For Proposals will be issued on March 29, 1996. The\nexpected deadline for proposal submission is in August 1996."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== 1. Motivation and Scope"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo efficiently code interactive 2D and 3D environments comprised of\nreal-time audio, video, and synthetic objects."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIncreasingly over the past years, movie and video data have been\nproduced with a combination of natural and synthetic data, both for\naudio and video. In the conventional environment of NTSC/PAL/SECAM\nvideo, the diverse components of the complete scene are rendered and\ncomposited into video frames with audio soundtracks. Thus the ability to\ninteract with the original component objects is severely restricted, and\nfor efficient transmission or storage, the compression coding is\nperformed on the composited data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRecently, the way we as humans receive and interact with audiovisual\ninformation has been changing rapidly. The conventional approach has\nbeen _linear_ video and movies, (with associated soundtracks), and\ninteraction has been limited to what we can call _VCR_ functions. Now\nnew opportunities present themselves, for example the World Wide Web,\nwhich potentially offer a whole new freedom for interacting with\naudiovisual data. Such interactivity is provided for individual objects,\nrather than at the level of the composited video frame. Therefore, it is\nappealing to perform coding on the pre-rendered, pre-composited\n(pre-mixed) audiovisual data, because it offers the potential for higher\ncompression performance, and the opportunity for user-interaction."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProblems exist however. There are many forms of audiovisual data, such\nas video games, mechanical CAD, architectural CAD, 3-D terrain databases\nand medical imagery. No universal way exists to exchange and integrate\nrelevant sets of these data into a composite scene. Second, the volume\nof audiovisual data is so high that compression of the data is required\neven on wideband networks, and even for non-real-time downloading of\ndata sets. Third, in a truly flexible environment, part of a scene will\nbe streaming in real-time (like conventional video), and part will be\nrunning under interactive control of the local user, which means that\nsynchronization of events with fine granularity is required."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG has developed considerable expertise in the areas of efficient\ncoding and real-time synchronization, and has established the MPEG4\nprogram to address the integration of audiovisual information in an\nobject-oriented way. This call for proposals is specifically concerned\nwith coding techniques for environments containing mixed synthetic and\nnatural data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== 2. Functional Architecture"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Functional Architecture figure shows the relationships between the\nmajor anticipated processes in MPEG4. The system layer allows the\nbitstream to be parsed for content addressing, synchronization and error\ncorrection, and also controls the compositing of video and audio\nobjects, and graphical objects before and during the rendering process.\nStorage is provided for persistent objects such as 3D geometry,\ntextures, audio clips and segmentation masks."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *3. Program of Work*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe goal of the work program is to establish a standard for the coding,\nrepresentation, and integration of A/V, 2D/3D, and synthetic-natural\nhybrid media models. The standard will support real-time media\nexperiences on a wide range of current and future platforms."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Development of *\u201cVirtual Playground\u201d*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Proposers will be invited to help establish a digital 2D/3D* \u201cVirtual\nPlayground\u201d providing a Test Data Set. This test data will support\nexperiments to establish the leading approach to the baseline for an\nobject standard in media models. MPEG4 participants will oversee the\ndevelopment of this Test Data Set during the standards development\nprocess."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA cooperative, open version of the \u201cVirtual Playground\u201d will be\ndeveloped as a creative forum for showcasing contributions by a wide\ncommunity beyond MPEG4. This will foster build-out of the \u201cVirtual\nPlayground\u201d that will help create momentum for extensions to the formal\nstandard for MPEG4. This process will develop details of the technical\nobjectives for the standardization of Media Models and core experiments\nto demonstrate merits of proposal submissions."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe longer-term purpose of the SNHC effort is to act as a vanguard for\nsoliciting new ideas in real-time, networked media technology, and\nincorporating the best ideas into extensions of the standard. MPEG4\nprovides the ideal foundation of cooperating interests and competence in\ncoding and manipulating real-time media."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Coding *experiments*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe coding experiments will utilize the Test Data Set to test\noperational submissions in the development of focus areas of technology\nfor standardization. Some of the initial areas contemplated for\ntechnology focus are detailed in Section 4. They include compression,\nscalability, new media primitives, timing & synchronization, and\nreal-time interactivity with diverse media types."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nContributions will include specific methods of media model\nrepresentation and bitstream coding, with supporting tools and\nalgorithms. The convergence phase of the standardization process will\nharmonize SNHC with MPEG4 Syntatic Description Language and the overall\nMPEG4 standards in audio and video."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe \u201cVirtual Playground\u201d requirements are summarized in Annex A."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn outline of preliminary requirements for media models can be found in\nAnnex C."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *4. What Is Called For*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis technology focuses on the coding for storage and communication of\n2D and 3D scenes involving synthetic-natural images, sounds, and\nanimated geometry. Therefore, proposals are solicited for a universal\nbit-efficient coding of the relevant information, as well as the\nalgorithms and tools associated with the coding process."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe coding enables the synchronization of the different media and\nsupports consistent scalability for extracting time-critical simplified\nmodels. Furthermore, the standard should support an encoding of the\nbehavior and of the control parameters for animated components.\nProposals should address one or more of the following challenges:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Compression and simplification of synthetic data representations:\n* Images and video imbedded in 2D/3D (synthetic and natural texture,\npanoramic views, etc.)\n* Synthetic and natural audio data, including 2D/3D sound sources\n* Geometry (polyhedra, voxels, meshes, etc.)\n* Photometry (normals, colors, surface properties, texture attachments,\netc.)\n* Animation and deformation\n* Parameterized animated models:\n* Encoding of paramatrized models\n* Encoding of parameter streams\n* New primitive operations for compositing of natural and synthetic\nobjects\n* Scalability:\n* Extraction of subsets of the data for time-critical use in a\nconsistent way across hybrid models.\n* Time-critical rendering\n* Real-time interactivity with hybrid environments\n* Rigorous modeling of timing and synchronization in hybrid models\n* Synthetic audio (including 3D localization, audio attached to 3D\ngeometry, MIDI or higher-level symbolic musical data, extensibility)\n* {blank}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5. What a Proposal Should Provide"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA Test Data Set will be available on MPEG home pages (site to be\ndetermined). It will include hybrid synthetic-natural audio-visual\nscenes from several application domains. Each scene may comprise one or\nseveral polyhedral models with photometric and texture information, an\nassembly structure, a parameterized animation model, and 3D embedded\nvideo and captured or synthesized audio. The representation of the\ndifferent components of the Test Data Set will be selected from popular\nformats. For example, VRML 1.0 may be used for representing the\ngeometry."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThose intending to submit a proposal should provide one or several of\nthe following as applicable:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* A technical description:\n* Scope of the submission and its advantages.\n* Format of a coded representation of a subset of the above mentioned\ninformation.\n* Detailed textual description of the algorithms.\n* Relevant statistics from the submissions.\n* A floppy disk containing:\n* A coded bitstream of the relevant parts of the Test Data Set\n* An executable decoder capable of decoding the submitted bitstream.\n* A D1 video tape showing the results of compression/decompression,\nsimplification or other processes that may degrade the integrity of the\ndata set.\n* {blank}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProposals should be submitted by August of 1996 to: Leonardo\nChiariglione, MPEG Convenor, and Cliff Reader, MPEG Integration chair."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== 6. How Proposals Will Be Evaluated"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn September of 1996, members of the MPEG experts group will evaluate\nthe proposals for potential inclusion in the MPEG4 standard. The\ncriteria for evaluation will include: functionality, coding efficiency,\nquality of the decoded model, support for real-time interaction, and\nprojected performance and cost of implementation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *7. Milestones & Schedule*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnticipated schedule of the standardization process is planned as\nfollows:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFinal Call For Proposals March 29, 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExperiment Design March 29, 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest Data Set Submissions April 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest Data Set Complete April 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProposal Submissions August 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProposal Evaluation September 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInitial Working Draft Standard November 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFinal Working Draft July 1997"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCommittee Draft Standard November 1997"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDraft International Standard March 1998"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInternational Standard November 1998"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== 8. Additional Information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAddition information may be obtained from:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"50%,50%\",]\n|===\n|Peter K. Doenges Chair, Ad hoc group, SNHC Evans & Sutherland 600 Komas\nDrive P.O. Box 58700 Salt Lake City, Utah 84158 USA Tel.: +1 801\n588-7423 Fax: +1 801 588-4521 Email: pdoenges@es.com |Itaru Kaneko\nChair, Ad hoc group, SNHC Audio Graphics Communications Laboratories\n3-4-1 Okubo Shinjuku-ku Tokyo 169 JAPAN Tel.: +81 3 5273 8521 Fax: +81 3\n5273 0118 Email: itaru-k@gctech.co.jp"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Dr. Leonardo Chiariglione MPEG Convenor CSELT Via G. Reiss Romoli, 274\n10148 Torino ITALY Tel.: +39 11 228 6120 Fax: +39 11 228 6299 Email:\nleonardo.chiariglione@cselt.stet.it |Dr. Cliff Reader Chair MPEG\nIntegration Group Samsung Semiconductor, Inc. 3655 North 1st Street San\nJose, CA 95134 USA Tel.: +1 408 954 7853 Fax: +1 408 954 7150 Email:\ncreader@samsung.com\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Annex A Test Data Set and the \u201cVirtual Playground\u201d*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG4 wishes to facilitate the submission of proposals for coding of\nsynthetic 3D environments which incorporate images, video, and various\nforms of audio."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe \u201cVirtual Playground\u201d(VP) is a collection of these objects which are\nInternet accessible for use by proponents in experiments and\nsubmissions. The objects will be stored in popular formats such as\nVRML1.0 for geometric objects, JPEG for images (textures), and AIFF for\naudio clips. All objects will be downloadable by selection in the MPEG\nWWW home page. Compositions of VP objects will be used to demonstrate\nMPEG4 applications and to further expose areas for study and\nstandardization. For example, a village with animated characters,\ncomplex geometry, texture mapping, and various sound sources could be\nused to test synchronization and complexity issues. CAD models of\nfurniture, and vehicles could be used to represent complex geometry.\nTalking synthetic characters could exercise the use of parameterized\nmodels, and audio synchronization and 3D localization."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA subset of the submissions to the VP will be selected to form the Test\nData Set."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG4 is soliciting submissions from all interested parties in this\nhighly visible endeavor. Participants will benefit from exposure to a\nwide range of media types and their integration into a common\nenvironment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== *Annex B Proposal Package Description*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis section will be provided at the March 1996 MPEG meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Annex C *Media Model: Preliminary Requirements*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe media model will focus on providing the building blocks for the\nefficient coding and rendering of interactive environments, which\nsynchronize 3D embedding of diverse objects, such as images, real-time\nvideo, audio, and static or animated shapes. These objects may originate\nfrom natural or synthetic sources. The following are candidates for\ninclusion:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Basic visual & audio primitives (wavetables, sprites, polygons,\ntextures)\n* 2D & 3D spatial models including geometric & structural properties\n* Surface/material properties relative to scene illuminants\n* Texture mapping attributes for still and moving imagery\n* Combining natural and synthetic, static and moving, imagery & audio\n* Combining synthetic spatial structures with traditional A/V\n* Structures for compositing or constructing scenes from objects\n* Conventions for coordinate systems & addressing in space/time/network\n* Use of hierarchy for control, complexity, interaction, instantiation\n* Complying with different transmission-consumption-interaction models\n* Static transformations for composing 2D/3D collections of objects\n* Constraints & transformations for animation or behavior of models\n* Provisions for generating events such as collision & reactions\n* Compressed & uncompressed data forms for system storage\n* Scalability/quality modeling such as level of detail, MIP capabilities\n* Color space transformations & optimal coding per color vs. per pixel\n* Representation of viewers, cameras, sound sources for rendering scenes\n* Naming & hyper-linking conventions for utilizing servers, libraries\n* Continuous time, discretizing it & means to condition/synchronize\nevents\n* Dynamic properties\n* Parameterized models and free-form deformations\n* Modeling for different classes of terminal resources & scene\ndegradation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCandidates for lossy vs. lossless compression techniques included:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Geometry (polyhedra, voxels, TINs, tri-linear interpolation, scaling,\nnormals)\n* Imagery (JPEG, sub-band coding, model-based, etc.)\n* Texture (MIP with tri-linear. interpolation, hierarchies, etc.)\n* Video (MPEG video - DCT, polygon-based motion compensation)\n* Audio (MPEG audio, MIDI, etc.)\n* Real-time parameter streams in animation control\n* Real-time deformation and animation\n* Automatic decimation/LOD of spatial data\n* Sparse or localized models\n* Progressive transmission"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExtension mechanisms will be provided for accommodating higher-level\nconstructs and future evolution of the relevant technologies."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANIZATION FOR STANDARDIZATION\nPeter Schirling\n1996-01-23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11 *N1176*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG 96/*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n1996 January"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"19%,81%\",]\n|===\n|Source: |Leonardo Chiariglione - Convenor\n|Title: |Integrated WG11 workplan\n|Status: |Approved at 33rd meeting\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"14%,52%,8%,9%,9%,8%\",]\n|===\n|Part |Title |WD |CD PDAM PDTR |DIS DAM DTR DCOR |IS AMD TR COR\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nRob Koenen\n1996-07-01"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11N1177*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*MPEG96*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"20%,80%\",]\n|===\n|Source: |Leonardo Chiariglione - Convenor\n|Title: |MPEG-4 project description\n|Status: |Approved at 33rd meeting\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Coding of audio-visual objects*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA number of concurrent evolutions have created the need for new ways to\nrepresent, integrate and exchange pieces of audio-visual information:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* the deployment of diverse new two-way delivery systems such as fixed\nbroadband and mobile narrowband;\n* the progress of micro-electronic technology that is providing\nextremely powerful and programmable processors, and\n* the change of the audio-visual information production and consumption\nparadigm, because of the increased role of synthetic information and\nhigher degrees of interactivity."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MPEG-4 project aims to establish a universal, efficient coding of\ndifferent forms of audio-visual data, called audio-visual objects. These\nobjects can be of natural and synthetic origin."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe goal will be reached by defining two basic elements:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. A _set of coding tools for audio-visual objects_ capable of providing\nsupport to different functionalities such as object based interactivity\nand scalability, and error robustness, in addition to efficient\ncompression.\n. A _syntactic description of coded audio-visual objects_, providing a\nformal method for describing the coded representation of these objects\nand the methods used to code them."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe coding tools will be defined in such a way that users will have the\nopportunity to assemble the standard MPEG-4 tools to satisfy specific\nuser requirements, some configurations of which are expected to be\nstandardized. The syntactic description will be used to convey to a\ndecoder the choice of tools made by the encoder. It can also be used to\ndescribe new algorithms and download their configuration to the decoding\nprocessor for execution."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPart of the MPEG-4 coding tools will be drawn from existing major\naudio-visual coding standards such as MPEG-1, MPEG-2, G.723, H.261 and\nH.263. These tools will provide a simple way to achieve backwards\ncompatibility."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOther tools will be defined by the collaborative development efforts of\nindividuals taking part in MPEG. The necessary information is obtained\nby issuing \u201cCalls for Proposals\u201d. Calls are open in the sense that\nanybody will be given the opportunity to make a proposal. A Call will be\nissued whenever functionalities falling within the MPEG-4 work item are\nidentified which are not already sufficiently covered by the ongoing\ndevelopment, and for which adequate evidence is brought to the working\ngroup that the needed technology is likely to be available. Two such\nCalls were already issued, in July and November 1995. The next Call (for\nhybrid coding) will be issued in March 1996, and another is planned for\nproposals to be evaluated in July 1997."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWorkplan"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"60%,40%\",]\n|===\n|Nov. 96 |WD\n|Nov. 97 |CD\n|Jul. 98 |DIS\n|Nov. 98 |IS\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= The MPEG-2 standard provides a broad range of compression tools that\nallow its use in a variety of different applications. Forcing... On the\nother hand, letting each user arbitrarily pick his own tools can cause\ninteroperability problems. Therefore MPEG\nZFE T SN 2\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11**N1178**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary, 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: MPEG-2 4:2:2 Profile at Main Level Informative Annex"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSource: Video and Test"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis annex provides guidance to users regarding the applicability of the\n4:2:2 Profile at Main Level to applications which may require:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( higher quality than Main Profile at Main Level"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( better chroma resolution than Main Profile at Main Level"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( post processing after compression and decompression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( multiple generations of compression and decompression"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( short Group of Pictures (GOP) for editability"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( capability to pass all active video"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( capability to pass vertical blanking interval information"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt should be noted that application of this Profile is an area of\nongoing progress. Results presented here reflect varying degrees of\nalgorithm refinement, so further improvement can be expected."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest Sequences"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe test sequences were generated using computer simulation of the\nMPEG-2 compression and decompression. For 525/60, the test material\nincluded:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Gwen"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Trailblazers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Mobile and Calendar"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Dissolve"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor 625/50, the test material included:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Balls of Wool"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Cactus and Comb"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Basketball"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Wall"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Renata and Butterfly"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Mobile and Calendar"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cGwen\u201d is a chroma key test sequence with a woman in the foreground\nkeyed over a forest scene in the background. \u201cGwen\u201d is a difficult\nsequence to chroma key but an easy sequence to compress. Both \u201cCactus\nand Comb\u201d and \u201cBalls of Wool\u201d are chroma key sequences which were used\nwith a colored background. \u201cTrailblazers\u201d is a rapid motion basketball\nsequence shot with an un-shuttered CCD camera. \u201cBasketball\u201d is also a\nrapid motion sports sequence. Both are typical program material and\nmoderately difficult to compress. \u201cWall\u201d consists of a woman standing in\nfront of wall made of many small stones. \u201cRenata\u201d consists of a woman in\nfront of a complex background with a dissolve to a complex image of\nbutterflies. \u201cMobile and Calendar\u201d is a particularly difficult\ncompression test sequence with saturated colors and complex motion.\n\u201cDissolve\u201d consists of two segments of \u201cMobile and Calendar\u201d with a one\nsecond fade between the two segments and is also difficult to compress."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest sequences were supplied by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( ITU-R"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Portland Trailblazers"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( SMPTE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Tektronix"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Test Procedures*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMPEG has conducted experiments to verify the performance of the 4:2:2\nProfile. The results of those experiments are presented here. There are\nseparate tests for 525/60 and 625/50. The 525/60 tests explore a broad\nrange of data rates and GOP structures, while the 625/50 tests include\nmore variety of test material but less combinations of data rate, GOP\nstructure, and number of generations. The parameters chosen for the\nexperiments are for example only, and do not cover the entire range of\nallowed parameter values. The examples are not intended as specific\nrecommendations. Each application should use the combination of\nparameters that is most appropriate, depending on its requirements for\nquality, editability, and cost."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tests include both a single generation and eight generations of\ncascaded compression and decompression. For the eight generation tests,\nseparate tests were done with no shifts, with two spatial shifts, and\nwith two temporal shifts. Spatial shifting means that the picture was\nshifted horizontally and vertically by two pixels and two spatial lines\nbetween the first and second generations and then back between the fifth\nand sixth generations. Spatial shifting represents the effects of\npicture repositioning which might occur in a DVE. Temporal shifting\nmeans that the GOP structure was shifted one frame between the first and\nsecond generations and again between the fifth and sixth generations.\nTemporal shifting represents the effect of multiple generations which\nhave different GOP alignment."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nChroma key experiments were done by processing the foreground with blue\nscreen through compression and decompression. After decompression the\ncomponent digital signal was chroma keyed to add the background. The\nbackground image was not compressed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMixed environment tests for 525/60 used MPEG-2 4:2:2 compression and\ndecompression cascaded with a compressed digital VTR using 2:1\nintra-field compression. The tests used a total of eight generations of\ncompression. The four odd number generations were MPEG and the four even\nnumber generations were compressed digital VTR. There were no shifts\nbetween generations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMixed environment tests for 625/50 used only MPEG compression. The tests\nused a total of three generations of compression. The first and third\ngenerations were MPEG-2 4:2:2 compression with IBBP GOP structure at 20\nMbits/s, while the second generation was MPEG-2 4:2:2 compression with\nI-only GOP structure at 50 Mbits/s. A temporal shift of one frame was\nincluded between the second and third generations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCompression and decompression processing were contributed by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( CCETT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( FTZ"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( IRT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( JVC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Sony"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Technical University of Braunschweig/BTS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Tektronix"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEditing and duplication of test tapes were contributed by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( RAI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Tektronix"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Subjective Assessment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe subjective assessment used the DSCQS method described in ITU-R Rec.\nBT.500-6. Both expert and non-expert viewing sessions were conducted at\na number of sites around the world. All of the expert viewing results\nwere combined, and all of the non-expert viewing results were combined.\nBoth expert and non-expert results are presented here. Only subjective\ntest results are presented, as signal to noise is not regarded as a\nreliable measure of picture quality in these cases."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExpert subjective assessment viewing sessions were conducted by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( NHK"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( SMPTE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNon-expert subjective assessment viewing sessions were conducted by:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( CCETT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( JVC/MPT/NHK/NTV"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( RAI"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( Technical University of Braunschweig/BTS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Test Results*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTest results are presented in the following order:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 525/60 Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 525/60 Non-Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 625/50 Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 625/50 Non-Homogeneous Environment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe tables of test results are organized with higher data rates\npresented first and lower data rates presented last. Within a given bit\nrate, results are organized by GOP structure, number of generations, and\ntype of shifting. The mean and confidence interval are given for each\ntest sequence."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that while subjective viewing tests often use a five point\nimpairment scale, these tests used the continuous quality scale\nspecified in ITU-R Rec. BT.500-6. The subjective assessments were done\non a continuous 0 to 100 scale. The mean differences between original\nand compressed sequence ratings were calculated, on a 0 to 100 scale,\nwith 0 representing no degradation through compression and 100 being the\nworst possible rating. The results presented here are based on the\nfollowing quality definitions:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 0 to 12.5 Transparent"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 12.5 to 20 Nearly Transparent"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n( 20 to 40 Good"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThree quality ratings appear in the tables of test results.\n\u201cTransparent\u201d is the best quality, followed by \u201cNearly Transparent\u201d, and\nthe lowest quality observed was \u201cGood\u201d."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"57%,43%\",]\n|===\n|Compression Parameters |Viewer Ratings\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"58%,42%\",]\n|===\n|Compression Parameters |Viewers\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= Accredited Standards Committee\nportable\n1996-01-24"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*ISO/IEC JTC1/SC29/WG11N1179*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source: Audio Subgroup*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Requirements for Submission of Technical Proposals *to MPEG\nAudio*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Status: Approved*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthors: S. Quackenbush, K. Brandenburg, M. Bosi"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1.0 Background*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSubmissions and technical proposals to MPEG Audio have often been found\nto lack details in the \u201edetailed textual description\u201c of the technical\ncontents. To prevent this from happening in the future, this document\noutlines requirements for technical contributions and submissions to the\nMPEG-Audio standardization work. Depending on the actual target for the\nsubmission, the provision of additional information may be necessary."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2.0 Requirements*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following are mandatory steps that proposers shall satisfy when\nsubmitting audio technical descriptions to MPEG."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* One page summary detailing the main features of the submission.\n* Block diagram.\n* Syntax elements needed to implement the proposal (bit stream\ndescription if the proposal is an algorithm)\n* If the proposal is an algorithm, the proposers shall specify the main\ntools contained in the proposal.\n* Provision of a description for each tool, including equations and\ntables needed to implement the proposal.\n* Provide the proposer\u2019s view on what are the major\nadvantages/disadvantages of the proposed technique."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition it is recommended that for each tool input/output data\nstructures be described."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nChris Adams\n1996-01-23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALIISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND ASSOCIATED AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWG11 *N1180*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Jan 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Ad Hoc Group to Review and Clarify the DSM-CC DIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Convenor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To review DIS and document clarifications as needed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings:* The group will correspond by regular DSM-CC e-mail\nreflector. The e-mail reflector address is dsmcc@divi.com. No meetings\nare planned at this time."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Duration:* Until the March meeting in Florence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* Chris Adams"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"50%,50%\",]\n|===\n|Bruce Siegell |Bellcore\n|Ala Nazari |Telia Research\n|Chia-Chang Li |AT&T\n|Mike McPheters |AT&T\n|Liam Casey |BNR\n|Vahe Balabanian |BNR\n|Bernard Peigne |CCETT\n|Don Hooper |DEC\n|Matthew Goldman |DEC\n|Chris Adams |DiviCom\n|John Fetvedt |IBM\n|Takuyo Kogure |Matsushita\n|David Malloy |NLC\n|Taisto Heinonen |Nokia\n|Frank Bosveld |Philips\n|Tim Addington |Scientific Atlantic\n|Obi-Ron Jacoby |SGI\n|Peter Gleissl |Siemens\n|Jim Van Loo |Sun\n|Martin Fisher |Sybase\n|Regis Crinon |TCE\n|Guy Cherry |Tektronix\n|Hideyuki Ueno |Toshiba\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nChris Adams\n1996-01-23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALIISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWG11 *N1181*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Jan 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Ad Hoc Group to Investigate Low Bandwidth Data Representations\nfor DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Convenor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To investigate data representations which could reduce\nbandwidth"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nrequirements for DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings:* The group will correspond by regular DSM-CC e-mail\nreflector. The e-mail reflector address is dsmcc@divi.com. No meetings\nare planned at this time."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Duration:* Until the March meeting in Florence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* Ron Jacoby"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"27%,26%,47%\",]\n|===\n|Name |Organization |E-mail\n|Liam Casey |BNR |liam@bnr.ca\n|Don Hooper |DEC |hooper@mpgs.enet.dec.com\n|Chris Adams |DiviCom |cadams@divi.com\n|Mark Porter |Oracle |maporter@us.oracle.com\n|Ronald Jacoby |SGI |rj@sgi.com\n|Jim Van Loo |Sun |james.vanloo@sun.com\n|Martin Fisher |Sybase |mrf@gain.com\n|Hideyuki Ueno |Toshiba |ueno@eel.rdc.toshiba.co.jp\n|Liam Casey |BNR |\n|Chia Li |AT&T |\n|Regis Crinon |TCE |\n|Ala Nazari |Telia Research |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANISATION FOR STANDARDISATION\nChris Adams\n1996-01-23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANISATION FOR STANDARDISATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE DE NORMALIISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11**N1182**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Ad hoc group of DSM-RSF."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Source:* Convenor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Mandate:* To plan, coordinate, synchronize, execute and evaluate tests"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Meetings:* The group will correspond by e-mail reflector, telephone\nconferencing, and can have one meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Duration:* Until the March MPEG"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Chairman:* Martin Fisher (mrf@sybase.com)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"27%,26%,47%\",]\n|===\n|Name |Organization |E-mail\n|Bob Dalton |AT&T |rwd1@mvulo.att.com\n|James Clark |AT&T |jclark@ivs.att.com\n|Joseph Xavier |Bell South |xavier_js@bstgw1.bst.bls.com\n|Liam Casey |BNR |liam@bnr.ca\n|Vahe Balabanian |BNR |balabani@bnr.ca\n|Bernard Peigne |CCETT |peigne@ccett.fr\n|Keunhwan Kim |Daewoo |khwan@phoenix.dwe.co.kr\n|Don Hooper |DEC |hooper@mpgs.enet.dec.com\n|Matthew Goldman |DEC |goldman@mpgs.enet.dec.com\n|Bob Tausworthe |DiviCom |tozz@divi.com\n|Chris Adams |DiviCom |cadams@divi.com\n|Hirofumi Muratani |DVL |muratani@dvl.co.jp\n|Seung Seok Jang |ETRI |jss@media.etri.re.kr\n|Seonja Kim |ETRI |sjkim@media.etri.re.kr\n|Kiyoshi Sakai |Fujitsu |sakai@flab.fujitsu.co.jp\n|Tsuyoshi Hanamura |GCL |hana@gctech.co.jp\n|Takao Kasahara |GCL |kasahara@gctech.co.jp\n|Sam Narasimha |General Instrument |snarasimha@gi.com\n|Koichi Shibata |Hitachi |kshibata@crl.hitachi.co.jp\n|Henrik Braun Jakobsen |HyperVision |vision@inet.uni-c.dk\n|Takuyo Kogure |Matsushita |kogure@drl.mei.co.jp\n|Yuki Kusumi |Matsushita |kusumi@isl.mei.co.jp\n|Kazuhiro Matsuzaki |Mitsubishi |koufum@atom.isl.melco.co.jp\n|Tatsuya Kurioka |NHK |kurioka@strl.nhk.or.jp\n|Ron Brown |Nokia |ron.brown@research.nokia.com\n|Taisto Heinonen |Nokia |taisto.heinonen@research.nokia.com\n|Masahisa Kawashima |NTT |kawasima@nttssl.nslab.ntt.jp\n|Mark Porter |Oracle |maporter@us.oracle.com\n|Frank Bosveld |Philips |bosveldf@adc-bcl.ce.philips.nl\n|Tihao Chiang |Sarnoff |tchiang@sarnoff.com\n|Tim Addington |Scientific Atlantic |tim.addington@sciatl.com\n|Ronald Jacoby |SGI |rj@sgi.com\n|Peter Gleissl |Siemens |Peter.Gleissl@mch.scn.de\n|Jim Van Loo |Sun |james.vanloo@sun.com\n|Martin Fisher |Sybase |mrf@gain.com\n|Hideyuki Ueno |Toshiba |ueno@eel.rdc.toshiba.co.jp\n|Toshinori Odaka |Toshiba |odaka@eel.rdc.toshiba.co.jp\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= INTERNATIONAL ORGANIZATION FOR STANDARDIZATION\nChris Adams\n1996-02-08"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANISATION INTERNATIONALE NORMALISATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO INFORMATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*WG11* *N1183*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Jan 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTitle: Clarifications on the DSM-CC DIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFrom: Munich DSM-CC Meeting"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDate: Jan 24, 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Server Session Setup Problem"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n** questions: Server Session Setup - IT DOES NOT WORK!!!*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-how are resources allocated for the first time"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-note that only ClientSessionSetupIndication has a resource list but\nthere is no method provided for Server to provide list of required\nresources to the SRM."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-how does UU attach work?"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-how would DBS get initiated in this case."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-how does Capabilities info get exchanged"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-how does Download get kicked off, how does the module set get selected."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere are many options:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1) Status quo"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-This approach tries to use the message flows as they exist"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-would include a PathSpec and ResumeContext in uuData in\nServerSessionSetupRequest and ClientSessionSetupIndication."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-The Client can then include the UU Attach info (Download req, PathSpec\netc) in the ClientSessionSetupResponse uuData, which is passed through\nby ServerSessionSetupConfirm uuData."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-After the ServerSessionSetupConfirm the Server would do the\nServerAddResourceRequest sequence."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-When the Client receieves the ClientAddResourceIndication with a\nDownload resource the Client can now start the download sequence."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-BUG: no way to deliver the UU Attach reply. The creation of resources\nand the startup of Download is also a little fuzzy."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}2) ServerSessionCallbackRequest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Interpret ServerSessionSetupRequest/ ClientSessionSetupIndication as a\nrequest for the Client to call back with a ClientSessionSetupRequest\netc."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-May want to rename ServerSessionSetupRequest as\nServerSessionCallbackRequest etc."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-would include a PathSpec and/or ResumeContext in uuData in\nServerSessionSetupRequest and ClientSessionSetupIndication. The client\ncould then use this info in the following ClientSessionSetupRequest UU\nAttach (uuData) info."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-The response in ClientSessionSetupResponse will either say WillCallback\nor RefuseToCallback (or something along those lines)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-probably no need to even have a sessionId in these messages. Session is\ncreated when Client does the ClientSessionSetupRequest."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-BUG: Race condition between the ClientSessionSetupResponse (or renamed\nClientSessionCallbackResponse) and the resulting\nClientSessionSetipRequest."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}3) Passthrough Callback Request"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-This is a little like \u20182) ServerSessionCallbakcRequest\u2019 except that we\nassume that there is not a Response/Confirm sequence that would provide\nthe WillCallback or RefuseToCallback type of response."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Could redefine ServerSessionSetupRequest in this manner or just enable\n(add fields if needed) ServerPassThruRequest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-No sessionId created in the ServerSessionSetupRequest /\nServerSessionCallBackRequest / ServerPassThruRequest (note we are\nconsidering three different names for same message function)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Client can respond with ClientSessionSetupRequest. There is no race\nwith the ClientSessionSetupResponse because that message is no longer\nused."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-BUG: no response that says RefuseToCallback so Server does not know to\nstop trying."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}4) Pipelined ClientSessionSetupResponse /\nClientSessionSetupRequest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Option \u20182) ServerSessionCallbackRequest\u2019 is desireable but has a race\ncondition between ClientSessionSetupResponse and\nClientSessionSetupRequest. One solution is to send only one or the\nother."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-In the positive response case when the Client receives\nClientSessionSetupIndication it responds by sending a\nClientSessionSetupRequest but does not send the\nClientSessionSetupResponse. Client uses the same sessionId provided in\nthe ClientSessionSetupIndication - this binds the servers request with\nthe clients setup request."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Two options on how to respond in the negative case:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Option 4a) Client uses ClientSessionSetupResponse to indicate a\nnegative reply. This should result in the sessionId being released."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Option 4b) Client uses ClientSessionReleaseRequest to reject session\nand inform the SRM and Server of the rejection."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-In this option may also rename ServerSessionSetupRequest to\nServerSessionCallbackRequest."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-BUG?: The only concern is that the resulting message flows are a little\nunusual or inconsistent with other DSM-CC UN message flows."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Download"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe DSM-CC Download Subgroup meet on January 24, 1996 at the 33rd MPEG\nmeeting in Munich Germany. This submission summarizes the discussions\nheld."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Contribution 0577: *Binding Resources for Download and the Download\nInterface*\n. {blank}\n. Revise Figures 7-1 to 7-3 to reflect the possibility of 4 flows. These\nflows are: control upstream, control downstream, data upstream, data\ndownstream.\n. Move the description detailing the classification of messages into\ncontrol and data messages earlier in Section 7.\n. The DSM-CC Download Subgroup solicits for contributions for an\ninformative annex describing the use of download over an ATM network.\n. {blank}\n. Contribution 0666: *DSMCC: Modification to U-U Object Carousels in\nAnnex F*\n. {blank}\n. Add a clarifying paragraph to 15.3.3.3 to on including a\ndownloadInfoResponse message in the data carousel.\n. Add a block_time_out field definition in the list of module location\nidentifiers that specifies the maximum time period for the next module\nblock to arrive once a block of the same module has been received.\n. Reduce the size of the location_identifier to 8 bits and define its\nrange.\n. A tag value for the BIOP ProfileBody is required and a request to\ninclude a definition in the User-User IDL will be forwarded to the\nDSM-CC User-User subgroup.\n. Remove the history, locks, and permissions fields from the\nExtendedBindingList since suitable defaults can be generated by the\nUser-User library and default values can be overridden using the\nobject_info structure. Default values could be: aVersion = 0, aDataTime\n= 0, readLock = 0, writeLock = 1, all permissions = READ_ONLY, owner =\n0, aPassword = NULL, rAuthData = NULL, and allSecure = False.\n. The MsgType enum is removed from the BIOP module definition in Section\n15.3.2.1 and a description of the message_type field is added specifying\nthe range of values.\n. {blank}\n. Contribution 0667: *DSMCC: Transport of Download messages in DSMCC\nsections*\n. {blank}\n. Clarifying text is added to Section 9 explaining the use of DSM-CC\nsection fields for the DSM-CC User-Network Messages and for the DSM-CC\nDownload Data Messages.\n. The values of certain table_id assignments should be changed as to be\nmore consistent with the rest of DSM-CC.\n. In Section 7, clarifying text is added to the description of\ndownloadDataBlocks specifying that their size is limited by the maximum\ntransmission unit of the underlying network transport. For example, when\ncarried in MPEG-2 sections, their size is restricted to less than or\nequal to 4066 bytes.\n. Text is added to define the encapsulation of Download Data Messages\nand Download Control Messages in MPEG-2 sections in such a way that\nenhances the ability to filter these messages using Transport Stream\ndemultiplexing hardware. This includes rules for storing certain data in\nthe table_id_extension, section_number, and version_number fields.\n. DSM-CC Download Control Messages, when encapsulated in MPEG-2\nTransport Streams, are carried in private sections which restricts their\nsize to under (4096 - headers) bytes.\n. In Section 7, an additional syntax description is necessary to define\nthe proper encapsulation of Download Data Messages. The current syntax\nis incomplete.\n. {blank}\n. Contribution 0672: *DSMCC: Need for additional IDL syntax*\n. {blank}\n. The submission is forwarded to the Ad Hoc group chartered to review\nthe efficiency of DSM-CC encodings.\n. {blank}\n. Contribution 0673: *DSMCC: Proposal to make Annex F (U-U Object\nCarousels) normative*\n. {blank}\n. Annex F is within the scope of DSM-CC.\n. A decision on the inclusion of Annex F in Section 7 as normative text\nhas been tabled to the March 1996 meeting pending further review.\n. The DSM-CC Download Subgroup solicits for review comments on Annex F.\n. {blank}\n. Contribution 0674: *DSMCC: Modifications to Download and U-U Object\nCarousels*\n. {blank}\n. The downloadLeakRate is seen as a description of a hardware\ncompatibility. As such, it should be moved into the User Compatibility\nstructure as a descriptor. This also allows the information to be part\nof the downloadInfoRequest message and not just the downloadInfoResponse\nas currently defined in the DIS. Supporting changes should be made in\nthe rest of Section 7, such as in Section 7.7.5.\n. Table 7-5 downloadLeakRate values should be changed to include slower\nleak rates, clarify the use of a value of 0. If the specific structure\nof the new descriptor defining leak rate is not defined, Table 7-5\nshould be removed.\n. A new field, min_block_spacing, is added to Table 15-2 Module location\nidentifiers. This field defines the minimum time between the last byte\nof a block and the first byte of the next block of a Module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Update to: *INFORMATIVE ANNEX F -- User-to-User Object Carousels*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n**(This annex do**es not form an integral part of this International\nStandard)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUser-to-User Object Carousels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Introduction*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe U-U Application Portability API provides Clients a standardized\nmechanism to access a collection of U-U assets (e.g. NameSpaces, Files,\nand Streams). For interactive networks, the U-U API is tightly coupled\nto the Client-Server interface for interoperability purposes. The use of\nthe U-U API is however not limited to interactive networks and may be\nused to access, for example, local objects and broadcasted objects. In\norder to do so, the Client has to implement a subset of the User-to-User\nfunctionality locally and has to access the Broadcast network for new\ndata when necessary. Figure 3-1 below illustrates this situation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure *3-1 Use of U-U API in the Broadcast Environment*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe main difference in using the U-U API in broadcast networks is that\nthe Client can not communicate with the Server that provides the\nobjects. This difference implies that the Server has to periodically\nbroadcast every object to facilitate access by Clients. Because\nbandwidth is generally limited in a broadcast network, Clients will\nexperience a non-negligible access-time to the objects. To limit the\naccess time for particular key-objects (such as Name Spaces), the Server\nmay choose to send these objects more frequently than others."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe periodic transmission of application data in a Data Carousel is\nstandardized in DSM-CC Download. In particular, it is specified how\nModules can be used to broadcast application data, how these Modules are\nfragmented into smaller Blocks, and how coherency problems due to Module\nupdates can be detected. However, to insure interoperability between\nClients and broadcast Servers, the carriage of the U-U objects in the\nModules and the transportation of the Modules in the Broadcast network\nhave to be standardized also."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis Appendix specifies a method for the carriage of U-U Objects in Data\nCarousels and the transportation of the Data Carousel in Broadcast\nnetworks based on MPEG-2 Transport Streams. Henceforth, the term U-U\nObject Carousels is used to indicate Data Carousels that contain U-U\nObjects. The following objectives were pursued in the design of this\nspecification:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* _Easy interaction with the U-U API_. Clients will offer applications\naccess to the broadcasted U-U objects via the U-U API. In order to limit\nthe complexity of the local U-U implementation, it is necessary that\nbroadcasted objects are similar to the data actually used by the\napplication. Section 2 elaborates further on this point.\n* {blank}\n* _Maximum coherency with OMG-UNO (IIOP)_. In Broadcast networks, one\nServer may serve many Clients with different architectures. Therefore, a\nrepresentation protocol is necessary that specifies how the U-U objects\nare carried on the wire. In Interactive networks, the Object data is\ntransported via the Internet Inter ORB Protocol (IIOP) on top of TCP/IP.\nIn IIOP, the bits-on-the-wire are defined by the Common Data\nRepresentation (CDR) to make an exchange of objects between ORB with\ndifferent architectures possible. In order to avoid having two different\nrepresentation protocols in hybrid Clients, U-U Object Carousels should\nalso make use of CDR.\n* {blank}\n* _Simplicity, generality and modularity_. The specification should be\nsimple to ensure a variety of independent, interoperable\nimplementations. The specification should be generic enough to\naccommodate a wide variety of U-U applications. For example, this\nimplies that small U-U objects can be broadcasted as efficiently as\nlarge U-U objects. In addition, the specification should be modular to\nease implementations and allow for future extensions.\n* {blank}\n* _Reliable and Client friendly transportation of Modules_. The\ntransmitted objects will be sensitive to transmission errors which may\noccur in Transport Streams. Hence, the transport mechanism for\napplication objects should include error detection. In addition, Clients\nshould be able to receive the Modules in which they are interested via\nan interrupt-based procedure with a low processing load.\n* {blank}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe proposed specification is consistent with the Object Request Broker\n(ORB) framework as defined by CORBA. Therefore, the specification is\nhenceforth called the Broadcast Inter-ORB Protocol (BIOP). BIOP employs\nthe Interoperable Object Reference (IOR) data structure to provide a\nunique reference to the Object in the Broadcast network. For this\npurpose, it has defined an own Protocol Profile Body. The BIOP\nspecification is described in Section 3 and consists of three elements:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. _Broadcast IOP Profile Body definition._ The definition of the BIOP\nProfile Body. The Profile Body uniquely references a U-U Object in the\nBroadcast network.\n. _Broadcast IOP Message Formats_. BIOP consists of four messages which\nshare a common message structure. These messages are described using OMG\nIDL and are converted to bits-on-the-wire by means of the Common Data\nRepresentation (CDR) as specified by UNO. BIOP messages convey a.o. the\nU-U objects.\n. _Broadcast IOP Message Transport._ BIOP messages are conveyed in\nModules of the Data Carousel. A Module may convey multiple BIOP\nmessages. The Modules are fragmented into Blocks (as defined by DSM-CC\nDownload) and are conveyed in DSMCC_sections. BIOP specifies a number of\nspecific requirements for these mappings."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Editor\u2019s note: By the above definition, BIOP adopts CDR as the rule for\nthe bits-on-the-wire encoding scheme. A provision for alternative\nrepresentations makes the use of BIOP more generic and should be made\npossible. The topic is under current investigation._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Concepts for U-U Object Carousels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== U-U Objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe U-U API is based on a number of interfaces which U-U Objects may\ninherit. Within the U-U Object Carousel, three Objects are defined that\nsupport the following READER interfaces: namely"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable *3-1 Objects supported within the U-U Object Carousel*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"27%,73%\",]\n|===\n|Object |Supported READER Interfaces\n|Name Space |Base,Access, Directory, Service\n|File |Base,Access, File\n|Stream |Base,Access, Stream, Event\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Name Space object allows Clients to list the objects within the Name\nSpace and to resolve the names of the objects into unique references.\nNames can be resolved into pointers to other Name Space objects, File\nobjects, and Stream objects. In order to support the quick browsing\nthrough the contents of the Name Space, the Name Space Object contains\nalso the access attributes of the listed objects. Finally, the Name\nSpace objects includes also an optional service context in order to\nsupport the Service interface."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe File object conveys data from the File object."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Stream object is used to point to a stream somewhere in the\nBroadcast network. The referenced stream can be either an MPEG-2 program\nor an elementary stream. The stream object conveys the U-U Stream Info\nattributes and an optional list of Stream Events to which Clients may\n(locally) subscribe."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Object Locations"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nObjects are conveyed in Modules and are unique referenced by the tuple\n(CarouselId, ModuleId, ObjKey). The CarouselId uniquely identifies the\nData Carousel within the Broadcast network. The ModuleId identifies the\nModule in which the object is conveyed within the Data Carousel. The\nObjKey provides an unique reference within one Module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe locations of the Modules that are referenced within Name Space\nobjects are conveyed in Module Info and Location Tables (MILT). MILT\ntables are treated like objects and are also conveyed in Modules.\nBesides the locations of Modules, MILT tables contain also the size,\nversion, and download time-out values for each of the referenced\nModules. These parameters are necessary for Clients to perform memory\nallocation in advance, detect Module coherency problems, and time-out\nthe reception of Modules, respectively. The location and contents of the\nMILT messages are constrained. In particular, MILT messages should be\nconveyed in the same Modules in which their referencing Name Space\nmessages are conveyed. In addition, the contents of the MILT messages\nshould at least contain the referenced Modules."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MILT tables allow for a flexible referencing in Broadcast networks.\nIn particular, to indicate the position of one particular Module, a\nnetworkId, a transportStreamId, a programId, a correlationId and a\ntable_id_extension field may be used. The use of the programId and\ncorrelationId identifiers allows for a transparent multiplexing (and\nre-multiplexing) of the Transport Stream by avoiding 'hard-coded' PID\nvalues."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Service Gateway"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIt is only possible to resolve a name within a certain naming context.\nThe U-U API solves this problem by introducing the concept of a Service\nGateway. This entity provides the root of the name spaces of all\nservices under that Service Gateway. With U-U Object Carousels, the root\nof the name spaces will be contained in a Module, say Module X. Service\nGateway functionality with U-U Object Carousels is provided by either a\nDownloadInfoResponse() message (as described in Section 7.8.3) or by a\nService Gateway Descriptor (described in Section 3.3.3.3). The\nDownloadInfoResponse() message provides the identifier of the module,\ni.e. X, conveying the root NameSpace in the carousel. If the U-U Object\nCarousel is encapsulated in MPEG2 Transport Stream, an alternative way\nto provide Service Gateway Information is to use the Service Gateway\nDescriptor in the PSI/SI information. Beside the reference to the root\nof the Name Space, the Service Gateway provides also the CarouselId of\nthe U-U Object Carousel, as well as the blockSize of the Module Blocks."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nConsequently, the functionality of the U-U attach primitive consists of\nfinding the Service Gateway at a well-known place(s), and retrieve\nsubsequently the Module of the U-U Object Carousel with root name space\nof that service gateway."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Broadcast Inter ORB Protocol (BIOP)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Profile Body"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe BIOP Profile Body facilitates the construction of an unique\nreference to an U-U Object within a Broadcast Network. The ProfileBody\ncontains 3 identifiers, namely CarouselId, ModuleId, ObjKey. The BIOP\nProfileBody is described below."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module BIOP \\{*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct Version \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchar major;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchar minor;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct ProfileBody \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVersion biop_version;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunsigned short carousel_id"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunsigned short module_id;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunsigned long object_key;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbiop_version - The biop_version describes the version of BIOP. The major\nversion of this specification is 1; the minor version is 0."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*carousel_id* - The CarouselId unique identifies the Carousel within the\nBroadcast network."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module_id* - The ModuleId identifies the Module in which the object is\nconveyed within the Carousel."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*object_key* - The ObjKey is an opaque value supplied by the Server."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Message Set Definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBIOP consists of four messages which share a common BIOP message header.\nThe four BIOP messages are:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. _a NameSpace message_. The NameSpace message is used to convey a U-U\nObject of the type NameSpace. It contains references to other NameSpace,\nFile and Stream Objects as well as an optional service context.\n. _a File message._ The File message is used to convey a U-U Object of\nthe type File. It just contains file data.\n. _a Stream message._ The Stream message is used to convey a U-U Object\nof the type Stream. It contains a reference to the referenced stream as\nwell as an optional list of events.\n. _a MILT message_. The MILT message contains a MILT table. The MILT\ntable lists the locations of referenced Modules within the Broadcast\nnetwork as well as the size, version, and download time-out value of\neach of the referenced Modules."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Message Header*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe BIOP message header is described below. The message header resembles\nthe message header of the IIOP messages closely:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*magic* - identifies the BIOP message. The value is always \"BIOP\"."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*biop_version* - contains the version number of the BIOP protocol"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*byte_order* - indicates the byte ordering used for the following\nfields."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*message_type* - indicates the type of the message. The following table\ntabulates the allowed values for BIOP."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable *3-2 Message type values*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"56%,44%\",]\n|===\n|message_type |type of message\n|0x00 |NameSpace\n|0x01 |File\n|0x02 |Stream\n|0x03 |MILT\n|0x04-0x0F |13818-6 Reserved\n|0x10-0xFF |User Private\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmessage_size - contains the length of the messages following the message\nheader in octets. This count includes alignment gaps."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*object_key* - The ObjKey is an opaque value supplied by the Server.\nClients use this field to locate the carried object."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module BIOP \\{*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct MessageHeader\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchar magic[4];"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVersion biop_version;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nboolean byte_order;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noctet message_type;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunsigned long message_size;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunsigned long object_key;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *BIOP NameSpace Message Body Definition*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe BIOP NameSpace message consists of the common BIOP Message Header\nand the BIOP NameSpace Message Body. The latter is described below. The\nNameSpace message body uses similar data structures as defined by the\nCosNaming Module (Name, BindingType)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe body of the NameSpace message consists basically of a loop of\n'Extended Bindings'. An extended binding links an Object name to a\nparticular IOR (with the BIOP Profile body) and provides additional\ninformation about the Object (User private). An extended binding\ncontains the following fields:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*binding_name* - path of object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*binding_type* - type of object binding (as defined by CosNaming)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*object_ior* - the IOR of the object. The IOR may include the BIOP\nprofile body. In that case, the MILT object that is pointed to by the\nmilt_key field provides the location information about the Module in\nwhich the object is contained. When the object is conveyed in the same\nModule as the Name Space, the milt_key may be omitted (set to zero)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*milt_key* - the ObjKey of MILT object that contains location\ninformation of the Module in which the object pointed to by object_ior\nis contained. The MILT object is contained in the same Module as the\nNameSpace object."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*size* - Size of the Object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*object_info* - User private information about the object. This field\nmay contain information about the history, locks, and permissions of the\nobject. These values could be used in the Hist_T, Lock_T, and Perms_T\nstructures used by U-U API. If this information is not carried in the\nobject_info field the Hist_T, Lock_T, and Perms_T structures shall\ndefault to the following values:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nHist_T: Version and DateTime shall have entries all equal to 0."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nLock_T: readLock shall be 1 and writeLock shall be 0."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nPerms_T: all permission fields shall indicate Read-Only permission; the\naPassword string shall be NULL;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nthe rAuthData opaque shall be empty; allSecure shall be zero."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe body of the NameSpace message consists then of the following two\nfields:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*service_context* - used to transfer service-specific information with\nthis NameSpace."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*binding_list* - the list of extended bindings."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Module BIOP \\{*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef unsigned long ServiceID;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct ServiceContext \\{ ServiceID context_id; sequence<octet>\ncontext_data;};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef sequence <ServiceContext> ServiceContextList;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef string Istring;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct NameComponent \\{Istring id;Istring kind;}; // CosNaming"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef sequence<NameComponent> Name;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nenum BindingType \\{nobject, ncontext };"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct ExtendedBinding \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nName binding_name;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBindingType binding_type;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIOR object_ior;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunsigned long milt_key;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\numsigned long size; // object size in octets;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsequence <octet> object_info; // User Private Info about object"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef sequence <ExtendedBinding> ExtendedBindingList;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct NameSpaceMessageBody\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nServiceContextList service_context"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nExtendedBindingList binding_list;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== BIOP MILT Message Body Definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe BIOP MILT message consists of the common BIOP Message Header and the\nBIOP MILT Message Body. The MILT Message conveys a MILT table that\nprovides information about the location and characteristics of\nreferenced Modules within the Broadcast network. The MILT message should\nbe conveyed in the same Module as the NameSpace messages that are\nreferencing the MILT object. The MILT message body consist of two\nfields, namely:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*carousel_id -* This field indicates the carousel to which the modules\nbelong that are described in this message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module_list -* This field contains a list of module descriptions. Each\nmodule is described with the following fields:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module_id -* the identifier of the Module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module_size -* the size of the Module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module_version -* the version of the Module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module_location -* the location of the Module. This field is actually a\nconcatenation of location identifiers that are relevant in Broadcast\nTransport Streams. Each identifier has an associated value field of\nwhich the type is dependent of the identifier. The identifiers and the\ntypes of the associated value fields are described below :"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable *3-3 Module location identifiers*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"24%,19%,14%,43%\",]\n|===\n|Identifier |Type of location_value field |location_id |Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|network_id |u_long |0x00 |An unique identifier of the network"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|transport_stream_id |u_short |0x01 |An unique identifier of the\ntransport stream within the network"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|program_id |u_short |0x02 |An unique identifier of the program within\nthe network"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|correlation_id |octet |0x03 |A correlation tag to identify an\nelementary stream within a PMT"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|table_id_extension |u_short |0x04 |An unique identifier of\ntable_section's within a section stream"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|time_out_value |u_long |0x05 |The value of the time-out period of the\nModule."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|block_time_out |u_long |0x06 |The value of the time-out period for\npresentation of the next module block once a block has been acquired."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|min_block_spacing |u_long |0x07 |The minimum time between the last byte\nof a block and the first byte of the next block of the same Module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |any |0x08-0x0F |ISO/IEC 13818-6 Reserved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |any |0x10-0xFE |User Private"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |0xFF |Forbidden\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe concatenation of several LocationIdentifiers into a\nTransportStreamLocation value facilitates the exact localization of a\nModule within a Broadcast network. Note that not all identifiers have to\nbe used to make an exact reference. For example, when the reference is\nin the same network and transport stream as specified in the Service\nGateway Description, these fields may be omitted. In general, not\nspecified fields are inherited of the Service Gateway Description. The\nTransportStreamLocation string is capable of referencing multiple\nlocations of the object in one single reference. This property is useful\nwhen a particular Module is transmitted at multiple locations in the\nBroadcast network. Such a multiple referencing mechanism is done by\nrepeating various identifiers. Repeated identifiers inherit all the\nidentifiers before and after the identifier except for the ones of the\nsame type. The use of the program_id and correlation_id identifiers\nallows for the transparent multiplexing (and re-multiplexing) of the\nTransport Stream."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe time_out_value, block_time_out, and min_block_spacing identifiers\ncan be used by the Server to inform Clients about the delivery schedule\nof a particular module. Clients may use these identifiers to adjust\ntheir acquisition procedures for optimization purposes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe time_out_value identifier and the table_id_extension identifier are\nmandatory in the module_location string."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module BIOP \\{*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct LocationIdentifier\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nu_char location_id;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nany location_value;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef sequence<LocationIdentifier> TransportStreamLocation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct ModuleDescription\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nu_short module_id;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nu_long module_size"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\noctet module_version"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTransportStreamLocation module_location"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypdef sequence< ModuleDescription> ModuleDescriptionList"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct MiltMessageBody\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nu_short carousel_id;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nModuleDescriptionList module_list;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *BIOP File Message Body Definition*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe BIOP File message consists of the common BIOP Message Header and the\nBIOP File Message Body. The latter is described below."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*object_data* - The actual file data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module BIOP \\{*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct FileMessageBody\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsequence <octet> ObjectData;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *BIOP Stream Message Body Definition*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe BIOP Stream message consists of the common BIOP Message Header and\nthe BIOP Stream Message Body. The Stream Message is used to point to a\nstream somewhere else in the Broadcast network. The referenced stream\ncan be either an MPEG-2 program or an elementary stream. It contains the\nInfo attributes of the stream and an optional list of associated events.\nThe Stream Message Body is described below."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*info* - the stream attributes as defined for U-U Streams."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*event_list -* a list of string events and their associated tokens."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*stream_location* - The reference to the stream in the Transport Stream.\nThe stream_location field has the same syntax as the module_location\nstring in the MILT message. However, the time_out_value, block_time_out,\nand min_block_spacing identifiers and the table_id_extension identifier\nmay not occur in the stream_location string. If the referenced stream is\nan MPEG-2 program the correlation_id may also not occur in the\nstream_location field. If the referenced stream is an elementary stream\nthe correlation_id identifier should be present in the stream_location\nfield."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module BIOP \\{*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct Info_T \\{string aDescription;NPT duration;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nboolean audio;boolean video;boolean data;};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct EventDescription \\{string EventName; u_short aEventToken;};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct StreamMessageBody\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInfo_T info;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nsequence <EventDescription> event_list;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTransportStreamLocation stream_location;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *BIOP Message Transport*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Message encapsulations"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBIOP messages are transported in Modules of a DSM-CC Data Carousel.\nMultiple BIOP messages may be carried in one Module. The start of a BIOP\nmessage coincide with the start of the Module. When a Module contains a\nNameSpace message that references a MILT object then the MILT message\nwith the referenced MILT Table should also be contained in the Module."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Modules of the Data Carousel are fragmented into Blocks. These\nBlocks are transported in DownloadDataBlock messages which are conveyed\nin DSMCC_sections (as defined in the Transport Chapter of DSM-CC). One\nDSMCC_section conveys one DownloadDataBlock message. The downloadId\nfield of the dsmccDownloadDataHeader has the same value of the\ncarouselId of the U-U Object Carousel."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Correlation_id Descriptor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWhen a TransportStreamLocation string contains the correlation_id field,\nthe PMT of the program to which the referenced stream belongs should\ncontain the following descriptor in the description of the referenced\nstream:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable *3-4 Correlation_tag_descriptor*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"62%,19%,19%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|Correlation_tag_Descriptor() \\{ | |\n|descriptor_tag |8 |uimsbf\n|descriptor_length |8 |uimsbf\n|correlation_id |8 |uimsbf\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*descriptor_tag*-- this 8-bit field has the value 0x52."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*descriptor_length* -- this is an 8-bit field has the value 0x01."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*correlation_id --* this 8-bit field identifies the elementary_stream in\na PMT for associating it with a description given in a\nTransportStreamLocation string."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== The Service Gateway Descriptor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nService Gateways are considered to be (part of) MPEG-2 programs. The\nPSI/SI of the program contains a Service Gateway Descriptor. The Service\nGateway descriptor contains the following fields:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable *3-5 Service Gateway Descriptor*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"62%,19%,19%\",]\n|===\n|Syntax |No. of bits |Mnemonic\n|Service_Gateway_Descriptor() \\{ | |\n|descriptor_tag |8 |uimsbf\n|descriptor_length |8 |uimsbf\n|service_gateway_name_length |8 |uimsbf\n|for (i=0;i<N;i++) \\{ | |\n|name_byte |8 |bslbf\n|} | |\n|carousel_id |16 |uimsbf\n|blocksize |16 |uimsbf\n|module_id |16 |uimsbf\n|object_key |8 |uimsbf\n|correlation_id |32 |uimsbf\n|table_id_extension |16 |uimsbf\n|network_id |32 |uimsbf\n|transport_stream_id |16 |uimsbf\n|private_data_length |8 |uimsbf\n|for (i=0;i< private_data_length;i++) \\{ | |\n|private_data_byte |8 |bslbf\n|} | |\n|} | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*descriptor_tag*-- this 8-bit field has the value 0xFB."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*descriptor_length* -- this is an 8-bit field has the value 0x01."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*service_gateway_name_length* --this 8-bit field specifies the number of\nbytes that follow the service_gateway_name_length field for describing\ncharacters of the name of the service gateway."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*name_byte* -- this is an 8-bit field. The string of name bytes specify\nthe name of the Service Gateway."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*carousel_id* -- this field contains the unique identifier of the\ncarousel"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*blocksize --* this field contains the blocksize of the Blocks that are\npart of this carousel."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*module_id* -- this field contains the unique identifier of the Module\nthat contains the top-level NameSpace"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*object_key* -- this field contains the object key of the top-level\nNameSpace within the described Module"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*correlation_id* -- this field contains the correlation_id of the\nelementary stream that is used to transmit the Module that conveys the\ntop-level NameSpace."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*table_id_extension* -- this field contains the table_id_extension field\nof the DSMCC_sections that are used to transport the Module that\ncontains the top-level NameSpace."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*network_id* -- this field contains the unique identifier of the\nnetwork. This is the default networkId."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*transportstream _id* -- this field contains the unique identifier of\nthe transport_stream. This is the default transportStreamId."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*private_data_length* --this 8-bit field specifies the number of private\ndata bytes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*private_data_byte* -- private data bytes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Extension to general objects"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe above described method for conveying objects to the client can be\nextended to cover other objects such as an object that inherits from\nFile but adds additional exported attributes. This can be achieved by\nusing the following general rule for definition of the object value\nnamely to lay out a structure in the order of the IDL definition, i.e."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<ObjData> ::= \"struct\" <type_spec> \"\\{\" <included_objects> \"}\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<included_objects> ::= <incl_object>+"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<incl_object> ::= \"DSM_TypeCode aType; \" <exported_attributes> \"opaque\noctets;\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<exported_attributes> ::= <exp_attribute>+"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<exp_attribute> ::= <type_spec> <declarators> \";\""
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n<type_spec> is defined in CORBA Grammar."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe TypeCode is the structure returned by Interfaces define() or\nInterfaces show(). The resulting object will be a struct with TypeCode\nfollowed by exported attributes followed by opaque data, in the order of\n1st) included interfaces and 2nd) the top interface.."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Update to : INFORMATIVE ANNEX G - AssociationTag"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *16.1 Use of the Association Tag*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*The association tag is used to indicate a horizontal association and\nalso identify the descriptor ties. Figure 16-1 provides an example of an\nSVC connection resourceNum=1 and associationTag=1 at the Server which is\nmapped into a non-ATM HFC Client access. In this illustration the\nnon-ATM access consists of an MPEG TS in the downstream direction and\nTDMA in the upstream direction. The associationTag 50 provides the\ndescriptor tie between the MPEG TS and the MPEG Program descriptor and\nis not visible to the ServiceGateway interface or the User-to-User\nLibrary. The associationTag=1 is however visible to both interfaces and\nis maintained constant across the end-to-end connection.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *16.2 Use of the SharedResource Descriptor*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe sharedResourceDescriptor is used when a number of resources are\nrequired to ride on a common resource. In figure 16-2, an\nAtmSvcConnection resourceNum=1 is shared by an RPC IP upstream\nresourceNum=12 as well as by an DownloadControl IP upstream\nresourceNum=14. This occurs in cases where a single VC is assigned to\nboth MPEG, RPC and DownloadControl as shown in later examples in section\n16.4. The SharedResource Descriptors resourceNum=13 and 15 provide the\nlinkage to the shared resourceNum=1 as shown in figure 16-2 and 16-3\n(left)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure 16-1 Use of the associationTag to indicate horizontal\nassociation of different resources in the same end-to-end connection and\nstack nesting*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure 16-2 Use of SharedResource Descriptor*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 16.3 Use of the SharedRequestId Descriptor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe sharedRequestId Descriptor is used in place of the sharedResource\nDescriptor in case the assignment of the resource numbers is in the\nnetwork as opposed to the originator of the request for the resource. In\nthis case the as shown in figure 16-3 the same approach as in section\n16.2 is followed except instead of the sharedResourceNum a\nsharedResourceRequestId is used to refer back to the resourceRequestId\nas opposed to the resourceNum."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure 16-3 Use of SharedRequestId Descriptor*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== 16.4 Common Examples of Use of the associationTag, the SharedResource Descriptor and the SharedRequestId Descriptor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following examples provide different realistic scenarios for\nconnections indicating how both the Association Tags and the Shared\nResource descriptors are used:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Download Phase, Multiple ATM SVCs\n* Video Play Phase, Multiple ATM SVCs\n* Single Asymmetric ATM SVC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1- Download Phase, Multiple ATM SVCs*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis example uses separate ATM SVCs in order to carry the flows\nidentified below:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[loweralpha]\n. Download Data downstream\n. Download Data Response upstream\n. Download Control downstream\n. Download Control upstream\n. RPC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTwo scenarios are considered:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[upperroman]\n. End-to-End ATMIn this case the ATM SVC is maintained intact between\nthe Server and the Client\n. Core ATM network and non-ATM HFC Client accessIn this case the flows\nbeing carried on the ATM SVC are mapped to non-ATM resources through the\nnon-ATM resource descriptors."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1-A End-to-End ATM*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe top diagram in Figure 16-4 provides the list of resource descriptors\ncommunicated from the Server to the Network and the Network to the\nClient. Since it is end-to-end ATM the resource numbers and the\nassociation tags are unchanged."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the bottom diagram in Figure 16-4, the flows corresponding to\nDownloadControl, DownloadData and RPC are carried on separate ATM SVCs,\nRN 1, 2 and 3 respectively and use the respective ATs 1, 2 and 3. The\nbindings to the interfaces are done using the ATs. Through the bindings,\nthe information format at the interfaces is expected to be in IP format."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 16-4 End-to-End ATM, Download Phase, Multiple ATM SVCs Server and\nClient Views"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*1-B Non-ATM HFC Client View*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe top diagram in Figure 16-5 provides the list of resource descriptors\ncommunicated from the Server to the Network and the Network to the\nClient. Since the ATM terminates in the Network, new resources between\nthe Network and the Client are used over the non-ATM HFC. The flows on\nthe ATM SVC are mapped into those new non-ATM HFC resources. Although\nthe resource numbers for each flow on the Client side are different, the\nassociation tags are kept the same."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach of the DownloadControl, DownloadData and RPC consists of 2-way\nflows. The downstream flows are carried on the MPEG TS and the upstream\nflows are carried on TDMA. The bindings to the corresponding interfaces\nare done using the ATs. Through the bindings, the information format at\nthe interfaces is expected to be in IP format."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSince the MPEG TS is carried over TsDownstreamBandwidth, RN 20, the SRM\nassigns an AT 50 to associate it with the MpegProgram RN 30. The\nAssociation Tag in this instance is used to identify a stack and does\nnot appear in interface bindings at the User-to-User level."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 16-5 Non-ATM HFC Client View Corresponding to Download Phase,\nMultiple ATM SVCs Server and Client Views"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n2- Video Play Phase, Multiple ATM SVCs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis example uses separate ATM SVCs in order to carry the flows\nidentified below:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}a) MPEG Audio/Video/Data downstream"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}b) RPC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTwo scenarios are considered:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[upperroman]\n. End-to-End ATMIn this case the ATM SVC is maintained intact between\nthe Server and the Client\n. Core ATM network and non-ATM HFC Client accessIn this case the flows\nbeing carried on the ATM SVC are mapped to non-ATM resources through the\nnon-ATM resource descriptors."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2-A End-to-End ATM*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe top diagram in Figure 16-6 provides the list of resource descriptors\ncommunicated from the Server to the Network and the Network to the\nClient. Since it is end-to-end ATM the resource numbers and the\nassociation tags are unchanged."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the bottom diagram in Figure 16-6, the flows corresponding to MPEG\nAudio/Video/Data downstream and RPC are carried on separate ATM SVCs, RN\n1 and 3 respectively and use the respective ATs 1 and 3. The AT 4\nidentifies a stack and is not used in the bindings. The bindings to the\ncorresponding interfaces are done using the ATs 10. 11. 6 and 3. Through\nthe AT 3 binding the information format at the interface is expected to\nbe in IP format."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 16-6 End-to-End ATM, Video Play Phase, Multiple ATM SVCs Server\nand Client Views"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2-B Non-ATM HFC Client View*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe top diagram in Figure 16-7 provides the list of resource descriptors\ncommunicated from the Server to the Network and the Network to the\nClient. Since the ATM terminates in the Network, new resources between\nthe Network and the Client are used over the non-ATM HFC. The flows on\nthe ATM SVC are mapped into those new non-ATM HFC resources. Although\nthe resource numbers for each flow on the Client side are different, the\nassociation tags are kept the same."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn the bottom diagram of Figure 16-7, the MPEG Audio/Video/StreamEvent\nconsist of only downstream flows, the RPC consists of 2-way flows. Both\nMPEG Audio/Video/StreamEvent and RPC downstream flows are carried on the\nMPEG TS and the RPC upstream flow is carried on TDMA. The bindings to\nthe corresponding interfaces are done using the ATs."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSince the MPEG TS is carried over TsDownstreamBandwidth, RN 20, the SRM\nassigns an AT 50 to associate it with the MpegProgram RN 11. The\nAssociation Tag in this instance is used to identify a stack and does\nnot appear in interface bindings at the User-to-User level."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure 16-7 Non-ATM HFC Client View Corresponding to Video Play Phase,\nMultiple ATM SVCs Server View"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n3- Single Asymmetric ATM SVC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis example uses a single asymmetric ATM SVC in order to carry the\nflows identified below:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[loweralpha]\n. MPEG Audio/Video/Data downstream\n. RPC over TCP/IP downstream flow over private data on MPEG TS\n. RPC over TCP/IP upstream flow over ATM\n. Download Control and Data downstream flow in UDP/IP over private data\non MPEG TS\n. Download Control and Data Response upstream flow over ATM"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTwo scenarios are considered:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[upperroman]\n. End-to-End ATMIn this case the ATM SVC is maintained intact between\nthe Server and the Client\n. Core ATM network and non-ATM HFC Client accessIn this case the flows\nbeing carried on the ATM SVC are mapped to non-ATM resources through the\nnon-ATM resource descriptors."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3-A End-to-End ATM*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe top diagram in Figure 16-8 provides the list of resource descriptors\ncommunicated from the Server to the Network and the Network to the\nClient. Since it is end-to-end ATM the resource numbers and the\nassociation tags are unchanged."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe bottom diagram in Figure 16-8 shows how the SharedResource\ndescriptor is used to share the AtmSvcConnection between the MpegProgram\nand Ip descriptors."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MPEG Transport Stream Resource number, RN 10, through\nSharedResource, RN 11 shares the AtmSvcConnection, RN 1 with the other\nIP connections. The link between the MPEG TS and the SharedResource is\nmaintained through the Association Tag, AT 1. The Audio, the Video and\nthe StreamEvent carried in PIDs 100, 101 and 102 respectively are\nassigned the ATs 10, 11 and 6 respectively."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSince the RPC consists of 2-way flows, the downstream is carried on the\nMPEG TS, PID 204 and the upstream is carried on the IP connection RN 12.\nAT 2, links the two directions to the same interface. The\nSharedResource, RN 13 also is tagged at AT 2. Similarly the PID, RN 14\nand RN 15 for Download are tagged at AT 3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure 16-8 End-to-End ATM, Single Asymmetric ATM SVC Server and Client\nViews*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3-B Non-ATM HFC Client View*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe top diagram in Figure 16-9 provides the list of resource descriptors\ncommunicated from the Server to the Network and the Network to the\nClient. Since the ATM terminates in the Network, new resources between\nthe Network and the Client are used over the non-ATM HFC. The flows on\nthe ATM SVC are mapped into those new non-ATM HFC resources. Although\nthe resource numbers for each flow on the Client side are different, the\nassociation tags are kept the same."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe bottom diagram in Figure 16-9 shows how the SharedResource\ndescriptor is used to share the ClientTdmaAssignment between the Ip\ndescriptors used to carry the DownloadControl/Data and the RPC flows.\nSince the TsDownstreamBandwidth only carries the MPEG TS then both\ndescriptors share the same AT 1."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe MPEG Transport Stream Resource number, RN 30 carries the Audio, the\nVideo and the StreamEvent in PIDs 100, 101 and 102 respectively,\nassigned the respective Association Tag numbers 10, 11 and 6."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSince the RPC consists of 2-way flows, the downstream is carried on the\nMPEG TS, PID 204 and the upstream is carried on the IP connection RN 12.\nThe Association Tag, AT 2, links the two directions to the same\ninterface. The SharedResource, RN 31 also share the AT 2. Similarly the\nPID, RN 14 and RN 32 for Download are share the AT 3."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure 16-9 Non-ATM HFC Client View Corresponding to Single Asymmetric\nATM SVC Server Views*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4- Single Asymmetric ATM PVC*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe example with PVC is similar to the example in 1 \u00d2Single Asymmetric\nATM SVC\u00d3 except AtmSvcConnection is replaced by AtmConnection and SVC is\nreplaced by PVC in the text."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*5- Download Phase, Multiple ATM PVCs*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe example with PVC is similar to the example in 2 \u00d2End-to-End ATM,\nDownload Phase, Multiple ATM SVCs\u00d3 except AtmSvcConnection is replaced\nby AtmConnection and SVC is replaced by PVC in the text."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6- Video Play Phase, Multiple ATM PVCs*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe example with PVC is similar to the example in 3 \u00d2End-to-End ATM,\nVideo Play Phase, Multiple ATM SVCs\u00d3 except AtmSvcConnection is replaced\nby AtmConnection and SVC is replaced by PVC in the text."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*7- Use of sharedResourceRequest Descriptors*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn examples 1 through 6 above the resource numbers are assigned by the\noriginator of the request. If the resource numbers are assigned by the\nNetwork, then the sharedResourceRequest Descriptor replaces the\nSharedResource Descriptor at every instance of its occurrence in\nexamples 1 through 6 and correspondingly the sharedResourceNum is\nreplaced by sharedResourceRequestId. In the request message, from the\noriginator to the Network, the ResourceNums are filled with \u00d20\u00d3s. In the\nconfirm message from the Network to the originator, the ResourceNums\ntake their actual values assigned by the Network.."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== User to User Erata"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following changes to the the DIS represent the concensus of the MPEG\nDSM-CC group from discussions at the above meeting."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Section 5.2.3 Application and Service Interfaces_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_under_ Extended Interfaces"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_remove_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSessionGateway Interface _(summary)_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nService Interface _summary_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunder Extended Operation Set _(table)_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nremove"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSessionGateway addResource"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSessionGateway modResource"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSessionGateway deleteResource"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nService launch"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nService unlaunch"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Section 5.3.3 The Object Reference_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_after_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst ProfileId TAG_DSM_ONC = 0x49534F01;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_add_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnote: struct DSM_ONC_ProfileBody is defined at 12.5.1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst ProfileId TAG_DSM_BIOP = 0x49534F02;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnote: struct BIOP_ProfileBody is defined at 15.3.1"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Section 5.3.4.1.1 ClientSessionSetupRequest_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_replace paragraph_ \u201cA path specification identifying a path to the\ndesired service...\u201d _with_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cA path specification identifying a path to the desired service, placed\nin the *rPathSpec* parameter. If it is zero-length, the serverId of the\nof the ClientSessionSetupRequest shall be associated with a default\nServiceGateway to be resolved. If the first node is a ServiceGateway\nkind, it shall identify a ServiceGateway to be resolved. Following\neither an implied or specified ServiceGateway, a second node may\nidentify the desired initial Service.\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Section 5.4.3 Exceptions_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunder \u201cThe following common user exceptions are defined by DSM:\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_replace_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define ExceptUser \\{u_long minor; CompletionStatus aCompleted;}"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define ExceptAuth ..."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_with_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nexception ExStruct ex_body;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define ExceptAuth \\{u_long minor; completion_status completed; opaque\nauthData};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_note: to be determined: compile the above to assure one structure\ndefinition results for all ExceptUser exceptions._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Section 5.5.1.2 DSM Base close_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nunder semantics,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nremove paragraphs starting with"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cA Service launch() from ...\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nand"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cA ServiceGateway suspend()\u201d will ...\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nto an informative section."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_1.5.3 Directory_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nremove the last sentence reference to Service launch() to an informative\nsection."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_1.5.3.l3 Directory open_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nremove the following sentence and to an informative section."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n\u201cNeither is a substitute for *Service launch()*.\u201d"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Section 5.5.6.5 DSM ServiceGateway detach_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmake informative the descriptions of unlaunch()."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_5.6.1 SessionGateway_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmake this section informative."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_5.6.2 Service_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmake this section informative."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_5.6.3.1 Interfaces Definitions, Exceptions_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nadd two new exception types:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TCKind tk_BLOCK_SIZE 0x49535046;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TCKind tk_TIMEOUT 0x49535047;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nadd system exception kinds:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// DSM-CC SYSTEM_EXCEPTION TCKind values"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// They are defined because DSM-CC Exception is a CORBA_any"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// CORBA_any TypeCode member identifies the exception structure"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// Therefore these are needed for DSM-CC SYSTEM exceptions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_UNKNOWN = 0x49535080; /*the unknown exception*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_BAD_PARAM = 0x49535081; /* an invalid parameter was passed\n*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_NO_MEMORY = 0x49535082; /* dynamic memory allocation\nfailure */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_IMP_LIMIT = 0x49535083; /* violated implementation limit */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_COMM_FAILURE = 0x49535084; /* communication failure */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_INV_OBJREF = 0x49535085; /* invalid object reference */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_NO_PERMISSION = 0x49535086; /* no permission for attempted\nop */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_INTERNAL = 0x49535087; /* ORB internal error */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_MARSHALL = 0x49535088; /* error marshalling param/result */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_INITIALIZE = 0x49535089; /*ORB initialization failure */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_NO_IMPLEMENT = 0x4953508A; /* operation implementation\nunavailable */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_BAD_TYPECODE = 0x4953508B; /* bad typecode */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_BAD_OPERATION = 0x4953508C; /* invalid operation */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_NO_RESOURCES = 0x4953508D; /* insufficient resources for\nrequest */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_PERSIST_STORE = 0x4953508E; /* persistent storage failure\n*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_BAD_INV_ORDER = 0x4953508F; /* routine invocations out of\norder */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_TRANSIENT = 0x49535090; /* transient failure - reissue\nrequest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_FREE_MEM = 0x49535091; /* cannot free memory */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_INV_IDENT = 0x49535092; /* invalid identifier syntax */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_INV_FLAG = 0x49535093; /* invalid flag was specified */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_INTF_REPOS = 0x49535094; /*error accessing interface\nrepository */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_BAD_CONTEXT = 0x49535095; /*error processing context object\n*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_OBJ_ADAPTER = 0x49535096; /* failure detected by object\nadapter */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst DSM_tk_DATA_CONVERSION = 0x49535097; /*data conversion error */"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Section 5.6.8.1 Interfaces Definitions, Exceptions_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmake Download messages request and reply structures opaque by"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nremoving following IDL structs"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDataHeader"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInfoRequest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nModuleInfo"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nModuleInfoList"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInfoResponse"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDataResponse"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCancelRequest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInstead of the above sturctures, the definitions of Chapter 6 and 7 will\nbe used in the operaton arguments of the interactive RPC Download."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Section 5.6.8.3 DSM Download info_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchange argument types qand exceptions returned by Download info() and\nDownload infoSI()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid info(out opaque moduleInfoList);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRAISES(BAD_COMPAT_INFO, BLOCK_SIZE, BUF_TOO_SMALL);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNote that moduleInfoList contains structure defined in Chapter 7\nDownload. The structure is unnamed but is part of DownloadInfoResponse.\nIt is embodied in the following structs, which are not representable in\nCORBA IDL."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct DownloadModuleInfo \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDSM_u_short moduleId;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCORBA_octet moduleVersion;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCORBA_octet moduleInfoLength;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDSM_u_long moduleSize;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCORBA_octet * moduleInfoBytes;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct DownloadModuleInfoList\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCORBA_octet numberOfModules;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDownloadModuleInfo *modulesInfo;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid infoSI(in opaque reqNegotiation, out opaque respNegotiation);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nRAISES(BAD_COMPAT_INFO, BLOCK_SIZE, BUF_TOO_SMALL);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe opaque data of reqNegotiation is defined by the structure\nDownloadInfoRequest in Chapter 7. The opaque data of respNegotiation is\ndefined by the structure DownloadInfoResponse in Chapter 7."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_Section 5.6.8.5 DSM Download start_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchange argument types and exceptions returned by of Download cancel()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid continue(in opaque ackNack)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nraises(BAD_MODULE_ID, MPEG_DELIVERY, TIMEOUT);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe opaque data of ackNack is defined in the structure\nDownloadDataResponse in Chapter 7."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_5.6.8.6 DSM Download cancel_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchange argument types and exceptions returned by Download cancel()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nvoid cancelSI(in opaque cancelReq)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nraises(BAD_MODULE_ID, TIMEOUT);"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe opaque data of ackNack is defined in the structure DownloadCancel in\nChapter 7."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_5.7.2.7 ev_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe CORBA functions to access free exceptions are recommended:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCORBA_exception_value(), to obtain a pointer to the structure\ncorresponding to the exception."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCORBA_exception_free(), to free memory allocated in the construction of\nev."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn a non CORBA system, a DSM-CC application may call"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDSM_exception_kind(), to obtain the constant unsigned long kind assigned\nto the exception."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn a CORBA system, a DSM-CC application calls"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCORBA_exception_id(), to obtain the string id (assigned by a CORBA\nInterface Repository) of the exception. A DSM-CC Library may return a\nconverted string form of the DSM-CC exception constant, in reply to\nCORBA_exception_id()."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nElsewhere in this C Mapping section, require the use of CORBA_free(), to\nfree memnory associated with variable length structure members, e.g.,\n*_buffer of sequence structs, and strings."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCORBA_free(), to"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_5.7.2.9 Macros to Shorten Identifiers in the C Mapping_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(new)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAdd text to describe the use of #define macros to shorten names."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the C mapping identifier exceeds 31 characters in length, #define\nmacros may be used to shorten the identifier input to the compiler."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nVery long identifiers are generated in C mapping of some names, causing\nthe DSM-CC code to be uncompilable by most C Compilers. e.g.,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCosNaming: maximum symbolic length exceeded for C mapping:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n38 characters: CosNaming_NamingContext_NotFoundReason"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n37 characters CosNaming_NamingContext_CannotProceed"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n38 characters CORBA_sequence_CosNaming_NameComponent"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUse macros (#define <long_name> <short_name>)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nas necessary to reduce identifier length. (Be careful not to cause name\ncollisions)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ne.g.,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define CosNaming_NamingContext COS_NamingCtxt"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#define CORBA_sequence_CosNaming CORBA_seq_COS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nresults in"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n29 characters: COS_NamingCtxt_NotFoundReason"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n28 characters: COS_NamingCtxt_CannotProceed"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n27 characters CORBA_seq_COS_NameComponent"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_12.3 DSM-CC Simple Types Include Files_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*dsmtype.h*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBasic types(short, long) shall be given machine-independent definitions:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n/* machine-independent types"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* some will have a 64 bit unsigned long"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* others will need an array of 2 u_longs to produce the u_longlong"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*/"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#if SIZEOF_LONG == 64"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef short DSM_s_short;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef unsigned short DSM_u_short;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef int DSM_s_long;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef unsigned int DSM_u_long;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef unsigned long DSM_u_longlong"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#else"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef short DSM_s_short;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef unsigned short DSM_u_short;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef long int DSM_s_long;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef unsigned long int DSM_u_long;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct \\{unsigned long int v0; unsigned long int v1;}\nDSM_u_longlong;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n#endif"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll consts will be changed to #define."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis file will be expanded to include all DSM common const IDL\ndefinitions in Chapter 5,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nplus DSM common type structs (not contained within an interface)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*dsmcomx.x, dsmcomx.h*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe ONC XDR variable-length structs will be condensed in these files,\ni.e the variable-length structs defined in the previous files dsmcom.x,\ndsmobref.x and dsmhdr.x will be combined in the file dsmcomx.x, and\ndsmcom.h, dsmobref.h and dsmhdr.h will be combined in the file\ndsmcomx.h. The structs will include a DSM_u_long _maximum first member,\nin order for the structure to match the contents of the corresponding\nCORBA IDL-compiled structure. In addition, all of the variable-length\nONC structure names will begin with DSM_XDR_, to avoid a compile-time\nname conflict with the CORBA IDL-compiled structure. With these changes,\nthe structures can be readily assigned from one to the other, achieving\ncomplete compatibility between generated ONC and CORBA structures."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ne.g.,"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nXDR:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct DSM_XDR_PathSpec\\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDSM_u_long _maximum;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDSM_XDR_Step a<>;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nyields:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct DSM_XDR_Pathspec \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDSM_u_long _maximum;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nu_int a_len;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDSM_XDR_Step *a_val;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nwhich is equal to and assignable to the CORBA-compiled structure:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef struct DSM_PathSpec \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCORBA_unsigned_long _maximum;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCORBA_unsigned_long _length;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDSM_Step * _buffer;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n} DSM_PathSpec;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Digital Broadcast Service"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== *Digital Broadcast Service - New Chapter*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *?.1 Overview and the General Message Format*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Digital Broadcast Service (DBS) messages are assumed to be part of a\nlarger protocol stack. The DBS messages are designed to be carried on\ntop of various protocols (e.g., UDP/IP, TCP/IP, or none). Constraints on\nspecific lower level protocols are given in this document in the section\nwhich addresses transport issues."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis section describes the format of all Digital Broadcast Service\nMessages. Subsequent sections describe how these messages are used in\nthe operation of a Network. DSM-CC UN messages are used to establish the\nDBS service (and connections, as resources of this service) to a Client\nfrom the DBS-Server. Digital Broadcast Service resources are assigned by\nthe Network and are described by resource descriptors, each of which\nconsist of resource data elements."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe syntax has been designed to be extensible. Additional messages may\nbe defined."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn general, *Request* messages are generated when the Client initiates a\nmessage sequence. The DBS-Server responds to a Request message with a\n*Confirm* message. Messages which are sent asynchronously to the Client\nfrom the DBS-Server are *Indication* messages. The Client responds to an\nIndication message with a *Response* message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll of the control messages in this document use a request/response\nmechanism. When a DBS-Server or a Client issues a request message, the\ndestination device issues a definite response to the request."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAll messages between the DBS-Server and the Client have a common message\nformat. Table ?-1 General Format of DSM-CC Digital Broadcast Service\nMessage defines the Digital Broadcast Service message format. This\nformat is called the DigitalBroadcastServiceMessagePacket()."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?-1 General Format of DSM-CC Digital Broadcast Service Message"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"76%,24%\",]\n|===\n|Syntax |Num. of Bytes\n|DigitalBroadcastServiceMessagePacket() \\{ |\n|DSMCCMessageHeader() |\n|MessagePayload() |\n|} |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *DSMCCMessageHeader* is defined in the general message format\nsection of this document."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *MessagePayload* is constructed from resource descriptors and data\nfields and differs in structure depending on the function of the\nparticular message. Section ?-2 defines the DSM-CC DBS Messages."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== ?.2 Digital Broadcast Service Messages"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis section defines the Digital Broadcast Service messages. Each\nmessage is identified by a specific messageId which is encoded to\nindicate the class and direction of the message. Table ?-2 DSM-CC\nDigital Broadcast Service messageIds defines the encoding of the\nmessageId fields used in the Digital Broadcast Service messages:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ? -2 DSM-CC Digital Broadcast Service messageIds"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,34%,48%\",]\n|===\n|messageId |Message Name |Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0000 |Reserved |ISO/IEC 13818-6 Reserved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0001 |DBSProgramSelectRequest |Sent from a User to the DBS-Server to\nrequest that a broadcast program be provided."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0002 |DBSProgramSelectConfirm |Sent from the DBS-Server to a User in\nresponse to the DBSProgramSelectRequest."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0003 |DBSProgramSelectIndication |Sent from the DBS-Server to a User\nto indicate that a new broadcast program will be provided."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0004 |DBSProgramSelectResponse |Sent from a User to the DBS-Server in\nresponse to the DBSProgramSelectIndication message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0005 - 0x7fff |Reserved |ISO/IEC 13818-6 Reserved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x8000 - 0xffff |User Defined |User Defined DBS message.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *?.2.1 New Structures in DBS messages*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== ?.2.1.1 Use of PrivateData() in DBS messages"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nService messages from a Client to the DBS-Server may contain a\nPrivateData() field. The PrivateData() field in DSM-CC Digital Broadcast\nService messages is mandatory, however, the number of privateDataBytes\nmay be zero. The data transported in privateData() is outside of the\nscope of this specification. Table ?-3 defines the format of the\nPrivateData() which is transported in DBS messages:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?-3 DSM-CC DBS PrivateData format"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"76%,24%\",]\n|===\n|Syntax |Num. of Bytes\n|PrivateData()\\{ |\n|privateDataCount |2\n|for(i=0;i<pDataCount;i++) \\{ privateDataByte } |1\n|} |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *privateDataCount* field shall indicate the total number of\nprivateDataBytes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *privateDataByte* fields ** contain the private data. The format and\nusage of this data is outside of the scope of this specification."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== ?.2.1.2 Use of BroadcastProgramId in DBS messages"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn DBSProgramSelect messages a *broadcastProgramId* field is used to\nspecify a single broadcast program at the interface between Client and\nDBS-Server. Table ?-4 specifies the allowed values for the\n*broadcastProgramId* field:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?-4 DSM-CC DBS broadcastProgramIds"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"23%,29%,48%\",]\n|===\n|broadcastProgramId |Broadcast Program Name |Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0000 |Reserved |ISO/IEC 13818-6 Reserved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0001 |NullProgram |Identifies that NO broadcast program is selected /\nindicated."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0002 |LastProvided |Identifies the broadcast program which was\nprovided last before the current one."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0003 |SubscribedUpNext |Identifies the next subscribed broadcast\nprogram in \u2018up\u2019 direction (i.e. with rising program number)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0004 |SubscribedDownNext |Identifies the next subscribed broadcast\nprogram in \u2018down\u2019 direction (i.e. with falling program number)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0005 |FavoriteUpNext |Identifies the next favorite broadcast program\nin \u2018up\u2019 direction (i.e. with rising program number)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0006 |FavoriteDownNext |Identifies the next favorite broadcast\nprogram in \u2018down\u2019 direction (i.e. with falling program number)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0007 - 0x00ff |Reserved |ISO/IEC 13818-6 Reserved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x0100 - 0x7fff |Broadcast Program Numbers |Uniquely identifies a\nsingle broadcast program."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x8000 - 0xffff |User Defined |User Defined special purpose DBS\nbroadcastProgramIds.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA group of possible values is reserved for special applications like to\nidentify the last used broadcast program or next one in either\ndirection. Additional identifiers for special applications may be\ndefined."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== ?.2.2 DBS message definitions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== ?.2.2.1 DBSProgramSelectRequest message definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis message is sent from a Client to the DBS-Server to request that a\nselected broadcast program shall be established. The DBS-Server will\nrespond with a DBSProgramSelectConfirm message. Table ?-5 defines the\nDSM-CC DBSProgramSelectRequest message:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?-5\u00a0DSM-CC DBSProgramSelectRequest message"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"76%,24%\",]\n|===\n|Syntax |Num. of Bytes\n|DBSProgramSelectRequest()\\{ |\n|sessionId |10\n|broadcastProgramId |4\n|PrivateData() |\n|} |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *sessionId* is used to identify a session throughout its life cycle.\nIt shall be set to the same value as it was set during the\nUser-to-Network Session Setup message exchange."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *broadcastProgramId* field shall be set by the Client and shall\ncontain a value which identifies the new broadcast program which shall\nbe provided now to the Client."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *PrivateData()* structure contains private data. The definition of\nthe content of this field is outside the scope of this specification.\nRefer to Section ?.2.1.1 for more information on this data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== ?.2.2.2 DBSProgramSelectConfirm message definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis message is sent from the DBS-Server to a Client in response to a\nDBSProgramSelectRequest message. Table ?-6 defines the DSM-CC\nDBSProgramSelectConfirm message:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?-6\u00a0DSM-CC DBSProgramSelectConfirm message"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"76%,24%\",]\n|===\n|Syntax |Num. of Bytes\n|DBSProgramSelectConfirm()\\{ |\n|sessionId |10\n|broadcastProgramId |4\n|response |2\n|PrivateData() |\n|} |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *sessionId* is used to identify a session throughout its life cycle.\nIt shall be set to the same value as it was set during the\nUser-to-Network Session Setup message exchange."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *broadcastProgramId* field shall be set to a value indicating the\nbroadcast program that is provided to the Client."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *response* field shall be set by the DBS-Server to a value which\nindicates the DBS-Server\u2019s response to the DBSProgramSelectRequest\nmessage."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *PrivateData()* structure contains private data. The definition of\nthe content of this field is outside the scope of this specification.\nHowever, it is expected that the PrivateData() structure contains\nconnection information necessary for the Client to receive the broadcast\nprogram. Refer to Section ?.2.1.1 for more information on this data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== ?.2.2.3 DBSProgramSelectIndication message definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis message is sent from the DBS-Server to a Client to indicate that a\nnew broadcast program is provided. The Client shall respond with a\nDBSProgramSelectResponse message. Table ?-7 defines the DSM-CC\nDBSProgramSelectIndication message:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?-7\u00a0DSM-CC DBSProgramSelectIndication message"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"76%,24%\",]\n|===\n|Syntax |Num. of Bytes\n|DBSProgramSelectIndication()\\{ |\n|sessionId |10\n|broadcastProgramId |4\n|reason |2\n|PrivateData() |\n|} |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *sessionId* is used to identify a session throughout its life cycle.\nIt shall be set to the same value as it was set during the\nUser-to-Network Session Setup message exchange."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *broadcastProgramId* field shall be set to a value specifying the\nbroadcast program which will be provided by the DBS-Server."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *reason* field shall be set by the DBS-Server to a value which\nindicates why the DBS-Server has selected the broadcast ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *PrivateData()* structure contains private data. The definition of\nthe content of this field is outside the scope of this specification.\nHowever, it is expected that the PrivateData() structure contains\nconnection information necessary for the Client to receive the broadcast\nprogram. Refer to Section ?.2.1.1 for more information on this data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== ?.2.2.4 DBSProgramSelectResponse message definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis message is sent from the Client to the DBS-Server in response to a\nDBSProgramSelectIndication message. Table ?-8 defines the\nDBSProgramSelectResponse message:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?-8\u00a0DSM-CC DBSProgramSelectResponse message"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"76%,24%\",]\n|===\n|Syntax |Num. of Bytes\n|DBSProgramSelectResponse()\\{ |\n|sessionId |10\n|response |2\n|PrivateData() |\n|} |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *sessionId* is used to identify a session throughout its life cycle.\nIt shall be set to the same value as it was set during the\nUser-to-Network Session Setup message exchange."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *response* field shall be set by the Client to a value which\nindicates the Client\u2019s response to the DBSProgramSelectRequest message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *PrivateData()* structure contains private data. The definition of\nthe content of this field is outside the scope of this specification.\nRefer to Section ?.2.1.1 for more information on this data."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== ?.3 DBS Command Scenarios"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== ?.3.1 Client Initiated Program Select Command Sequence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure ?-1 illustrates the procedure for program selection initiated by\nthe Client."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure ?-1 Scenario for Client Initiated Program Select Sequence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep 1 Client:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTo select a broadcast program to be provided, the Client shall send a\nDBSProgramSelectRequest to the DBS-Server and start timer *Tmsg*. The\nsessionId field shall be set to the same value as it was set in the\nUNSessionSetupConfirm message received from the Network. The\nbroadcastProgramId shall be set to a value which identifies the\nbroadcast program the Client wants to receive."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf timer *Tmsg* expires before a DBSProgramSelectConfirm is received,\nthe Client shall assume the program select request failed. The Client\nmay repeat the DBSProgramSelectRequest message or it may initiate an\naudit with the Network."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep 2 DBS-Server:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOn receipt of a DBSProgramSelectRequest, the Network shall verify that\nthe sessionId field refers to an active session. If the DBS-Server\ndetermines that the sessionId is invalid, the DBS-Server shall respond\nwith a DBSProgramSelectConfirm message with the response field set to\n*rspSeNoSession.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the sessionId is valid, the DBS-Server shall verify that the\nDBSProgramSelectRequest message is encoded correctly, especially the\nlength fields are encoded consistently. If the DBS-Server detects\nencoding errors in the DBSProgramSelect message, it shall reply with a\nDBSProgramSelectConfirm message with the response field set to\n*rspSeFormatError*."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf sessionId is valid and encoding of the message is correct, the\nDBS-Server shall verify that the broadcastProgramId field represents a\nvalid broadcast program. If the requested broadcast program is not\navailable (either currently or permanently), the DBS-Server shall reply\nwith a DBSProgramSelectConfirm message with the response field set to\n*rspSeBPOutOfOrder*."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf broadcastProgramId is valid, the DBS-Server may verify that the\nClient is entitled to receive the broadcast program identified by the\nbroadcastProgramId. If the Client is not entitled to receive the\nbroadcast program, the DBS-Server shall reply with a\nDBSProgramSelectConfirm message with the response field set to\n*rspSeEntitlementFailure*."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the Client is entitled to receive the broadcast program channel,\nhowever, the DBS-Server has not enough internal resources to provide the\nbroadcast program to the Client, the DBS-Server shall reply with a\nDBSProgramSelectConfirm message with the response field set to\n*rspSeNoResource*."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the DBS-Server has enough internal resources to provide the broadcast\nprogram to the Client, the DBS-Server shall request the Network to\nprovide the broadcast program to the Client. If the Network rejects this\nrequest, the DBS-Server shall respond to the Client with a\nDBSProgramSelectConfirm message with the response field indicating why\nthe Network rejected (e.g. *rspNeNoResource*)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the DBS-Server can provide the requested broadcast program to the\nClient across the Network, the DBS-Server shall send a\nDBSProgramSelectConfirm with response field set to *rspOk* to the\nClient. The value of the sessionId field shall be set by the DBS-Server\nto the value used to identify the session throughout its duration. The\nvalue of the privateDataCount field shall be equal to the number of\nprivateDataBytes present in the remainder of the message. It is assumed\nthat these privateDataByte fields contain a description of the new\nresources, if needed, to provide the broadcast program."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep 3 Client:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOn receipt of DBSProgramSelectConfirm the Client shall verify that the\nresponse field is set to rspOk. The Client can now consider the new\nbroadcast program to be available. It may have to process the\nprivateDataByte fields to know how to receive (\u201ctune to\u201d) the broadcast\nprogram."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== ?.3.2 DBS-Server Initiated Program Select Command Sequence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure ?-2 illustrates the procedure for program selection initiated by\nthe DBS-Server:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure ?-2 Scenario for DBS-Server Initiated Program Select Sequence"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep 1 DBS-Server:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the DBS-Server determines to switch to another broadcast program\n(e.g. a pre-subscribed Pay-per-View event starts or the subscriber is no\nmore entitled to receive a broadcast program), the DBS-Server shall\nrequest the Network to provide the new broadcast program to the Client.\nAfter acknowledgment by the Network the DBS-Server shall send a\nDBSProgramSelectIndication to the Client to indicate that a broadcast\nprogram will be provided, and start timer *Tmsg*. The sessionId field\nshall be set to the same value as it was negotiated during the\nUN-Session-Setup. The broadcastProgramId shall be set to a value which\nidentifies the broadcast program, which the Network provides to the\nClient."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf timer *Tmsg* expires before a DBSProgramSelectResponse is received,\nthe DBS-Server shall repeat the DBSProgramSelectIndication message and\nstart timer *Tmsg* again. If *Tmsg* expires repeatedly before a\nDBSProgramSelectResponse message is received, the DBS-Server may\ninitiate an audit with the Network."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep 2 Client:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOn receipt of a DBSProgramSelectIndication, the Client shall verify that\nthe sessionId field refers to an active session. If the Client\ndetermines that the sessionId is invalid, the Client shall respond with\na DBSProgramSelectConfirm message with the response field set to\n*rspClNoSession.*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the sessionId is valid, the Client shall verify that the\nDBSProgramSelectIndication message is encoded correctly, especially the\nlength fields are encoded consistently and, if needed, the\nprivateDataByte fields contain enough information to receive the\nbroadcast program. If the Clients detects encoding errors in the\nDBSProgramSelectIndication message, it shall reply with a\nDBSProgramSelectConfirm message with the response field set to\n*rspClFormatError*."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf sessionId is valid and encoding of the message is correct, the Client\nshall accept the new broadcast program and reply with a\nDBSProgramSelectResponse message with the response field set to *rspOk*.\nIf the Client does not want to receive the indicated broadcast program,\nit may either release the UN session with the DBS-Server or generate a\nDBSProgramSelectRequest message after the DBSProgramSelectResponse\nmessage."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep 3 DBS-Server:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOn receipt of DBSProgramSelectResponse the DBS-Server shall verify that\nthe response field is set to rspOk. The DBS-Server can now consider the\nnew broadcast program to be accepted by the Client."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *?.4 DBS State Event Engine*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *?.4.1 DBS State Event Engine for the Client Side*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following states are defined at the Client side for the Digital\nBroadcast Service:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Cidle Client considers the service session inactive.\n* CprogramInactive Client considers the service session active but NO\nbroadcast program active.\n* CprogramActive Client considers the service session and a broadcast\nprogram active.\n* CprogramRequest Client has requested to change the broadcast program\nand waits for an acknowledgment by the DBS-Server."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe possible state transitions are described in Figure ?-8:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure ?-8 State-Event Diagram for Client DBS States"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following internal and external events are defined at the Client\nside for the DBS State-Event-Engine:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* internal events:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[initiate-ProgSelReq] The application requests the state-event-engine to\ngenerate a DBSProgramSelectRequest message and enter new state\naccordingly."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[UN-Setup] The state-event engine is informed that a UN-Session has been\nestablished for Digital Broadcast Service."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[UN-Release] The state-event engine is informed that the DBS UN-Session\nhas been released."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[Tmsg-timeOut] The state-event engine is informed that the message\nresponse timer Tmsg has expired without a response being received."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* external events:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProgramSelectCnf A DBSProgramSelectConfirm message is received from the\nNetwork."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProgramSelectIndication A DBSProgramSelectIndication message is received\nfrom the Network."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following conditions are defined for the Client side DBS\nState-Event-Engine:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbpId valid The broadcastProgramId field in a received\nDBSProgramSelectIndication or a DBSProgramSelectConfirm message contains\na valid value."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nencoding valid The entire encoding of a received\nDBSProgramSelectIndication or a DBSProgramSelectConfirm message is\nsyntactically correct and all information needed to process the event is\navailable within the message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nresponse == _rspCode_ The response field in a received\nDBSProgramSelectIndication or a DBSProgramSelectConfirm message is equal\nto _rspCode._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following reactions are defined for the Client side DBS\nState-Event-Engine:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDBSProgSelReq The Client sends a DBSProgramSelectRequest message to the\nDBS-Server."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDBSProgSelRsp: _rspCode_ The Client sends a DBSProgramSelectResponse\nmessage to the DBS-Server, which contains the response field encoded to\n_rspCode_."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUNStatusReq: _rsnCode_ The DBS state-event engine triggers the UN Client\nstate event engine to send a UNStatusRequest message to the SRM the\nreason field encoded to _rsnCode_."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?-9 describes the Client side DBS State-Event-Engine:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?- 9 DBS Client State Table"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"18%,15%,20%,31%,16%\",]\n|===\n|Current State |Event |Conditions |Actions |Next State"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Cidle |[UN-Setup] | | |CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |[UN-Release] | | |Cidle"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |ProgramSelectCnf | |UN StatusRequest: rsnClNoSession (o) |Cidle"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |ProgramSelectInd | |DBSProgSelRsp: rspClNoSession UN StatusRequest:\nrsnClNoSession (o) |Cidle"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |[Tmsg-timeOut] | | |Cidle"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|CprogramInactive |[initiate-ProgSelReq] | |DBSProgSelReq\n|CprogramRequest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |[UN-Setup] | | |CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |[UN-Release] | | |Cidle"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |ProgramSelectCnf | |UN StatusRequest: rsnClProcError (o)\n|CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |ProgramSelectInd |! encoding valid |DBSProgSelRsp: rspClFormatError\n|CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |! bpId valid |DBSProgSelRsp: rspOk |CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |bpId valid |DBSProgSelRsp: rspOk |CprogramActive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |[Tmsg-timeOut] | | |CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|CprogramRequest |[UN-Setup] | | |CprogramRequest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |[UN-Release] | | |Cidle"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |ProgramSelectCnf |! encoding valid | |CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |response != rspOk | |CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |! bpId valid | |CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |bpId valid | |CprogramActive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |ProgramSelectInd |! encoding valid |DBSProgSelRsp: rspClFormatError\n|CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |! bpId valid |DBSProgSelRsp: rspOk |CchannelInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |bpId valid |DBSProgSelRsp: rspOk |CprogramActive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |[Tmsg-timeOut] |!retrans-failed |DBSprogSelReq |CprogramRequest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |retrans-failed |UNStatusRequest: rsnClProcError (o)\n|CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|CprogramActive |[UN-Setup] | | |CprogramActive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |[UN-Release] | | |Cidle"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |ProgramSelectCnf | | |CprogramActive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |ProgramSelectInd |! encoding valid |DBSProgSelRsp: rspClFormatError\n|CprogramInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |! bpId valid |DBSProgSelRsp: rspOk |CchannelInactive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |bpId valid |DBSProgSelRsp: rspOk |CprogramActive"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |[initiate-ProgSelReq] | |DBSprogSelReq |CprogramRequest"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| |[Tmsg-timeOut] | | |CprogramActive\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n====== ?.4.2DBS State Event Machine for the DBS-Server Side"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following states are defined at the DBS-Server side:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Sidle DBS-Server considers the service session inactive.\n* SprogramInactive DBS-Server considers the service session active but\nNO broadcast program.\n* SprogramActive DBS-Server considers the service session and a\nbroadcast program active.\n* SprogramRequest DBS-Server has indicated switching to a new broadcast\nprogram and waits for an acknowledgment by the Client."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*[pic]*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure ?-10 State-Event Diagram for Network SDB States*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following internal and external events are defined at the Network\nside for the SDB Service State-Event-Engine:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* internal events:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[initiate-ProgSelInd] The application requests the state-event-engine to\ngenerate a DBSProgramSelectIndication message and enter new state\naccordingly."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[UN-Setup] The state-event engine is informed that a UN-Session has been\nestablished for Digital Broadcast Service."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[UN-Release] The state-event engine is informed that the DBS UN-Session\nhas been released."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[Tmsg-timeOut] The operation system informs the state-event-engine that\nthe message response timer Tmsg has expired without a response being\nreceived."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* external events:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProgramSelectReq A DBSProgramSelectRequest message is received from the\nClient."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProgramSelectRsp A DBSProgramSelectResponse message is received from the\nClient."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following conditions are defined for the DBS-Server side DBS\nState-Event-Engine:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nbpId valid The broadcastProgramId field in a received\nDBSProgramSelectRequest message contains a valid value."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nencoding valid The entire encoding of a received DBSProgramSelectRequest\nor a DBSProgramSelectIndication message is syntactically correct."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nprogram available The DBS-Server determines that a requested broadcast\nprogram is available, i.e. not ouf of order."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ndbs resources available The DBS-Server has enough internal resources to\nits disposal to process a DBSProgramSelectRequest message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnet resources available The Network has enough internal resources to its\ndisposal to provide a broadcast program on request of the DBS-Server to\na Client."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nentitlement failed The DBS-Server determines that a Client is not\nentitled to receive the requested broadcast program."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nresponse == _rspCode_ The response field in a received\nDBSProgramSelectResponse message is equal to _rspCode_."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following reactions are defined for the DBS-Server side DBS\nState-Event-Engine:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDBSProgSelInd The DBS-Server sends a DBSProgramSelectIndication message\nto the Client."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDBSProgSelCnf: _rspCode_ The DBS-Server sends a DBSProgramSelectConfirm\nmessage to the Client, which contains the response field encoded to\n_rspCode_."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUNStatusReq: _rsnCode_ The DBS state-event engine triggers the UN\nDBS-Server state event engine to send a UNStatusRequest message to the\nSRM the reason field encoded to _rsnCode_."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?- 10 describes the DBS-Server side DBS State-Event-Engine:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?-10 SDB Service Network State Table"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"19%,15%,20%,31%,15%\",]\n|===\n|Current State |Event |Conditions |Actions |Next State\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_[table to be provided]_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== New DBS Annex: *INFORMATIVE ANNEX H - Digital Broadcast Services*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n(This annex does not form an integral part of this International\nStandard)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn some network architectures, such as Hybrid Fiber Coax (HFC) and Fiber\nto the Curb (FTTC), the economics of network design favor delivering\ndigital broadcast programs to an Interworking Unit (IWU) in a delivery\nsystem and multicasting the digital broadcast programs to Clients.\nAlthough the entire range of broadcast programming is available at the\nIWU, it is typically not practical in these architectures to\nsimultaneously deliver all digital broadcast programs to each Client.\nWhen a Client wishes to switch from channel to channel (\u201cchannel surf\u201d),\nhe must signal to the Network in order to establish a connection (which\nis typically a multicast connection) from the IWU to the Client."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Digital Broadcast Service (DBS) messages, defined in the normative\ntext in Chapter ??, specify a protocol specifically for this\napplication. The Digital Broadcast Service protocol is exchanged between\na Client and between the DBS-Server in the Network. This annex describes\nan example use of Digital Broadcast Service messages which conforms to\nthe DSM-CC functional model."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn addition to the Digital Broadcast Service messages, two additional\nresource descriptors have been defined to support digital broadcast\nservices. The first of these, the DBSControlChannel resource, is a\nresource in the IWU that represents the termination point of DBS\nmessages. Defining a resource descriptor for this function allows the\nSRM to manage the allocation of DBS control chanels, should that be\nnecessary."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA number, the broadcastProgramId, is used to uniquely identify each of\nthe different broadcast programs that may be available at an IWU. The\nbroadcastProgramId\u2019s must be insured to be unique. Reserved\nbroadcastProgramId\u2019s may be used to provide \u201chandheld remote\u201d functions\nsuch as \u201cchannel up\u201d, \u201cchannel down\u201d, \u201cnext\u201d and \u201cprevious\u201d."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA mapping in the Client is needed between the Client\u2019s view of the\nbroadcast program (e.g., its name \u201cHBO\u201d, or \u201cchannel number\u201d), and the\nbroadcastProgramId."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA mapping in the DBS is needed between the broadcastProgramId and the\nconnection resources that transport the broadcast program as it arrives\nfrom the broadcast source. The connection resources would typically\ncontain port/VPI/VCI, and possibly, an MPEGProgram resource, which\nindicates the MPEG program number and PIDs. The new resource descriptor,\nthe BroadcastService resource, is used to associate a Continuous Feed\nsession Id, the ResourceNumbers of the connection resources , and a\nbroadcastProgramId in the IWU."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Digital Broadcast Server"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe main architectural elements are illustrated below:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure 1. Digital Broadcast Service*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn this example, the Digital Broadcast is provided over a FTTC system.\nTwo signaling connections from the Client are shown: an ATM VC which\nterminates on the DBS in the IWU, and an additional ATM VC which\nterminates in the SRM. In this example, the protocol stack used for the\nDBS messages is \u201cnone\u201d: the DBS messages are transported directly over\nAAL5. The protocol stack used for User-Network messages to the SRM could\nbe UDP/IP."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nMany other possibilities are allowed. For example, both DBS and\nUser-Network messages could be carried over a single connection: the IWU\ncould terminate DBS messages and route User-Network messages to the SRM.\nAlternately, it is possible to implement a DBS and an SRM in a single\nbox, and terminate both sets of messages in a single place."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Functional Flows"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis annex describes several functional flows. Note although many of the\nflows given below are recognized to exist, they are out of scope of\nDSM-CC and are provided for information only. The following functional\nflows are considered:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Broadcast Program Configuration\n* Client Service Profile Download to the DBS\n* Broadcast Program Guide Download To Client\n* Digital Broadcast Session Establishment\n* Client Initiated Channel Changes\n* Network Initiated Channel Changes\n* Digital Broadcast Session Release"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nBroadcast Program Configuration"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Broadcast Program sources must be delivered to the IWU, and as\nmentioned above, an association must be established between the\nconnection resources (that describe how to obtain the Broadcast\nProgram), and the broadcastProgramId\u2019s. This association, which\ndescribes the Broadcast Programs available to the DBS, may be performed\nby private means. Alternately, DSM-CC Continuous Feed Sessions may be\nused to facilitate the configuration of this information in the DBS.\nWhen a server establishes a Continuous Feed Session, it advertises its\nexistence to the SRM via the ContinuousFeedSessionSetupRequest message\nto the SRM. By including BroadcastService resource descriptor in this\nlist, the Server can notify the SRM of the broadcastProgramId\u2019s of the\ndifferent broadcast programs available in the Continuous Feed Session."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_The message flow for this is simple. It might be worth elaborating on\nthe example to show how an example encoding of this resource would be\nperformed._"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== *Client Service Profile Download to the DBS*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOne method of authentication is to perform \u201centitlement checking\u201d in the\nDBS. A list of subscribed services for each Client is maintained by the\nDBS, and requests for broadcast programs are validated by the DBS. If\nthe Client is not entitled to the requested program, the\nDBSProgramSelectConfirm message, which is used by the DBS-Server to\nrespond to the Client, will fail with a response code\nrsnSeEntitlementFailure which has been defined for this purpose."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe format of Client Service Profile information, how it is communicated\nto the DBS, and how entitlement checking is performed, are outside the\nscope of this specification."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Broadcast Program Guide Download to Client"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA list of the available broadcast programs (the Program Guide) may be\nrequired by the Client in order to request a Broadcast Program. The\nformat of the Program Guide and the method by which it is sent to the\nClient is out of the scope of this specification. However, the\ninformation in the Program Guide is assumed to contain information that\nrelates the Client\u2019s notion of a Broadcast Program (e.g., the \u201cchannel\nnumber\u201d, and, perhaps, a printable string, such as \u201cCNN\u201d) to the\nbroadcastProgramId."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Program Guide _may_ include additional application level information\nabout the broadcast program content (such as language / parental\nadvisory, event cost, start time, etc.), and may include additional\nconnection information. In cases where the VPI/VCI of a Broadcast\nProgram is fixed, additional connection information could be used by the\nClient to improve \u201cchannel surfing\u201d response time, as it would then not\nneed to wait for a Confirm message to be notified which VPI/VCI to\n\u201ctune\u201d to."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOne method by which the Program Guide may be sent to the Client is via a\nbroadcast carousel mechanism. The Program Guide may be managed by a\nnetwork provider (and arrive to the Client in one piece), or managed by\nindividual service providers, and transferred to the Client piecemeal.\nIn any case, the allocation of broadcastProgramId\u00b4s must be coordinated."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Digital Broadcast Session Establishment"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAs with all sessions, the purpose of a Digital Broadcast Session is to\nallocate the resources needed to provide the service. Typically, two\nresources are needed in order to provide a digital broadcast service: a\ncontrol channel from the Client to a DBS, and downstream bandwidth from\nthe IWU to the Client."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nSimultaneous SDB sessions to a Client are allowed. Additional sessions\nmay be used to receive multiple video streams (in order to support\n\u201cpicture in picture\u201d), or for other purposes, such as to gain background\naccess to a broadcast carousel."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFigure ?? illustrates a normal digital broadcast session establishment.\nIn this picture, it is useful to keep in mind that the role of the\nServer in this flow is perfomed by the \u201cManagement Server\u201d in Figure ??,\nabove. In this capacity, the Management Server terminates the U-N\nsignaling flow from the SRM."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure ??. Digital Broadcast Service*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep1 (Client)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Client sends a ClientSessionSetUpRequest message to the SRM where\nthe serverId indicates a broadcast server. The userData includes the\nServerGatewayAttach message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep 2 (SRM)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe SRM verifies the clientId from the Network provider\u2019s point of view,\nand if valid, sends a ServerSessionSetUpIndication message to the\nServer."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep 3 (SRM)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nProceeding."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep4 (Server)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUpon receipt of the ServerSessionSetUpIndication message, the Server\nverifies the clientId from the Server\u2019s point of view, and if valid,\naccepts the request to establish broadcast Session. The Server sends the\nServerAddResoureRequest to establish the appropriate resources. In this\nexample, two resources are needed, a DBSControlChannel, and a\nTSDownstreamBandwidth resource."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep5 (SRM)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUpon receipt of the ServerSessionSetUpIndication message, the SRM\nprocesses the broadcast session resource descriptors included in the\nmessage. At this point, there may be a private dialog between the SRM\nand the IWU to establish the resources. If the SRM determines that the\nresources are available for this Client to join the broadcast session,\nthe ServerSessionSetupResponse message is returned with the\nresourceStatus set to Assigned. Otherwise, the resourceStatus is set to\nFailed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep6 (Server)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Server shall send the ServerSessionSetUpResponse message to the SRM\nwhich contains userData to be forwarded to the Client necesary for the\nbroadcast session. The userData includes the ServerGatewayAttachReply\nand the ResourceBindingList."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nStep7 (SRM)"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe SRM sends the ClientSessionSetUpConfirm to the Client which contains\nthe response, the Client view resource descriptors from the broadcast\nsession, any additional resources which may have been added to the\nsession, and the uuData passed from the Server in the\nServerSessionSetUpResponse."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Client Initiated Channel Changes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIn order to request a Digital Broadcast Program, the following is\nassumed: the Broadcast Program Configuration and Client Service Profile\ninformation has been defined in the DBS, the Program Guide has been\nobtained by the Client, and a DBS Session has been established."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAt this point, the Client may request a Broadcast Program from the DBS.\nThe first field in the DBSProgramSelectRequest message (after\ndsmccMessageHeader), is the sessionId. This field consists of\nsessionNumber (four bytes), and the Client\u2019s deviceId (6 bytes). The\nsessionNumber is used to distinguish between different sessions that may\nactive at a single Client. The second field in the\nDBSProgramSelectRequest message is broadcastProgramId, which is used to\nidentify the Broadcast Program the Client desires."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nParameter checking is performed and appropriate error response code\nvalues will be returned to the Client upon error. Typical errors at this\nstep are: rspSeNoSession (invalid session number), rspSeFormatError\n(badly formatted message)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAuthentication keys may be placed in the Conditional Access Adaptation\nheader of the message (see Section _DSM-CC Adaptation Header Format_) as\na means of performing entitlement checking. Alternately, User Service\nProfile information, described above, can be used at this step to\nauthenticate the request. A new response code rspSeEntitlementFailure,\nhas been defined for this purpose. It is possible to return an alternate\nchannel in the case of entitlement failure. (Such a feature might be\nused when the Client requests an unsubscribed channel, and instead of\ncompletely rejecting the request, is directed to a Broadcast Program\nthat contains an advertisement). In this case, the broadcastProgramId\nand connection information (transported in privateData) in the\nDBSProgramSelectConfirm message is set to the broadcastProgramId of the\nalternate broadcast program."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe operational state of the source of the Broadcast Program is checked.\nIf the Broadcast Program cannot be delivered due to facility or network\nfailure, the rspSeBCProgramOutOfService response code is returned."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the request can be successfully satisfied, then the connection is\nmade that allows the Client to receive the requested Broadcast Program,\nand a DBSProgramSelectConfirm message is built with a response value of\nrspOK, and filled with the necessary connection information needed by\nthe Client to receive the Broadcast Program. The format of this\ninformation is unspecified, and is transported in privateDAta, if\nneeded. In the case of FTTC, the connection information includes VPI/VCI\ninformation; in the case of HFC, it includes PhysicalChannel and\nmpegProgram resource descriptors."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn example successful \u201cchannel change\u201d message sequence follows:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure x. Client Initiated DBS Program Select*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Network Initiated Channel Changes"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nNetwork initiated \u201cchannel changes\u201d can be used to tune a Client \u201cto\u201d a\nchannel (for example, just before a Pay-per-view event begins), or\n\u201caway\u201d from a channel (for example, when a Pay-per-view event ends, or a\nClient is unsubscribes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe DBSProgramSelectIndication message contains a sessionId, which\nindicates the sessionNumber and deviceId of the Client. A reason field\nis provided which indicates why the DBS-Server has decided to initate\nthe BroadcastProgramSelectIndication. If the reason is rsnSeNormal, then\nthe DBS-Server has decided to provide a channel. If the reason is\nrsnSeEntitlementFailure, then the Client is no longer entitled to the\nchannel, and will no longer receive it. In this case the\nbroadcastProgramId is empty. It is expected that the Client application\nsoftware will recover from this situation appropriately, but how this is\ndone is not specified here."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf supplied, the broadcastProgramId indicates the new Broadcast Program\nto be received, and privateData maz be used to transport appropriate\nconnection information. These data elements have the same syntax (and\nsemantics) of the same fields in the BPSProgramSelectConfirm."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nWhen received by the Client, parameter checking is performed and\nappropriate error response code values will be returned to the\nDBS-Server upon error. Typical errors at this step are: rspClNoSession\n(invalid session number), rspClFormatError (badly formatted message)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nIf the indication is successfully processed in the Client, it responds\nwith a DBSProgramSelectResponse message. The response value will be set\nto rspOK."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAn example successful network initiated \u201cchannel change\u201d message\nsequence follows:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Figure x. Network Initiated Broadcast Program Select*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Digital Broadcast Session Release"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_probably should be included, for completeness sake. Fortunately, this\none is pretty easy_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== DBS Edit List"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Update Table 2-2 MPEG-2 DSM-CC dsmccType values:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *dsmccType* field is used to indicate the type of MPEG-2 DSM-CC\nmessage. Table 2-2 MPEG-2 DSM-CC dsmccType values defines the possible\ndsmccTypes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 2-2 MPEG-2 DSM-CC dsmccType values"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"29%,71%\",]\n|===\n|dsmccType |Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x00 |ISO/IEC 13818-6 Reserved"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x01 |Identifies the message as an ISO/IEC 13818-6 IS User-to-Network\nconfiguration message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x02 |Identifies the message as an ISO/IEC 13818-6 IS User-to-Network\nprimitive message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x03 |Identifies the message as an ISO/IEC 13818-6 IS User-to-User\nconfiguration message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x04 |Identifies the message as an ISO/IEC 13818-6 IS User-to-User\nprimitive message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x05 |Identifies the message as an ISO/IEC 13818-6 IS Switched Digital\nBroadcast message."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x06-0x7f |ISO/IEC 13818-6 Reserved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|0x80-0xff |User Defined message type.\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Update User-to-Network resourceDescriptorTypes Table*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThree new descriptors are needed. The first two are explained in the\nannex. One is a variant of ATM connection resource that is being\nproposed for SDB service, but it may have general use elsewhere."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe new resource descriptors types are: DBSControlChannel,\nBroadcastService, and ATMVcConnection."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable 4-66 DSM-CC User-to-Network resource**DescriptorTypes**"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"34%,10%,56%\",]\n|===\n|resourceDescriptorType |Value |Description"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Reserved |0x0000 |ISO/IEC 13818-6 reserved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n| | |"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|ATMVcConnection |0x000b |Indicates the VPI/VCI of an ATM connection."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|DBSControlChannel |0x000c |This is a Digital Broadcast Control Channel\nresource."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|BroadcastService |0x000d |This resource associates a Continuous Feed\nSession Id with a Broadcast Program Id and the connection resources\nneeded to deliver the Broadcast Program."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|Reserved |0x000e - 0x7ffd |ISO/IEC 13818-6 reserved."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|SharedResource |0x7ffe |Sent by the Server to the Network, or by the\nNetwork to the Client to instruct the recipient to share an already used\nresource (the shared resource)."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|SharedRequestId |0x7fff |Sent by the Server to the Network along with\nthe resource descriptors in a request message and is used by the Server\nto associate the resource numbers assigned by the network to the\nspecific resource descriptors."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|UserDefined |0x8000 - 0xfffe |Resource descriptors in this range are\nuser definable."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|TypeOwner |0xffff |Defines owner of the UserDefined resource type\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Insert new resource descriptor definitions:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== *4.5.5.12 ATMVcConnection resource descriptor definition*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis descriptor describes an ATM VC Connection."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?? AtmVcConnectionDescriptor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"52%,15%,13%,20%\",]\n|===\n|Field Name |Encoding |Variable |Field Length In Bytes\n|atmVpi |s |no |2\n|atmVci |s |no |2\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *atmVpi* and *atmVci* parameters contain the VPI and VCI values for\nthe ATM connection."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 4.5.5.12 DBSControlChannel resource descriptor definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis descriptor describes a DBSControlChannel."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable ?? dbsControlChannelDescriptor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"52%,15%,13%,20%\",]\n|===\n|Field Name |Encoding |Variable |Field Length In Bytes\n| | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== 4.5.5.12 BroadcastService resource descriptor definition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis descriptor describes a BroadcastResource."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nTable?? BroadcastService resource descriptor"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"100%\",cols=\"50%,13%,13%,24%\",]\n|===\n|Syntax |Encoding |Variable |Num. of Bytes\n|cfSessionId |s,l |Yes |10\n|broadcastPgmCount |s |No |2\n|for(i=0;i<broadcastPgmCount;i++)\\{ | | |\n|BroadcastProgramId |s |No |4\n|resourceNumCount |s |No |2\n|for(i=0;i<resourceNumCount;i++)\\{ | | |\n|resourceNum |s.r.l |Yes |2\n|} | | |\n|} | | |\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *cfSessionId* is used to indicate the sessionId of the continuous\nfeed session."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *broadcastPgmCount* is used to indicate the number of broadcast\nprograms available within this continuous feed session."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *BroadcastProgramId* is used to indicate the Broadcast Program Id of\na broadcast program."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe *resourceNum* fields are used to indicate the resources needed to\naccess the Broadcast Program."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Insert new reason codes (section 4.11):*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"28%,36%,36%\",]\n|===\n|rsnSeEntitlementFailure |0x000f |Indicates that a Broadcast Program has\nbeen discontinued due to entitlement failure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|reserved |0x0010 - 0x7fff |ISO/IEC 13818-6 reserved\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Insert new response codes (section 4.12):*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[width=\"99%\",cols=\"26%,37%,37%\",]\n|===\n|rspSeEntitlementFailure |0x0042 |Indicates that a Broadcast Program\ncould not be delivered to a Client due to entitlement failure."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|rspSeBcProgramOutOfService |0x0043 |Indicates that a Broadcast Program\ncannot be delivered because it is out of service."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|rspClFormatError |0x0044 |Indicates that the condition is due to\ninvalid format (e.g., missing parameter) detected at the Client."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n|reserved |0x0045 - 0x7fff |ISO/IEC 13818-6 reserved\n|==="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Insert a new Tap Use type in section 5.3.3.1:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA new TAP use is needed: BROADCAST_CONTROL_USE"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nmodule DSM \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nstruct Tap \\{"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nu_short use; // the use for the Tap"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nopaque selector; // upper protocol selection info"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nu_long assocTag; // the group identifier for network resource\ndescriptors"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n};"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef sequence<Tap> ConnBinder; // typically have request and data\nchannels"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef u_short TapUse;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TapUse UNKNOWN_USE = 0;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TapUse MPEG_UP_USE = 1; // MPEG upstream from client"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TapUse MPEG_DOWN_USE = 2; // MPEG downstream to client"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TapUse DOWNLOAD_CTRL_UP_USE = 3; // control request from client"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TapUse DOWNLOAD_CTRL_DOWN_USE = 4;// control response to client"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TapUse DOWNLOAD_DATA_UP_USE = 5; // data response upstream from\nclient"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TapUse DOWNLOAD_DATA_DOWN_USE = 6;// data block downstream to\nclient"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TapUse STREAM_EVENT_USE = 7; // stream event in MPEG downstream"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nconst TapUse RPC_USE = 8; // RPC bi-directional"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*const TapUse BROADCAST_CTRL_USE = 9; // control channel for Digital\nBroadcast Service*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n// A sequence of ConnectionBinder is defined as ConnBinderList:"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\ntypedef sequence<ConnBinder> ConnBinderList;"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Add New Chapter Switched Digital Broadcast Messages:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nprovided separately"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Add Text for Annex H:*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nprovided separately"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Transfer"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nUU and UN do not support the same kind of Session Transfer. Must be\nfixed for the IS."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDiscussion tabled because all the \u2018right people\u2019 were not present at the\nsame time."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Review of Ad Hoc email"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Review email from Masa Dec 1 regarding ATM descriptors"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-table discussion"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-must be reopened on reflector"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Review email from Masa Dec 6 regarding SRM location and address"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-have CONFIG address as a pre-condition"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-get SRM Session Management address in the networkParameterDataByte\u2019s in\nthe"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nnetworkConfigurationParameters of the UNConfigConfirm."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-Recommend use resourceDescriptor structure within the\nnetworkParameterDataByte\u2019s - but it is network specific."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-As a side note, we agree that the SRM may be distributed."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n* Review email from Masa Dec 5 regarding CFS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n-confirm that ServerContinuousFeedSessionRequest is missing from DIS"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n= DSM-RSF standard\nChris Adams\n1996-01-23"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=="
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*INTERNATIONAL ORGANIZATION FOR STANDARDIZATION*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nORGANIZATION INTERNATIONALE DE NORMALIZATION"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC1/SC29/WG11"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nCODING OF MOVING PICTURES AND AUDIO"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nISO/IEC JTC/SC29/WG11 *N1184*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*January 1996*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDSM-RSF"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nJanuary 23, 1996"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis document is still under study and subject to"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nchange. It should not be used for reference purposes."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*Title*: Description of MPEG-2 Systems extension for Validation,\nVerification and Conformance testing tools for DSM-CC"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}1. Foreword *1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*2. INTRODUCTION 1*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*3. SCOPE 3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4. CONFORMANCE 3*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*4.1 PROFILES* 3"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}5. REFERENCES *4*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*6. DEFINITIONS 4*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*7. SCENARIOS 5*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*8. TEST HARNESS SUPPORT 5*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*9. INTERFACE VALIDATION 5*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*9.1 ITEMS* 5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}10. UNIT TEST VERIFY *5*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*10.1 METHODOLOGY* 5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n10.2 TASKS 5"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}11. COMPONENT VALIDATION. *6*"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n*11.1 ITEMS* 6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n11.1.1 END TO END, U-N, COMMUNICATION SETUP _6_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_11.1.2 Communication setup will test that end-to-end communication can\noccur. 6_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_11.1.3 End to end, U-U resolve 6_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_11.1.4 End to end, U-U attach 6_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_11.1.5 End to end, teardown 6_"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n_11.2 Methodology_ 6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n11.3 TASKS 6"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Foreword"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThis current edition cancels and replaces the all previous documents,\nwhich are now obsolete."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Introduction"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe Experts Group for the Coding of Moving Pictures and Associated Audio\n(MPEG) has defined the Digital Storage Media Command and Control\n(DSM-CC) protocol in ISO/IEC 13818-6 \u00d2MPEG-2 DSM-CC\u00d3 Committee Draft,\nMay 1995. DSM-CC is intended to provide control functions and operations\nspecific to managing services using ISO/IEC 13818 MPEG-2. MPEG systems\nare deployed in diverse network environments to support many\napplications such as, for example, video on demand and interactive\nmultimedia. The MPEG-2 DSM-CC protocol is defined to provide many\ncontrol functions such as establishing and clearing of sessions\n(including network connections in some environments) and interactions\nbetween Client, Server and a network controlling entity."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nDSM-RSF is chartered with the specification and implementation of tests\nto validate and verify DSM-CC, as well as describing the conformance\ntests for DSM-CC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere are six possible areas of work for DSM-RSF"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Interface validation\n. The interface validation level will ensure that the interface as\nspecified in the DSM-CC specification, for U-N and U-U is correct.\n. Unit test verify\n. The unit test verification consists of unit tests for the modules\nwithin DSM-CC.\n. Protocol Layer validation\n. Protocol Layer validation will ensure that DSM-CC modules that are\nimplemented by different organizations will be able to interact\naccording to the interface specified by DSM-CC.\n. Component validation\n. Component validation will allow a component, such as a client device,\nto be tested in a standalone environment.\n. Integration validation\n. Implementation conformance will verify that a number of units will\nwork together as an entire system.\n. Application validation\n. Application verification will verify that the total system will\nsupport applications that represent classes of applications likely to be\nimplemented using DSM-CC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThere are five components to DSM-CC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. Client\n. Session Resource Manager\n. Service Gateway\n. Service\n. Asset"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAdditionally, each component can implement up to three layers of DSM-CC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n[arabic]\n. User to User (U-U)\n. User to Network (U-N)\n. Download"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe matrix below shows the relationship between the test areas, the\ncombination of component and protocol layers and the tasks required to\nensure each area can be tested."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following chapters describe each test area and enumerate the items\nto be tested, the methodology to be used and the tasks to be performed\nto complete validation, verification and conformance testing for DSM-CC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Scope"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe scope of this document is to provide the development of the\nspecification of an environment and tests for the Validation,\nVerification and Conformance testing of DSM-CC (MPEG2 part 6) ."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nOther issues within the scope of the document"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative Annex A describes the DSM-RSF profiles and scenario."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative Annex B describes the pre- and post- conditions fo reach of\nthe unit tests."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative Annex C describes a test harness implementation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nInformative Annex D describes the results of the wlakthrough of the\nscenario"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Conformance"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nConformance to the environment and tests for the Validation,\nVerification and Conformance testing of DSM-CC (MPEG2 part 6) will be\ndescribed within the relevant sections of the standard."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Profiles"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe profiles used are described in Annex A"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== References"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe following standards contain provisions which, through reference in\nthis text, constitute provisions of this part of ISO/IEC 13818. At the\ntime of publication, the editions indicated were valid. All standards\nare subject to revision, and parties to agreements based on this part of\nISO/IEC 13818 are encouraged to investigate the possibility of applying\nthe most recent editions of the standards indicated below. Members of\nIEC and ISO maintain registers of currently valid International\nStandards. The same applies to ITU-T Recommendations."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Definitions"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nFor the purposes of DSM-RSF the following definitions apply"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\no Definitions as in ISO 8824:1990 and ISO 8825:1990"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\no Definitions as in ISO 8879:1986"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\no Definitions as in ISO 9070:1991"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Scenarios"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Test harness support"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nA test harness is described in Annex C that allows each test to be\nperformed automatically and to compare the results with those expected.\nThis harness may be used in those test areas where automatic testing is\nfeasible."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Interface validation"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe interface validation level ensures that the interface as specified\nin the DSM-CC specification, for U-N and U-U is correct."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Items"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe walkthrough of the scenario described above produced the results\ndescibed in Annex ??"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Unit test verify"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nThe unit verification consists of unit tests for the modules within\nDSM-CC."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Methodology"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nAnnex ? describes the APIs and documentation that are used to test the\nunit parts of DSM-CC. The tests and their expected results are included\nas Annex ??"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Tasks"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nEach interface for each unit is investigated and the necessary pre- and\npost- conditions are defined (see Annex G). The interface is called and\nthe response compared with the expected response."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n== Component validation."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\nImplementation conformance verifies that a particular module of DSM-CC\nwould work if plugged in to a DSM-CC network, to replace a similar\nmodule, implemented by another supplier."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n{empty}[pic]"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Items"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== End to end, U-N, communication setup"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== Communication setup will test that end-to-end communication can occur."
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== End to end, U-U resolve"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== End to end, U-U attach"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Attach with destroy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Attach without destroy()"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n==== End to end, teardown"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Teardown on session with destroy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n===== Teardown on session without destroy"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Methodology"
    },
    {
        "instruction": "",
        "input": "",
        "output": "\n=== Tasks"
    }
]